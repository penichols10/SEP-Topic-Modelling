Although debates concerning the reality or precise nature of emergence
are largely driven by contemporary scientific theorizing, the basic
notion has quite a long history stretching back at least to Aristotle
(384–322 BC). On Aristotle’s view, human beings, like
other “secondary” substances, arise from a distinctive
arrangement of the four material elements. While the mental powers of
human beings require and are necessitated by such an arrangement,
these powers are distinct from, and downwardly causally efficacious
with respect to, any non-mental powers. Furthermore, Aristotle’s
form/matter compound conception of material substances is consonant
with the standard emergentist stance between substance dualism and
reductionism. For detailed discussion, see Caston (1997). Among
Peripatetic philosophers, Alexander of Aphrodisias (late
2nd–early 3rd century AD; in On the Soul) and Galen
(129–c.200; in On the Elements According to Hippocrates
and elsewhere) develop distinctive versions of Aristotle’s basic
emergentist picture to apply to chemical compounds and other
non-living phenomena as well as living beings. (For discussion of
several texts, see again Caston 1997: 347–353.)
Aristotle’s philosophy of nature is re-appropriated in the
medieval era, first by Persian and Arabic philosophers such as
Avicenna/Ibn Sina (980–1037) and then, with the translation of
many of Aristotle’s key texts into Latin, by philosophers in the
West, including Thomas Aquinas (1225–1274). In the Latin West,
Aristotelian ideas, once introduced, become pervasive throughout the
era. In particular, Aristotle’s matter/form conception of
substance and his concomitant rejection of atomism become axiomatic
points of departure in theorizing about the nature of particular kinds
of bodies and the distinctive kinds of processes associated with them.
(On Aquinas, see Pasnau 2001 and Stump 2003, Part II; Pasnau 2011
examines in detail a wide range of views of substance in the
post-Aquinas scholastic period.)
The consensus around the Aristotelian philosophy of nature was
dismantled by the Scientific Revolution, with Aristotle’s
physics being the first casualty. René Descartes advances an
austerely mechanistic and reductionist conception of material bodies,
and this broad outlook becomes widespread. However, Descartes argues
that the human mind or soul is a non-material substance, and so
endorses a substantial form of mind-body dualism. For those also
accepting the reductionist conception of the physical world, the
alternatives to Descartes’ substance dualism are stark: idealism
(on which matter is a mere “phenomenon” to be analyzed in
terms of sensations, as advocated by George Berkeley) or reductionist
materialism, as exemplified by Julien de la Mettrie’s
L’homme Machine (Man the Machine, 1747).
This menu of options is rejected in the nineteenth century by the
so-called British Emergentists (with Lewes [1875] first using the term
“emergence” for the philosophical position). In “On
the Composition of Causes” (A System of Logic, 1843:
Ch. 6),
 John Stuart Mill (see entry)
 argues that the behavior of living beings involves a failure of
aggregativity or linearity of influence among their elements. He
proposes an account that distinguishes “homopathic” and
“heteropathic” laws and effects involving organized
phenomena, maintaining that the latter laws (governing emergent
phenomena) supplement without supplanting basic physical laws of more
general scope. 
Samuel Alexander (see entry)
 suggested that life was a “new quality” that emerges from
physico-chemical processes and brings with it “special laws of
behavior” and which must “be accepted with the
‘natural piety’ of the investigator. It admits no
explanation” (1920: vol.2, 46–47). Even so, he insists
that he is endorsing “a species of the identity doctrine”
(1920: 9), which suggests that he is seeking to articulate a more
intimate relationship between levels of the natural world, perhaps
very much akin to weak emergence accounts discussed in
 section 3
 below.
Finally, British Emergentism reaches its most developed form in
 C. D. Broad’s (see entry)
The Mind and Its Place in Nature (1925). Broad uses an
epistemological criterion for what he intends to be a metaphysical
condition of emergent autonomy: 
the characteristic properties of the whole R(A, B, C) [where R marks
their structural arrangement] cannot, even in theory, be deduced from
the most complete knowledge of the properties of A, B, and C in
isolation or in other wholes which are not of the form R(A, B, C).
(1925: 61) 
He adds that emergent features are “completely determined”
by such lower-level features, in that 
whenever you have a whole composed of these […] elements in
certain proportions and relations you have something with the
[compound’s] characteristic properties and […] nothing
has these properties except a whole composed in this way. (1925: 64)
Reminiscent of Mill, he distinguishes “intra-ordinal” from
emergent “trans-ordinal” laws (1925: 77–8) which,
although dealing solely with complex phenomena, are “unique and
ultimate” (1925: 64–5). As a consequence:
On the emergent theory we have to reconcile ourselves to much less
unity in the external world and a much less intimate connexion between
the various sciences. At best the external world and the various
sciences that deal with it will form a kind of hierarchy. (1925:
78)
The popularity of the emergentist vision waned beginning shortly after
Broad’s writing, with important scientific developments eroding
the boundaries between adjacent “levels” (most notably
quantum chemistry and molecular biochemistry—see McLaughlin 1992
for discussion). However, attention to emergence was substantially
reinvigorated starting in the 1970s with the discovery and creation of
non-linear complex systems of both natural and artifactual varieties.
There is now a large recent literature developing accounts of
emergence motivated by such systems. It has gradually broadened to
encompass mental phenomena that seem to resist physicalist treatment
(e.g., consciousness and free will) and some have even begun to
re-think received wisdom concerning the relationship of chemistry and
biology to lower-level sciences. These debates are of considerable
importance for our understanding of the natural world and of our own
place within it. As the bibliography attests, the questions at issue
here engage philosophers and scientists alike. This should be
unsurprisingly, for these questions are neither simply empirical nor
wholly a priori in character, but are rather such that
plausible (if not uncontroversial) answers require consideration of
and support for metaphysical interpretations of the structure of
natural reality in light of our best empirical theories.
Affirming that there are emergent phenomena that are both
dependent on and yet autonomous with respect to underlying physical
structures leaves a great deal open, however, as both of the
characteristics have been explicated in diverse ways (see Van Gulick
2001, Gillett 2002, Wilson 2015, and Humphreys 2016 for discussions
highlighting this diversity). Accounts of the dependence at issue may
appeal to relations of composition, supervenience, realization,
grounding, or causation. Accounts of the autonomy at issue may appeal
to fundamental or non-fundamental novelty of powers, properties,
forces, laws, or effects; irreducibility; non-aggregativity; or
non-linearity.
Though diverse, accounts of ontological emergence can be usefully
grouped by a basic division between those that are and are not
compatible with physicalism, understood as the thesis that
all natural phenomena are wholly constituted and completely
metaphysically determined by fundamental physical phenomena. This
thesis is standardly understood to entail “the causal closure of
the physical”, according to which (roughly) any
fundamental-level physical effect has a purely fundamental physical
cause. “Strong” emergence accounts are inconsistent with
physicalism and causal closure (as just elucidated) while weak
emergence accounts are consistent with it.
The general division into weak and strong varieties of ontological
emergence frames much of the discussion to follow:
This section considers the core features of dependence and autonomy in
turn, noting the variety of ways theorists of emergence have
elucidated them.
Emergents depend on micro-configurations. That the objects or
systems manifesting emergent features and patterns are exhaustively
composed by lower-level physical entities is assumed by almost all
theorists (but see
 section 4.3).
 But there are at least three different ways one might suppose the
features and patterns themselves to depend on the features and
patterns exhibited by those parts.
Accounts of emergence of both strong and weak varieties typically
suppose that emergents modally depend on their physical bases, such
that it is necessary that if an emergent occurs, some or other
physical basis occurs, and it is further necessary that if that basis
occurs the emergent occurs. The holding of both directions of
necessary correlation corresponds to what is called
“strong” supervenience (Kim 1984: 165):
A strongly supervenes on B just in case, necessarily, for
each x and each property F in A, if x has F, then there is a property
G in B such that x has G, and necessarily, if any y has G, it
has F.
Here A and B are families of properties (the supervening and
supervenience base properties, respectively).
Emergence may differ with respect to the strength of these two modal
correlations. Accounts of weak emergence typically specify the
necessity as metaphysical necessity (absolute or unconditional
necessity), indicating that emergent phenomena are (in a somewhat hazy
sense) “nothing over and above” their subvening base
phenomena. Accounts of strong emergence specify it as (merely)
nomological necessity (conditional on the holding of relevant laws of
nature), indicating a greater ontological distinctness between
emergent features and their bases. Indeed, it has sometimes been
suggested that the difference between strong and weak varieties of
emergence is best understood in terms of the distinction between
merely nomological and metaphysical supervenience (Chalmers 1996,
Noordhof 2010).
Philosophy of mind in the past half-century has been dominated by the
thesis that (many) mental concepts are functional concepts, specifying
mental states (or properties or events) in terms of the functional or
causal roles they play in response to incoming stimuli, in relation to
each other, and in generating goal-directed behavior (see, e.g.,
Putnam 1967, Fodor 1974, and Shoemaker 1984). Functionalists who are
also physicalists maintain that mental states are “functionally
realized”, in that their defining roles are implemented, on any
given occasion, by lower-level physical processes. As a schematic
example, the mental state of being a certain kind of physical pain is
a state caused by certain kinds of injury to one’s body, and
which causes certain kinds of behaviors in response (certain vocal
expressions, treating or getting help for the injury, etc.), and
(supposes the physicalist), this functional/causal role is always
played by some lower-level physical process. 
One account of (weak) emergent dependence is just this sort of
functional realization. A concomitant of such a functionalist approach
is that any token power (i.e., particular instance of it) associated
with a weak emergent feature will be identical to a token power of its
realizer (Wilson 1999, 2015). This will render emergence compatible
with the physicalist thesis of physical causal closure. However, if
properties have non-causal quiddities—primitively individuating
aspects that are the property equivalent of individual
haecceities—additional to their causal powers, then token
identity of powers will not necessarily guarantee that a functionally
realized emergent property is dependent on its lower-level base in a
way compatible with physicalism (Melnyk 2006). (It has become common
in recent metaphysics to invoke a primitive notion of
“grounding” relating the more fundamental to the less
fundamental, so the reader may be surprised not to see it listed as a
distinct option here. The reason is two-fold: it is not often used by
theorists of emergence, and it is a generalized notion that
encompasses the present, more specific notion of functional
realization. For discussion of the relative merits of deploying more
specific notions or a more general unifying notion in discussions of
forms of ontological dependence, see the exchange between Wilson 2014
and Schaffer 2016.)
Accounts of strong emergence commonly characterize dependence as
(merely) nomological or causal. Such external relations are consistent
with strong emergents being “over and above” the physical
entities upon which they depend in a straightforward way. It also
leads to a rejection of physical causal closure, often through the
posit of fundamentally novel “compositional” powers or
forces (as described by, but not endorsed in McLaughlin 1992). One
might take strong emergents to be diachronically caused by base-level
events (O’Connor & Wong 2005) or maintain that they are
synchronically nomologically dependent on their bases, with new
fundamental interactions, powers, or laws appearing solely at the
operative level of complexity (Broad 1925).
Discussion of stronger and weaker varieties of emergent dependence
inevitably hints at differences in the ways one might specify the
correlate thesis that emergents are to some extent autonomous from
their physical bases. The commonality to the genus of autonomy is
distinctness: emergents are not identical to their
bases—at least at the level of types, and perhaps also at the
level of tokens. What follows are three central ways of understanding
the source of such distinctness.
Emergent autonomy might be characterized in terms of a specific
elucidation of the idea of compositional or structural
“non-aggregativity”. Wimsatt (1994), an early proponent of
non-aggregativity as key to emergence, defines aggregativity in terms
of the “associativity, commutativity, inter-substitutivity,
linearity, and invariance under decomposition and reaggregation”
of a system’s parts (1994: 237), with varieties of
non-aggregativity simply being the failure of such conditions. More
direct and positive characterizations of non-aggregativity appeal to
distinctive, self-organizing group-level behaviors, such as ant
colonies and flocking birds, whereby “interaction among the
parts generates properties which none of the individual components
possess” (Mitchell 2012: 179). (Other developments of this
approach are found in Kauffman 1993 & 1995, Thompson & Varela
2001, Camazine et al. 2001, and Thompson 2007.)
A second way one might characterize the autonomy of emergent entities
is through realization by base properties that does not depend on any
specific realization. Physical realization secures a clear form of
dependence on base properties
 (section 2.1.2).
 But realized functional properties and processes are (or appear to
be) consistent with a variety of possible realizer properties (e.g.,
having a headache, even of a highly specific type, is consistent with
different precise neural states, and more general mental state types
may be realized more widely still, across biological species and
perhaps in alien or artificial minds). They are multiply realizable,
dependent on there being some physical property or process or other
within a range, without depending on any specific such
feature. There are other varieties of realization beyond the
functional that might be apt candidates for understanding particular
cases of emergent autonomy. For example, emergent properties might be
determinables which are determined by different lower-level
determinates (Macdonald & Macdonald 1986, 1995 and Yablo 1992);
types and/or tokens which are proper parts of lower-level types or
tokens (Clapp 2001 and Shoemaker 2000 [2001]); or having strictly
fewer degrees of freedom than do their bases (Wilson 2010). These
options, which need not be mutually exclusive, are discussed further
in
 section 3.2.
Multiple realizability, or something akin to it, is expressed in
contemporary physical sciences by the notions of universalizability
(where diverse systems behave in similar ways), stability under
perturbation, and eliminations in micro-physical degrees of freedom,
and many writers point to such phenomena as instances of emergence.
See Batterman (2000 and 2001) for detailed examination of the
scientific application of these notions.
Almost all accounts of emergence suppose that emergents are not just
distinct from, but also distinctively efficacious as compared to,
their bases. Weak emergentists typically deny that emergents have any
fundamentally new powers, on grounds that such new powers would be,
either directly or indirectly, powers to produce certain basic
physical effects, violating the causal closure of the fundamental
physical realm. They maintain, however, that distinctive efficacy does
not require having a new power. Distinctive efficacy might be
understood in terms of distinctive counterfactual patterns over time,
yoked to a counterfactual account of causation (LePore & Loewer
1987 and 1989); difference-making or “proportionality”
considerations in accounting for macroscopic as against microscopic
effects (Yablo 1992); or more generally through the proposal that
special science laws track comparatively abstract levels of causal
grain (Antony & Levine 1997, Wilson 2010).
Strong emergentists, by contrast, standardly take emergents to
introduce fundamentally novel causal powers—powers that their
lower-level physical bases do not have. These are often taken to be
powers of the high-level features themselves, and are directed
“downwardly” at the structures from which they emerge (as
well as “horizontally” in contributing to emergent
features of the system at subsequent times). But some propose that
high-level structural features induce novel powers in
component entities; others suggest that systemic
“transformations” occur in which parts either lose their
identity when caught up in emergent wholes or have their behavior
transformed in virtue of such embeddedness. Details concerning these
proposals are provided in
 section 4.2
 below.
Weak emergence affirms the reality of entities and features posited in
the special sciences, while also affirming physicalism, the thesis
that all natural phenomena are wholly constituted and completely
metaphysically determined by fundamental physical phenomena, entailing
that any fundamental-level physical effect has a purely fundamental
physical cause.
Special sciences describe non-ubiquitous, structured phenomena (e.g.,
plate tectonics, molecular interactions, cellular repair, and
organismic development) and successfully predict their behavior
through higher-level laws. Weak emergentists take the existence of
such stable and distinctive phenomena, amenable to high-level but not
low-level explanation, as reason to accept the taxonomic categories of
the special sciences into our ontology of the natural world, no less
real than the categories of a final, completed physics. On this view,
there are molecules, cells, organisms, and minded creatures,
and they do not reduce to—are not identical to—complex
combinations of basic physical entities or features. Correspondingly,
explanations adverting to special science laws are to some extent
autonomous from the explanations adverting to laws of lower-level
physical theories.
This section introduces two commonly pressed challenges to the
in-principle viability of weak emergence. The accounts of weak
emergence in the subsequent section are partly motivated as ways of
meeting one or both of the challenges.
The simplest challenge to weak emergence is from parsimony, and it can
be pressed from the side of reductionism or anti-realism (e.g., Heil
2003 and Ney 2010) or from the opposing side of strong emergentism
(e.g., O’Connor & Churchill 2010a,b). The weak emergentist
grants that the ontology and dynamical laws of a completed, true
physics metaphysically determine all fundamental physical facts,
and that the latter metaphysically determine all
non-fundamental facts or associated truths about the world. In that
case, why add to the ontology of the world? Why not parsimoniously
rest with the lower-level physical ontology, and offer a deflationary
account of truths that appear to refer to “higher-level”
phenomena? One might, e.g., construe the phenomena as coarse-grained
patterns running through the world of fundamental physical phenomena,
and regard truths invoking concepts such as cell,
metabolism, cat, and desire as referring
(perhaps schematically) to distinctive types of arrangements of
underlying physical entities and their qualities. This stance can
grant that in practice we cannot dispense with special scientific
claims. (The associated coarse-grained patterns are in some sense the
starting point of empirical inquiry for creatures like us, and even
were we to arrive at a true final physical theory, our cognitive
limitations would make it impossible for us to track the evolution of
the world in terms directly corresponding to such a fine-grained
reality.) But (says the critic) such broadly pragmatic considerations
should not guide our views concerning the world’s ontology;
blocking such deflationary moves requires a stronger form of autonomy
than physicalism allows.
Weak emergence accepts the following five premises:
Jaegwon Kim (in, e.g., his 1993 and 1998) argues that these premises
entail an unacceptable conclusion:
The present presentation of Kim’s argument follows Wilson 2015,
with some modifications (see also the discussion in Sturgeon 1998).
Emergent effects might be same-level, downward, or both
(Efficacy is neutral). Suppose, first, that emergent E
causes emergent E* (same level), while E superveniently
depends on P and E* superveniently depends on
P* (Supervenient Dependence). P* has a purely
lower-level physical cause (Physical Causal
Closure)—plausibly, P. If P causes P*,
and P* necessitates E*, then it is plausible that
P causes E*, by causing P*. So both P and
E cause E*, and given that P and E are
both real and distinct (Reality, Distinctness),
E* is causally overdetermined.
Second, suppose that E instead causes some lower-level base
feature P*. P* also has a purely lower-level cause
(Physical Causal Closure)—again, plausibly P. So
both P and E cause P*, and given that P
and E are both real and distinct (Reality,
Distinctness), P* is causally overdetermined.
Thus, whether we conceive emergent causation as same-level or
downward, the weak emergentist’s commitments entail
overdetermination (or as it is sometimes put, holding fixed
non-overdetermination, emergent causation is causally
excluded by the ubiquity of fundamental physical causes). Finding
such systematic overdetermination to be implausible, Kim concludes
that we should reject Distinctness and embrace
reductionism.
Rejecting other premises leads to alternative stances. Eliminativists
deny Realism, epiphenomenalists deny Efficacy, and
substance dualists and some strong emergentists deny Supervenient
Dependence. Strong emergentists commonly deny Physical Causal
Closure, maintaining that emergent features are non-redundant
causal contributors alongside lower-level physical factors to some
lower-level physical effects. Weak emergentists instead point to the
intimate relation they see between emergents and their bases in order
either to show a way to resist the argument’s overdetermination
conclusion or to make plausible that emergent and basal physical
causes are non-competing in a way that renders
overdetermination harmless.
In this section, three broad accounts of weak emergence are introduced
and proposed variations noted.
One weak emergentist approach locates the distinctness and distinctive
efficacy of emergents in feature or process types, while
maintaining that every token feature or process is identical with a
token fundamental physical entity. This view in a sense “splits
the difference” with the reductionist, and so is the most
minimalist of the weak emergent positions. One advantage of the view
is that it provides a basis for resisting Kim’s argument for
causal overdetermination. Causation is a token-token relation. If
token higher- and lower-level entities are identical, then there is
but one token cause of a given effect, which seems to dismantle the
challenge. At the same time, the type-distinctness of weakly emergent
and base features provides a basis for claiming distinctive efficacy
through “causal relevance” considerations. We may query
the cause of a token effect through the prism of distinct
effect types, and which type we select will determine which
cause type is relevant to its explanation.
Proponents of such accounts typically offer some specific account of
the relation at issue, aimed at rendering it plausible that the
features at issue might be type-but-not-token distinct. Cynthia and
Graham Macdonald (1986, 1995) suggest that higher-level features are
determinables of lower-level physical features and determinable types
are reducible to disjunctions of determinate types. Given this
combination of views, higher-level determinable features are
type-distinct from associated lower-level determinate features (since
a disjunctive type is not identical to any one disjunct type), but
every instance of a higher-level determinable feature is
token-identical with some lower-level determinate feature (since
instances of disjunctive types are token-identical with instances of
some or other disjunct type). Some critics object that higher-level
features are not appropriately modeled as determinables of lower-level
physical determinates (Ehring 1996), or that determinables cannot be
reductively analyzed in terms of determinates (Wilson 2012).
Robb (1997) and Ehring (1996) offer token identity accounts on which features of things
are “tropes” (particularized properties, such as the
alleged particular whiteness of a given sheet of paper) and properties
per se are sets or collections of tropes (see
 entry on tropes).
 We may suppose that every higher-level trope is identical with a
lower-level physical trope, notwithstanding that the one trope is a
member (or part) of different property-identifying sets of tropes, and
hence of different types. Here again, the suggestion is that such a
view avoids overdetermination while preserving a role for the
distinctive efficacy/causal relevance of higher-level features.
Perhaps the most common approach to weak emergence is one appealing to
one or other account of “realization”. (Recall the point
made in
 section 2.1.2
 that realization falls under the more general concept of grounding
that is deployed more frequently in some other contexts.) The first
accounts of realization were in functionalist terms, according to
which a realized feature is characterized by a distinctive causal or
functional role, which role is implemented, on any given occasion, by
some or other lower-level physical feature. Hence, Putnam (1967)
suggests that, just as a software program might be implemented on
multiple hardware platforms, so mental states might be associated with
causal-functional roles which are played by multiple neurological, and
ultimately fundamental physical, states. Such an approach accommodates
the ontological autonomy of weak emergents to the extent that a
functionally associated type is not identified with any one of its
realizer types. It would also appear to provide a basis for blocking
concerns about causal overdetermination by analogy again to software
programs, whose powers are inherited from their lower-level
realizers. Given such an inheritance thesis for higher-level powers,
even if there is a sense in which both realized and realizing features
can cause a given effect, only one power is exercised, not
two—in which case, it is maintained, the overdetermination is
benign. (This functionalist perspective on special science entities
and features was influentially developed by Fodor 1974.)
Other approaches to realization appeal to other specific relations. As
noted above, one might endorse an account of weak emergence in terms
of determination through the assumption that instances of
determinables are token-identical to instances of their realizing
determinates. But one might adopt this general approach while
rejecting the assumption of token identity, either on grounds that
determinable tokens as well as types have less specific essences than
associated determinate tokens and types (Yablo 1992) or on grounds
that determinable tokens as well as types are associated with fewer
powers than associated determinate tokens and types (Wilson 1999,
2015). Yet another approach to realization is based in the part-whole
relation, with higher-level types and tokens taken to be proper parts
of lower-level types/tokens (Shoemaker 2000 [2001], Clapp 2001).
Common to these particular strategies is the idea that token and type
powers of a realized feature are a (non-empty) proper subset of the
token or type powers of the lower-level physical feature upon which it
depends (Wilson 1999, 2015). Causal autonomy can result from a
higher-level feature’s having fewer, not more, powers than the
feature upon which it depends because the latter encodes distinctive
difference-making (e.g., if one’s neurological state had been
slightly different, one would still have been thirsty and still have
reached for the glass).
Finally, it has recently been proposed that a distinctive form of
physical realization comes through implementing mechanisms:
enduring structures of organized components that realize higher-level
role functions, endowing higher level entities with novel,
non-aggregative behaviors and properties (see Machamer et al. 2000,
Craver 2007, and
 entry on mechanisms in science).
 Craver (2007) argues that in neuroscience and psychology in
particular, we should think of minded biological agents as constituted
by a hierarchy of mechanisms (or networks of such mechanisms). While
he avoids use of the term “emergence”, which he associates
with strong emergence (2007: 16), he is plausibly taken to advance a
distinctive form of weak emergence. He defends the reality of such
high-level, fully-realized powers on the grounds that they satisfy the
conditions for causal relevance on the (manipulationist) account of
causal explanation that he favors (2007: 216–220). Haug (2010)
develops a mechanistic account of realization incorporating a
distinction between what he calls “constitutive” and
“integrative” mechanisms, associated with two distinct
roles mechanisms play in the realization of special science
properties. He argues that his mechanistic account contrasts favorably
with determinable/determinate approaches (and more generally,
“proper subset of powers” approaches) to realization, and
that it provides a principled basis for claims of multiple
realizability. (Gillett 2016 also emphasizes realizing mechanisms
associated with novel powers in his account of emergence. But as he
rejects physical causal closure, his account will be discussed under
the rubric of strong emergence in
 section 4.)
The appeal to unpredictability or other epistemic criteria plays a
significant role in accounts of weak emergence (going all the way back
to Broad’s [1925] highly influential discussion), even though
the intended contrast with “reductionism” is ontological.
It is near the surface in the non-aggregativity account of emergent
autonomy summarized in
 section 2.2.1
 above, in which the non-linearity of macro-system dynamics (resulting
in practical unpredictability) is taken to be a hallmark of (weak)
emergence. Bedau (1997, 2010) proposes that we build this distinctive
discovery of modern complex systems research into our theoretical
elucidation of emergence. Specifically, a feature of or process within
a macro-system is weakly emergent just in case it is derivable from
the prior micro-facts leading up to it, but only in an informationally
incompressible way: describing its macro-state at prior times by
aggregating all of its underlying micro-states at those times and
iterating their micro-dynamics. When a system’s macro-evolution
is explanatorily incompressible in this way, it is not dynamically
characterizable in fundamental physical terms: its distinctive
evolutionary patterns are not foreshadowed in any way in the
micro-evolutionary patterns.
It is possible to see special cases, giving rise to distinct species
of weak emergence, within the broad framework of non-linear dynamics.
Rueger (2000) and McGivern and Rueger (2010) suggest that a form of
diachronic (or evolutionary) emergence occurs when there is a sharp
change in the behavior of a single system—behavior which is
“qualitatively novel” with respect to its earlier
behavior—as a result of a comparatively small perturbation in
one of its underlying control parameters. There are well-documented
cases of such transitional changes in a system’s behavior.
Strong emergentists maintain that at least some higher-level
phenomena exhibit a weaker dependence/stronger autonomy than weak
emergence permits. This often takes the form of rejecting physical
realization, affirming fundamental higher-level causal
powers, or both.
Perhaps the most commonly cited phenomena offered as requiring strong
emergentist treatment have to do with the nature and capacities of the
conscious mind in relation to its neural substrate. Other non-mental,
scientific phenomena also have been advanced as possibly or plausibly
requiring treatment in strong emergentist terms. Such claims are
canvassed in
 section 5.
This section introduces three commonly pressed challenges to the
in-principle viability of strong emergence. Possible replies are noted
in connection with certain accounts of strong emergence introduced in
the subsequent section.
An initial worry about strong emergence is that there is a tension in
the very idea of a feature that is both dependent and
fundamental—a worry exacerbated by recent accounts of
fundamentality according to which what it is to be fundamental is
precisely to be independent (see Bennett 2017 and
 entry on fundamentality).
This worry might be resolved by distinguishing two senses of
“fundamental”: first, a sense applying to an ingredient of
physical reality that is ubiquitous (or “basic” in a
building-block sense), and so not even dependent on any arrangements
of other entities; and second, a sense applying to an ingredient of
reality that is not (entirely) constituted by or otherwise internally
(as opposed to external-causally) related to the structured
arrangement of some other same-category entities. We might then use
the term “basic” for the first sense and reserve
“fundamental” for the second sense, which aligns the
latter term with the way it is used in contemporary discussions of
“grounding” or metaphysical dependence in metaphysics. So
understood, there is no tension in the notion of an entity or feature
that is fundamental but non-basic (O’Connor 2018).
Granting that there is no incoherence in the idea of a non-basic,
fundamental entity or feature, one might be concerned that such an
entity or feature would introduce an inexplicable (since fundamental)
addition to reality at an arbitrary juncture. Avoiding such
inexplicability might give reason to prefer a panpsychist
accommodation of the irreducibility of consciousness to physical
properties, as it (unlike strong emergence) posits proto-conscious
qualitative character into the basic structure of the world
(Nagel 1979 and Strawson 2006).
A second initial worry with strong emergence is that it is
inconsistent with a “naturalist” point of view, insofar as
(on most accounts) strongly emergent properties are associated with
fundamentally novel powers or laws that apparently would interfere
with more basic physical laws or processes. However, basic dynamical
laws in contemporary physics have an open-ended character
(Schrödinger’s equation, Hamiltonians or Lagrangians more
generally), taking forces or energies as input. The notion of a
strongly emergent force or energy is no more problematic than that of
the standard physical forces or energies that physicists take to be
input into the operative laws (McLaughlin 1992).
The real problem here, if there is one, is not inconsistency with
physics, but rather that there is at present a lack of clear empirical
evidence for strong emergence. If there were strongly emergent causal
powers, forces, or laws, we might expect to see, in candidate
emergentist contexts, evidence for a hitherto unrecognized
configurational interaction, much as occurred with the weak nuclear
interaction. But, McLaughlin avers, “there is not a scintilla of
evidence” in support of there being such fundamental novelty
(1992: 91). For strong emergentist replies to this contention, see
 section 4.2.2
 and
 section 5.
A final challenge to the viability of strong emergence is that such
accounts are vacuous, in that any purportedly fundamentally novel
power possessed by an emergent is, on any of a number of plausible
accounts of powers, “already” possessed by its lower-level
base goings-on.
On one version of this “collapse” objection, certain ways
of individuating lower-level physical features entail that such
features will have dispositions to produce any purportedly strongly
emergent features, undermining the supposed metaphysical novelty of
the emergent features in favor of an enriched understanding of the
base features (O’Connor 1994: 98–9 and 2000: Ch.6,
introduces this objection; see Howell 2009 and Taylor 2015 for
development). On another version of the objection, certain ways of
assigning powers to features entail that lower-level physical features
will inherit any powers had by purportedly strongly emergent features
(Kim 1998). For strong emergentist replies to the
“collapse” challenge, see
 section 4.2.2.
I now discuss a representative range of contemporary accounts of this
form of emergence.
A metaphysically minimalist characterization of strong emergence is
supervenience-based. In contrast to weakly emergent or physically
reducible features, which are taken to supervene with metaphysical
necessity on their physical dependence base, strongly emergent
features are taken to supervene with merely nomological necessity (van
Cleve 1990, Chalmers 2006, Noordhof 2010).
This approach assumes that the conceptual distinction between
nomological and metaphysical necessity corresponds to a substantial
one, such that fundamental causal laws are metaphysically contingent
and what supervenes of metaphysical necessity on the fundamental
physical domain is necessarily physical. Both these assumptions have
been challenged. Moral anti-naturalists such as G.E. Moore maintain
that fundamental moral features supervene of metaphysical necessity on
natural features, and on neo-Aristotelian essentialist ontologies,
strongly emergent features, were they to exist, would supervene with
metaphysical necessity on physical features. See, however, Howell
(2009) and Noordhof (2010) for strategies aimed at defending
supervenience-based approaches to strong emergence.
One variant of this approach is epiphenomenalist (Jackson 1982, Kim
2005, and Chalmers 1996 all express sympathy for this view). It
presumes that the most plausible candidates for strong emergence are
the qualitative features of conscious experience—e.g., the way
that the redness of a rose looks to a particular subject on a given
occasion. On this approach, such “qualia” (qualitative
features) are caused or otherwise nomologically necessitated by the
neural processes underlying human experience, but they are themselves
incapable of producing any effects, including on any mental states
generated by the purely physical aspect of the perceptual process.
Epiphenomenal strongly emergent features are consistent with
physical causal closure. For this reason, the account is less
vulnerable than standard accounts to the objection that it entails
presently unsupported empirical predictions about brain processes. (It
is still incompatible with physicalism, since strongly emergent qualia
are not physically realized, and so are wholly additional to token
lower-level physical phenomena.) A special challenge for the view is
that qualia would seem (paradoxically) explanatorily irrelevant to a
subject’s beliefs concerning their existence (see Chalmers 1996:
Ch.5, for possible responses).
On a second formalist explication, strongly emergent phenomena are
those which are both fundamental and dependent, and where the notions
of fundamentality (whose converse is the “grounded”) and
dependence are each taken to be primitive (Barnes 2012). Such a
primitivist account clearly blocks ontological reduction: if some
goings-on are fundamentally novel vis-à-vis the goings-on upon
which they depend, then the former are clearly not identical to the
latter. A potential advantage of the approach is that it might capture
the common denominator to all other, more distinctive accounts of
strong emergence. A corresponding shortcoming is that its high level
of abstraction leaves it without the resources of more specific
accounts for addressing the general challenges facing strong emergence
noted above (Paolini Paoletti 2018 and Pearson 2018).
Another account of strongly emergent autonomy posits fundamentally new
powers, forces, or laws directly associated with the emergent property
of a complex object or system (O’Connor 1994, Silberstein &
McGeever 1999, Wilson 2002, and O’Connor & Wong 2005).
“Fundamental” here signifies that the power is not the
resultant of any generalized kind of summation on the powers of the
object’s constituents relative to the relational structure in
which they are embedded. One variation on this basic account concerns
the way emergents depend on their bases. One common variant
holds that emergent features are synchronically nomologically
necessitated by the base-level structure, where the necessitation,
while law-governed, is not via causal production (Broad 1925,
Silberstein & McGeever 1999, and Wilson 1999 and 2002). An
alternative (naturally suited to a neo-Aristotelian causal powers
metaphysics) maintains that emergent features are diachronically
caused by a plurality of micro-properties acting jointly (perhaps
together with other emergent features), under the triggering condition
of the micro-properties’ being appropriately structurally
organized (O’Connor & Wong 2005). This alternative can allow
that, even granting that causal necessity is a species of metaphysical
necessity, the supervenience of strongly emergent features on base
phenomena will fail in (at least possible) scenarios in which the
causal dependence between either base and emergent features or
emergent features and their effects is non-deterministic. That said,
whether supervenience does in fact fail for any actual cases of strong
emergence is an empirical question (on which, see
 section 5.2).
The fundamental powers account of strong emergence is consistent with
a range of replies to the challenges noted in
 section 4.1.
 The first challenge asserts that strongly emergent features are
“inexplicable”, insofar as they appear only in certain
organized structures and could not be predicted in principle through
the laws of basic physics applied to emergent-antecedent conditions.
One reply is simply to observe that in the history of physics itself
there is precedent for adding new fundamental laws to explain what
previously recognized laws could not (e.g., electromagnetism and the
weak nuclear force—see Wilson 2002). When determining the
fundamenta of the natural world, we must go where the evidence leads.
An alternative reply in line with the second variant of the previous
paragraph denies the charge of inexplicability by supposing that
emergent features are the product of micro-structural dispositions
that, unlike those which are more or less continuously manifested,
have structural triggering conditions. A Laplacian observer of the
unfolding universe prior to the initial onset of such emergent
features would have no inkling of there being such latent dispositions
towards collective emergent effects. But they are as fundamental as
the more generally manifested dispositions associated with such
properties as mass and charge (O’Connor & Wong 2005). And it
might be contended that while it is rational to presume that the
natural world is a causally unified totality, we cannot
presume that it is causally uniform (O’Connor 2000:
Ch.6).
The collapse challenge asserts that any purportedly strongly emergent
powers would “collapse” into—that is, end up being
associated with—their dependence bases. One might seek to block
collapse by distinguishing between collective dispositions for
producing certain powers and the powers themselves, or between direct
and indirect having of powers; or by characterizing emergent powers as
relative to specified sets of fundamental interactions (see
O’Connor 1994: 98–99, and 2000, Ch.6, Wilson 2002, and
Baysan & Wilson 2017). Two other reasons for resisting attempts to
interpret (possible) discontinuous microphysical behavior in terms of
micro-physical powers alone are epistemological. One might contend
that we should seek to provide as unified an explanation as possible
of such phenomena, and that an explanation in micro-physical terms
alone would be highly complex and disunified compared to one that
posits a family of emergent macroscopic determinables fitted to
structures of organized complexity. Second, we can describe certain
possible situations involving causal indeterminism that would be
readily understandable in strong emergentist terms, whereas the only
microphysical explanation possible would require an objectionable
action at a temporal distance. (See O’Connor & Wong 2005 for
development of these replies.)
Finally, possible responses to the final, evidential challenge to
strong emergence are best considered in
 section 5,
 where a range of candidate emergent phenomena are introduced.
Notwithstanding the replies just above to the collapse challenge, a
recent trend in theorizing about strong emergence has been to embrace
collapse, arguing that emergence is better understood as the
introduction of novel powers had by components when embedded
in configured wholes. This section introduces four ways this account
has been developed.
In a series of articles culminating in a 2016 book, Carl Gillett
advances a distinctive account of strong emergence rooted in a
hierarchy-of-mechanism picture of complex systems that, he maintains,
is strongly supported by a range of sciences. Gillett invokes
considerable conceptual machinery in developing his view; making
substitutions in linked definitions, we arrive at the following
compact statement:
A property is strongly emergent just in case it is a
property of a composed individual that is realized and that (in
addition to having same-level effects) non-productively determines the
individual’s parts to have powers that they would not have given
only the laws/principles of composition manifested in simpler
collectives.
There are two distinctive features of Gillett’s account. As
noted, the account ascribes fundamentally novel properties not to the
bearer of the emergent property, but to the bearer’s components.
Second, a realized structural property of the whole is nonetheless
said to be the emergent property in virtue of its
“nonproductively determining” the components’ coming
to have those novel powers. It is tempting to think of this last as
also ascribing a novel (albeit non-productive) power to the emergent
property, although Gillett does not describe it in these terms. Note
that Gillett’s account does not squarely fit the strong
emergence classification given in this entry, insofar as he takes
strongly emergent properties to be “realized by”
lower-level properties, when standing in a complex relation;
nonetheless, the account properly belongs to the present strong
emergent classification to the extent that it is inconsistent with the
causal closure of the microphysical realm.
As regards the general charge that strong emergence is inexplicable,
Gillett maintains that this account provides an intelligible,
scientifically informed basis for making sense of strong emergence. As
regards the charge of there being no evidence of strong emergence,
Gillett suggests that while its reality has not been established
empirically, it is seriously proposed by a number of contemporary
theorists of complex systems (see
 section 5.2
 and
 section 5.3
 below).
David Yates (2016, forthcoming) has proposed an account with some
similarities to Gillett’s. He discusses the way that the bent
geometry of a water molecule determines its dipole moment, which
latter feature confers a range of causal powers on the molecule, such
as its disposition to align in an electric field and its being liquid
at room temperature (2016: 822–225). He argues that this
geometrical property, while fully realized by the spatial relations
between the molecule’s atoms, confers a new conditional
power on the molecule that in tandem with the causal powers inherited
from the molecule’s basic constituents enables the molecule to
produce its characteristic effects. Key to Yates’s proposal is
the suggestion that higher-level features may be
“qualitatively”, as opposed to functionally, realized:
while a functionally realized property is characterized in terms of
derivative causal powers, qualitatively realized properties are
non-causally (e.g., spatiotemporally) characterized, making room for
them to be causally fundamental. As he puts it:
[Q]ualitatively realized properties are defined by non-causal
specifications, and their realization is not a matter of bestowing the
right causal powers. Properties such as molecular geometry are
causally fundamental […] because their bearers have certain
causal powers in virtue of meeting their defining specifications, but
not in virtue of the realizer properties in virtue of which
they meet those specifications on a given occasion. (2016: 812)
Yates contends that these examples demonstrate the reality of
his distinctive variety of strong emergence. A skeptic might press
that the effects Yates cites as pointing to a distinctive kind of
higher-level causal power are themselves all higher-level. Assuming
that all macroscopic properties are microphysically realized, if one
were able to take a wide-angle view of the evolving process in purely
micro-physical terms throughout (including in characterizing the
targeted token effects), it’s not clear that reference to
anything other than the features of and basic relations among
microphysical entities is required for explanation. It might well be
the case that to explain the token effects under their
macroscopic description requires equally macroscopic appeal
to molecular geometry (where a given geometric shape is multiple
realizable by distinct spatial arrays of atoms). But such explanatory
irreducibility is, as we’ve seen, the hallmark of forms of weak
emergence.
Jonardon Ganeri (2011) also advances an account with affinities to
Gillett’s. On this account, in virtue of entering into certain
configurations, elements are “transformed” in that they
acquire new causal powers. He does not speak of “noncausal
downward determination” from a configurational state to the
component powers, though the view seems materially equivalent to
Gillett’s in this regard. The account differs, however, in
maintaining that in the evolving dynamic that follows the appearance
of such new powers, there come to be emergent macro-states that
together with the transformed micro-entities determine subsequent
micro- and macro-states. The resulting account is thus a hybrid of
Gillett’s view and the more familiar novel causal power of the
whole view we saw in the previous section.
Sydney Shoemaker (2002, 2007), while agreeing with Gillett and Ganeri
that emergence occurs within special kinds of organized objects or
systems and features novel component powers, dispenses with any
downward determination relation, causal or otherwise. But these powers
are novel in a qualified way:
The component entities have powers that, collectively, determine the
instantiation of the emergent property when they are combined in an
emergence-engendering way. But these being cases of emergence, these
cannot all be powers that manifest themselves when the components are
not combined in emergence-engendering ways. Some of them must be
“latent” powers. Or, since these powers do not remain
latent when their possessors are combined in emergence-engendering
ways, let us speak of them as “micro-latent” powers. We
can contrast these with the “micro-manifest” powers which
these same entities manifest when they are not combined with other
entities at all, or are configured in ways that are not
emergence-engendering. (Shoemaker 2007: 73)
The thesis that newly manifest powers are “latent” will
appeal to those who both take causal power to be a primitive feature
of fundamental reality and see it as fundamental to all explanatory
linkages between earlier and later stages in the evolution of things.
(We saw in the previous section that O’Connor 1994 and
O’Connor & Wong 2005, who share these commitments, postulate
that emergent and fundamental macro-states are “upwardly”
determined by micro-structural states manifesting latent dispositions
of fundamental individuals to jointly cause such states when so
configured.)
Finally, several recent authors have proposed “transformational
emergence” accounts that severs the idea of a privileged class
of hierarchically-organized wholes from the concept altogether. They
advance an ontological framework in which basic and structured
individuals undergo fundamental change, acquiring new powers that are
not “latent” (in the sense of there being an antecedent,
ontologically-grounded disposition for their subsequent appearance)
and perhaps losing others. With the advent of new powers, there are
new laws describing their evolution.
Santos (2015a,b) promotes such a view under the banner of
“relational ontology”. The dynamic itself is constantly
evolving, as elements are transformed through interactions with other
elements. 
[W]hole is just a word that names the relational totality of
the individual relata and their relations, [which are] the
only real causal agents…. (2015a: 28) 
Santos suggests that such a view of things is indicated by modern
cellular and developmental biology, but the theoretical descriptions
he cites (e.g., 2015a: 30–32; 2015b: 439–440) appear to be
consistent with the other metaphysical frameworks described in the
previous two sections. The issue of whether enduring
structured entities are essential or inessential to the broad
frameworks embraced by the special sciences is a large issue that
cannot be discussed here.
Humphreys (2016), while not committing to the ubiquity of
“transformational emergence”, takes the account a step
further away from those emphasizing structured wholes by making
interactions inessential: 
Transformational emergence occurs when an individual a that is
considered to be a fundamental element of a domain D transforms
into a different kind of individual a*, often but not always as
a result of interactions with other elements of D…They
possess at least one novel property and are subject to different
laws…. (2016: 60) 
As an intuitive (though perhaps not realistic) example, he notes that
people undergo significant temporary psychological change when they
are caught up in the interactions constituting a mob. His central
realistic example comes from the Standard Model of particle physics,
which describes partless muons as very quickly “decaying”
into electrons, electron neutrinos, and muon neutrinos (2016:
66–67). Here there is fundamental change apart from any
triggering interactions, and not merely a change within individuals
but change of individuals from one kind to others. Humphreys
further notes that his earlier “fusion” account of
emergence (1997) is a special case of transformation. When fusion
occurs, basal entities or certain of their properties are lost when
they fuse with others in producing a unified whole (2016: 74–5).
(For accounts similar to Humphrey’s, see Guay & Sartenaer
2016 and Sartenaer 2018.)
Transformational accounts clearly stretch the classical concept (which
informs the taxonomy of the present article). The common thread is
simply that of fundamental but lawlike change in the observable
patterns in physical reality through time. For purposes of assessing
how competing accounts fare in characterizing the range of empirical
phenomena uncovered in the sciences, it may be necessary for greater
terminological regimentation to emerge.
Emergentists of all varieties standardly are physical substance
monists about the natural world: all worldly (natural or artifactual)
entities are composed or otherwise “made of” entities that
would be described in a completed fundamental physics, whether
physical particles, fields, strings, or something else. This view is
common enough among emergentists that some influential theorists took
it to be a defining element of the doctrine. One might maintain,
consistent with substance monism, that wholes exhibiting strongly
emergent, efficacious properties are fundamental, albeit composite
objects or systems, on the grounds that quantification over
them is required for a minimally adequate account of the world’s
dynamics. This might also give rise to an objective basis for identity
through time, even for organisms undergoing constant change of parts
(see O’Connor & Jacobs 2003).
But one can argue that strong emergentism, at least with respect to
some or all mental states, in fact requires a form of substance
dualism. On a biological view of emergent thinkers, the micro-physical
boundaries of such thinkers may inevitably be vague, for empirical
reasons. But it is perhaps doubtful that fundamental causal
laws associated with strongly emergent properties would reference
vague conditions. The sole apparent alternative is that the properties
are instantiated in a distinct, non-vague object instead, as a
non-physical mind would be. (See Zimmerman 2010 and Hasker 2016 and,
for a reply, O’Connor 2016.)
One might also argue for an emergentist form of substance dualism as
necessary to account for (what many strong emergentists regarding
consciousness accept) there being unified subjects of conscious
experience (Nida-Rümelin 2007) or it being an objective matter
whether a conscious subject does or does not survive certain kinds of
radical change (Swinburne 2013). Finally, many general accounts of the
categories of substance/object or physical substance/object in
particular entail that if an object has non-physical properties, it
will fail to count as a composed or physical substance (Francescotti
2001, Schneider 2012, and O’Connor 2018.)
Supposing that strong emergence does bring a new substance in its
wake, the spirit if not the letter of the usual emergentist commitment
to substance monism is maintained by the weaker constraint that no
“higher-level” substances or subjects “float
free”, actually or modally, from their dependence bases. It is
for just this reason that both Lowe (2008) and Nida-Rümelin
(2007) characterize their substance dualism as
“non-Cartesian”.
Certain phenomena and theoretical considerations motivating some
contemporary theorists to endorse a strong emergentist construal of
those phenomena. (It bears emphasis that strong emergentists typically
also suppose that some interesting organized behavior is more
plausibly understood either reductively or as weakly emergent: their
strong emergentism is piecemeal.) This final section summarizes those
phenomena and considers in general terms the different ways strong and
weak emergentists might go about treating them.
The conscious mind in its different aspects has long seemed to many to
resist plausible ontological characterization in any physical terms,
whether reductive or non-reductive (i.e., weak emergentist). (For a
fairly comprehensive overview, see Chalmers 1996.)
Consider, for a start, our apparently direct awareness of our
own conscious experiential states. (Conscious cognitive states such as
beliefs and desires have complicating aspects that cannot be explored
here. But see
 section 5.1.2
 immediately below for a possible linkage between the two germane to
strong emergentist conjecture.) The natural physicalist strategy for
characterizing such awareness would be in terms of a distinctive form
of informational flow among distinct physical states (the experiential
state itself and a distinct state of awareness of the experience); yet
any such account would seem consistent with the possibility
of a nonstandard causal source of the state of awareness of the
conscious state, such that the subject is utterly mistaken about its
object, the subject’s current conscious state. Such strong
fallibilism about the contents of consciousness seems implausible, as
is shown by the fact that philosophers such as Descartes who entertain
radical skeptical doubts about much of human knowledge do not
typically extend it to our grasp of our current conscious experience.
Is it, for example, conceivable that I am only seemingly (but
mistakenly) aware of undergoing excruciating pain as of being laid out
on the torturer’s rack, while in fact I am in a serene conscious
state as of lying on a warm sandy beach? It seems not, but it is hard
to account for this datum in physicalist terms.
Also puzzling for physicalism is the unity of conscious
experience: the fact that our experiences engaging distinct sensory
modalities and our conscious thoughts, moods, and feelings come
together as aspects of one overall conscious state of a single
conscious subject. On a plausible physicalist account, each of these
aspects will be realized in distinct, physically-separated neural
networks, but as yet there is no worked-out physicalist strategy for
capturing the unity of these aspects in experience.
In recent decades, highly general functional characterizations of
conscious awareness have been proposed, notably: higher-order
theories, on which a state is conscious just in case it stands in the
right kind of relationship to a higher-order state that represents it
(Carruthers 2000; Rosenthal 2005;
 entry on higher-order theories of consciousness);
 global workspace theories, on which a state is conscious just in case
its content is globally accessible to multiple cognitive subsystems
(Baars 1997, Dehaene et al. 2006); and integrated information theory
(Tononi & Koch 2015), on which a system is conscious just in case
it carries more information than the sum of its parts (and is more
conscious the greater the amount of such “integrated”
information). Anti-physicalists have argued that the first of these
theories implicitly denies or fails to adequately capture the two
features of direct awareness and unity; the second and third are
highly suggestive frameworks for theorizing about dynamical aspects of
consciousness, but insofar as they are developed in purely neural
terms, they seem to provide only a weaker surrogate for what we
introspectively grasp concerning the unity of consciousness, and
don’t speak clearly to the direct awareness relation.
That said, it is worth noting that these features, while present in
standard conscious experience, are arguably absent or diminished in
unusual clinical cases, and in particular in “split-brain”
patients. (See Bayne 2008 and Schechter 2018 for philosophical
exploration of clinical accounts regarding the reports of split-brain
patients.) This suggests a physicalist strategy of using these unusual
phenomena as a tool for chipping away at the ostensible
phenomenological basis for rejecting the possibility of an eventual
physicalist account of consciousness. (See
 entry on the unity of consciousness,
 Sect. 4 for a survey of such disorders of unified consciousness and
discussions of their possible implications.) An alternative, perhaps
complementary physicalist strategy is to argue that certain seeming
aspects of consciousness are simply illusions which can be
explained in terms of inevitable organizational tradeoffs in the
construction of finite minds (see Pereboom 2011 and Chalmers
2018).
Even more than the nature and unity of conscious awareness, certain
seeming intrinsic characteristics—so-called
“qualia”—of conscious states have seemed to many to
require an anti-physicalist ontological account. The way a patch of
redness appears in one’s visual field, or the sound of a trumpet
note in one’s auditory field, do not seem to admit of
characterization in terms of neural processes within the visual and
auditory cortex. Rather, such experiential qualities seem to be
distinctive in kind, engendering a mismatch with the
physical-structural or functional kinds posited by physical theories,
and to have a degree of simplicity that is incongruent with the
massive physical complexity of the associated physical processes. (For
two much-discussed arguments from these apparent characteristics of
conscious experience to at least a modest form of physical-mental
dualism, see Jackson 1982 and
 entry on qualia and the knowledge argument;
 and Chalmers 1996 and
 entry on zombies.)
Some accept this claim regarding these “phenomenal”
qualities of conscious experience, but think that there is no
corresponding deep challenge to physicalism with regards to the
intentional properties of experiences, representing what the
world around us is like (again, Jackson 1982 and Chalmers 1996). (This
limited anti-physicalism most lends itself to—although it does
not entail—the epiphenomenalist version of strong emergence
discussed in
 4.2.1
 above, as it is consistent with the claim that information-processing
intentional states are the only mental states that causally contribute
to the individual’s future mental and physical states.) However,
one may question the independence of phenomenal and intentional
properties (see, e.g., Horgan & Tienson 2002), and some go so far
as to conjecture that intentional properties are in some way
constituted by phenomenal properties (Mendelovici 2018, Woodward
2019). If some such connection thesis is correct, then not only
experiences, but other cognitive states such as belief and desire may
resist purely physical characterization (see
 entry on phenomenal intentionality).
Human and other animals are not only experiencers and knowers but also
doers. (The nature of non-human animal choice or volition and their
concomitant experience of action is here set aside, as it is difficult
to conjecture concerning it with any confidence on present knowledge.)
Many take Aristotle to have expressed a truism when he said that the
choice of how to act is “up to us”, unlike the inevitable
unfolding of causal processes lacking in rationality or other sources
of deliberative choice. It is widely claimed that the human experience
of conscious, deliberate choice (“willing”) is of direct,
“top down” control over one’s action by the agent
(see, e.g., O’Connor 2000: Ch.1&4; for an overview of
discussions regarding agential experience, see Bayne 2017 and Woodward
forthcoming). At least sometimes, we seem to ourselves not to be
merely loci in which a host of psychological and merely physical
influences converge and resolve themselves in behavior, but rather to
exercise a power to decide which among the options we are considering
we shall take, thereby determining whether and how these influences
will be acted upon.
Such agential experience, if veridical, might indicate that the
ability to freely choose is strongly emergent. On one account, free
choice manifests a distinctive power that, unlike typical powers, is
neither causally “triggered” by a stimulus condition nor
is made more or less probable by antecedent factors (Lowe 2008, 2013).
Alternatively, the kind of power agential experience represents is
consistent with non-determining causal influences that collectively
confer objective probabilities on possible choices (O’Connor
2008). On either understanding, conscious control over one’s own
actions through exercising the power of choice is at odds with a
physicalist conception on which all systemic behavior is fixed by the
arrangement and activity of the system’s parts. Coupled with the
plausible position that mental states of whatever variety depend on
lower-level physical states, such a result might be seen as providing
support for taking free will to be a strongly emergent power.
Agential experience is defeasible, and cognitive and social psychology
and more recently neuroscience have been probing the determinants of
choice and its relationship to conscious awareness. One particular
form of study has been taken by many to undermine the veridicality of
the experience of conscious control over arbitrary choice. Libet 1999
and more sophisticated successor studies aim to compare the
self-reported time of occurrence of conscious choice with the time of
occurrence of certain brain activity (a steadily increasing
“readiness potential”) that Libet took to be associated
with the production of the subsequent action. He interpreted the
results as indicating that the behavior was unconsciously initiated by
that brain activity just prior to the time of the
subject’s awareness of having so chosen, and hence that the
agent’s sense that she consciously initiated the action is
illusory.
Philosophers have roundly criticized the “no free will”
interpretation of these studies offered by Libet and some other
neuroscientists (see Mele 2009 for a thorough discussion and Caruso 2012: 189ff, for a dissent from the
consensus). Many have emphasized that the “choices”
Libet’s subjects are asked to make depart from paradigmatically
free cases in important ways. Some note that the ability of subjects
to precisely time their own conscious events of any kind (including
simple perceptual cues) have been shown to be not fully reliable:
their estimates can be manipulated by conscious primes before and
after the target event. (They also come in degrees of intensity, such
that the onset of an event that might quickly intensify or otherwise
evolve might be more difficult to determine than the event itself.)
Others observe that the studies do not even purport to identify a
determining physical antecedent to conscious choice. Finally,
other recent studies (beginning with Schurger et al. 2012) have called
into question just what kind of neural activity Libet-style studies
are tracking, and in particular whether it is even involved in the
production of choice and subsequent behavior. All this remains a
subject of continued scientific study and debate. (A large-scale
project is currently underway that is developing a wide array of
experimental probes of conscious will and its physical determinants:
< https://neurophil-freewill.org/> For an overview of
philosophical and empirical issues concerning human free will, see
 entry on free will.)
A striking feature of quantum mechanics is known as “quantum
entanglement”. When two (or more) quantum particles or systems
interact in certain ways and are then (even space-like) separated,
their measurable features (e.g., position and momentum) will correlate
in ways that cannot be accounted for in terms of “pure”
quantum states of each particle or system separately. In other words,
the two need to be thought of as a coupled system, having certain
features which are in no sense a compositional or other resultant of
individual states of the system’s components (see Silberstein
& McGeever 1999 and entries on
 holism and nonseparability in physics
 and
 quantum entanglement and information).
 Humphreys (2016) construes this as an instance of emergent fusion
 (section 4.2.4).
 Insofar as these features have physical effects, they indicate a
near-ubiquitous failure of whole-part property supervenience at a very
small scale. However, it should be observed that quantum entanglement
does not manifest a fundamental novelty in feature or associated
causal power, as it concerns only the value or magnitude of a
feature/associated power had by its components. (Correlated
“spin” values, e.g., are permutations on the fundamental
feature of spin, rather than being akin to mass or charge as wholly
distinctive features.) As such, it does not fit the criteria of many
accounts of strongly emergence. It is, however, relevant to the
epistemic status of such accounts: if one thinks that the existence of
strong emergence is implausible on grounds that a kind of strong local
supervenience is a priori very plausible for composed systems
generally, then the surprising phenomenon of quantum entanglement
should lead you to be more circumspect in your assumptions regarding
how complex systems are put together.
The interface of physics with chemistry has long been thought to
support ontological reductionism (or physicalism, more generally).
This sentiment goes back to an early declaration by Paul Dirac, one of
the founding figures of quantum mechanics:
The underlying laws necessary for the mathematical theory of a larger
part of physics and the whole of chemistry are thus completely known,
and the difficulty is only that exact applications of these laws lead
to equations much too complicated to be soluble. (1929: 714)
In recent decades, there has recently been reconsideration of this
perspective. Hendry (1998, 2010, 2017, 2019), following Woolley (1978,
1998) and Primas (1981), contends, to the contrary, that molecular
structure is (or may well be) strongly emergent, in failing to be
wholly determined by the arrangements of a molecule’s quantum
constituents; isomers, which have distinct molecular structure yet the
same subatomic constituents, are a particular focus in these
discussions. Scerri (2012) criticizes this line of thought, suggesting
that it overlooks the possibility that a molecule’s
quantum-mechanical interaction with its environment may contribute to
fixing its overall structure. It should be noted that the details of
Scerri’s counter-proposal depend on a particular
(collapse-based) interpretation of quantum mechanics. There has been a
steady uptick of discussion of this issue among philosophers of
chemistry, and it appears to be unresolved at present. This in turn
suggests that, contra Dirac, strong emergence even at the interface of
physics and chemistry remains a live possibility. (For further
discussion, see Hettema (2015) and entry on
 philosophy of chemistry,
 Section 6.)
Fundamental physics encompasses two successful theories, General
Relativity (GR) and Quantum Field Theory (QFT), that are mutually
inconsistent. In recent years, a number of Quantum Gravity theories
have been put forward as candidate deeper theories that can account
for core dynamical principles and successful predictions of both
theories within one consistent framework. Strikingly, in almost all
such theories, spacetime is not part of the fundamental ontology, it
being supplanted by a framework that lacks at least some of its
structure. Many theorists say that the spacetime of GR is thereby
rendered emergent. Its dependence is reflected in how the many roles
that spacetime plays in GR and the spatiotemporally structured
experimental observations themselves (and indeed, ubiquitous
perceptions of everyday life!) are grounded in nonspatiotemporal
structures in the proposed fundamental theories. Its autonomy takes
the form of nonfundamental spacetime’s being qualitatively
different from any feature of the fundamental theory.
The issues raised by such radical proposals are complex, and it is
even debated whether they are empirically coherent, given the role
that space and time play in our understanding of physical causation
and empirical observation, and hence of empirical evidence itself. For
present purposes, the key point is that such theories propose
systematic theoretical reductions, akin to the reduction of
thermodynamics to statistical mechanics, with a concommitant
ontological reduction of the structures of the reduced theories. In
this, the case appears unlike the relationship between physics and
biology as weak emergentists see it, in which biological entities
appear to be special kinds of organized physical structures that
explain equally distinctive phenomena that are unexplained by more
fundamental theories. For a non-technical introduction to some of the
theories at issue and the case for describing them as entailing
spacetime emergence, see Wüthrich (2019). For more general
philosophical reflection on our ordinary concepts of space and time
and their compatibility with theories that treat them as
nonfundamental, see Chalmers (forthcoming).
Champions of physicalism see the marked successes of the physical and
biological sciences in the twentieth and twenty-first centuries as
establishing, at a minimum, that the characteristic processes at all
levels of these domains are fixed by fundamental physical states and
processes. However, some draw a different conclusion from these
advances, seeing new bases for strongly emergentist perspectives.
Many sciences treating complex systems of one or other variety have
undergone extensive and impressive development in the last fifty
years. Theorists in these disciplines freely use terms such as
“emergence” and “top-down causation” to
describe the phenomena they study. It is often unclear, however,
whether they are best interpreted as describing weakly or strongly
emergent states and associated behavior. Among those who have
reflected recently on the state of their discipline, solid state
physicist Laughlin (2005), systems biologists Noble (2006) and Boogerd
(Boogerd et al. 2005, 2007), and neuroscientist Walter Freeman (1999,
2000) and cosmologist Ellis (2016) appear to advocate
strongly emergentist accounts of aspects of solid state
physics, biological life, and the human mind, respectively. They argue
that the pertinent sciences encompassing these domains give equal,
complementary places to “bottom up” and “top
down” determinants and principles, and argue that we cannot
understand the latter as themselves ultimately fixed by instances of
the former. The general thrust of their detailed arguments is that
there is no fully “bottom up” way to describe, let alone
explain, certain organized phenomena. See also Ellis, Noble, and
O’Connor (2012) for a collection of state-of-the-art overviews
of the interaction of top-down and bottom-up principles in numerous
scientific domains, from fundamental physics to sociology.
Finally, philosopher Nancy Cartwright (1983, 1994, 1999) has defended
over several decades a thorough-going “patchwork” or
pluralistic understanding of the relation between the sciences, as an
alternative to the sort of “physics-at-the-bottom”,
asymmetrical hierarchy common to weak emergentists and reductionists
alike. She argues that close consideration of scientific practice
suggests that fundamental physical laws hold only in certain
artificial contexts limited to small-scale systems, which systems are
maintained by macroscopic barriers and mechanisms serving to screen
off “downward” causal effects. She suggests that such
carefully contrived results can give us no reasonable confidence in a
vision on which all of natural reality is fixed by the unfolding of
bottom-up physical laws alone. While arguing in somewhat different
ways, Dupré (1993) is sympathetic to the general pluralist or
“anti-fundamentalist” thrust of Cartwright’s
perspective. More generally, if anything like Cartwright’s view
is correct, and the right ontological characterization of the
underlying pluralism is one according to which there is fundamental
novelty across the spectrum of natural reality, one might naturally
take strong emergence to be much more prevalent than even its
proponents have usually assumed. This perspective has affinities to
the “transformational” accounts of emergence noted in
 section 4.2.4.
 For discussion of the broad issues raised by Cartwright, see Cat
(1998) and entry on
 the unity of science,
 Section 5.