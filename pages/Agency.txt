In a very broad sense, agency is virtually everywhere. Whenever
entities enter into causal relationships, they can be said to act on
each other and interact with each other, bringing about changes in
each other. In this very broad sense, it is possible to identify
agents and agency, and patients and patiency, virtually 
everywhere.[1]
Usually, though, the term ‘agency’ is used in a much narrower sense to denote the performance of intentional actions. This
way of thinking about agency has a long history in philosophy and it
can be traced back to Hume and Aristotle, among other historical
figures. In contemporary analytic philosophy, it is most commonly
associated with the influential work of Anscombe (1957) and Davidson
(1963). Anscombe’s and Davidson’s views differ
significantly in many respects, but they share the central doctrine
that action is to be explained in terms of the intentionality of intentional action. In the debates that followed, the philosophy of
action revolved largely around the notion of intentional action. For
some time, the term ‘agency’ was rarely used, and if it was, it was usually taken to refer to the exercise of the capacity to perform intentional actions.[2] This has changed in the more recent
debate, where talk about agency has become more and more common in
many areas of philosophy (and in other areas of
research).[3] To
some extent, this focus on the notion of agency has been fuelled by a
resistance to the assimilation of agency to intentional action. As we
will see in the following section, this resistance amounts in some
cases to the rejection of the standard conception of action,
in some cases it amounts to the rejection of the
standard theory of action, and in some it amounts to the
more modest claim that there are different kinds of
agency.
The contributions of Anscombe and Davidson have established a
standard conception of action, and Davidson’s work has provided
the groundwork for a standard theory of action. At the core of the
standard conception are the following two claims. First, the notion of
intentional action is more fundamental than the notion of action. In
particular, action is to be explained in terms of the intentionality
of intentional action. Second, there is a close connection between
intentional action and acting for a reason.
There are two ways of spelling out the first claim (which
correspond to two different views on the individuation of actions; see
section 3.4). According to the first, one
and the same event can be more than one action under different
descriptions, and an event is an action just in case it is an
intentional action under some description. An action, that
is, may be intentional under some description and unintentional under
others (Anscombe 1957; Davidson 1963). Suppose that you alert the
burglar by turning on the light, and suppose that this is one event
that is intentional under the description ‘turning on the
light’, but not under ‘alerting the burglar’. On this view, alerting the burglar is nevertheless something that you do,
given that the event is an intentional action under some description.
According to a second way of spelling out the first claim, something
is an action either if it is identical with or “generated
by” an intentional action (Goldman 1970; see also Ginet
1990).[4] On this view, alerting the burglar is an action of yours either if it
is an intentional action or if it is generated by an intentional
action (your turning on the light, in this case). If it is merely
generated by an intentional action, it is an unintentional action of
yours. On both views, intentional action is more fundamental than
action itself: action derives from and is dependent on intentional
action.[5]
According to the second claim of the standard conception, there is
a close connection between acting intentionally and acting for a
reason. According to Anscombe and Davidson’s early view, this
close connection is identity. Following Aristotle, they both held the
view that to act intentionally is to act for a reason, and that to
act for a reason is to act in a way that can be rationalized by the
premises of a sound practical syllogism, which consists, typically,
of a major premise that corresponds to the agent’s goal and a
minor premise that corresponds to the agent’s take on how to
attain the goal. Furthermore, Davidson held the view that having an
intention consists in having a desire and a belief that correspond to
the major and the minor premise of the relevant syllogism (Davidson
1963, 1970; see also Goldman 1970; Audi
1986).[6]
One can still find a fairly widespread commitment to this
desire-belief version of the standard conception (in the philosophy of
mind, the philosophy of psychology, ethics, meta-ethics, and in other
areas of research). In the philosophy of action, however, it is now
widely thought that intentions cannot be reduced to desires and
beliefs (and combinations thereof). On this view, intentions play a
crucial and irreducible role in practical reasoning, long-term
planning, and in the initiation and guidance of action (see,
especially, Bratman 1987; see also Harman 1976; Brand 1984; Bishop
1989; Mele 1992, 2003; Enç 2003). It is nevertheless still
widely accepted that there is a close connection between intentional
action and acting for reasons and that intentional actions are
typically performed for reasons (Mele and Moser 1994; Mele 2003;
Enç 2003; Clarke 2010b, for instance).
The standard conception is not committed to a particular
account of what it is to act intentionally and for reasons, and it is
not committed to a particular account of the nature of reason
explanations. It is important to distinguish the standard conception
from the standard theory, which provides a causal account of
intentional action and reason explanation. This theory says, very
roughly, that something is an intentional action and done for reasons
just in case it is caused by the right mental states and events in the
right way. The right mental states and events are states and events
that rationalize the action from the agent’s point of view (such
as desires, beliefs, and intentions). The right way of causation is
non-deviant causation (see
section 3.2). On this view, a reason explanation is an explanation in terms of
mental states and events that cause the action and that rationalize it
from the agent’s point of view (typically by providing a
means-end rationale). This theory is often called “the causal
theory of action”. Strictly speaking, it is an event-causal
theory and it consists of an event-causal theory of reason explanation
and an event-causal theory of intentional action. In conjunction with
the standard conception, this causal theory provides us with a theory
of action, which has been the standard theory in the contemporary
philosophy of mind and action (see also the entry on
action).
As indicated, the standard conception is compatible with non-causal
theories of intentional action and reason explanation. It is generally
agreed that a reason explanation of an action usually renders the
action intelligible by revealing the agent’s goal or intention.
According to non-causal theories, having the relevant goals or
intentions does not consist in the possession of causally
efficacious mental states or events (Melden 1961; Ginet 1990;
O’Connor 2000; Sehon 2005). Non-causal theories are, however,
widely rejected (the most influential critique is due to Davidson
1963; see also Goldman 1970: 76–85; Mele 2003: 38–51;
Clarke 2003: 21–24). The standard conception is compatible,
furthermore, with dual standpoint theories. We will turn to this view
in
section 3.3.
The standard conception of action provides us with a conception of
agency. According to this view, a being has the capacity to exercise agency just
in case it has the capacity to act intentionally, and the exercise of
agency consists in the performance of intentional actions and, in many
cases, in the performance of unintentional actions (that derive from
the performance of intentional actions; see
section 2). Call this the standard conception of agency. The standard theory of action provides us with a theory of agency, according to which a being
has the capacity to act intentionally just in case it has the right
functional organization: just in case the instantiation of certain
mental states and events (such as desires, beliefs, and intentions)
would cause the right events (such as certain movements) in the right
way. According to this standard theory of agency, the exercise of
agency consists in the instantiation of the right causal relations
between agent-involving states and events. (Proponents include
Davidson 1963, 1971; Goldman 1970; Brand 1984; Bratman 1987; Dretske
1988; Bishop 1989; Mele 1992, 2003; Enç 2003.)
The most serious problem for this standard theory has been the
problem of deviant causal chains. Further, some have argued that this
view altogether fails to capture agency, because it reduces actions to
mere happenings. We will turn to those issues in
section 3. Recently, it has been argued that reasons for actions cannot be the
causes of actions, because reasons are facts or states of affairs, not
mental states or events (Dancy 2000; Alvarez 2010). But the standard
theory is not committed to the claim that reasons are identical with
mental entities. It is, in particular, compatible with the view that
reasons are the things that are represented by the contents of the
relevant mental states and events (see Scanlon 1998: 56–64; Mele
2003: 82–84; Setiya 2007: 28–31).
It has often been claimed, and it is widely agreed, that agency
involves the initiation of action by the
agent.[7] But it
has been controversial what this consists in. The standard conception
is compatible with the claim that intentional actions are initiated
by the agent, and proponents of the standard theory have argued that
initiation can be explained in terms of causation by the
agent’s mental states and events. According to desire-belief
versions of the view, initiation by the agent consists in causation
by the relevant desire-belief pairs (Goldman 1970; Davidson 1971;
Dretske 1988). According to more recent versions, initiation consists
in causation by the relevant intentions (Brand 1984; Bratman 1987;
Bishop 1989; Mele 1992, 2003; Enç 2003). Opponents of the
standard conception argue, however, that an agent’s power to
initiate action cannot be reduced to the capacity to act
intentionally and for reasons. They argue that the exercise of agency
may be entirely spontaneous, in the sense that an agent may initiate
an action for no reason and without prior intent. On this view,
reasons and intentions may have a strong and even a decisive
influence on how an agent acts. But agency has its source in the
power to initiate, and the exercise of this power cannot be reduced
to the agent’s being moved by reasons or intentions. This is an
alternative conception of agency (Ginet 1990; O’Connor
2000; Lowe 2008; see also McCann 1998; for critical discussion see
Mele 2003: 38–51, 71–76; Clarke 2003:
17–24). Proponents of this alternative conception reject the
standard theory and they reject, more generally, any account of
agency in terms of causal relations between agent-involving states
and events. According to some, the initiation of action consists in
irreducible agent-causation, others appeal to uncaused mental acts of
the will. The main positions on this issue correspond to the main
positions in the metaphysics of agency, to which we turn in
section 3.1.
In an influential article, Frankfurt (1971) argued that the
difference between persons and other agents consists in the structure
of their will. Only persons reflect on and care about their
motivations. According to Frankfurt, this reflective evaluation of our
motives usually results in the formation of second-order desires:
desires that are directed at first-order desires (which are directed
at goals and actions). When a person wants to have a certain desire
and wants to be moved by it, then he or she is said to
“identify” with the desire and its motivational efficacy.
On this hierarchical account of agency, the role of higher-order
attitudes is essential to the kind of agency that distinguishes
persons from other agents. Taylor (1977) took this as a starting point
for an account of distinctively human agency, under the
assumption that the distinction between persons and non-persons is,
essentially, the distinction between human and non-human agents. It is
not entirely clear whether Frankfurt and Taylor meant to provide an
alternative to the standard theory of agency or an extension
of it.[8] On one
reading, they accepted the account of intentional agency provided by
the standard theory, and they proposed a hierarchical extension of the
standard theory that captures the kind of agency that is distinctive
of persons or human agents. (For an influential critique of such
hierarchical accounts see Watson 1975.)
According to Velleman (1992), Frankfurt’s observation that an
agent may fail to identify with a particular motive points to a
fundamental flaw in the standard theory. As it seems always possible
that an agent “disowns” the mental attitudes that cause an
action, those attitudes do not “add up to the agent’s
being involved” (1992: 463). This shows, according to Velleman,
that the standard theory captures, at best, actions that are
defective. It fails, in particular, to capture “human
action par excellence”, because it fails to account for
the agent’s participation. Velleman rejects the appeal to
irreducible agent-causation (see
section 3.1), and he argues that this leaves only one strategy for solving the
problem: we must find a mental attitude that the agent cannot disown
and that is, therefore, fit to play the role of the agent. We must,
that is, find a mental attitude that is the agent,
functionally speaking. According to Velleman, the desire to act in
accordance with reasons is fit to play this role.
Bratman (2000, 2001) agrees with Velleman that the standard theory
does not explain genuine self-governance. On his view, though, an
account of “full-blown agency”, as he calls it, does not
require reference to a mental attitude that the agent cannot disown.
Building on his work on temporally extended planning agency (Bratman
1987), he argues that an agent’s “self-governing
policies” have the “authority to speak for the
agent”, because they help to establish and support the
agent’s identity across time, and because they specify which
desires are to be treated as providing justifying reasons in practical
deliberation. According to Bratman, these self-governing policies
explain what it is for an agent “to take a stand in favor of or
against certain motivations, a stand that can itself be subject to
reexamination and revision” (2000: 50–51). (For a critical
discussion of Bratman’s account see Hornsby 2004 and Franklin 2017.)
In defense of the standard theory, Mele (2003: Ch. 10) has argued
that the search for a mental attitude that plays the role of the agent
is misguided and that Velleman’s critique of the view is off
target. As Mele points out, it seems clear that a desire cannot
possibly be the agent, because agents deliberate, decide, and act.
Desires do none of these things. He suggests that any talk of a mental
attitude as playing the role of the agent can at best be metaphorical.
Further, there is no obvious reason why an agent’s failure to
identify with a motive should be diagnosed in terms of the
agent’s failure to participate. It seems more plausible to
suggest that the agent does participate in such cases, but in a
defective manner. Once defective participation is distinguished from a
failure to participate, it is easy to avoid Velleman’s
conclusion that the standard theory “leaves out the
agent”. Moreover, one can then separate the question of whether
the standard theory accounts for the agent’s participation from
the question of whether it captures human action par
excellence. According to Mele, the human agent is simply a human
being who acts. On this view, the agent does play some role in all
instances of agency, no matter how deficient. The standard theory
provides, first and foremost, an account of what it is for an agent to
perform intentional actions. It does not claim that the capacity to
perform intentional actions is the capacity that separates human from
non-human agency, and it does not claim to give an account of more
refined or excellent kinds of human agency, such as self-controlled,
autonomous, wholehearted, or free agency. It is an interesting and
important task to investigate whether or not the standard theory can
be extended so as to account for the more refined or excellent kinds
of human agency (Mele 1995; Bratman 2007, for instance). But to reject
the view because it fails to do so is to misconstrue its aim and scope
(see also
section 3.3).
Arguments for the claim that the standard theory does not account
for important aspects of agency are usually driven by a focus on
distinctively human agency. Once we shift our focus to non-human
agents, and simpler organisms, a very different challenge
emerges. When we turn to such agents, it seems that the standard
theory is clearly too demanding. The view explains agency in terms of
the agent’s desires, beliefs, and intentions. Usually, it is
assumed that this is an explanation in terms of mental
representations: in terms of intentional mental states and events that
have representational contents (typically, propositional contents). It
seems, however, that there are beings that are capable of genuine
agency and that do not possess representational mental states. We can
distinguish here between three claims (and three
challenges). According to the first, there are non-human beings that
are capable of agency and that do not possess representational mental
states. Second, there are many instances of human agency that can and
should be explained without the ascription of representational mental
states. Third, all instances of agency can and should be explained
without the ascription of representational mental states. We turn to
each claim in turn.
We have a pervasive tendency to interpret and explain behavior in
terms of intentional mental states. We tend, even, to interpret the
interaction between animated objects in terms of desires, beliefs, and
intentions (Heider and Simmel 1944). This raises the question of when
it is appropriate to attribute mental states in the explanation of
behavior. According to an instrumentalist stance (Dennett 1987:
Ch. 2), the question of when it is appropriate to ascribe mental
states cannot be separated from the question of when it is appropriate
to ascribe agency, and both questions are to be answered in terms of
predictive success: it is appropriate to attribute mental states in
the explanation of agency when doing so supports successful
predictions of behavior. However, most proponents of the standard
theory presume some form of realism, according to which the ascription
of mental states is appropriate only if the agent in question
possesses the right internal states with the right representational
contents. The question of what the possession of representational
mental states consists in is one of the most controversial questions
in the philosophy of mind and cognitive science, and it is clearly
beyond the scope of this entry (see the entries on
mental representation
and
cognitive science). Consider, though, the following remarks. Davidson (1982) held the view
that only human agents have the relevant mental attitudes, because he
thought that having such attitudes requires linguistic
competence. Others have argued that we are justified in ascribing
representational mental states to non-human agents if doing so
provides the best explanation of their behavior (Allen and Bekoff
1997, for instance). Sometimes it is rather difficult to decide
whether or not the best explanation of an agent’s behavior
requires the ascription of representational mental states. Sterelny
(2001: Ch. 11, 12), for instance, has argued that plausible
explanations in terms of desires can sometimes be replaced by equally
good explanations in terms of drives. The ascription of a desire is
usually construed as the ascription of a representational mental
state, whereas a drive can be construed in terms of more basic
mechanisms (and without the ascription of representational
content). What is important to bear in mind, here, is that the issue
concerns not only the possession of the relevant mental states and
events. It concerns, moreover, the capacity to combine or process the
contents of such attitudes in rational inferences: the capacity to
treat the relevant contents as premises in practical reasoning (as
emphasized by Anscombe 1957 and Davidson 1970).
Suppose, for the sake of argument, that it is appropriate to
ascribe representational mental states to non-human beings of various
kinds. It may still be the case that there are other kinds of
non-human beings that are capable of agency and that do not possess
representational mental states. Would this show that the standard
theory is too demanding? Only if the standard theory is construed as
providing an account of agency as such. According to a less
demanding view, the standard theory provides an account of one
particularly interesting and central kind of agency:
intentional agency (and the kind of unintentional agency that derives
from it; see
section 2).[9] On this construal, the standard theory is perfectly compatible with
the claim that there are more basic kinds of agency, including kinds
of agency that do not require the possession of representational
mental states. It is, for instance, compatible with what Barandiaran
et al. (2009) call “minimal agency”. On their view, an
agent is a unified entity that is distinguishable from its environment
and that is doing something by itself in accord with a certain goal
(or norm). This view departs from the standard conception and theory
in its characterization of action (“doing something”) in
terms of the “adaptive regulation” of the agent’s
“coupling with the environment” and in terms of metabolic
self-maintenance (inspired by Varela et al. 1974). They suggest that
organisms as simple as bacteria exhibit this minimal kind of
agency. The crucial point is that this provides an account of
goal-directed behavior that does not appeal to the mental
representation of goals. Barandiaran et al. suggest, rather, that
even very simple organisms can be said to have the intrinsic
goal to be: to bring about the continuation of their
existence.
We turn now to the second claim, which says that many instances of
human agency can and should be explained without the ascription of
representational mental states. This view is usually based on and
motivated by embodied and enactive approaches in the philosophy of
mind and cognitive science. Some versions of this approach are
inspired by the works Husserl, Heidegger, and Merleau-Ponty (Dreyfus
1991, 2002), others are based on more recent developments in robotics
and dynamical systems theory (Brooks 1991; Beer 1995). Common to such
views is the focus on skillful and “online” engagement with the world:
the ability to engage with others and with one’s circumstances
by responding to the demands of the situation in a skillful and often
effortless manner, without conscious deliberation, reasoning, or
planning (often called “skilled coping”). Examples of
human agency include instances of habitual action, such as the actions
that one performs while driving a car, and cases where the agent is
engaged in a responsive flow of interaction, such as in jazz
improvisation or in verbal exchanges. Examples from robotics include
skills like the coordination of limb movements and the ability to
navigate through novel environments. The challenge to the standard
theory often involves the following three points. First, it is argued
that the explanation of such skills and abilities in terms of mental
representations is both costly and clumsy: it imposes very high
demands on the agent’s information-processing resources and it
leads to an inelegant and implausible overpopulation of highly
specific mental representations. Second, it is pointed out that
current accounts of mental representation are untenable or, at least,
controversial and that there is no obvious reason to think that there
will ever be a generally accepted account of mental
representation. Third, it is argued that the explanation of skilled
coping does not require the ascription of representational mental
states, because it can be explained in terms of behavioral
dispositions and direct guidance by the relevant features of the
situation. The proposed conclusion is that we should, therefore,
explain instances of skilled coping without reference to
representational mental states and events.
In response, proponents of the standard theory (and of
representational theories of mind) usually argue as follows. First, it
is pointed out that the standard theory does not require that the
agent considers the relevant mental contents in conscious deliberation
or reasoning. This reduces the information-processing demands to a
significant degree. Second, it is argued that the standard theory is
compatible with explanations of habitual actions in terms of motor
schemata (or motor intentions). Motor schemata are not represented in
the contents of personal-level mental states, and they are usually
recruited automatically in the service of personal-level goals and
intentions. The utilization of motor schemata further reduces the
required processing load. Third, it is pointed out that most instances
of skilled coping do not occur in an intentional vacuum, as it were.
They are, rather, usually constrained by and often integrated with the
agent’s long-term goals and intentions. Given this, it seems
that a full explanation of skilled coping must, at some point or
level, make reference to representational mental states after
all. (For more on this see Clark and Toribio 1994; Antony 2002; Rey
2002; Adams 2010; Clarke 2010b; Schlosser 2018.)
According to the third claim, all instances of agency, including
all instances of human agency, can and should be explained without the
ascription of representational mental states. This position is usually
motivated by radical versions of the embodied and enactive approach to
the mind (Chemero 2009; Silberstein and Chemero 2011; Hutto and Myin
2014). The main strategy here is usually to generalize the argument
outlined above: explanations in terms of representational mental
states are costly and clumsy; there is no generally accepted account
of mental representation; and there is reason to think that we will,
eventually, be able to explain all kinds of agency without the
ascription of representational mental states. This radical view raises
some obvious and difficult questions. How can one explain our ability
to deliberate about the future without assuming mental
representations? How can one explain reasoning about abstract
concepts, counterfactuals, and theoretical generalizations? And how
can one explain that our agency is to a significant extent motivated,
guided, and constrained by our long-terms plans and commitments?
Temporally extended planning agency (Bratman 1987, 2000) is clearly a
“representation-hungry” phenomenon: it is difficult to see
how it can be explained without the ascription of representational
mental states (Clark and Toribio 1994; Schlosser 2018; see also the entry on
embodied cognition).
There is, as we have seen, good reason to distinguish between
different kinds of agency. The standard theory offers an account of
what is, arguably, the most central kind of agency: intentional agency
(and the kind of unintentional agency that derives from it; see
section 2). This can be distinguished from higher or more refined kinds of agency,
such as self-controlled, autonomous, and free agency, and it can be
distinguished from more basic kinds of agency that do not require the
ascription of representational mental states. Apart from that, there are
several candidates for further kinds of agency. They include mental
agency, shared agency, collective agency, relational agency, and
artificial agency. In each case, we can ask whether the agency in
question can be explained in terms of the standard conception and
theory, or whether it is indeed a different kind of agency. The main
focus in this section will be on mental agency, and we will address the
other candidates only very briefly.
It may seem obvious that our mental lives are filled with mental
action. We attend, consider, judge, reason, deliberate, accept,
endorse, decide, try, and so on. It may seem that these are all things
that we do. If we consider such cases through the standard theory of
agency, we encounter immediately two difficulties. First, it seems
that such mental occurrences are hardly ever, if ever, intentional
actions. According to the standard theory, an event is an intentional
action of the type A only if the agent has an intention that
includes A in its content. In the basic case, this would be
an intention to A. In an instrumental case, this would be an
intention to perform some other action B in order
to A. Now, thoughts are individuated in part by their
contents. Take the thought that p. According to the standard
theory, thinking that p is an intentional action only if the
agent has an intention that includes “think
that p” in its content. This is rather odd and
problematic, because we would have to have the intention to think a
certain thought before we think it. Second, there are problems with
the central case of decision-making. According to the standard
theory, deciding to A would be an intentional action only if
one already had the intention to make a decision that includes
“deciding to A” in its content. This seems,
again, rather odd and problematic. Further, our reasons for making a
decision to A are usually our reasons
to A—they are reasons for performing
the action. According to the standard theory, something is
an action only if it has a reason explanation (in terms of the
agent’s desires, beliefs, and intentions). As reasons are
usually reasons for action, it is again difficult to see how making a
decision can ever be an action. Considerations of this kind may lead
one to conclude that thoughts are hardly ever, if ever, mental actions
(see Strawson 2003).
It is not difficult to avoid this conclusion, as Mele
(1997, 2003: Ch. 9, 2009b) has shown. Consider again the central case
of decision-making, and assume that making a decision consists in the
formation of an intention. According to the standard theory, the
formation of an intention is an action if it is an intentional action
under some description (or if it is either identical with or generated
by an intentional action; see
section 2). What could plausibly be the
agent’s intention in making a decision? Mele suggests that
processes of decision-making are usually motivated by the intention to
settle the practical question at hand. This proposal avoids the
problem outlined above. Suppose the agent decides to A. For
this to be an action, it is not required that the agent has the
intention to decide to A. For if the agent has the intention
to settle the question by making a decision, making the decision is
intentional under a description. In particular, making a
decision is then an intentional action and making the
decision to A is then an unintentional action (that is either
identical with or generated by the intentional action of
making a
decision).[10]
Similar considerations apply to the mentioned issue concerning reason
explanation and to other cases, such as remembering. Mele (2009b)
argues that remembering something is never an intentional action,
because no one has ever the intention to remember the particular
content in question. But there is nevertheless a closely associated
intentional mental action that one might perform: intentionally trying
to bring it about that one remembers the particular content in
question. See Shepherd (2015) for a defense of the view that decisions are intentional actions by construing them as extensions and conclusions of deliberative activity.
Hieronymi (2009) takes a very different line. She thinks that we
engage in mental agency whenever we settle the question of whether to
do or whether to believe something, and she argues that this kind of
mental agency differs from ordinary intentional agency, primarily due
to a difference in control. According to Hieronymi, we have
“evaluative control” over our mental attitudes. This
consists in the ability to form and revise “our take on
things”, and it is to be distinguished from the kind of
voluntary control that we have over our overt bodily
actions. According to volitionist theories of agency, mental acts of
willing (choosing or trying) are also different in kind from overt
bodily actions. On such views, mental acts of willing are furthermore
fundamental, in the sense that they are the source of overt
agency (Ginet 1990; McCann 1998; Lowe 2008; more on this in
section 3.1).
Epistemic agency concerns the control that agents may
exercise over their beliefs (and other doxastic states). It is common
to distinguish between two main positions: indirect doxastic
voluntarism and direct doxastic voluntarism. The former concerns the
ways in which we may acquire or revise beliefs by doing research,
evaluating the evidence, considering opposing opinions, and so on. It
is fairly uncontroversial that we can exercise control over our
beliefs in such indirect ways. In contrast, direct doxastic
voluntarism is very controversial. It says that we have direct
voluntary control over some of our beliefs, where voluntary control is
usually understood as the kind of control that agents exercise in the
performance of intentional actions. A main issue here is that direct
doxastic voluntarism appears to be incompatible with the nature of
beliefs. Beliefs are supposed to represent the world (or “aim at
truth”). One may argue that there is no fundamental difference in the
control over action and belief-formation, because in both cases the
control consists basically in reason-responsiveness. But this proposal
overlooks the central role of intentions. According to the standard
theory, actions must be initiated and guided by intentions, in
addition to being responsive to reasons. The challenge is to find
beliefs-formations that are initiated and guided by intentions in the
same or similar way as intentional actions. (For a more extensive
overview and references see Vitz 2019.)
Shared agency occurs when two or more individuals do
something together (such as carry a piece of furniture or sing a
song). Collective agency occurs when two or more individuals
act as a group (in accordance with certain principles or procedures
that constitute and organize the group). Research on shared and
collective agency has flourished over the past two decades or so. One
central question has been whether shared and collective agency can be
reduced to the agency of the individuals involved, or whether they are
constitutive of different kinds of agency—whether they are, in
some sense, something over and above individual agency. An account of
collective agency in terms of the standard theory raises the question
of whether it makes sense to attribute mental states and events (such
as desires, beliefs, and intentions) to groups of individuals. (For
references and discussion see the entries on
shared agency
and
collective intentionality.)
The notion of relational agency derives from relational
accounts of autonomy. According to feminist critiques, traditional
accounts of autonomy are overly individualistic, insofar as they
overlook or neglect the importance of interpersonal relationships in
the development and sustenance of an autonomous individual. As
Westlund (2009) points out, however, most traditional accounts are
compatible with the feminist emphasis on interpersonal relationships
as long as relationships and dependence on others are construed as
being causally necessary for the development and sustenance
of an individual agent. Autonomy is genuinely relational only if
interpersonal relationships and dependence are constitutive
of autonomy. On Westlund’s own view, autonomous agency requires
an “irreducibly dialogical form of reflectiveness and
responsiveness to others” (2009: 28). On this account, autonomy
is an irreducibly relational kind of agency. (For more on this see the
entry on
feminist perspectives on autonomy.)
Finally, we turn briefly to the question of whether robots and
other systems of artificial intelligence are capable of agency. If one
presumes the standard theory, one faces the question of whether it is
appropriate to attribute mental states to artificial
systems (see
section 2.4). If one takes an instrumentalist stance (Dennett 1987: Ch. 2), there is
no obvious obstacle to the attribution of mental states
and intentional agency to artificial systems. According to realist
positions, however, it is far from obvious whether or not this is
justified, because it is far from obvious whether or not artificial
systems have internal states that ground the ascription of
representational mental states. If artificial systems are not capable
of intentional agency, as construed by the standard theory, they may
still be capable of some more basic kind of agency. According to
Barandiaran et al. (2009), minimal agency does not require the
possession of mental states. It requires, rather, the adaptive
regulation of the agent’s coupling with the environment and
metabolic self-maintenance. This means, though, that on this view
artificial systems are not even capable of minimal agency: “being specific about the requirements for agency
has told us a lot about how much is still needed for the development
of artificial forms of agency” (Barandiaran et al. 2009:
382). 
What is the nature of agency? How should we construe the relation
between agents and actions? How can agency be part of the event-causal
order? In this section, we will first turn to the three main
approaches in the metaphysics of agency that provide three different
frameworks for how to think about such metaphysical questions (the
event-causal, the agent-causal, and the volitionist framework). After
considering some problems and objections, we turn to an alternative
approach that rejects the project of providing a metaphysics of agency
(dual standpoint theory). Finally, we briefly consider the
individuation of actions and some further issues in the metaphysics of
agency.
According to an event-causal approach, agency is to be
explained in terms of event-causal relations between agent-involving
states and events.[11]
On this view, actions are events, and an
event is an action just in case it has the right event-causal
history.[12] We
may call this a reductive approach to agency, as it reduces
the agent’s role in the exercise of agency to the causal roles
of agent-involving states and events. Obviously, the standard theory
belongs to this reductive event-causal framework, because it explains
agency in terms of causation by the agent’s mental states and
events.[13]
(Proponents include Davidson 1963, 1971; Goldman 1970; Brand 1984;
Bratman 1987; Dretske 1988; Bishop 1989; Mele 1992, 2003; Enç
2003.)
According to an agent-causal approach, agency is to be
explained in terms of a kind of substance-causation: causation by the
agent, construed as a persisting substance. On this view, actions are
events, and an event is an action just in case it has the right
agent-causal history.[14]
This framework provides
a non-reductive account of agency insofar as it holds that an
agent’s role in the exercise of agency is to be construed in
terms of the exercise of an irreducible agent-causal power (Chisholm
1964; Taylor 1966; O’Connor 2000; see also Clarke 2003; Lowe
2008).
According to a volitionist approach, agency is to be
explained in terms of acts of the will, usually called
“volitions”. On this view, volitions are the source of
agency: an overt movement is an action just in case it is caused, in
the right way, by a volition. Volitions themselves are entirely
uncaused and they are sui generis acts: they are acts in
virtue of their intrinsic properties, not in virtue of some extrinsic
or relational property (such as having the right causal
history). This is also a non-reductive approach to agency, but it
differs sharply from both the event-causal and the agent-causal
framework in the important respect that it rejects the suggestion
that all actions are events with a certain causal history (Ginet
1990; McCann 1998; see also Lowe 2008).[15]
The event-causal framework is by far the most widely accepted view
in the contemporary philosophy of mind and action. One reason for this
is that the commitment to the event-causal framework is tantamount to
a commitment to a very minimal and widely endorsed kind of naturalism,
according to which any appeal to irreducible substance-causation or
teleology is to be avoided. Further, this commitment to the
event-causal framework is sustained by a widespread dissatisfaction
with alternative agent-causal and volitionist theories of agency. Some
objections to agent-causal theories derive from more general
objections to the notion of substance-causation, others address more
directly the agent-causal account of agency. It has been argued, for
instance, that appeal to substances leaves both the timing and the
manner of causation mysterious (Broad 1952). Further, it has been
argued that substance-causation collapses into event-causation, once
it is acknowledged that a substance has its causal powers in virtue of
its properties (Clarke 2003: Ch. 10). Others have argued that an
appeal to the agent as a cause is vacuous, because it has no
explanatory import (Davidson 1971), and because it cannot explain what
an agent’s exercise of control consists in (Schlosser 2010). A
common objection to volitionist accounts is that they generate a
regress of mental acts (Ryle 1949). Arguably, though, this objection
begs the question. The view holds that overt actions are to be
explained in terms of volitions. There is no need to appeal to further
mental acts of the will in order to explain why volitions are actions,
because volitions are actions sui generis (see Enç
2003 for discussion). This, however, points also to the reason why
the view is widely rejected. Volitionist theories stipulate as
primitive what appears to be in need of explanation. In particular,
they do not explain what an agent’s exercise of control consists
in, as the agent is merely the subject or the bearer of volitions
(O’Connor 2000: 25–26; Clarke 2003:
17–24). Moreover, if, as most contemporary philosophers would
assume, volitions are realized by events in the brain, the view
appears to be in tension with the fact that there are no events in the
brain that are entirely uncaused.
In the 1950s and 60s, several philosophers argued that the
event-causal framework is incoherent. Their main argument was the so
called “logical connection argument”, which says, very
roughly, that the relation between mental attitudes and actions
cannot be causal, because the connection between them is logical,
conceptual, or in some sense non-contingent (Hampshire 1959; Melden
1961; Kenny 1963, for instance). It is widely agreed now that this
attack was unsuccessful (the most influential reply is due to
Davidson 1963; see also Goldman 1970:
109–116).[16]
Shortly after that another challenge
emerged, which turned out to be the most serious and most persistent
problem for the standard theory and the event-causal framework: the
problem of deviant causal chains.
In general, the problem is that it seems always possible that the
relevant mental states and events cause the relevant event (a certain
movement, for instance) in a deviant way: so that this event is
clearly not an intentional action or not an action at all. It is
common to distinguish between cases of basic deviance
and consequential deviance (also called primary and
secondary deviance). A murderous nephew intends to kill his uncle in
order to inherit his fortune. He drives to his uncle’s house
and on the way he kills a pedestrian by accident. As it turns out,
this pedestrian is his uncle. This is a case of consequential
deviance (Chisholm 1966). In a standard case of basic deviance
(Davidson 1973), a climber intends to rid himself of the weight and
danger of holding another man on a rope by loosening his grip. This
intention unnerves him so that it causes him to loosen his hold on
the rope. The difference between the cases is best explained in terms
of the distinction between basic and non-basic
actions. Very roughly, basic actions are the things that one can do
without doing something else (such as raising one’s hand),
whereas the performance of non-basic actions requires that one does
something else (such as giving someone a signal by raising
one’s hand).[17] In the consequential case, the nephew
has an intention to perform a non-basic action (to kill his
uncle). He successfully performs several basic actions, but it is a
sheer coincidence that he brings about the intended end. The climber,
in contrast, does not perform any action at all. The mental
antecedent causes a movement that would have been a basic
action, had the causal chain not been deviant.
Any event-causal theory of agency must require that the relevant
mental attitudes cause the action in the right way. The right way of
causation is non-deviant causation. The challenge is to spell out
what non-deviant causation consists in within the event-causal
framework; without, in particular, any appeal to some unanalyzed
notion of agent-causation or control. Davidson (1974) was pessimistic
about the prospects for finding an event-causal account of
non-deviant causation, and he suggested that the standard theory is
best understood as providing only necessary conditions for
agency. Goldman (1970) suggested that giving an account of
non-deviant causation is an empirical rather than a philosophical
task. Since then, however, most proponents of the event-causal
approach have acknowledged that the problem of deviant causal chains
is a serious philosophical problem, and various solutions have been
proposed (see Peacocke 1979; Brand 1984; Bishop 1989; Mele 2003;
Schlosser 2007, 2011; Wu 2016).[18]
Sometimes it is suggested that the problem of deviant causal chains
is merely a symptom of the deeper problem that event-causal theories
altogether fail to capture agency, because they reduce actions to
things that merely happen to us (Lowe 2008: 9, for instance). Put
differently, this challenge says that the event-causal framework is
deficient because it leaves out agents: all there is, on this view, is
a nexus of causal pushes and pulls in which no one does
anything (Melden 1961; Nagel 1986; see also Velleman 1992). This
has been called the problem of the “disappearing agent”
(Mele 2003: Ch. 10; Lowe 2008: 159–161; Steward 2013).
According to Mele (2003: Ch. 10), some formulations of this
disappearing agent objection are easily dismissed. Some proponents of
this challenge use the terms ‘event-causal order’ and
‘natural order’ interchangeably. This would seem to
suggest that, on their view, agency is a supernatural
phenomenon­—a view that most contemporary philosophers find
hard to take seriously. However, sometimes the challenge is raised in
order to motivate alternative agent-causal or volitionist theories of
agency, and the main proponents of agent-causal and volitionist
theories maintain that their views are compatible with
naturalism. They would argue that it is a mistake to presume that the
event-causal order exhausts the natural order of things.
Further, the disappearing agent objection is not always put forward
as a general objection to the event-causal framework. As we have seen
(section 2.3), Velleman (1992) argued
that the standard theory leaves out the agent, or the agent’s
participation, and he proposed a solution to this
problem within the event-causal framework. In his reply,
Mele (2003: Ch. 10) suggested that it would be more appropriate to
call this the problem of the “shrinking agent”. According to
Velleman, the standard theory captures only deficient instances of
agency, in which the agent’s participation is
“unwitting” or “halfhearted”. Instances of
deficient agency can be explained in terms of various capacities or
properties that the agent does not possess, exercise, or instantiate;
capacities and properties such as conscious awareness, reflective
awareness, reason-responsiveness, self-control, self-governance, and
so on. Given this, there is no need to conceptualize instances of
deficient agency in terms of the agent’s absence. Further,
doing so creates a rather implausible dichotomy between a kind of
agency in which the agent does participate and a kind of agency in
which the agent does not participate (Schlosser 2010).
Others, yet, press the disappearing agent objection in order to
motivate a dual standpoint theory. According to dual standpoint
theories, agency cannot be explained from any theoretical standpoint
or metaphysical framework. Agency can only be understood from a
practical and normative standpoint (Nagel 1986; Korsgaard 1996;
Bilgrami 2006, for instance). Arguably, this view has its roots in
Kant’s account of practical reason (see the entry on
Kant and Hume on morality). Usually, dual standpoint theories do not reject metaphysics as such,
and they often provide a metaphysical framework of their own. But they
reject both reductive and non-reductive theories of agency, and they
reject, in general, the notion that we can have a metaphysical account
of what the exercise of agency consists in. They align themselves
naturally with non-causal theories of reason explanation (see
section 2).
Both views tend to emphasize the normative and irreducibly
teleological nature of reason explanation and, hence, agency. Dual
standpoint theories have received relatively little attention in the
philosophy of action. To many, it seems that such views are deeply
unsatisfactory precisely because they refuse to face a central
question in the metaphysics of agency: how can agents exercise control
over their actions in a world in which all movements can be explained
in terms of event-causation? It seems that this is in need of
explanation, and it seems that this requires a metaphysics of agency
(see Bishop 1989; Schlosser 2010). Nelkin (2000) has questioned the
coherence of dual standpoint theories on the basis of an argument for
the claim that they entail commitments to contradictory beliefs about
free will.
We now turn, in brief, to some further issues in the metaphysics of
agency. The first concerns the individuation of actions. You flick the
switch, turn on the light, illuminate the room, and you thereby also
alert the burglar. How many actions do you perform? According
to coarse-grained (or minimizing) views on the individuation
of actions, you perform one action under different descriptions
(Anscombe 1957; Davidson 1963). According to fine-grained (or
maximizing) views, how many actions you perform depends on how many
act-properties are instantiated. If you instantiate four
act-properties, then you perform four distinct actions (Goldman 1970;
see also Ginet 1990). According to a third alternative, actions can
have other actions as their components or parts (Thalberg 1977; Ginet
1990). According to all three views, actions are events, and the
individuation of actions derives from different views on the
individuation of events (see the entry on
events). Not much work has been done on this recently (see, however, Enç
2003: Ch. 3). This is partly because it is now widely agreed that the
individuation of actions has little or no bearing on other issues. To
illustrate, the question of whether agency is to be explained within
an event-causal or an agent-causal framework bears directly on various
issues in the debate on free will and moral responsibility (see the
entry on
free will). But event-causal and agent-causal theories are both compatible with
coarse-grained and fine-grained views on the individuation of actions.
Similarly, it seems that the views on the individuation of actions
have no substantial bearing on the question of whether or not reason
explanations are causal explanations.
A related issue is whether actions are to be identified with
the outcomes of causal processes or with
the processes themselves. According to most versions of
event-causal and agent-causal theories, an action is an event that is
caused in the right way: the action is identical with or constituted
by the outcome of that process.[19] According to process views, the action
is either identical with or constituted by that process (Searle 1983;
Dretske 1988; Wu 2011; see also Thompson 2008). This issue has also not
received much attention. Again, this is mainly because it is widely
assumed that this issue has little or no substantial bearing on more
fundamental issues in the metaphysics of agency and on debates
outside the philosophy of
action.[20]
Another issue in the metaphysics of agency that has received more
attention in the recent debate is the nature of omissions (in
particular, intentional omissions). According to Sartorio (2009), an
intentional omission is the absence of an action that is caused by the
absence of an intention. She argues, on the basis of this account,
that intentional omissions cannot be accommodated easily by the
standard theory. In reply, Clarke (2010a) has argued that in cases of
intentional omission the agent usually does have an intention not to
act that plays an important causal role, and he has identified various
parallels between intentional actions and intentional omissions. On
his view, there are no major obstacles to an account of intentional
omissions that is compatible and continuous with the standard theory
of intentional action. Further, he argues that a failure to account
for intentional omissions would not obviously be a shortcoming of a
theory of intentional action. There are, after all, significant
differences between actions and omissions, and so we should not expect
that a theory of action provides all the resources that are required
for an account of omissions. (For more on this see Clarke 2014.)
According to our commonsense conception of agency, our reasons and
conscious intentions tend to make a real difference to how we act
(D’Andrade 1987; Malle 2004, for instance). This assumption is
part and parcel of the standard theory and of numerous psychological
theories of intentional action and motivation (Fishbein and Ajzen
1975; Locke and Latham 1990; Heckhausen 1991; Gollwitzer 1993; Austin
and Vancouver 1996, for instance). There are, however, various
empirical findings from psychology and cognitive neuroscience that
have been taken to show that this commonsense assumption is
unwarranted, and that have raised interesting and challenging
questions concerning the role of consciousness in the initiation and
guidance of agency. This section provides an overview of the most
relevant research.
An early and highly influential source of the skepticism concerning
the causal relevance of our reasons is a theoretical review by Nisbett
and Wilson (1977). This article reports numerous experiments and
studies in which participants appear to construct or confabulate
rationalizing explanations by giving reasons that could not possibly
have been the reasons they acted for. Despite some rather serious
methodological problems (White 1988), this research has achieved and
retained the status of textbook knowledge within psychology and
cognitive science. Moreover, it has been taken to show that ordinary
reason explanations are not causal explanations, even though the
authors themselves rejected this conclusion. On their view, the
evidence shows, first and foremost, that verbal reports of mental
states are based on self-interpretation (theorizing or
rationalization), rather than on direct or introspective access. They
noted that this epistemic view is perfectly compatible with the
assumption that we can and often do give the actual causes of our
actions when we give an ordinary reason explanation. The upshot is
that, even if the proposed epistemic view is correct, there is nothing
in the evidence which shows that reason explanations cannot be causal
explanations, and there is nothing in the evidence which shows that
reason explanations are usually not causal explanations.
It seems that the empirical evidence in support of
situationism raises a challenge for our commonsense conception of
agency. According to situationism, empirical research shows that
commonsense explanations of actions in terms of character traits (such
as honesty, kindness, or courage) are systematically mistaken or
inaccurate, because this research shows that the actions in question
are better explained in terms of situational features (Ross and
Nisbett 1991; Harman 1999; Doris 2002). But none of the common
philosophical theories of agency say that actions are to be explained
in terms of the agent’s character traits, and so it seems that
situationism does not raise a problem for the standard theory and
other philosophical accounts of agency. Moreover, the interpretation
of the empirical evidence in question and the argument for
situationism have been controversial (Sreenivasan 2002, for
instance). It has been argued, however, that this evidence raises the
further question of whether we are genuinely reason-responsive. The
evidence suggests that our actions are, under certain conditions,
driven by situational and morally irrelevant factors even when there
are salient moral reasons to act otherwise. This suggests that we (or
most of us) are not as reason-responsive as we would like to
think. But it is controversial whether or not the evidence supports
any stronger claims than that (for more on this see Nelkin 2005;
Schlosser 2013; Vargas 2013).
The most influential empirical challenge concerning the role of
conscious intentions stems from Libet’s seminal neuroscientific
work on the initiation of movements. In the Libet experiment (Libet
1985), participants were instructed to initiate a simple and
predefined movement when the wish or urge to do so arises. During
this, EEG measurements were taken to record the readiness potential, a
brain potential that was known to precede intentional movements. The
main finding was that the readiness potential precedes the occurrence
of the conscious wish or urge to move by about 350ms. According to
Libet, this shows that movements are not consciously initiated and
that we do not have free will in the sense we commonly think we do
(Libet 1999). The methodology of this experiment has been scrutinized
extensively and criticized on a number of points. Some of those
methodological issues have been addressed in follow-up experiments
(Soon et al. 2008; Fried et al. 2011).
Most philosophers who have addressed Libet’s work have argued
that the conclusions about the role of conscious intentions and about
free will do not follow, even if it is granted that the experimental
methods and results are sound. They have argued that there are
alternative interpretations of the evidence that preserve a causal
role for conscious intentions and that are as plausible and probable
as Libet’s own interpretation of the evidence (Flanagan 1992:
136–138; Zhu 2003; Mele 2009a; Schlosser 2012b). Further, it has
been argued that the experiment creates a very unusual and artificial
context in which participants are instructed to
decide spontaneously. Due to this, it is questionable that
the results of the experiment can be generalized (Keller and
Heckhausen 1990; Roskies 2011; Waller 2012; Schlosser 2014). Schurger
et al. (2012) have proposed and tested a model that addresses this
issue. According to this model, the timing of the movement in the
Libet experiment is determined by random threshold crossings in
spontaneous fluctuations in neural activity. In particular, the model
says that a decision when to move is determined by random threshold
crossings only when it is not constrained by any evidence or
reasons for action. The fact that this model has been tested
successfully supports the claim that the results from the Libet
experiment and from similar follow-up studies do not generalize,
because most of our everyday decisions clearly are constrained by
evidence and by reasons for action.
A related challenge concerning the role of conscious intentions
stems from Wegner’s model of apparent mental
causation. According to this view, conscious intentions provide mere
“previews” of our actions: they precede our actions, but
they do not cause them (Wegner and Wheatley 1999; Wegner
2002). Wegner provided evidence of dissociations between the sense of
agency and the actual exercise of agency, and he argued that the
model of apparent mental causation provides the best explanation of
the data. This view has been strongly criticized for conceptual ambiguities and
argumentative flaws (see also section 4.5). One common objection is that the fact that the sense of agency can come apart from the exercise of agency is
perfectly compatible with the assumption that conscious intentions
tend to cause the intended actions. (See Bayne 2006; Mele 2009a; for
a reply to Wegner’s inference to the best explanation see
Schlosser 2012a.)
The work of Libet and Wegner has nevertheless raised interesting
and challenging questions concerning the role of consciousness in
agency. Proponents of the standard theory often qualify the view
with the claim that the relevant mental attitudes need not be
consciously accessed in order to play the right role in the exercise
of agency. When, for instance, Davidson (1978: 85–86)
considered the example of an agent who adds some spice to a stew with
the intention of improving the taste, he claimed that intentional
agency requires only that the agent would have reasoned on
the basis of the relevant attitudes that the action is to be
performed, had he been aware of those attitudes at the
time. Few, though, would be prepared to accept the view that all of
our actions might be like this: initiated and guided by attitudes
that are not consciously accessed at the time. This raises various
questions that are rarely addressed. How often, or in what kinds of
cases, should actions be preceded by conscious intentions or
conscious reasoning? What kind of consciousness is required? In cases
where the relevant attitudes are not consciously accessed, must they
be accessible? And so forth.[21]
One strand of empirical research that is relevant to questions
concerning the role of consciousness in agency is the work on
automaticity; in particular, the research on automatic goal
pursuit. It has been shown, for instance, that the goal to perform a
certain task accurately can be primed, so that the agent pursues the
goal without any awareness of doing so (Bargh et al. 2001). There is
a large body of research on this, and it has been suggested that this
research shows that most of our actions are executed
automatically and without conscious control (Bargh and Chartrand
1999, Custers and Aarts 2010).[22] This claim is less radical than the
claims put forward by Libet (1999) and Wegner (2002), as it concerns
only the extent or scope of conscious control. Further, this appears
to be much less challenging once it is noted that the great majority
of automatic actions are sub-routines that are in the service of
higher goals and long-term intentions. Consider, for instance, all
the sub-routines that one performs while driving a car. The claim
that such actions are performed automatically and without conscious
control can be reconciled with our commonsense conception of agency
and it can be accommodated by the standard theory, provided that
conscious intentions and plans can recruit the relevant routines
automatically, either by generating the relevant motor intentions, or
by activating the relevant motor schemata. (For more on this see
Pacherie 2008; Adams 2010; Clarke 2010b.)
Another relevant strand of research is the work on dual-process (or
dual-system) theories of decision-making. According to such models,
there are two distinct types of mental processes (or systems) that
underlie decision-making and agency: one is typically characterized as
automatic, effortless, and heuristics-based, and the other as
conscious, deliberate, and rule-based. Dual-process models have been
deployed widely and successfully in many areas of research (for
overviews see Sloman 1996; Evans 2008; for critical reviews see Osman
2004; Keren and Schul 2009). In philosophy, it is commonly assumed,
explicitly or implicitly, that there is one mechanism (or
faculty) of practical reason that underlies practical reasoning and
reason-based agency. This appears to be incompatible with the
dual-process framework. What complicates this issue, though, is that
there is no consensus on the details of the dual-process model. There
is, for instance, no commonly accepted view on how the two processes
(or systems) interact. Conscious and deliberate processes may have a
top-down influence on automatic processes; the two processes may
interact with each other; they may interfere with each other in some
cases; there may be cases in which processing switches from one to the
other; and so on. Not all of those possibilities are obviously
incompatible with the assumption that there is one mechanism (or
faculty) of practical reason. Further research is needed in order to
investigate whether the two types of processes are in the relevant
respects independent or whether they can be construed as interacting
parts of one mechanism of decision-making. For a discussion of whether
the dual-system framework is compatible with the philosophical
standard theory of action see Schlosser
2019.[23]
There has been some debate concerning the kind of knowledge we have
of our own actions. Most prominently, Anscombe (1957) argued that the
knowledge of our actions is direct, in the sense that it is not based
on observation or inference (see the entry on
action). 
This section provides an overview of the closely related debate on the
so called “sense of agency”. It seems that when we act, we
have a sense of doing something: a sense of control and of being the
agent or owner of the action. The debate about this has been driven
largely by empirical findings from psychology and cognitive science,
and it has become common to distinguish between the following three
main positions.
The first is largely due to Wegner’s work on the “model of
apparent mental causation” (Wegner and Wheatley 1999; Wegner
2002). According to this view, the sense of agency (or the
“experience of conscious will”, as Wegner called it)
arises when we interpret a conscious intention to perform a
certain action as its cause. It says, in particular, that an agent
interprets an intention as the cause of an action when the following
conditions obtain: the intention proximately precedes the action, the
action is consistent with the intention, and the agent is not aware of
any factors that could provide an alternative
explanation. Wegner’s argument for the model of apparent mental
causation is based on various experiments, studies, and observations
concerning illusions of control and failures in the ascription of
agency. This work initiated the empirical study of the sense of
agency, but Wegner’s model is now widely rejected. Philosophers
have criticized the view for various conceptual ambiguities and flaws
in the interpretation and use of the evidence (Nahmias 2002; Bayne
2006; Dennett 2008; and Mele 2009a, for instance). Moreover, there is
now plenty of empirical evidence to suggest that the sense of agency
is not merely a matter of self-interpretation (Haggard 2005; Bayne and
Pacherie 2007; Gallagher 2007; and Synofzik et al. 2008).
The second account of the sense of agency is based on a
feedback-comparator model of motor control. According to this model,
the motor control system uses copies of motor commands in order to
generate predictions of the ensuing bodily movements. Those
predictions (so called “forward models”) are then used for
comparisons between the predicted and the intended trajectories of
movements, and for comparisons between the predicted and actual
trajectories (based on information from sensory feedback). The model
holds that a sub-personal system of motor control uses those
predictions and comparisons in order to adjust and fine-tune the
execution of bodily movements (Wolpert and Kawato 1998; Frith et
al. 2000; Haggard 2005). It has been suggested that this system may
also play a crucial role in the generation of the sense of agency. On
this view, positive matches in the comparator system generate a sense
of agency, whereas mismatches generate error signals that disrupt the
sense of agency. This model can explain a wide range of phenomena
concerning the sense and control of agency (Frith et al. 2000;
Blakemore et al. 2002). More recently it has been argued, however,
that this comparator model provides at best a partial explanation of
the sense of agency (Haggard 2005; Bayne and Pacherie 2007; Gallagher
2007; Synofzik et al. 2008).
The third account of the sense of agency is a hybrid of the first
two. Proponents of this approach usually distinguish between a basic
sense of agency and post-act judgments concerning one’s agency.
The basic sense of agency is construed as an online and
phenomenologically rather thin experience that accompanies the
performance of actions, and that does not necessarily require the
presence of a conscious intention. Judgments about one’s agency,
in contrast, are offline and usually post-act, and they are, thereby,
subject to various biases that may distort the interpretation of
one’s own agency. The feedback-comparator model is well suited
to explain the basic sense of agency, whereas a self-interpretation
theory, akin to Wegner’s, can explain why judgments about
one’s own agency tend to be distorted or illusory under certain
conditions (Bayne and Pacherie 2007; Gallagher 2007; Synofzik et
al. 2008).
Pacherie (2008) develops the feedback-comparator model into an account
of the phenomenology of agency that postulates three integrated
feedback loops at three different levels of intention: the level of
distal (or future-directed) intention, proximal (or present-directed)
intention, and motor intention. These are levels of action
specification in which progressively more detailed representations of
the action are generated, at the later stages in response to
perceptual and proprioceptive feedback. Pacherie’s main thesis
is that the component representations of the stages in the process of
action specification are strongly interconnected with the components
and contents of the phenomenology of agency. At the level of proximal
intentions, for instance, the model explains how the conceptual
information that is inherited from the distal intention is integrated
with perceptual input and situational constraints. Concerning the
sense of agency, the model distinguishes between the awareness of what
(the goal), awareness of how (the means), the sense of intentionality,
the sense of initiation, the sense of situational control, and the
sense of motor control. Shepherd (2017) argues that the components in
the phenomenology of agency are so richly integrated that they can be
regarded as fused in the total experience.
The analytical philosophy of action neglected the role of perception
and attention in the guidance of agency for a long time. Concerning
perception it was common to assume, often without any elaboration,
that the reference to the guiding role of beliefs takes care of the
role of perception. The standard theory does not limit the causal role
of beliefs to those that the agent considers or possesses prior to the
execution of the action, and so we may assume that the beliefs that
are supposed to play a causal guidance role include perceptual beliefs
that the agent acquires during the performance of the action. More
recent work (Mele 2003; Pacherie 2008; Schlosser 2012a) has shown that
the standard theory is compatible with the feedback-comparator model
of movement control outlined above (see section
4.5). This model accounts not only for the role of perceptual and
proprioceptive input, but also for the guidance provided by internal
predictions in the fine-tuning and execution of motor control.
The role of attention, however, was almost entirely unacknowledged, as
pointed out by Wu (2011, 2016). Whenever we pursue a goal, we must not
only select appropriate means. We must also select which features of
the situation to attend to in the guidance of action. Wu
conceptualizes this in terms of a “many-many problem”: in the pursuit
of a goal we face typically too many perceptual inputs and too many
possible behavioral outputs. The formation of an intention provides
only a partial solution. The content of an intention usually includes
the selection of the appropriate means. One intends, for instance, to
open the window in order to let in some fresh air. This constrains the
range of behavioral outputs and the range of perceptual inputs that
one needs to attend to. But it does not determine a specific enough
input-output mapping. Generally, the content of intentions is not
fine-grained enough in order to properly guide the execution of
movements and the direction of attention. Wu suggests that the
many-many problems at those finer-grained levels are solved by
attention. Following William James, Wu proposes that
attention is the missing selection for action: the selection
of perceptual inputs for the implementation of motor control. On this
view, intention-mediated attention is an essential component
of embodied agency. This raises the question of whether the selection
of attention can itself be a genuine exercise of agency, and whether
the proposed account can be extended so as to account for the
intentional direction and control of attention.