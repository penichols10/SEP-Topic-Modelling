Montague semantics is the approach to the semantics of natural
language introduced by Richard Montague in the 1970s. He described the
aim of his enterprise as follows:
The salient points of Montague’s approach are a model theoretic
semantics, a systematic relation between syntax and semantics, and a
fully explicit description of a fragment of natural language. His
approach constituted a revolution: after the Chomskyan revolution that
brought mathematical methods into syntax, now such methods were
introduced in semantics.
Montague’s approach became influential, as many authors began to
work in his framework and conferences were devoted to ‘Montague
grammar’. Later on, certain aspects of his approach were adapted
or changed, became generally accepted or were entirely abandoned.
Nowadays not many authors would describe their own work as
‘Montague semantics’ given the many differences that have
taken shape in semantics since Montague’s own work, but his
ideas have left important traces, and changed the semantic landscape
forever. In our presentation of Montague semantics the focus will be
on these developments.
Richard Montague was a mathematical logician who had specialized in
set theory and modal logic. His views on natural language must be
understood with his mathematical background in mind. Montague held the
view that natural language was a formal language very much in the same
sense as predicate logic was a formal language. As such, in
Montague’s view, the study of natural language belonged to
mathematics, and not to psychology (Thomason 1974, 2). Montague
formulated his views:
Sometimes only the first part of the quote is recalled, and that might
raise the question whether he did not notice the great differences:
for instance that natural languages develop without an a priori set of
rules whereas artificial languages have an explicit syntax and are
designed for a special purpose. But the quote as a whole expresses
clearly what Montague meant by ‘no important theoretical
difference’; the ‘single natural and mathematically
precise theory’ which he aimed at, is presented in his paper
‘Universal Grammar’ (Montague 1970c). He became most
well-known after the appearance of Montague 1973, in which the theory
is applied to some phenomena which were discussed intensively in the
philosophical literature of those days.
According to Caponigro (forthcoming), Montague’s interest in the
field arose when preparing a seminar on the philosophy of language as
a visiting professor in Amsterdam in 1966. Only a couple of years
earlier, he had deemed the “systematic exploration of the
English language, indeed of what might be called the ‘logic of
ordinary English’, […] either extremely laborious or
impossible” and did ‘not find it rewarding’
(Montague and Kalish 1964, 10). Yet he appears to have changed his
mind after perusing Quine’s (1960) Word and Object as
well as Chomsky’s (1965) Aspects of the Theory of
Syntax: the latter opened the perspective of treating the syntax
of natural language as a formal system but failed to provide any
serious analysis of linguistic meaning; the former offered a
systematic connection between traditional grammar and formal logic
– and much more systematically so than contemporary logic texts.
In fact, Montague’s semantic work owes a lot to Quine’s
descriptive insights into the ‘logic of ordinary English’,
but differs from his predecessor by making the connection between
language and logic in rigorous, mathematical terms:
We next describe the basic ideas of Montague semantics. Section
 2
 presents several components of Montague semantics in more detail.
Section
 3
 includes a discussion of philosophically interesting aspects, and
Section
 4
 provides a detailed example and further reading.
To implement his objective, Montague applied the method which is
standard for logical languages: model theoretic semantics. This means
that, using constructions from set theory, a model is defined, and
that natural language expressions are interpreted as elements (or
sets, or functions) in this universe. Such a model should not be
conceived of as a model of reality. On the one hand, the model gives
more than reality: natural language does not only speak about past,
present and future of the real world, but also about situations that
might be the case, or are imaginary, or cannot be the case at all. On
the other hand, however, the model offers less: it merely specifies
reality as conceived by language. An example: we speak about mass
nouns such as water as if every part of water is water again,
as if it has no minimal parts, which physically is not correct. For
more information on natural language metaphysics, see Bach 1986b.
Montague semantics is not interested in a particular situation (e.g.
the real world) but in semantical properties of language. When
formalizing such properties, reference to a class of models has to be
made, and therefore the interpretation of a language will be defined
with respect to a set of (suitable) models. For example, in the
introduction we mentioned that the characterization of entailment was
a basic goal of semantics. That notion is defined as follows. Sentence
\(A\) entails sentence \(B\) if in all models in which the
interpretation of \(A\) is true, also the interpretation of \(B\) is
true. Likewise, a tautology is true in all models, and a contradiction
is true in no model.
An essential feature of Montague semantics is the systematic relation
between syntax and semantics. This relation is described by the
Principle of Compositionality, which reads, in a formulation
that is standard nowadays:
An example: Suppose that the meaning of walk, or
sing is (for each model in the class) defined as the set of
individuals who share respectively the property of (being an
individual that is) walking or the property of (being an individual
that is) singing. By appealing to the principle of compositionality,
if there is a rule that combines these two expressions to the verb
phrase walk and sing, there must be a corresponding rule that
determines the meaning of that verb phrase. In this case, the
resulting meaning will be the intersection of the two sets.
Consequently, in all models the meaning of walk and sing is a
subset of the meaning of walk. Furthermore, we have a rule
that combines the noun phrase John with a verb phrase. The
resulting sentence John walks and sings means that John is an
element of the set denoted by the verb phrase. Note that in any model
in which John is element of the intersection of walkers and singers,
he is an element of the set of walkers. So John walks and
sings entails John walks.
An important consequence of the principle of compositionality is that
all the parts that play a role in the syntactic composition of a
sentence must also have a meaning. And furthermore, each syntactic
rule must be accompanied by a semantic rule which says how the meaning
of the compound is obtained. Thus, the meaning of an expression is
determined by the way in which the expression is formed, and as such
the derivational history plays a role in determining the meaning. For
further discussion, see Section
 2.5.
The formulation of the aim of Montague semantics mentioned in the
introduction (‘to characterize truth and entailment of
sentences’) suggests that the method is restricted to
declarative sentences. But this need not be the case. In Montague 1973
(241 fn) we already find suggestions for how to deal with imperatives
and questions. Hamblin (1973) and Karttunen (1977) have given a
semantics for questions by analyzing them as expressing sets of
propositions, viz. those expressed by their (declarative) answers; an
alternative approach, taken by Groenendijk and Stokhof (1989)
considers questions as partitioning logical space into mutually
excluding possibilities.
Since Montague only considered sentences in isolation, certain
commentators pointed out that the sentence boundary was a serious
limitation for the approach. But what about discourse? An obvious
requirement is that the sentences from a discourse are interpreted one
by one. How then to treat co-referentiality of anaphora over sentence
boundaries? The solution which was proposed first was Discourse
Representation Theory (Kamp 1981). On the one hand, that was an
offspring of Montague’s approach because it used model theoretic
semantics; on the other hand, it was a deviation because (discourse)
representations were an essential ingredient. Nowadays there are
several reformulations of DRT that fit into Montague’s framework
(see van Eijck and Kamp 1997). A later solution was based upon a
change of the logic; dynamic Montague semantics was developed and that
gave a procedure for binding free variables in logic which has an
effect on subsequent formulas (Groenendijk and Stokhof 1990, 1991).
Hence the sentence boundary is not a fundamental obstacle for Montague
semantics.
Montague’s most influential article was ‘The Proper
Treatment of Quantification in Ordinary English’ (Montague
1973), commonly abbreviated as ‘PTQ’. It presented a
fragment of English that covered several phenomena which were in those
days discussed extensively. One of the examples gave rise to the
trademark of Montague grammar: the unicorn (several publications on
Montague grammar are illustrated with unicorns).
Consider the two sentences John finds a unicorn and John
seeks a unicorn. These are syntactically alike
(subject-verb-object), but are semantically very different. From the
first sentence follows that there exists at least one unicorn, whereas
the second sentence is ambiguous between the so called de
dicto (or non-specific, or notional) reading
which does not imply the existence of unicorns, and the de re
(or specific, or objectual) reading from which
existence of unicorns follows.
The two sentences are examples of a traditional problem called
‘quantification into intensional contexts’. Traditionally,
the second sentence as a whole was seen as an intensional context, and
the novelty of Montague’s solution was that he considered the
object position of seek as the source of the phenomenon. He
formalized seek not as a relation between two individuals,
but as a relation between an individual and a more abstract entity
(see section 2.2). Under this analysis the existence of a unicorn does
not follow. The de re reading is obtained in a different way
(see section 2.5).
It was Montague’s strategy to apply to all expressions of a
category the most general approach, and narrow this down, when
required, by meaning postulates (and, in some cases, logical
decomposition). So initially, find is also considered to be a
relation between an individual and such an abstract entity, but some
meaning postulate restricts the class of models in which we interpret
the fragment to only those models in which the relation for
find is the (classical) relation between individuals.
As a consequence of this strategy, Montague’s paper has many
meaning postulates. Nowadays semanticists often prefer to express the
semantic properties of individual lexical items directly in their
lexical meaning, and then find is directly interpreted as a
relation between individuals. Meaning postulates are mainly used to
express structural properties of the models (for instance, the
structure of the time axis), and to express relations between the
meanings of words. For a discussion of the role of meaning postulates,
see Zimmermann 1999.
Noun phrases like a pig, every pig, and
Babe, behave in many respects syntactically alike: they can
occur in the same positions, can be conjoined, etc. But a uniform
semantics seems problematic. There were proposals which said that
every pig denotes the universally generic pig, and a
pig an arbitrary pig. Such proposals were famously rejected by
Lewis (1970), who raised, for instance, the question which would be
the color of the universal pig, all colors, or would it be
colorless?
Montague proposed the denotation of a descriptive phrase to be a set
of properties. For instance, the denotation of John is the
set consisting of properties which hold for him, and of every
man the set of properties which hold for every man. Thus they are
semantically uniform, and then conjunction and/or disjunction of
arbitrary quantifier phrases (including e.g. most but not
all) can be dealt with in a uniform way.
This abstract approach has led to generalized quantifier theory, see
Barwise and Cooper 1981 as well as Peters and Westerståhl 2006.
Among the most popular achievements of generalized quantifier theory
is a semantic characterization of so-called ‘negative polarity
items’: words like yet and ever. Their
occurrence can be licensed by negation: The 6:05 has arrived
yet is out, whereas The 6:05 hasn’t arrived yet is
OK. But there are more contexts in which negative polarity items may
occur, and syntacticians did not succeed in characterizing them.
Ladusaw (1980) did so by using a characterization from generalized
quantifier theory. This has been widely acknowledged as a great
success for formal semantics. His proposal roughly was as follows.
Downward entailing expressions are expressions that license inferences
from supersets to subsets. No is downward entailing because
from No man walks it follows that No father walks. A
negative polarity item is acceptable only if it is interpreted in the
scope of a downward entailing expression, e.g. No man ever
walks. Further research showed that the analysis needed refining,
and that a hierarchy of negative polarity items should be used
(Ladusaw 1996, Homer 2021).
An expression may directly be associated with some element from the
model. For instance, walk with some set of individuals. Then
also the operations on meanings have to be specified directly, and
that leads to formulations such as:
Such descriptions are not easy to understand, nor convenient to work
with. Montague (1973, 228) said, ‘it is probably more
perspicuous to proceed indirectly’. For this purpose he
introduced a language, called ‘intensional logic’. The
operation described above is then represented by \(^{\wedge}\lambda
t\lambda u[t = u\)]. The \(\lambda t\) says that it is a function that
takes \(t\) as argument, likewise for \(\lambda u\). So \(\lambda
t\lambda u[t = u\)] is a function which takes two arguments, and
yields true if the arguments are equal, and otherwise false. The
preceding \(^{\wedge}\) says that we consider a function from possible
worlds and moments of time to the thus defined function.
Three features of the Montague’s ‘intensional logic’
attracted attention:
It is a higher-order logic. Even though type logic was
already an established logical framework in those days, linguists,
philosophers and mathematicians were more familiar with first order
logic (the logic in which there are only variables for basic
entities). Since in Montague semantics the parts of expressions must
have meaning too, a higher order logic was needed (we have already
seen that every man denotes a set of properties).
It is intensional in that it obeys neither Leibniz’ law
of substitution of co-extensional terms nor existential
generalization, thereby seemingly bringing logic closer to natural
language. To achieve this, Montague generalized Kripke’s (1963)
groundbreaking semantic techniques from first-order modal logic to
higher-order type logic. However, the same interpretive effect could
have been achieved by using a two-sorted, extensional type logic
(Gallin 1975; Zimmermann 1989; 2021), which many semanticsists prefer
today.
Montague used \(\lambda\)-abstraction, which at the time was
not a standard ingredient of logic. As illustrated in section 4.1, the
\(\lambda\)-operator makes it possible to express higher-order
functions, which may serve as the contributions that parts of
sentences make to their truth-values. The importance of
\(\lambda\)-expressions was once expressed by Barbara Partee in a talk
on ‘The first decade of Montague Grammar’: ‘Lambdas
changed my life’ (Partee 1996, 24). Nowadays
\(\lambda\)-expressions are a standard tool in natural language
semantics, and particularly in the type-driven approach made popular
by Heim and Kratzer (1998). In section 4.1, an example will be given
that illustrates the power of \(\lambda\)-expressions.
This motivation for indirect interpretation – by way of
compositional translation as a tool for obtaining perspicuous
representations of meaning – has a number of important
consequences:
The method of using logical notation for representing meanings has a
long history, going back at least to philosophers such as Dalgarno and
Leibniz who developed formal languages in order to express philosophy
clearly. In the 19th century, there were several proposals for
artificial languages in order to make mathematical argumentation more
transparent, for instance by Frege and by Peano. Frege’s
‘Begriffsschrift’ (Frege 1879) can be seen as the birth of
predicate logic: he introduced quantifiers. His motivation came from
mathematical needs; he did not use his Begriffsschrift in his papers
on natural language. Russell (1905) used logic to represent the
meanings of natural language. A classical example in his paper is the
analysis of The king of France is bald. Syntactically it has
the form subject-predicate, but if it were constructed logically as a
subject-predicate, then the king of France, which denotes
nothing, cannot be the subject. So syntactic form and logical form may
diverge: natural language obscures the view of the real meaning. This
became known as the ‘misleading form thesis’. Therefore,
philosophers of language saw, in those days, the role of logic as a
tool to improve natural language, an aim that is alien to Montague
semantics. In fact, using higher-order functional type theory (Church
1940) as the target of his translation, Montague (1970c) developed a
‘compositional’ version of Russell‘s analysis, which
does preserve the constituent structure of the source language
(English). An interesting overview of the history of translating
natural language into logic is given in Stokhof 2007.
Montague defined the denotation of a sentence as a function from
possible worlds and moments of time to truth values. Such a function
is called an ‘intension’. As he said (Montague 1970a,
220), this made it possible to deal with the semantics of common
phenomena such as modifiers, e.g. in Necessarily the father of
Cain is Adam. Its denotation cannot be obtained from the truth
value of The father of Cain is Adam: one needs to know the
truth value for other possible worlds and moments of time. The
intensional approach also made it possible to deal with several
classical puzzles. Two examples from Montague 1973 are: The
temperature is rising, which should not be analyzed as stating
that some number is rising; and John wishes to catch a fish and
eat it, which should not be analyzed as implying that John has a
particular fish in mind.
Intensional semantics has been criticized for the fact that all
tautologies get the same meaning (are synonymous). Indeed, a tautology
as John is ill or he is not ill gets as intension the
function that constantly yields true, and the same holds for
other tautologies. If one is interested in discriminating semantically
between tautologies, then a refinement of the notions
‘meaning’ and ‘equivalence’ is needed:
‘meaning’ should see distinctions between tautologies, and
‘equivalence’ should be sensitive for the thus refined
notion of meaning. The oldest proposals to account for this problem
goes back to Carnap (1947, §14) and was later taken up by Lewis
(1970, sec. 5): propositions are structured by including in their
meanings also the meanings of their parts. Then indeed Green grass
is green and White snow is white have different
meanings. However, lexical synonyms still pose a problem. Since
woodchuck and groundhog are names for the same
species, John believes that Phil is a groundhog is, under
this view, equivalent with John believes that Phil is a
woodchuck. One could consider belief contexts a separate problem,
but most authors see it as part of the problem of equivalence of all
tautologies.
Later several proposals for dealing with this have been developed;
surveys can be found in Bäuerle and Cresswell (2003), Fox and
Lappin (2005), and Egré (2021). The latter authors explain that
there are two strategies: the first is to introduce impossible worlds
in which woodchuck and groundhog are not equivalent,
and the second is to introduce an entailment relation with the
property that identity does not follow from reciprocal entailment. Fox
and Lappin follow the second strategy.
A well known example of scope ambiguity is Every man loves a
woman. Is there only one woman involved (e.g. Mother Mary), or
does every man love a different woman? The sentence has no lexically
ambiguous words, and there are no syntactic arguments to assign them
more than one constituent structure. How to account for the
ambiguity?
In Montague 1973, the scope ambiguity is dealt with by providing for
the sentence two different derivations. On the reading that
every has wide scope, the sentence is produced from every
man and loves a woman. On the reading that only one
woman is involved, the sentence is obtained from Every man loves
him\(_1\). The him\(_1\) is an artifact, a placeholder,
or, one might say, a syntactic variable. A special kind of rule,
called a ‘quantifying-in rule’, will replace this
him\(_1\) by a noun phrase or a pronoun (in case there are
more occurrences of this placeholder). The placeholder corresponds
with a logical variable that becomes bound by the semantic counterpart
of the quantifying-in rule. For the sentence under discussion, the
effect of the application of the quantifying-in rule to a
woman and Every man loves him\(_1\) is that the desired
sentence is produced and that the quantifier corresponding with a
woman gets wide scope. When we would depict its derivation as a
tree, this tree would be larger than the constituent structure of the
sentence due to the introduction and later removal of
him\(_1\).
This quantifying-in rule is used by Montague for other phenomena as
well. An example is co-referentiality: Mary loves the man whom she
kissed is obtained from He\(_1\) loves the man whom
he\(_1\) kissed. And the de re reading of
John seeks a unicorn is obtained from a unicorn and
John seeks him\(_1\).
Many researchers did not like this analysis in which powerful
syntactic rules and artificial symbols (him\(_1)\) are used.
Below we consider two strategies to remedy.
The first strategy was to deny the ambiguity. Some linguists have
argued that the scope order is the same as the surface order; this is
known as ‘Jackendoff’s principle’ (Jackendoff 1972).
But there are sentences where this does not work. Others said that it
is sufficient only to obtain the weakest reading (every wide
scope), and that the stronger reading is inferred when additional
information is available. But there are sentences for which the
different scope readings are logically independent, as in Every
woman loves one man.
The second strategy was to capture the ambiguity in another way than
by the quantifying-in rules. Historically the first method was to put
the interpretations of the noun phrases in a store from which these
interpretations could be retrieved when needed: different stages of
retrieving correspond with differences in scope. One might see this as
a grammar in which the direct correspondence between syntax and
semantics has been relaxed. The method is called ‘Cooper
Store’, after the author who proposed this (Cooper 1983). A
later proposal is DRT \((=\) Discourse Representation Theory), where
representations are used to account for such ambiguities (van Eijck
and Kamp 1997).
A recent method is by means of ‘lifting rules’ (see
section 3.3): the meaning of a noun-phrase is ‘lifted’ to
a more abstract level, and different levels yield different scope
readings (see Hendriks 2001 and Jacobson 2014).
Even if the role of derivational history can be avoided for scope and
co-referentiality, other phenomena remain for which derivational
histories have a role. An example is John wondered when Alice said
she would leave. This is ambiguous between John asking for the
time of leaving, or for the time of saying. So the sentence is
ambiguous, even though there are no arguments for assigning to it more
than one constituent structure. Pelletier (1993) presents this
sentence and others, and says: ‘In order to maintain the
Compositionality Principle, theorists have resorted to a number of
devices which are all more or less unmotivated (except to maintain the
Principle): Montagovian “quantifying-in” rules, traces,
gaps, […].’ Pelletier’s objection can be
appreciated if one assumes that meaning assignment is directly linked
with constituent structure. But, as explained in Section
 1.2,
 this is not the case. The derivation specifies which rules are
combined in which order, and this derivation constitutes the input to
the meaning assignment function. The constituent structure is
determined by the output of the syntactic rules, and different
derivation processes may generate one and the same constituent
structure. In this way, semantic ambiguities are accounted for. One
should not call something ‘constituent structure’ if it is
not intended as such, and next refute it because it does not have the
desired properties.
The distinction between a derivation tree and a constituent tree is
made in several theories of grammar. In Tree Adjoining Grammars (TAGs)
the different scope readings of the sentence about loving a woman
differ in the order in which the noun-phrases are substituted in the
basic tree. A classical example in Chomskyan grammar is The
shooting of the hunters was bloody, which is ambiguous between
the hunters shooting, or the hunters being shot at. The two readings
come from two different sources: one in which the hunters is
the subject of the sentence, and one in which it is the object.
Throughout most of his semantic work, Montague avowedly adopted a
version of Frege’s (1892) distinction between
‘sense’ and ‘denotation’. Frege’s
original line of thought concerns sentences like The Greeks did
not know that the morning star is the evening star, which does
not seem to express that the Greeks were confused about the
self-identity of Venus. Frege’s analysis accounts for this
observation by having descriptive names like the morning star
denote their referents in ordinary contexts, but something different
in embedded clauses (or, more generally, in ‘indirect
contexts’): their ‘sense’ – a semantic value
that captures the way in which an object is referred to. Since
referring to a celestial object by the morning star differs
from referring to it by the evening star, the embedded clause
does not denote an analytic truth but a contingent proposition, whose
truth may well have escaped the Greeks.
Frege’s approach is known to run into a number of problems. One
of them concerns the iteration of indirect contexts, as in Gottlob
suspected that the Greeks did not know that the morning star is the
evening star. Though he did not explicitly address the issue,
Frege is usually understood as resorting to an infinite hierarchy of
ever more indirect senses to be associated with each otherwise
non-ambiguous expression (Dummett 1981, 267; Carnap 1947, §30;
Kripke 2008, 183; see however Parsons 1981 for a more cautious
interpretation). The purported Fregean line of analysis has been
criticized for multiplying ambiguity beyond necessity (Janssen 2012)
as well as raising serious learnability issues (Davidson 1968, 11).
Though Montague did acknowledge a hierarchy of senses, he did not
employ it for the analysis of iterated indirect contexts. Instead, he
identified Frege’s (1892) senses with intensions along
the lines of Carnap (1947) – set theoretic functions on a
logical space of possible worlds (or world-time-pairs) whose values
are the denotations of expressions – their extensions.
In particular, the way in which a description refers to its referent
is captured by its dependence on contingent facts. As a case in point,
the famous Fregean descriptions differ in intension as long as there
is a possible world in which the brightest star at dawn is not the
same object as the brightest star at night.
The replacement of senses by intensions paves the way to an
alternative approach to iterated intensionality: generalizing
Kripke’s (1963) semantics of modality, Montague (1970b, 73)
accounted for clausal embedding in terms of propositional operators
whose extension, like that of their argument, depends on a given point
in logical space. As it turns out, this so-called ‘neighborhood
semantics’ of clausal embedding does without reference to a
sense hierarchy even in iterated indirect environments
(ibid., 76), which is why Montague used it as the basis for
his general compositional analysis of natural language. Montague
(ibid., 75f.) still presented his approach as being in line
with Frege’s, thereby emphasizing the commonalities in the
overall architecture of semantic theory, which he identified as
‘Frege’s functionality principle’:
Moreover, Montague (1970c, 390) called one of the key constructions of
his general theory of reference ‘Fregean interpretation’;
and in his type-logical hierarchy, intensions are marked by the letter
‘\(s\)’, which is short for ‘sense’
(ibid., 379). This notation has become quite common in
linguistic semantics, although the ‘\(s\)’ is frequently
taken to stand for possible \(s\)ituations!
Only at one point in his semantic work did Montague abandon his
Fregean stance: in his essay ‘English as a formal
language’ (1970a), he employed a one-level architecture of
‘Russellian’ denotations and expressed his doubts about
the cogency of Frege’s motivation for non-propositional senses
(ibid., sec. 9, remark xi), thereby foreshadowing
Kaplan’s (1975) comparison between the frameworks of Frege 1892
and Russell 1905. Yet in his ‘Universal Grammar’, Montague
commented:
Even though Montague tended to play down the difference, the switch
from senses to intensions is known to have dramatic consequences on
the fine-grainedness of semantic analysis. In particular, as mentioned
in section 2.4, any two logically equivalent sentences come out as
having the same intension; yet their senses will diverge if their
truth value is not determined in the same way. Montague indicated how
this unwelcome consequence may be avoided in terms of mismatches
between worlds and contexts, creating what he called
‘“unactualizable” points of reference’
(ibid., 382), but he did not provide a detailed analysis to
substantiate his sketchy remarks.
For Montague the principle of compositionality did not seem to be a
subject of deliberation or discussion, but the only way to proceed. In
effect he made compositionality the core part of his ‘theory of
meaning’ (Montague 1970c, 378), which was later summed up in the
slogan: ‘Syntax is an algebra, semantics is an algebra, and
meaning is a homomorphism between them’ (Janssen 1983, 25). Yet
although Montague used the term ‘Frege’s functionality
principle’ for the way in which extension and intension are
compositionally intertwined, he did not have a special term for
compositionality in general. Later authors, who identified the
Principle of Compositionality as a cornerstone of Montague’s
work, also used the term ‘Frege’s Principle’
(originating with Cresswell 1973, 75); Thomason 1980 is an early
source for the term ‘compositional’.
It has been claimed that Montague’s analysis of pronouns is not compositional. This is, however, not the case. In order to
explain the compositional nature of his treatment of pronouns, both
Janssen (1997) and Dowty (2007) explain how variables are interpreted
in logic; we follow their explanations. Consider the following clauses
from the traditional Tarskian interpretation of predicate logic.
The first clause says: \(\varphi \wedge \psi\) is true when using
assignment \(g\) if and only if \(\varphi\) and \(\psi\) are true when
the assignment \(g\) is used. In the second clause assignments \(h\)
are introduced (by \(\sim_x g)\) which are equal to \(g\) except maybe
for the value they assign to variable \(x\). Montague uses the same
format, with the difference that besides \(g\) he also has \(i\), the
time of reference and \(j\), the possible world, as superscripts.
In the formulation of the clauses there is nothing which can be
pointed at as ‘the meaning’, in fact it is a definition of
truth with \(g\) and \(h\) as parameters. So how is it possible that
this (and Montague’s work) are compositional?
The answer requires a shift in perspective. The meaning of a formula
\(\varphi\), shortly \(M(\varphi)\), is the set of assignments for
which the formula is true. Then the first clause says that
so a simple set-theoretic combination on the two meanings is
performed. And
i.e., \(\{g \mid \text{for some }h \in
M(\varphi), g \sim_x h \}\), which can be described as: extend the set
\(M(\varphi)\) with all \(x\)-variants. (The reference to
‘\(x\)’ may be felt as problematic, but Montague even
eliminated this trace of non-compositionality by assigning appropriate
meanings to variables; see Zimmermann and Sternefeld 2013, ch. 10, for
pertinent details.) In general, in Montague semantics the meaning of
an expression is a function which has as domain the triples
\(\langle\)moment of time, possible world, assignment to
variables\(\rangle\).
Is it possible to achieve compositionality for natural language?
Obvious candidates for counterexamples are idioms, because their
meanings seem not to be built from their constituting words. However,
Westerståhl (2002) presents a collection of methods, varying
from compound basic expressions, to deviant meanings for constituting
parts. Janssen (1997) refutes several other counterexamples that are
put forward in the literature.
How strong is compositionality? Mathematical results show that any
language can be given a compositional semantics, either by using an
unorthodox syntax (Janssen 1997) or by using an unorthodox semantics
(Zadrozny 1994). However their proofs are not helpful in practice.
Hodges (2001) showed under which circumstances a given compositional
semantics for a fragment can be extended to a larger language.
There is no general agreement among formal semanticists about the role
and status of compositionality; at least the following four positions
have been held (nearly the same list is given in Partee 1996):
An extensive discussion of compositionality is given in Janssen 1997,
and in the entry on
 compositionality.
According to Montague, the purpose of syntax is to provide the input
to semantics:
Although syntax was in his eyes subordinate, he was fully explicit in
his rules in which he used some ad hoc syntactic tools.
In Montague 1970a and 1970c, the relation between syntactic categories
and semantic types is given only by a list. Montague (1973) defines a
systematic relation which amounts to the same relation as one would
have in categorial grammar. However, Montague’s syntax is not a
categorial syntax because the rules are not always category driven and
because some of the rules are not concatenation rules.
For each of these two aspects, proposals have been put forward to
change the situation. One direction was to stay closer to the ideals
of categorial grammar, with only type-driven rules, sometimes allowing
for a restricted extension of the power of concatenation rules (see,
for example, Morrill 1994, Carpenter 1998). The other approach was to
incorporate in Montague grammar as much as possible the insights from
syntactic theories, especially originating from the tradition of
Chomsky. A first step was made by Partee (1973), who let the grammar
produce structures (labelled bracketings); a syntactically
sophisticated grammar (with Chomskyan movement rules) was used in the
Rosetta translation project (Rosetta 1994). The influential textbook
by Heim and Kratzer (1998) combined the two approaches by applying
type-driven interpretation to the syntactic level of (Chomskyan)
Logical Forms.
In his syntactic accounts, Montague tended to treat
‘logical‘ words like determiners (the, a,
every) and conjunctions (and, or, not)
syncategorematically, i.e., not by means of lexical entries, but as
the effect of specific syntactic rules; the reason for this decision
is unknown, but it may be speculated that it was part of a
characterization of grammatical meaning in terms of logicality,
presumably along the lines of Tarski’s 1986 invariance
criterion. As a consequence, a different rule is needed for John
walks and sings than for John walks and Mary sings:
syntactically the first one is a conjunction of verb phrases and the
second one of sentences. However, the two meanings of and are
closely related and a generalization is missed. As a general solution
it was proposed to use rules (or alternatively general principles)
that change the category of an expression – a change that
corresponds with a semantic rule that ‘lifts’ the meaning.
For instance, the meaning of and as a connective between verb
phrases is obtained by lifting the meaning of the sentence connective
\(\wedge\) to \(\lambda P\lambda Q\lambda x[P(x) \wedge Q(x)].\) The
line of analysis has been extensively studied in Partee and Rooth
1983, Partee 1987, Hendriks 2001, and Winter 2001.
Montague’s method of defining fragments with a fully explicit
syntax has become far less popular than it was in the heyday of
Montague Grammar in the 1980s. Nowadays semanticists prefer to focus
on specific phenomena, suggesting rules which are only explicit
concerning the semantic side. This tendency has been criticized by
Partee in Janssen 1997 and Jacobson 2014, where a fragment is actually
provided.
The truth conditions of sentences sometimes vary with the context of
use. Thus, whether I am happy is true, depends on who the
speaker is; other examples include the referents of here and
this. Montague (1968; 1970b) addressed these factors,
indicating that they could be treated by introducing additional
parameters besides the time and the possible world. Despite occasional
critcism (Cresswell 1973, 111; Lewis 1980, 86f.), the treatment of
contextual dependence by way of a fixed finite list of parameters has
become quite standard in formal semantics.
Montague initially treated contextual parameters on a par with times
and worlds, but in ‘Universal Grammar’ (Montague 1970c) he
indicated that a distinction should be made between those that
determine the content (which, following Frege 1892, is what is denoted
in indirect contexts) from those that constitute it:
While these remarks are still a far cry from double-indexing
approaches to context dependence (Kamp 1971), they do exhibit the
basic idea underlying the shiftability criterion for distinguishing
context and index (Lewis 1980). In particular, Montague’s
meanings share a core feature with Kaplan’s (1989) characters:
both map paramteterized contexts to propositions, understood as
(characteristic functions of) sets of possible worlds.
Montague (1970c, 68) followed Bar-Hillel 1954 in treating context
dependence as part of pragmatics. It was only after his death, that
his framework was connected to other aspects of pragmatics. In
particular, in early work on Montague grammar, various proposals were
made to give compositional characterizations of presuppositions and
(conventional) implicatures (Peters 1979; Karttunen and Peters 1979),
but later treatments were not always completely compositional, taking
several contextual factors into account (Beaver 1997). In a similar
vein, early work in the tradition was rather optimistic about directly
applying Montague semantics to non-declarative uses of (declarative)
sentences (Cresswell 1973), but later accounts had to invoke a lot
more than linguistic meaning, including models of interlocutors’
perspectives (Gunlogson 2003).
Montague’s semantic analyses were given in terms of a
type-logical hierarchy whose basic ingredients were truth values,
possible individuals, and possible worlds. While the exact nature of
individuals and worlds depends on the (arbitrary) choice of a
particular model (or ‘Fregean interpretation’), the truth
values 1 (true) and 0 (false) transcend the class of all models, thus
emphasizing their status as logical objects. A lot of work in current
linguistic semantics still applies Montague’s type-logical
hierarchy, which is however often enriched by events (or,
more generally: eventualities) that serve as the referents of
verbs and verb phrases (Bach 1986a; Parsons 1990).
In early work on intensional analysis (Carnap 1947, Kaplan 1964),
possible worlds had been identified with models of a suitable
extensional language. For reasons indicated in section 3.1, Montague
(1969, 164) broke with this tradition, appealing to Kripke’s
account of modality based on possible worlds as unstructured basic
objects. In his essay ‘On the nature of certain philosophical
entities’ (Montague 1969), he argued that this seemingly minor
technical innovation opens a new perspective in philosophical
analysis, by reducing certain ‘dubious’ entities to
predicate intensions or properties – functions mapping
possible worlds to sets of objects. The idea was that, once the
conceptual and techical problems of the semantics of intensional
languages had been overcome, they may replace extensional predicate
logic as a basis of philosophical argument:
Montague illustrated his claim by detailed analyses of (talk about)
pains, tasks, obligations, and events in terms of second-order
intensional logic, which contained the core elements of his (slightly)
later compositional interpretation of English.
Although it has since become common in linguistic semantics to analyse
content in terms of possible worlds, they are not always taken to be
totally devoid of structure. As a case in point, Kratzer (2002) has
argued that the verb know relates subjects to facts and thus
its interpretation requires appeal to the mereology of worlds: facts
are concrete parts worlds. Moreover, as in Kripke’s original
approach, semantic theory frequently imposes some external structure
on logical space. Thus, accessibility relations and distance measures
between worlds are invoked to account for, respectively, propositional
attitudes (along the lines of Hinitkka 1969) and counterfactual
conditionals (following Lewis 1973). In a similar vein, the universe
of individuals (or ‘entities’, in Montague’s
parlance) nowadays gives way to a richer domain of structured objects,
including substances and their parts, which may serve as extensions of
mass nouns such as water (Pelletier & Schubert 2003), as
well as groups and their members, which are denoted by plural noun
phrases (Link 1983). Also when properties (loving John) are
considered as entities for which predicates may hold (Mary likes
loving John), additional structure is needed: property theory
gives the tools to incorporate them (Turner 1983).
Occasional doubts have been raised as to the adequacy of
Montague’s higher-order intensional logic as a tool for the
semantic interpretation of natural language:
This objection does not appreciate the role played by higher-order
abstraction in compositional semantics, which is not to form sentences
about higher-order functions. Rather, \(\lambda\)-abstraction is used
as a heuristic tool to describe compositional contributions of
expressions to larger syntactic environments (cf. Zimmermann 2021,
sec. 2.1). Thus, e.g., the extension of a determiner is defined as its
contribution to the truth value of a sentence in which it occurs (in
subject position), which can be described in terms of the extensions
of the nouns and verb phrases it combines with – and these
extensions are themselves sets (by a similar reasoning). The abstract
higher-order objects are thus merely convenient ways of describing the
kinematics of compositionality and do not serve as the objects that
the sentences of the language so described are about, or that its
terms refer to. As a case in point, it can be shown that even though
the (indirect) interpretation of the English fragment of Montague 1973
makes use of \(\lambda\)-abstraction over second-order variables, its
expressive power is much weaker than higher-order type logic and does
not even have the resources to formulate certain meaning postulates to
which its lexical items abide (Zimmermann 1983). In fact,
Hintikka’s alternative (game-theoretical) semantics fares no
better once it is formulated in a compositional way (see Hodges 1997
or Caicedo et al. 2009).
Montague revolutionized the field of semantic theory. He introduced
methods and tools from mathematical logic, and set standards for
explicitness in semantics. Now all semanticists know that logic has
more to offer than first-order logic only.
A recent introduction is Jacobson 2014. It is a gentle introduction to
the field, especially for linguists and philosophers. It presents
several successes obtained by the approach. Older introductions are
Dowty et al. 1981 and Gamut 1991, which are more technical
and prepare for Montague’s original papers. An overview of the
history of the field is given by Partee and Hendriks (1997) as well as
Partee (2011); Caponigro (forthcoming) provides an extensive
biographical background on Montague. Collections of important papers
are Portner and Partee (eds.) 2002 and Partee 2004; further
information is provided in the volume edited by McNally and
Szabó (forthcoming). The ‘Handbook of
compositionality’(Werning et al. 2011) discusses many aspects of
the approach. The most important journals in the field are
Linguistics and Philosophy, the Journal of
Semantics, Natural Language Semantics, and Semantics
and Pragmatics.
A small example is presented below, it consists of the two sentences
John is singing, and Every man is singing. The
example is not presented in Montague’s original way, but
modernized: there is a lifting rule, the determiner is a basic
expression, and intensional aspects are not considered.
The grammar has four basic expressions:
The grammar has three rules.
The example given with the last rule helps us to understand the
formula for every : that denotes a relation between
properties \(A\) and \(B\) which holds in case every \(A\) has
property \(B\).
The next step is now easy. Apply the rule for combining a Noun Phrase
and an Intransitive Verb to the last result, producing Every man
is singing. The output of the semantic rule is \(\lambda Q\forall
x[\textbf{man}(x) \rightarrow Q(x)](\textbf{sing})\). By lambda
conversion we obtain \(\forall x[\textbf{man}(x) \rightarrow
\textbf{sing}(x)],\) which is the traditional logical representation
of Every man is singing.
Note the role of lambda-operators: