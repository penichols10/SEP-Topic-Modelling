There are three components to the traditional
(“tripartite”) analysis of knowledge. According to this
analysis, justified, true belief is necessary and sufficient for
knowledge.
The tripartite analysis of knowledge is often abbreviated as the
“JTB” analysis, for “justified true
belief”.
Much of the twentieth-century literature on the analysis of knowledge
took the JTB analysis as its starting-point. It became something of a
convenient fiction to suppose that this analysis was widely accepted
throughout much of the history of philosophy. In fact, however, the
JTB analysis was first articulated in the twentieth century by its
 attackers.[1]
 Before turning to influential twentieth-century
arguments against the JTB theory, let us briefly consider the three
traditional components of knowledge in turn.
Most epistemologists have found it overwhelmingly plausible that what
is false cannot be known. For example, Hillary Clinton did not win the
2016 US Presidential election. Consequently, nobody knows that Hillary
Clinton won the election. One can only know things that are true.
Sometimes when people are very confident of something that turns out
to be wrong, we use the word “knows” to describe their
situation. Many people expected Clinton to win the election. Speaking
loosely, one might even say that many people “knew” that
Clinton would win the election—until she lost. Hazlett (2010)
argues on the basis of data like this that “knows” is not
a factive
 verb.[2]
 Hazlett’s diagnosis is deeply controversial; most
epistemologists will treat sentences like “I knew that Clinton
was going to win” as a kind of exaggeration—as not
literally true.
Something’s truth does not require that anyone can know or prove
that it is true. Not all truths are established truths. If
you flip a coin and never check how it landed, it may be true that it
landed heads, even if nobody has any way to tell. Truth is a
metaphysical, as opposed to epistemological, notion:
truth is a matter of how things are, not how they can be
shown to be. So when we say that only true things can be
known, we’re not (yet) saying anything about how anyone can
access the truth. As we’ll see, the other conditions
have important roles to play here. Knowledge is a kind of relationship
with the truth—to know something is to have a certain kind of
access to a
 fact.[3]
The belief condition is only slightly more controversial than the
truth condition. The general idea behind the belief condition is that
you can only know what you believe. Failing to believe something
precludes knowing it. “Belief” in the context of the JTB
theory means full belief, or outright belief. In a
weak sense, one might “believe” something by virtue of
being pretty confident that it’s probably true—in this
weak sense, someone who considered Clinton the favourite to win the
election, even while recognizing a nontrivial possibility of her
losing, might be said to have “believed” that Clinton would win.
Outright belief is stronger (see, e.g., Fantl & McGrath 2009: 141;
Nagel 2010: 413–4; Williamson 2005: 108; or Gibbons 2013: 201.).
To believe outright that p, it isn’t enough to have a
pretty high confidence in p; it is something closer to a
commitment or a being
 sure.[4]
Although initially it might seem obvious that knowing that p
requires believing that p, a few philosophers have argued that
knowledge without belief is indeed possible. Suppose Walter comes home
after work to find out that his house has burned down. He says:
“I don’t believe it”. Critics of the belief
condition might argue that Walter knows that his house has burned down
(he sees that it has), but, as his words indicate, he does not believe
it. The standard response is that Walter’s avowal of disbelief
is not literally true; what Walter wishes to convey by saying “I
don’t believe it” is not that he really does not believe
that his house has burned down, but rather that he finds it hard to
come to terms with what he sees. If he genuinely didn’t believe
it, some of his subsequent actions, such as phoning his insurance
company, would be rather mysterious.
A more serious counterexample has been suggested by Colin Radford
(1966). Suppose Albert is quizzed on English history. One of the
questions is: “When did Queen Elizabeth die?” Albert
doesn’t think he knows, but answers the question correctly.
Moreover, he gives correct answers to many other questions to which he
didn’t think he knew the answer. Let us focus on Albert’s
answer to the question about Elizabeth:
Radford makes the following two claims about this example:
Radford’s intuitions about cases like these do not seem to be
idiosyncratic; Myers-Schutz & Schwitzgebel (2013) find evidence
suggesting that many ordinary speakers tend to react in the way
Radford suggests. In support of (a), Radford emphasizes that Albert
thinks he doesn’t know the answer to the question. He
doesn’t trust his answer because he takes it to be a mere guess.
In support of (b), Radford argues that Albert’s answer is not at
all just a lucky guess. The fact that he answers most of the questions
correctly indicates that he has actually learned, and never forgotten,
such historical facts.
Since he takes (a) and (b) to be true, Radford holds that belief is not necessary for knowledge. But either of (a) and (b) might be resisted. One might deny (a), arguing that Albert does have a tacit belief that (E), even though it’s not one that he thinks amounts to knowledge. David Rose and Jonathan Schaffer (2013) take this route. Alternatively, one might deny (b), arguing that Albert’s correct answer is not an expression of knowledge, perhaps because, given his subjective position, he does not have justification for believing (E). The justification condition is the topic of the next section.
 
Why is condition (iii) necessary? Why not say that knowledge is true
belief? The standard answer is that to identify knowledge with true
belief would be implausible because a belief might be true even though
it is formed improperly. Suppose that William flips a coin, and
confidently believes—on no particular basis—that it will
land tails. If by chance the coin does land tails, then
William’s belief was true; but a lucky guess such as this one is
no knowledge. For William to know, his belief must in some epistemic
sense be proper or appropriate: it must be
 justified.[5]
Socrates articulates the need for something like a justification
condition in Plato’s Theaetetus, when he points out
that “true opinion” is in general insufficient for
knowledge. For example, if a lawyer employs sophistry to induce a jury
into a belief that happens to be true, this belief is insufficiently
well-grounded to constitute knowledge.
There is considerable disagreement among epistemologists concerning
what the relevant sort of justification here consists in.
Internalists about justification think that whether a belief
is justified depends wholly on states in some sense internal
to the subject. According to one common such sense of
“internal”, only those features of a subject’s
experience which are directly or introspectively available count as
“internal”—call this “access
internalism”. According to another, only intrinsic states of the
subject are “internal”—call this “state
internalism”. See Feldman & Conee 2001
for the distinction.
Conee and Feldman present an example of an internalist view. They have
it that S’s belief that p is justified if and only
if believing that p is the attitude towards p that best
fits S’s evidence, where the latter is understood to
depend only on S’s internal mental states. Conee and
Feldman call their view “evidentialism”, and characterize
this as the thesis that justification is wholly a matter of the
subject’s evidence. Given their (not unsubstantial) assumption
that what evidence a subject has is an internal matter, evidentialism
implies
 internalism.[6]
Externalists about justification think that factors external
to the subject can be relevant for justification; for example, process
reliabilists think that justified beliefs are those which are formed
by a cognitive process which tends to produce a high proportion of
true beliefs relative to false
 ones.[7]
 We shall return to the question of how reliabilist approaches bear on
the analysis of knowledge in
 §6.1.
It is worth noting that one might distinguish between two importantly
different notions of justification, standardly referred to as
“propositional justification” and “doxastic
justification”. (Sometimes “ex ante”
justification and “ex post” justification,
 respectively.)[8]
 Unlike that between internalist and externalist approaches to
justification, the distinction between propositional and doxastic
justification does not represent a conflict to be resolved; it is a
distinction between two distinct properties that are called
“justification”. Propositional justification concerns
whether a subject has sufficient reason to believe a given
 proposition;[9]
 doxastic justification concerns whether a given belief is held
 appropriately.[10]
 One common way of relating the two is to suggest that propositional
justification is the more fundamental, and that doxastic justification
is a matter of a subject’s having a belief that is appropriately
responsive to or based on their propositional justification.
The precise relation between propositional and doxastic justification
is subject to controversy, but it is uncontroversial that the two
notions can come apart. Suppose that Ingrid ignores a great deal of
excellent evidence indicating that a given neighborhood is dangerous,
but superstitiously comes to believe that the neighborhood is
dangerous when she sees a black cat crossing the street. Since forming
beliefs on the basis of superstition is not an epistemically
appropriate way of forming beliefs, Ingrid’s belief is not
doxastically justified; nevertheless, she does have good
reason to believe as she does, so she does have propositional
justification for the proposition that the neighborhood is
dangerous.
Since knowledge is a particularly successful kind of belief, doxastic
justification is a stronger candidate for being closely related to
knowledge; the JTB theory is typically thought to invoke doxastic
justification (but see Lowy 1978).
Some epistemologists have suggested that there may be multiple senses
of the term “knowledge”, and that not all of them require
all three elements of the tripartite theory of knowledge. For example,
some have argued that there is, in addition to the sense of
“knowledge” gestured at above, another, weak
sense of “knowledge”, that requires only true belief (see
for example Hawthorne 2002 and Goldman & Olsson 2009; the latter
contains additional relevant references). This view is sometimes
motivated by the thought that, when we consider whether someone knows
that p, or wonder which of a group of people know that
p, often, we are not at all interested in whether the relevant
subjects have beliefs that are justified; we just want to know whether
they have the true belief. For example, as Hawthorne (2002:
253–54) points out, one might ask how many students know that
Vienna is the capital of Austria; the correct answer, one might think,
just is the number of students who offer “Vienna” as the
answer to the corresponding question, irrespective of whether their
beliefs are justified. Similarly, if you are planning a surprise party
for Eugene and ask whether he knows about it, “yes” may be
an appropriate answer merely on the grounds that Eugene believes that
you are planning a party.
One could allow that there is a lightweight sense of knowledge that
requires only true belief; another option is to decline to accept the
intuitive sentences as true at face value. A theorist might, for
instance, deny that sentences like “Eugene knows that you are
planning a party”, or “eighteen students know that Vienna
is the capital of Austria” are literally true in the envisaged
situations, explaining away their apparent felicity as loose talk or
hyperbole.
Even among those epistemologists who think that there is a lightweight
sense of “knows” that does not require justification, most
typically admit that there is also a stronger sense which does, and
that it is this stronger state that is the main target of
epistemological theorizing about knowledge. In what follows, we will
set aside the lightweight sense, if indeed there be one, and focus on
the stronger one.
Few contemporary epistemologists accept the adequacy of the JTB
analysis. Although most agree that each element of the tripartite
theory is necessary for knowledge, they do not seem
collectively to be sufficient. There seem to be cases of
justified true belief that still fall short of knowledge. Here is one
kind of example:
Imagine that we are seeking water on a hot day. We suddenly see water,
or so we think. In fact, we are not seeing water but a mirage, but
when we reach the spot, we are lucky and find water right there under
a rock. Can we say that we had genuine knowledge of water? The answer
seems to be negative, for we were just lucky. (quoted from Dreyfus
1997: 292)
This example comes from the Indian philosopher Dharmottara, c. 770 CE.
The 14th-century Italian philosopher Peter of Mantua
presented a similar case:
Let it be assumed that Plato is next to you and you know him to be
running, but you mistakenly believe that he is Socrates, so that you
firmly believe that Socrates is running. However, let it be so that
Socrates is in fact running in Rome; however, you do not know this.
(from Peter of Mantua’s De scire et dubitare, given in
Boh 1985: 95)
Cases like these, in which justified true belief seems in some
important sense disconnected from the fact, were made famous in Edmund
Gettier’s 1963 paper, “Is Justified True Belief
Knowledge?”. Gettier presented two cases in which a true belief
is inferred from a justified false belief. He observed that,
intuitively, such beliefs cannot be knowledge; it is merely lucky that
they are true.
In honour of his contribution to the literature, cases like these have
come to be known as “Gettier cases”. Since they appear to
refute the JTB analysis, many epistemologists have undertaken to
repair it: how must the analysis of knowledge be modified to
accommodate Gettier cases? This is what is commonly referred to as the
“Gettier problem”.
Above, we noted that one role of the justification is to rule out
lucky guesses as cases of knowledge. A lesson of the Gettier problem
is that it appears that even true beliefs that are justified can
nevertheless be epistemically lucky in a way inconsistent with
knowledge.
Epistemologists who think that the JTB approach is basically on the
right track must choose between two different strategies for solving
the Gettier problem. The first is to strengthen the justification
condition to rule out Gettier cases as cases of justified belief. This
was attempted by Roderick
 Chisholm;[11]
 we will refer to this strategy again in
 §7
 below. The other is to amend the JTB analysis with a suitable fourth
condition, a condition that succeeds in preventing justified true
belief from being “gettiered”. Thus amended, the JTB
analysis becomes a JTB+X account of knowledge, where the
“X” stands for the needed fourth condition.
Let us consider an instance of this attempt to articulate a
“degettiering” condition.
According to one suggestion, the following fourth condition would do
the trick:
In Gettier’s cases, the justified true belief is inferred from a
justified false belief. So condition (iv) explains why it isn’t
knowledge. However, this “no false lemmas” proposal is not
successful in general. There are examples of Gettier cases that need
involve no inference; therefore, there are possible cases of justified
true belief without knowledge, even though condition (iv) is met.
Suppose, for example, that James, who is relaxing on a bench in a
park, observes an apparent dog in a nearby field. So he believes
Suppose further that the putative dog is actually a robot dog so
perfect that it could not be distinguished from an actual dog by
vision alone. James does not know that such robot dogs exist; a
Japanese toy manufacturer has only recently developed them, and what
James sees is a prototype that is used for testing the public’s
response. Given these assumptions, (d) is of course false. But suppose
further that just a few feet away from the robot dog, there is a real
dog, concealed from James’s view. Given this further assumption,
James’s belief in (d) is true. And since this belief is based on
ordinary perceptual processes, most epistemologists will agree that it
is justified. But as in Gettier’s cases, James’s
belief appears to be true only as a matter of luck, in a way
inconsistent with knowledge. So once again, what we have before us is
a justified true belief that isn’t
 knowledge.[13]
 Arguably, this belief is directly justified by a visual experience;
it is not inferred from any falsehood. If so, then the JTB account,
even if supplemented with (iv), gives us the wrong result that James
knows (d).
Another case illustrating that clause (iv) won’t do the job is
the well-known Barn County case (Goldman 1976). Suppose there is a
county in the Midwest with the following peculiar feature. The
landscape next to the road leading through that county is peppered
with barn-facades: structures that from the road look exactly like
barns. Observation from any other viewpoint would immediately reveal
these structures to be fakes: devices erected for the purpose of
fooling unsuspecting motorists into believing in the presence of
barns. Suppose Henry is driving along the road that leads through Barn
County. Naturally, he will on numerous occasions form false beliefs in
the presence of barns. Since Henry has no reason to suspect that he is
the victim of organized deception, these beliefs are justified. Now
suppose further that, on one of those occasions when he believes there
is a barn over there, he happens to be looking at the one and only
real barn in the county. This time, his belief is justified and true.
But since its truth is the result of luck, it is exceedingly plausible
to judge that Henry’s belief is not an instance of knowledge.
Yet condition (iv) is met in this case. His belief is not the result
of any inference from a falsehood. Once again, we see that (iv) does
not succeed as a general solution to the Gettier problem.
Another candidate fourth condition on knowledge is
sensitivity. Sensitivity, to a first approximation, is this
counterfactual relation:
S’s belief that p is sensitive if and only if, if
p were false, S would not believe that
 p.[14]
A sensitivity condition on knowledge was defended by Robert Nozick
(1981). Given a Lewisian (Lewis 1973) semantics for counterfactual
conditionals, the sensitivity condition is equivalent to the
requirement that, in the nearest possible worlds in which
not-p, the subject does not believe that p.
One motivation for including a sensitivity condition in an analysis of
knowledge is that there seems to be an intuitive sense in which
knowledge requires not merely being correct, but tracking the
truth in other possible circumstances. This approach seems to be a
plausible diagnosis of what goes wrong in at least some Gettier cases.
For example, in Dharmottara’s desert water case, your belief
that there is water in a certain location appears to be insensitive to
the fact of the water. For if there were no water there, you would
have held the same belief on the same grounds—viz., the
mirage.
However, it is doubtful that a sensitivity condition can account for
the phenomenon of Gettier cases in general. It does so only in cases
in which, had the proposition in question been false, it would have
been believed anyway. But, as Saul Kripke (2011: 167–68) has
pointed out, not all Gettier cases are like this. Consider for
instance the Barn County case mentioned above. Henry looks at a
particular location where there happens to be a barn and believes
there to be a barn there. The sensitivity condition rules out this
belief as knowledge only if, were there no barn there, Henry would
still have believed there was. But this counterfactual may be false,
depending on how the Barn County case is set up. For instance, it is
false if the particular location Henry is examining is not one that
would have been suitable for the erecting of a barn façade.
Relatedly, as Kripke has also indicated (2011: 186), if we suppose
that barn facades are always green, but genuine barns are always red,
Henry’s belief that he sees a red barn will be
sensitive, even though his belief that he sees a barn will
not. (We assume Henry is unaware that colour signifies anything
relevant.) Since intuitively, the former belief looks to fall short of
knowledge in just the same way as the latter, a sensitivity condition
will only handle some of the intuitive problems deriving from Gettier
cases.
Most epistemologists today reject sensitivity requirements on
knowledge. The chief motivation against a sensitivity condition is
that, given plausible assumptions, it leads to unacceptable
implications called “abominable 
 conjunctions”.[15]
 To see this, suppose first that
skepticism about ordinary knowledge is false—ordinary subjects
know at least many of the things we ordinarily take them to know. For
example, George, who can see and use his hands perfectly well, knows
that he has hands. This is of course perfectly consistent with a
sensitivity condition on knowledge, since if George did not
have hands—if they’d been recently chopped off, for
instance—he would not believe that he had hands.
Now imagine a skeptical scenario in which George does not have hands.
Suppose that George is the victim of a Cartesian demon, deceiving him
into believing that he has hands. If George were in such a scenario,
of course, he would falsely believe himself not to be in such a
scenario. So given the sensitivity condition, George cannot know that
he is not in such a scenario.
Although these two verdicts—the knowledge-attributing one about
ordinary knowledge, and the knowledge-denying one about the skeptical
scenario—are arguably each intuitive, it is intuitively
problematic to hold them together. Their conjunction is, in
DeRose’s term, abominable: “George knows that he has
hands, but he doesn’t know that he’s not the handless
victim of a Cartesian demon”. A sensitivity condition on
knowledge, combined with the nonskeptical claim that there is ordinary
knowledge, seems to imply such abominable
 conjunctions.[16]
Most contemporary epistemologists have taken considerations like these
to be sufficient reason to reject sensitivity 
 conditions.[17]
 However, see
Ichikawa (2011a) for an interpretation and endorsement of the
sensitivity condition according to which it may avoid commitment to
abominable conjunctions.
Although few epistemologists today endorse a sensitivity condition on
knowledge, the idea that knowledge requires a subject to stand in a
particular modal relation to the proposition known remains a popular
one. In his 1999 paper, “How to Defeat Opposition to
Moore”, Ernest Sosa proposed that a safety condition
ought to take the role that sensitivity was intended to play. Sosa
characterized safety as the counterfactual contrapositive of
sensitivity.
Sensitivity:
If p were false, S would not believe that p.
Safety:
If S were to believe that p, p would not be
 false.[18]
Although contraposition is valid for the material conditional \((A
\supset B\) iff \(\mathord{\sim} B \supset \mathord{\sim}A)\),
Sosa suggests that it is invalid for counterfactuals, which is why
sensitivity and safety are not equivalent. An example of a safe belief
that is not sensitive, according to Sosa, is the belief that a distant
skeptical scenario does not obtain. If we stipulate that George,
discussed above, has never been at risk of being the victim of a
Cartesian demon—because, say, Cartesian demons do not exist in
George’s world—then George’s belief that he is not
such a victim is a safe one, even though we saw in the previous
section that it could not be sensitive. Notice that although we
stipulated that George is not at risk of deceit by Cartesian demons,
we did not stipulate that George himself had any particular
access to this fact. Unless he does, safety, like sensitivity, will be
an externalist condition on knowledge in the
“access” sense. It is also externalist in the
“state” sense, since the truth of the relevant
counterfactuals will depend on features outside the subject.
Characterizing safety in these counterfactual terms depends on
substantive assumptions about the semantics of counterfactual
 conditionals.[19]
 If we were to accept, for instance, David Lewis’s or Robert
Stalnaker’s treatment of counterfactuals, including a strong
centering condition according to which the actual world is always
uniquely closest, all true beliefs would count as safe according to
the counterfactual analysis of
 safety.[20]
 Sosa intends the relevant counterfactuals to be making a stronger
claim, requiring roughly that in all nearby worlds in which
S believes that p, p is not false.
Rather than resting on a contentious treatment of counterfactuals,
then, it may be most perspicuous to understand the safety condition
more directly in these modal terms, as Sosa himself often does:
Safety:
In all nearby worlds where S believes that p, p
is not false.
Whether a JTB+safety analysis of knowledge could be successful is
somewhat difficult to evaluate, given the vagueness of the stated
“nearby” condition. The status of potential
counterexamples will not always be straightforward to apply. For
example, Juan Comesaña (2005) presents a case he takes to
refute the requirement that knowledge be safe. In
Comesaña’s example, the host of a Halloween party enlists
Judy to direct guests to the party. Judy’s instructions are to
give everyone the same directions, which are in fact accurate, but
that if she sees Michael, the party will be moved to another location.
(The host does not want Michael to find the party.) Suppose Michael
never shows up. If a given guest does not, but very nearly does,
decide to wear a very realistic Michael costume to the party, then his
belief, based in Judy’s testimony, about the whereabouts of the
party will be true, but could, Comesaña says, easily have been
false. (Had he merely made a slightly different choice about his
costume, he would have been deceived.) Comesaña describes the
case as a counterexample to a safety condition on knowledge. However,
it is open to a safety theorist to argue that the relevant skeptical
scenario, though possible and in some sense nearby, is not
near enough in the relevant respect to falsify the safety condition.
Such a theorist would, if she wanted the safety condition to deliver
clear verdicts, face the task of articulating just what the relevant
notion of similarity amounts to (see also Bogardus 2014).
Not all further clarifications of a safety condition will be suitable
for the use of the latter in an analysis of knowledge. In particular,
if the respect of similarity that is relevant for safety is itself
explicated in terms of knowledge, then an analysis of knowledge which
made reference to safety would be in this respect circular. This, for
instance, is how Timothy Williamson characterizes safety. He writes,
in response to a challenge by Alvin Goldman:
In many cases, someone with no idea of what knowledge is would be
unable to determine whether safety obtained. Although they could use
the principle that safety entails truth to exclude some cases, those
are not the interesting ones. Thus Goldman will be disappointed when
he asks what the safety account predicts about various examples in
which conflicting considerations pull in different directions. One may
have to decide whether safety obtains by first deciding whether
knowledge obtains, rather than vice versa. (Williamson 2009: 305)
Because safety is understood only in terms of knowledge, safety so
understood cannot serve in an analysis of knowledge. Nor is it
Williamson’s intent that it should do so; as we will see below,
Williamson rejects the project of analyzing knowledge. This is of
course consistent with claiming that safety is a necessary condition
on knowledge in the straightforward sense that the latter entails the
former.
A third approach to modal conditions on knowledge worthy of mention is
the requirement that for a subject to know that p, she must
rule out all “relevant alternatives” to p.
Significant early proponents of this view include Stine 1976, Goldman
1976, and Dretske 1981. The idea behind this approach to knowledge is
that for a subject to know that p, she must be able to
“rule out” competing hypotheses to p—but that only
some subset of all not-p possibilities are “relevant” for
knowledge attributions. Consider for example, the differences between
the several models that have been produced of Apple’s iPhone. To
be able to know by sight that a particular phone is the 6S model, it
is natural to suppose that one must be able to tell the difference
between the iPhone 6S and the iPhone 7; the possibility that the phone
in question is a newer model is a relevant alternative. But perhaps
there are other possibilities in which the belief that there is an
iPhone 6S is false that do not need to be ruled out—perhaps, for
instance, the possibility that the phone is not an iPhone, but a
Chinese knock-off, needn’t be considered. Likewise for the
possibility that there is no phone at all, the phone-like appearances
being the product of a Cartesian demon’s machinations. Notice
that in these cases and many of the others that motivate the
relevant-alternatives approach to knowledge, there is an intuitive
sense in which the relevant alternatives tend to be more
similar to actuality than irrelevant ones. As such, the
relevant alternatives theory and safety-theoretic approaches are very
similar, both in verdict and in spirit. As in the case of a safety
theorist, the relevant alternatives theorist faces a challenge in
attempting to articulate what determines which possibilities are
relevant in a given
 situation.[21]
As we have seen, one motivation for including a justification
condition in an analysis of knowledge was to prevent lucky guesses
from counting as knowledge. However, the Gettier problem shows that
including a justification condition does not rule out all
epistemically problematic instances of luck. Consequently, some
epistemologists have suggested that positing a justification condition
on knowledge was a false move; perhaps it is some other condition that
ought to be included along with truth and belief as components of
knowledge. This kind of strategy was advanced by a number of authors
from the late 1960s to the early 1980s, although there has been
relatively little discussion of it
 since.[22]
 Kornblith 2008 provides a notable exception.
One candidate property for such a state is reliability. Part
of what is problematic about lucky guesses is precisely that they are
so lucky: such guesses are formed in a way such that it is unlikely
that they should turn out true. According to a certain form of
knowledge reliabilism, it is unreliability, not lack of justification,
which prevents such beliefs from amounting to knowledge. Reliabilist
theories of knowledge incorporate this idea into a reliability
condition on
 knowledge.[23]
 Here is an example of such a view:
Simple K-Reliabilism:
S knows that p iff
Simple K-Reliabilism replaces the justification clause in the
traditional tripartite theory with a reliability clause. As we have
seen, reliabilists about justification think that justification for a
belief consists in a genesis in a reliable cognitive process. Given
this view, Simple K-Reliabilism and the JTB theory are equivalent.
However, the present proposal is silent on justification. Goldman 1979
is the seminal defense of reliabilism about justification; reliabilism
is extended to knowledge in Goldman 1986. See Goldman 2011 for a
survey of reliabilism in general.
In the following passage, Fred Dretske articulates how an approach
like K-reliabilism might be motivated:
Those who think knowledge requires something other than, or
at least more than, reliably produced true belief, something
(usually) in the way of justification for the belief that one’s
reliably produced beliefs are being reliably produced, have,
it seems to me, an obligation to say what benefits this justification
is supposed to confer…. Who needs it, and why? If an animal
inherits a perfectly reliable belief-generating mechanism, and it also
inherits a disposition, everything being equal, to act on the
basis of the beliefs so generated, what additional benefits are
conferred by a justification that the beliefs are being
produced in some reliable way? If there are no additional benefits,
what good is this justification? Why should we insist that no one can
have knowledge without it? (Dretske 1989: 95)
According to Dretske, reliable cognitive processes convey information,
and thus endow not only humans, but (nonhuman) animals as well, with
knowledge. He writes:
I wanted a characterization that would at least allow for the
possibility that animals (a frog, rat, ape, or my dog) could know
things without my having to suppose them capable of the more
sophisticated intellectual operations involved in traditional analyses
of knowledge. (Dretske 1985: 177)
It does seem odd to think of frogs, rats, or dogs as having justified
or unjustified beliefs. Yet attributing knowledge to animals is
certainly in accord with our ordinary practice of using the word
“knowledge”. So if, with Dretske, we want an account of
knowledge that includes animals among the knowing subjects, we might
want to abandon the traditional JTB account in favor of something like
K-reliabilism.
Another move in a similar spirit to K-Reliabilism replaces the
justification clause in the JTB theory with a condition requiring a
causal connection between the belief and the fact
 believed;[24]
 this is the approach of Goldman (1967,
 1976).[25]
 Goldman’s own causal theory is a sophisticated one; we will not
engage with its details here. See Goldman’s papers. Instead,
consider a simplified causal theory of knowledge, which illustrates
the main motivation behind causal theories.
Simple Causal Theory of Knowledge:
S knows that p iff
Do approaches like Simple K-Reliabilism or the Simple Causal Theory
fare any better than the JTB theory with respect to Gettier cases?
Although some proponents have suggested they do—see e.g.,
Dretske 1985: 179; Plantinga 1993: 48—many of the standard
counterexamples to the JTB theory appear to refute these views as
well. Consider again the case of the barn facades. Henry sees a real
barn, and that’s why he believes there is a barn nearby. This
belief is formed by perceptual processes, which are by-and-large
reliable: only rarely do they lead him into false beliefs. So it looks
like the case meets the conditions of Simple K-Reliabilism just as
much as it does those of the JTB theory. It is also a counterexample
to the causal theory, since the real barn Henry perceives is causally
responsible for his belief. There is reason to doubt, therefore, that
shifting from justification to a condition like reliability will
escape the Gettier
 problem.[26]
 Gettier cases seem to pose as much of a problem for K-reliabilism and
causal theories as for the JTB account. Neither theory, unless amended
with a clever “degettiering” clause, succeeds in stating
sufficient conditions for
 knowledge.[27]
Gettier’s paper launched a flurry of philosophical activity by
epistemologists attempting to revise the JTB theory, usually by adding
one or more conditions, to close the gap between knowledge and
justified true belief. We have seen already how several of these
attempts failed. When intuitive counterexamples were proposed to each
theory, epistemologists often responded by amending their theories,
complicating the existing conditions or adding new ones. Much of this
dialectic is chronicled thoroughly by Shope 1983, to which the
interested reader is directed.
After some decades of such iterations, some epistemologists began to
doubt that progress was being made. In her 1994 paper, “The
Inescapability of Gettier Problems”, Linda Zagzebski suggested
that no analysis sufficiently similar to the JTB analysis could ever
avoid the problems highlighted by Gettier’s cases. More
precisely, Zagzebski argued, any analysans of the form JTB+X,
where X is a condition or list of conditions logically
independent from justification, truth, and belief, would be
susceptible to Gettier-style counterexamples. She offered what was in
effect a recipe for constructing Gettier cases:
Zagzebski suggests that the resultant case will always represent an
intuitive lack of knowledge. So any non-redundant addition to the JTB
theory will leave the Gettier problem
 unsolved.[28]
 We may illustrate the application of the recipe using one of
Zagzebski’s own examples, refuting Alvin Plantinga’s
(1996) attempt to solve the Gettier problem by appending to the JTB
analysis a condition requiring that the subject’s faculties be
working properly in an appropriate environment.
In step one of Zagzebski’s procedure, we imagine a case in which
a subject’s faculties are working properly in an appropriate
environment, but the ensuing belief, though justified, is false.
Zagzebski invites us to imagine that Mary has very good
eyesight—good enough for her cognitive faculties typically to
yield knowledge that her husband is sitting in the living room. Such
faculties, even when working properly in suitable environments,
however, are not infallible—if they were, the condition would
not be independent from truth—so we can imagine a case in which
they go wrong. Perhaps this is an unusual instance in which
Mary’s husband’s brother, who looks a lot like the
husband, is in the living room, and Mary concludes, on the basis of
the proper function of her visual capacity, that her husband is in the
living room. This belief, since false, is certainly not knowledge.
In step two, we imagine Mary’s misidentification of the occupant
of the living room as before, but add to the case that the husband is,
by luck, also in the living room. Now Mary’s belief is true, but
intuitively, it is no more an instance of knowledge than the false
belief in the first step was.
Since the recipe is a general one, it appears to be applicable to any
condition one might add to the JTB theory, so long as it does not
itself entail truth. The argument generalizes against all
“non-redundant” JTB+X analyses.
One potential response to Zagzebski’s argument, and the failure
of the Gettier project more generally, would be to conclude that
knowledge is unanalyzable. Although it would represent a significant
departure from much analytic epistemology of the late twentieth
century, it is not clear that this is ultimately a particularly
radical suggestion. Few concepts of interest have proved susceptible
to traditional analysis (Fodor 1998). One prominent approach to
knowledge in this vein is discussed in
 §11
 below.
Another possible line is the one mentioned in
 §2—to
 strengthen the justification condition to rule out Gettier cases as
justified. In order for this strategy to prevent Zagzebski’s
recipe from working, one would need to posit a justification condition
that precludes the possibility of step one above—the only
obvious way to do this is for justification to entail truth. If it
does, then it will of course be impossible to start with a case that
has justified false belief. This kind of approach is not at all mainstream, but it does
have its defenders—see e.g., Sturgeon
1993 and Merricks
1995. Sutton 2007 and Littlejohn 2012 defend factive approaches to
justification on other grounds.
A third avenue of response would be to consider potential analyses of
knowledge that are not of the nonredundant form JTB+X. Indeed,
we have already seen some such attempts, albeit unsuccessful ones. For
instance, the causal theory of knowledge includes a clause requiring
that the belief that p be caused by the fact that p.
This condition entails both belief and truth, and so is not
susceptible to Zagzebski’s recipe. (As we’ve seen, it
falls to Gettier-style cases on other grounds.) One family of
strategies along these lines would build into an analysis of knowledge
a prohibition on epistemic luck directly; let us consider this sort of
move in more detail.
If the problem illustrated by Gettier cases is that JTB and JTB+
analyses are compatible with a degree of epistemic luck that is
inconsistent with knowledge, a natural idea is to amend one’s
analysis of knowledge by including an explicit “anti-luck”
condition. Zagzebski herself outlines this option in her 1994 (p. 72).
Unger 1968 gives an early analysis of this kind. For example:
S knows that p iff
The first thing to note about this analysis is that it is
“redundant” in the sense described in the previous
section; the fourth condition entails the first
 two.[29]
 So its surface form notwithstanding, it actually represents a
significant departure from the JTB+ analyses. Rather than composing
knowledge from various independent components, this analysis demands
instead that the epistemic states are related to one another in
substantive ways.
The anti-luck condition, like the safety condition of the previous
section, is vague as stated. For one thing, whether a belief is true
by luck comes in degrees—just how much luck does it take to be
inconsistent with knowledge? Furthermore, it seems, independently of
questions about degrees of luck, we must distinguish between different
kinds of luck. Not all epistemic luck is incompatible with
having knowledge. Suppose someone enters a raffle and wins an
encyclopedia, then reads various of its entries, correcting many of
their previous misapprehensions. There is a straightforward sense in
which the resultant beliefs are true only by luck—for our
subject was very lucky to have won that raffle—but this is not
the sort of luck, intuitively, that interferes with the possession of
 knowledge.[30]
 Furthermore, there is a sense in which our ordinary perceptual beliefs
are true by luck, since it is possible for us to have been the victim of a
Cartesian demon and so we are, in some sense, lucky not to be. But
unless we are to capitulate to radical skepticism, it seems that this
sort of luck, too, ought to be considered compatible with
 knowledge.[31]
Like the safety condition, then, a luck condition ends up being
difficult to apply in some cases. We might try to clarify the luck
condition as involving a distinctive notion of epistemic
luck—but unless we were able to explicate that notion—in
effect, to distinguish between the two kinds of luck mentioned
above—without recourse to knowledge, it is not clear that the
ensuing analysis of knowledge could be both informative and
noncircular.
As our discussion so far makes clear, one standard way of evaluating
attempted analyses of knowledge has given a central role to testing it
against intuitions against cases. In the late twentieth century, the
perceived lack of progress towards an acceptable
analysis—including the considerations attributed to Zagzebski in
§7 above—led some epistemologists to pursue other
methodological strategies. (No doubt, a wider philosophical trend away
from “conceptual analysis” more broadly also contributed
to this change.) Some of the more recent attempts to analyse knowledge
have been motivated in part by broader considerations about the role
of knowledge, or of discourse about knowledge.
One important view of this sort is that defended by Edward Craig
(1990). Craig’s entry-point into the analysis of knowledge was
not intuitions about cases, but rather a focus on the role that the
concept of knowledge plays for humans. In particular, Craig suggested
that the point of using the category of knowledge was for people to
flag reliable informants—to help people know whom to trust in
matters epistemic. Craig defends an account of knowledge that is
designed to fill this role, even though it is susceptible to intuitive
counterexamples. The plausibility of such accounts, with a less
intuitive extension but with a different kind of theoretical
justification, is a matter of controversy.
Another view worth mentioning in this context is that of Hilary
Kornblith (2002), which has it that knowledge is a natural kind, to be
analysed the same way other scientific kinds are. Intuition has a role
to play in identifying paradigms, but generalizing from there is an
empirical, scientific matter, and intuitive counterexamples are to be
expected.
The “knowledge first” stance is also connected to these
methodological issues. See §11 below.
The virtue-theoretic approach to knowledge is in some respects similar
to the safety and anti-luck approaches. Indeed, Ernest Sosa, one of
the most prominent authors of the virtue-theoretic approach, developed
it from his previous work on safety. The virtue approach treats
knowledge as a particularly successful or valuable form of belief, and
explicates what it is to be knowledge in such terms. Like the
anti-luck theory, a virtue-theoretic theory leaves behind the JTB+
project of identifying knowledge with a truth-functional combination
of independent epistemic properties; knowledge, according to this
approach, requires a certain non-logical relationship between belief
and truth.
Sosa has often (e.g., Sosa 2007: ch. 2) made use of an analogy of a
skilled archer shooting at a target; we may find it instructive as
well. Here are two ways in which an archer’s shot might be
evaluated:
The kind of success at issue in (1), Sosa calls accuracy. The
kind of skill discussed in (2), Sosa calls adroitness. A shot
is adroit if it is produced skillfully. Adroit shots needn’t be
accurate, as not all skilled shots succeed. And accurate shots
needn’t be adroit, as some unskilled shots are lucky.
In addition to accuracy and adroitness, Sosa suggests that there is
another respect in which a shot may be evaluated, relating the two.
This, Sosa calls aptness.
A shot is apt if it is accurate because adroit. Aptness
entails, but requires more than, the conjunction of accuracy and
adroitness, for a shot might be both successful and skillful without
being apt. For example, if a skillful shot is diverted by an
unexpected gust of wind, then redirected towards the target by a
second lucky gust, its ultimate accuracy does not manifest the skill,
but rather reflects the lucky coincidence of the wind.
Sosa suggests that this “AAA” model of evaluation is
applicable quite generally for the evaluation of any action or object
with a characteristic aim. In particular, it is applicable to belief
with respect to its aim at truth:
Sosa identifies knowledge with apt belief, so
 understood.[33]
 Knowledge entails both truth (accuracy) and justification
(adroitness), on this view, but they are not merely independent
components out of which knowledge is truth-functionally composed. It
requires that the skill explain the success. This is in some respects
similar to the anti-luck condition we have examined above, in that it
legislates that the relation between justification and truth be no
mere coincidence. However, insofar as Sosa’s “AAA”
model is generally applicable in a way going beyond epistemology,
there are perhaps better prospects for understanding the relevant
notion of aptness in a way independent of understanding knowledge
itself than we found for the notion of epistemic luck.
Understanding knowledge as apt belief accommodates Gettier’s
traditional counterexamples to the JTB theory rather
straightforwardly. When Smith believes that either Jones owns a Ford
or Brown is in Barcelona, the accuracy of his belief is not
attributable to his inferential skills (which the case does not call
into question). Rather, unlucky circumstances (the misleading evidence
about Jones’s car) have interfered with his skillful cognitive
performance, just as the first diverting gust of wind interfered with
the archer’s shot. Compensating for the unlucky interference, a
lucky circumstance (Brown’s coincidental presence in Barcelona)
renders the belief true after all, similar to the way in which the
second gust of wind returns the archer’s arrow back onto the
proper path towards the target.
Fake barn cases, by contrast, may be less easily accommodated by
Sosa’s AAA approach. When Henry looks at the only real barn in a
countryside full of barn facades, he uses a generally reliable
perceptual faculty for recognizing barns, and he goes right in this
instance. Suppose we say the accuracy of Henry’s belief
manifests his competence as a perceiver. If so, we would have to judge
that his belief is apt and therefore qualifies as an instance of
knowledge. That would be a problematic outcome because the intuition
the case is meant to elicit is that Henry does not have
knowledge. There are three ways in which an advocate of the AAA
approach might respond to this difficulty.
First, AAA advocates might argue that, although Henry has a general
competence to recognize barns, he is deprived of this ability in his
current environment, precisely because he is in fake barn county.
According to a second, subtly different strategy, Henry retains
barn-recognition competence, his current location notwithstanding,
but, due to the ubiquity of fake barns, his competence does not
manifest itself in his belief, since its truth is attributable more to
luck than to his skill in recognizing
 barns.[34]
 Third, Sosa’s own response to the problem is to bite the
bullet. Judging Henry’s belief to be apt, Sosa accepts the
outcome that Henry knows there is a barn before him. He attempts to
explain away the counterintuitiveness of this result by emphasizing
the lack of a further epistemically valuable state, which he calls
“reflective knowledge” (see Sosa 2007: 31–32).
Not every concept is analyzable into more fundamental terms. This is
clear both upon reflection on examples—what analysis could be
offered of hydrogen, animal, or John F.
Kennedy?—and on grounds of infinite regress. Why should we
think that knowledge has an analysis? In recent work,
especially his 2000 book Knowledge and Its Limits, Timothy
Williamson has argued that the project of analyzing knowledge was a
mistake. His reason is not that he thinks that knowledge is an
uninteresting state, or that the notion of knowledge is somehow
fundamentally confused. On the contrary, Williamson thinks that
knowledge is among the most fundamental psychological and
epistemological states there are. As such, it is a mistake to analyze
knowledge in terms of other, more fundamental epistemic notions,
because knowledge itself is, in at least many cases, more fundamental.
As Williamson puts it, we should put “knowledge first”.
Knowledge might figure into some analyses, but it will do so in the
analysans, not in the
 analysandum.[35]
There is no very straightforward argument for this conclusion; its
case consists largely in the attempted demonstration of the
theoretical success of the knowledge first stance. Weighing these
benefits against those of more traditional approaches to knowledge is
beyond the scope of this
 article.[36]
Although Williamson denies that knowledge is susceptible to analysis
in the sense at issue in this article, he does think that there are
interesting and informative ways to characterize knowledge. For
example, Williamson accepts these claims:
Williamson is also careful to emphasize that the rejection of the
project of analyzing knowledge in no way suggests that there are not
interesting and informative necessary or sufficient conditions on
knowledge. The traditional ideas that knowledge entails truth, belief,
and justification are all consistent with the knowledge first project.
And Williamson (2000: 126) is explicit in endorsement of a safety
requirement on knowledge—just not one that serves as part of an
analysis.
One point worth recognizing, then, is that one need not engage in the
ambitious project of attempting to analyze knowledge in order to have
contact with a number of interesting questions about which factors are
and are not relevant for whether a subject has knowledge. In the next
section, we consider an important contemporary debate about whether
pragmatic factors are relevant for knowledge.
Traditional approaches to knowledge have it that knowledge has to do
with factors like truth and justification. Whether knowledge requires
safety, sensitivity, reliability, or independence from certain kinds
of luck has proven controversial. But something that all of these
potential conditions on knowledge seem to have in common is that they
have some sort of intimate connection with the truth of the relevant
belief. Although it is admittedly difficult to make the relevant
connection precise, there is an intuitive sense in which every factor
we’ve examined as a candidate for being relevant to knowledge
has something to do with truth of the would-be knowledgeable
beliefs.
In recent years, some epistemologists have argued that focus on such
truth-relevant factors leaves something important out of our picture
of knowledge. In particular, they have argued that distinctively
pragmatic factors are relevant to whether a subject has
knowledge. Call this thesis “pragmatic
 encroachment”:[37]
Pragmatic Encroachment:
A difference in pragmatic circumstances can constitute a difference in
knowledge.
The constitution claim here is important; it is trivial that
differences in pragmatic circumstances can cause differences
in knowledge. For example, if the question of whether marijuana use is
legal in Connecticut is more important to Sandra than it is to Daniel,
Sandra is more likely to seek out evidence, and come to knowledge,
than Daniel is. This uninteresting claim is not what is at issue.
Pragmatic encroachment theorists think that the practical importance
itself can make for a change in knowledge, without reliance on such
downstream effects as a difference in evidence-gathering activity.
Sandra and Daniel might in some sense be in the same epistemic
position, where the only difference is that the question is more
important to Sandra. This difference, according to pragmatic
encroachment, might make it the case that Daniel knows, but Sandra
does
 not.[38]
Pragmatic encroachment can be motivated by intuitions about cases.
Jason Stanley’s 2005 book Knowledge and Practical
Interests argues that it is the best explanation for pairs of
cases like the following, where the contrasted cases are evidentially
alike, but differ pragmatically:
Low Stakes. Hannah and her wife Sarah are driving
home on a Friday afternoon. They plan to stop at the bank on the way
home to deposit their paychecks. It is not important that they do so,
as they have no impending bills. But as they drive past the bank, they
notice that the lines inside are very long, as they often are on
Friday afternoons. Realizing that it wasn’t very important that
their paychecks are deposited right away, Hannah says, “I know
the bank will be open tomorrow, since I was there just two weeks ago
on Saturday morning. So we can deposit our paychecks tomorrow
morning”.
High Stakes. Hannah and her wife Sarah are driving
home on a Friday afternoon. They plan to stop at the bank on the way
home to deposit their paychecks. Since they have an impending bill
coming due, and very little in their account, it is very important
that they deposit their paychecks by Saturday. Hannah notes that she
was at the bank two weeks before on a Saturday morning, and it was
open. But, as Sarah points out, banks do change their hours. Hannah
says, “I guess you’re right. I don’t know that the
bank will be open tomorrow”. (Stanley 2005: 3–4)
Stanley argues that the moral of cases like these is that in general,
the more important the question of whether p, the harder it is
to know that p. Other, more broadly theoretical, arguments for
pragmatic encroachment have been offered as well. Fantl & McGrath
(2009) argue that encroachment follows from fallibilism and plausible
principles linking knowledge and action, while Weatherson 2012 argues
that the best interpretation of decision theory requires
encroachment.
Pragmatic encroachment is not an analysis of knowledge; it is merely
the claim that pragmatic factors are relevant for determining whether
a subject’s belief constitutes knowledge. Some, but not all,
pragmatic encroachment theorists will endorse a necessary
biconditional that might be interpreted as an analysis of knowledge.
For example, a pragmatic encroachment theorist might claim that:
S knows that p if and only if no epistemic weakness
vis-á-vis p prevents S from properly using
p as a reason for action.
This connection between knowledge and action is similar to ones
endorsed by Fantl & McGrath (2009), but it is stronger than
anything they argue for.
Pragmatic encroachment on knowledge is deeply controversial. Patrick
Rysiew (2001), Jessica Brown (2006), and Mikkel Gerken (forthcoming) have
argued that traditional views about the nature of knowledge are
sufficient to account for the data mentioned above. Michael
Blome-Tillmann (2009a) argues that it has unacceptably
counterintuitive results, like the truth of such claims as
S knows that p, but if it were more important, she
wouldn’t know, or S knew that p until the
question became important. Stanley (2005) offers strategies for
accepting such consequences. Other, more theoretical arguments against
encroachment have also been advanced; see for example Ichikawa,
Jarvis, and Rubin (2012), who argue that pragmatic encroachment is at
odds with important tenets of belief-desire psychology.
One final topic standing in need of treatment is contextualism about
knowledge attributions, according to which the word
“knows” and its cognates are context-sensitive. The
relationship between contextualism and the analysis of knowledge is
not at all straightforward. Arguably, they have different subject
matters (the former a word, and the latter a mental state).
Nevertheless, the methodology of theorizing about knowledge may be
helpfully informed by semantic considerations about the language in
which such theorizing takes place. And if contextualism is correct,
then a theorist of knowledge must attend carefully to the potential
for ambiguity.
It is uncontroversial that many English words are context-sensitive.
The most obvious cases are indexicals, such as “I”,
“you”, “here”, and “now” (David
Kaplan 1977 gives the standard view of indexicals).
The word “you” refers to a different person, depending on
the conversational context in which it is uttered; in particular, it
depends on the person one is addressing. Other context-sensitive terms
are gradable adjectives like “tall”—how tall
something must be to count as “tall” depends on the
conversational context—and quantifiers like
“everyone”—which people count as part of
“everyone” depends on the conversational context.
Contextualists about “knows” think that this verb belongs
on the list of context-sensitive terms. A consequence of contextualism
is that sentences containing “knows” may express distinct
propositions, depending on the conversational contexts in which
they’re uttered. This feature allows contextualists to offer an
effective, though not uncontroversial, response to skepticism. For a
more thorough overview of contextualism and its bearing on skepticism,
see Rysiew 2011 or Ichikawa forthcoming-b.
Contextualists have modeled this context-sensitivity in various ways.
Keith DeRose 2009 has suggested that there is a context-invariant
notion of “strength of epistemic position”, and that how
strong a position one must be in in order to satisfy
“knows” varies from context to context; this is in effect
to understand the semantics of knowledge attributions much as we
understand that of gradable adjectives. (How much height one must have
to satisfy “tall” also varies from context to context.)
Cohen 1988 adopts a contextualist treatment of “relevant
alternatives” theory, according to which, in skeptical contexts,
but not ordinary ones, skeptical possibilities are relevant. This
aspect is retained in the view of Lewis 1996, which characterizes a
contextualist approach that is more similar to quantifiers and modals.
Blome-Tillmann 2009b and
Ichikawa forthcoming-a defend and
develop the Lewisian view in different ways.
Contextualism and pragmatic encroachment represent different
strategies for addressing some of the same “shifty”
patterns of intuitive data. (In fact, contextualism was generally
developed first; pragmatic encroachment theorists were motivated in
part by the attempt to explain some of the patterns contextualists
were interested in without contextualism’s semantic
commitments.) Although this represents a sense in which they tend to
be rival approaches, contextualism and pragmatic encroachment are by
no means inconsistent. One could think that “knows”
requires the satisfaction of different standards in different
contexts, and also think that the subject’s practical
situation is relevant for whether a given standard is satisfied.
Like pragmatic encroachment, contextualism is deeply controversial.
Critics have argued that it posits an implausible kind of semantic
error in ordinary speakers who do not recognize the putative
context-sensitivity—see Schiffer 1996 and Greenough &
Kindermann forthcoming—and that it is at odds with plausible
theoretical principles involving knowledge—see Hawthorne 2003,
Williamson 2005, and Worsnip forthcoming. In addition, some of the arguments
that are used to undercut the data motivating pragmatic encroachment
are also taken to undermine the case for contextualism; see again
Rysiew 2001 and Brown 2006. 