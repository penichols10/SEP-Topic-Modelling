In Plato’s Meno, Socrates raises the question of why
knowledge is more valuable than mere true belief. Call this the
Meno problem or, anticipating distinctions made below, the
primary value problem.
Initially, we might appeal to the fact that knowledge appears to be of
more practical use than true belief in order to mark this difference
in value. But, as Socrates notes, this could be questioned, because a
true belief that this is the way to Larissa will get you to
Larissa just as well as knowledge that this is the way to
Larissa. Plato’s own solution was that knowledge is formed
in a special way distinguishing it from belief: knowledge, unlike
belief, must be ‘tied down’ to the truth, like the
mythical tethered statues of Daedalus. As a result, knowledge is
better suited to guide action. For example, if one knows, rather than
merely truly believes, that this is the way to Larissa, then one might
be less likely to be perturbed by the fact that the road initially
seems to be going in the wrong direction. Mere true belief at this
point might be lost, since one might lose all confidence that this is
the right way to go.
The primary value problem has been distinguished from the
secondary value problem (Pritchard 2007: §2). The
secondary value problem pertains to why knowledge is more valuable,
from an epistemic point of view, than any proper subset of
its parts. Put otherwise, why is knowledge better than any epistemic
standing falling short of knowing? This includes, but is not
restricted to, mere true belief. To illustrate the distinction,
consider a possible solution to the primary value problem: knowledge
is justified true belief, and justified true belief is better than
mere true belief, which explains why knowledge is better than true
belief. If correct, this hypothesis successfully answers the primary
value problem. However, it requires further development to answer the
secondary value problem. For example, it requires further development
to explain why knowledge is better than justified belief.
Of course, on many standard theories of knowledge, knowledge is not
defined as justified true belief. For instance, according to some
theorists, knowledge is undefeated justified true belief (Lehrer &
Paxson 1969); on other
widely discussed accounts, knowledge is true belief that is
non-accidental (Unger 1968), sensitive (Nozick 1981), safe (Sosa 1999), appropriately caused (Goldman 1967), or produced by intellectual
virtue (Zagzebski 1996). This puts us in a position to appreciate what
some theorists call the tertiary value problem. The tertiary
value problem pertains to why knowledge is qualitatively
better than any epistemic standing falling short of knowledge.
Consider that if knowledge were only quantitatively better than that
which falls just short—for instance, on an envisioned continuum
of epistemic value—then it would be mysterious why
epistemologists have given such attention to this particular point on
the continuum.
Why does knowledge have this “distinctive value” not
shared by that which falls just short of knowledge (Pritchard 2009:
14)?
Not all theorists accept that the value problems are genuine. For
example, in light of the literature on the Gettier problem, some
theorists deny that the secondary value problem is genuine. On this
approach, whatever is added to justified true belief to rule out
Gettier cases does not increase the value of the agent’s
intellectual state: it is of no consequence whether we have
Gettier-proof justified true belief rather than mere justified true
belief (Kaplan 1985). Of course, Gettier cases are peculiar and
presumably rare, so in practice having Gettier-proof justified true
belief is almost invariably confounded with having mere justified true
belief. This could lead some theorists to mistake the value of the
latter for that of the former. Other theorists deny that the primary
value problem is genuine. For example, on one approach, knowledge just
is true belief (Sartwell 1991). If knowledge is true belief, then knowledge cannot be
better than true belief, because nothing can be better than itself.
However, the definition of knowledge as true belief has not been
widely accepted.
The first contemporary wave of work on the value problem largely
concerned whether this problem raised a distinctive difficulty for
reliabilist accounts of knowledge—i.e., those views which
essentially define knowledge as reliably-formed true belief. In
particular, the claim was that reliabilism was unable to offer an
answer even to the primary value problem.
A fairly clear statement of what is at issue here is given in a number
of places by Linda Zagzebski (e.g., 2003a; cf. DePaul 1993; Zagzebski
1996; Jones 1997; Swinburne 1999, 2000; Riggs 2002a; Kvanvig 2003;
Sosa 2007: ch. 4; Carter & Jarvis 2012). To begin with, Zagzebski
argues that the reliability of the process by which something is
produced does not automatically add value to that thing, and thus that
it cannot be assumed that the reliability of the process by which a
true belief is produced will add value to that true belief. In defense
of this claim, she offers the analogy of a cup of coffee. She claims
that a good cup of coffee which is produced by a reliable coffee
machine—i.e., one that regularly produces good cups of
coffee—is of no more value than an equally good cup of coffee
that is produced by an unreliable coffee machine.
Furthermore, as this line of objection goes, true belief is in the
relevant respects like coffee: a true belief formed via a reliable
belief-forming process is no more valuable than a true belief formed
via an unreliable belief-forming process. In both cases, the value of
the reliability of the process accrues in virtue of its tendency to
produce a certain valuable effect (good coffee/true belief), but this
means that where the effect has been produced—where one has a
good cup of coffee or a true belief—then the value of the
product is no greater for having been produced in a reliable way.
Elsewhere in the literature (e.g., Kvanvig 2003), this problem has
been called the “swamping problem”, on account of how the
value of true belief ‘swamps’ the value of the true belief
being produced in a reliable (i.e., truth-conducive) way. So
expressed, the moral of the problem seems to be that where
reliabilists go awry is by treating the value of the process as being
solely captured by the reliability of the process—i.e., its
tendency to produce the desired effect. Since the value of the effect
swamps the value of the reliability of the process by which the effect
was achieved, this means that reliabilism has no resources available
to it to explain why knowledge is more valuable than true belief.
It’s actually not clear that this is a problem that is specific
to reliabilism. That is, it seems that if this is a bona fide
problem, then it will affect any account of the value of knowledge
which has the same relevant features as reliabilism—i.e., which
regards the greater value of knowledge over true belief as
instrumental value, where the instrumental value in question is
relative to the valuable good of true belief. See, for example,
Kvanvig 2003: Ch. 3, for discussion of how internalist approaches to
epistemic justification interface with the swamping problem.
Furthermore, as J. Adam Carter and Benjamin Jarvis (2012) have argued,
there are reasons to be suspicious of a key premise driving the
swamping argument. The premise in question, which has been referred to
as the “Swamping Thesis” (Pritchard 2011), states that if the value of
a property possessed by an item is instrumentally valuable only
relative to a further good, and that good is already present in that
item, then it can confer no additional value. Carter and Jarvis
contend that one who embraces the Swamping Thesis should also, by
parity of reasoning, embrace a corollary thesis which they call the
Swamping Thesis Complement, according to which, if the value of a
property possessed by an item is instrumentally valuable only relative
to a further good, and that good has already failed to be
present in that item, then it can confer no additional value. However,
as they argue, the Swamping Thesis and the Swamping Thesis Complement,
along with other plausible premises, jointly entail the unpalatable
conclusion that non-factive epistemic properties—most notably,
justification—are never epistemically valuable
properties of a belief. See Dutant (2013) for a critical response to
Carter and Jarvis’ line of reasoning. For an overview of the key
moves of the argument, see Pritchard (2011).
However, even granting the main elements of the swamping argument,
there are moves that the reliabilist can make in response (see, e.g.,
Goldman & Olsson 2009; Olsson 2011; Bates 2013; Roush 2010; cf. Brown 2012; Davis, &
Jäger 2012; Hovarth 2009; Piller 2009). For example, it is surely
open to the reliabilist to argue that the greater instrumental value
of reliable true belief over mere true belief does not need to be
understood purely in terms of instrumental value relative to the good
of true belief. There could, for instance, be all sorts of
practical benefits of having a reliable true belief which
generate instrumental value. Indeed, it is worth noting that the line
of response to the Meno problem sketched by Plato, which we
noted above, seems to specifically appeal to the greater practical
instrumental value of knowledge over mere true belief.
Moreover, there is reason to think that this objection will only at
best have an impact on process reliabilist
proposals—i.e., those views that treat all reliable
belief-forming processes as conferring a positive epistemic standing
on the beliefs so formed. For example, agent reliabilism
(e.g., Greco 1999, 2000) might be thought to be untouched by this sort
of argument. This is because, according to agent reliabilism, it is
not any sort of reliable process that confers positive epistemic
status to belief, but only those processes that are stable features of
the agent’s “cognitive character”. The main
motivation for this restriction on reliable processes is that it
excludes certain kinds of reliable but nonetheless strange and
fleeting processes which notoriously cause problems for the view (such
as processes where the reliability is due to some quirk in the
subject’s environment, rather than because of any cognitive
trait possessed by the agent herself). Plausibly, however, one might
argue that the reliable traits that make up an agent’s cognitive
character have some value independently of the instrumental value they
possess in virtue of being reliable—i.e., that they have some
final or intrinsic value. If this is right, then this opens up the
possibility that agent-reliabilists can evade the problem noted for
pure reliabilists.
Zagzebski’s diagnosis of what is motivating this problem for
reliabilism seems, however, explicitly to exclude
such a counter-response. She argues that what gives rise to this
difficulty is the fact that the reliabilist has signed up to a
“machine-product model of belief”—see especially,
Zagzebski (2003a)—where the product is external to the cause. It
is not clear what exactly Zagzebski means by this point, but she
thinks it shows that even where the reliable process is independently
valuable—i.e., independently of its being reliable—it
still doesn’t follow that the value of the cause will transfer
to add value to the effect. Here again the coffee analogy is appealed
to: even if a reliable coffee machine were independently valuable, it
would not thereby confer additional value on a good cup of coffee.
Perhaps the best way to evaluate the above line of argument is to
consider what is required in order to resolve the problem it
poses. Perhaps what is needed is an ‘internal’ connection
between product and cause, such as the kind of internal connection
that exists between an act and its motive which is highlighted by how
we explicitly evaluate actions in terms of the motives that led to
them (Zagzebski 2003a). On this picture, then, we are not to
understand knowledge as a state consisting of a known belief, but
rather as a state which consists of both the true belief and
the source from which that true belief was acquired. In short, then,
the problem with the machine-product model of belief is that it leads
us to evaluate the state of the knowledge independently of the means
by which the knowledge was acquired. If, in contrast, we have a
conception of knowledge that incorporates into the very state of
knowledge the way that the knowledge was acquired, we can avoid this
problem.
Once one effects this transition away from the machine-product model
of belief, one can allow that the independent value of the reliable
process can ensure that knowledge, by being produced in this way, is
more valuable than mere true belief (Zagzebski 2003a). In particular,
if the process by which one gained the true belief is an epistemic
virtue—a character trait which is both reliable and
intrinsically valuable—then this can ensure that the value of
the knowing state in this case is more valuable than any corresponding
state which simply consisted of a true belief.
Other commentators in the virtue epistemology camp, broadly conceived,
have put forward similar suggestions. For example, Wayne Riggs (2002a)
and Greco (e.g., 2003) have argued for a ‘credit’ version
of virtue epistemology, according to which the agent, in virtue of
bringing about the positively valuable outcome of a true belief, is
due credit as a result. Rather than treating the extra value of
knowledge over true belief as deriving simply from the agent’s
attainment of the target true belief, however, Riggs and Greco instead
argue that we should regard the agent’s knowing as the state the
agent is in when she is responsible for her true belief. Only in so
doing, they claim, can we answer the value problem. Jason Baehr
(2012), by contrast with Riggs and Greco, has argued that credit
theories of knowledge do not answer the value problem but, rather,
‘provide grounds for denying’ (2012: 1) that knowledge has
value over and above the value of true belief.
Interestingly, however, other virtue epistemologists, most notably
Ernest Sosa (2003), have also advocated a ‘credit’ view,
yet seem to stay within the machine-product picture of belief. That
is, rather than analyze the state of knowing as consisting of both the
true belief and its source, they regard the state of knowing as
distinct from the process, yet treat the fact that the process is
intrinsically valuable as conferring additional value on any true
belief so produced. With Sosa’s view in mind, it is interesting
to ask just why we need to analyze knowledge in the way that Zagzebski
and others suggest in order to get around the value problem.
 The most direct way to approach this question is by considering
whether it is really true that a valuable cause cannot confer value on
its effect where cause and effect are kept separate in the way that
Zagzebski claims is problematic in the case of knowledge. One
commentator who has objected to Zagzebski’s argument by querying
this claim on her part is Berit Brogaard (2007; cf. Percival 2003;
Pritchard 2007: §2), who claims that a valuable cause can indeed
confer value on its effect in the relevant cases. Brogaard claims that
virtue epistemologists like Zagzebski and Riggs endorse this claim
because they adhere to what she calls a “Moorean”
conception of value, on which if two things have the same intrinsic
properties, then they are equally valuable. Accordingly, if true
belief and knowledge have the same intrinsic properties (which is what
would be the case on the view of knowledge that they reject), it
follows that they must have the same value. Hence, it is crucial to
understand knowledge as having distinct intrinsic properties from true
belief before one can hope to resolve the value problem.
If one holds that there is only intrinsic and instrumental value, then
this conception of value is compelling, since objects with the same
intrinsic properties trivially have the same amount of intrinsic
value, and they also plausibly have the same amount of instrumental
value as well (at least in the same sort of environment). However, the
Moorean conception of value is problematic because—as Wlodek
Rabinowicz & Toni Rønnow-Rasmussen (1999, 2003) have
pointed out—there seem to be objects which we value for their
own sake but whose value derives from their being extrinsically
related to something else that we value. That is, such objects are
finally—i.e., non-instrumentally—valuable without
thereby being intrinsically valuable. For criticism of this account of
final value, see Bradley (2002).
The standard example in this regard is Princess Diana’s dress.
This would be regarded as more valuable than an exact replica simply
because it belonged to Diana, which is clearly an extrinsic property
of the object. Even though the extra value that accrues to the object
is due to its extrinsic properties, however, it is still the case that
this dress is (properly) valued for its own sake, and thus valued
non-instrumentally.
Given that value of this sort is possible, then it follows that it
could well be the case that we value one true belief over another
because of its extrinsic features—i.e., that the one true
belief, but not the other, was produced by a reliable cognitive trait
that is independently valuable. For example, it could be that we value
forming a true belief via a reliable cognitive trait more than a mere
true belief because the former belief is produced in such a way that
it is of credit to us that we believe the truth. There is thus a
crucial lacuna in Zagzebski’s argument.
A different response to the challenge that Zagzebski raises for
reliabilism is given by Michael Brady (2006). In defense of
reliabilism, Brady appeals to the idea that to be valuable is to be a
fitting or appropriate object of positive evaluative attitudes, such
as admiration or love (e.g., Brentano 1889 [1969]; Chisholm 1986;
Wiggins 1987; Gibbard 1990; Scanlon 1998). That one object is more
valuable than another is thus to be understood, on this view, in terms
of the fact that that object is more worthy of positive evaluation.
Thus, the value problem for reliabilism on this conception of value
comes down to the question why knowledge is more worthy of positive
evaluation on this view than mere true belief. Brady’s
contention is that, at least within this axiological framework, it
is possible for the reliabilist to offer a compelling story
about why reliable true belief—and thus knowledge—is more
valuable than mere true belief.
Central to Brady’s argument is his claim that there are many
ways one can positively evaluate something, and thus many different
ways something can be valuable. Moreover, Brady argues that we can
distinguish active from passive evaluative
attributes, where the former class of attitudes involve pursuit of the
good in question. For example, one might actively value the truth,
where this involves, for instance, a striving to discover the truth.
In contrast, one might at other times merely passively value the
truth, such as simply respecting or contemplating it.
With this point in mind, Brady’s central thesis is that on the
reliabilist account knowledge is more valuable than true belief
because certain active positive evaluative attitudes are fitting only
with regard to the former (i.e., reliable true belief). In particular,
given its intrinsic features, reliable true belief is worthy of active
love, whereas an active love of unreliable (i.e., accidental) true
belief because of its intrinsic features would be entirely
inappropriate because there is nothing that we can do to attain
unreliable true belief that wouldn’t conflict with love of
truth.
This is an intriguing proposal, which opens up a possible avenue of
defense against the kind of machine-product objection to reliabilism
considered. One problem that such a move faces, however, is that it is
unclear whether we can make sense of the distinction Brady draws
between active and passive evaluative attitudes, at least in the
epistemic sphere. When Brady talks of passive evaluative attitudes
towards the truth, he gives examples like contemplating, accepting,
embracing, affirming, and respecting. Some of these attitudes are not
clearly positive evaluative attitudes, however. Moreover, some of them
are not obviously passive either. For example, is to contemplate the
truth really to evaluate it positively, rather than simply to
consider it? Furthermore, in accepting, affirming or embracing the
truth, isn’t one actively positively evaluating the
truth? Wouldn’t such evaluative attitudes manifest themselves in
the kind of practical action that Brady thinks is the mark of active
evaluative attitudes? More needs to be said about this distinction
before it can do the philosophical work that Brady has in mind.
So far this discussion has taken it as given that whatever problems
reliabilism faces in this regard, there are epistemological theories
available—some form of virtue epistemology, for
example—that can deal with them. But not everyone in the
contemporary debate accepts this. Perhaps the best known sceptic in
this respect is Jonathan Kvanvig (2003), who in effect argues that
while virtue epistemology (along with a form of epistemic internalism)
can resolve the primary value problem (i.e., the problem of explaining
why knowledge is more valuable than mere true belief), the real
challenge that we need to respond to is that set by the secondary
value problem (i.e., the problem of explaining why knowledge is more
valuable than that which falls short of knowledge); and Kvanvig says
that there is no solution available to that. That is, Kvanvig
argues that there is an epistemic standing—in essence, justified
true belief—which falls short of knowledge but which is no less
valuable than knowledge. He concludes that the focus of epistemology
should not be on knowledge at all, but rather on
understanding, an epistemic standing that Kvanvig maintains
is clearly of more value than knowledge and those epistemic
standings that fall short of knowledge, such as justified true
belief.
What Kvanvig says about understanding will be considered below. First
though, let us consider the specific challenge that he poses for
virtue epistemology. In essence, Kvanvig’s argument rests on the
assumption that it is essential to any virtue-theoretic account of
knowledge—and any internalist account of knowledge as well, for
that matter (i.e., an account that makes a subjective justification
condition necessary for knowledge possession)—that it also
includes an anti-Gettier condition. If this is right, then it follows
that even if virtue epistemology has an answer to the primary value
problem—and Kvanvig concedes that it does—it will not
thereby have an answer to the secondary value problem since knowledge
is not simply virtuous true belief. Moreover, Kvanvig argues that once
we recognize what a gerrymandered notion a non-Gettierized account of
knowledge is, it becomes apparent that there is nothing valuable about
the anti-Gettier condition on knowledge that needs to be imposed. But
if that is right, then it follows by even virtue epistemic lights that
knowledge—i.e., non-Gettierized virtuous true believing—is
no more valuable than one of its proper sub-sets—i.e., mere
virtuous true believing.
There are at least two aspects of Kvanvig’s argument that are
potentially problematic. To begin with, it isn’t at all clear
why the anti-Gettier condition on knowledge fails to add value,
something that seems to be assumed here. More generally, Kvanvig seems
to be implicitly supposing that if an analysis of knowledge is ugly
and gerrymandered then that is itself reason to doubt that knowledge
is particularly valuable, at least assuming that there are epistemic
standings that fall short of knowledge which can be given an elegant
analysis. While a similar assumption about the relationship between
the elegance (or otherwise) of the analysis of knowledge and the value
of the analysandum is commonplace in the contemporary epistemological
literature—see, for example, Zagzebski (1999) and Williamson
(2000: chapter 1)—this assumption is contentious. For critical
discussion of this assumption, see DePaul (2009).
In any case, a more serious problem is that many virtue
epistemologists—among them Sosa (1988, 1991, 2007), Zagzebski
(e.g., 1996, 1999) and Greco (2003, 2007, 2008, 2009)—hereafter, ‘robust virtue
epistemologists’—think that their view can deal
with Gettier problems without needing to add an additional
anti-Gettier condition on knowledge. The way this is achieved is by
making the move noted above of treating knowledge as a state that
includes both the truly believing and the virtuous source by which
that true belief was acquired. However, crucially, for robust virtue
epistemologists, there is an important difference between (i) a
belief’s being true and virtuously formed, and (ii) a
belief’s being true because virtuously formed.
Formulating knowledge along the latter lines, they insist, ensures
that the target belief is not Gettiered. Even more, robust virtue
epistemologists think the latter kind of formulation offers the
resources to account for why knowledge is distinctively valuable.
To appreciate this point about value, consider the following
‘performance normativity framework’ which robust virtue
epistemologists explicitly or implicitly embrace when accounting for
the value of knowledge as a true belief because of virtue.
Performance Normativity Framework
Dimensions of evaluation thesis Any performance with an aim
can be evaluated along three dimensions: (i) whether it is successful,
(ii) whether it is skillful, and (iii) thirdly, whether the success is
because of the skill.
Achievement thesis If and only if the success is because of
the skill, the performance is not merely successful, but also, an
achievement.
Value thesis Achievements are finally valuable (i.e.,
valuable for their own sake) in a way that mere lucky successes are
not.
Notice that, if knowledge is a cognitive performance that is an
achievement, then with reference to the above set of claims,
the robust virtue epistemologist can respond to not only the secondary
value problem but also the tertiary value problem (i.e., the problem
of explaining why knowledge is more valuable, in kind and not merely
in degree, than that which falls short of knowledge). This is because
knowledge, on this view, is simply the cognitive aspect of a more
general notion, that of achievement, and this is the case even if mere
successes that are produced by intellectual virtues but which are not
because of them, are not achievements.
As regards the value thesis, one might object that some
successes that are because of ability—i.e., achievements, on
this view—are too trivial or easy or wicked to count as finally
valuable. This line of objection is far from decisive. After all, it
is open to the proponent of robust virtue epistemology to argue that
the claim is only that all achievements qua achievements are
finally valuable, not that the overall value of every achievement is
particularly high. It is thus consistent with the proposal that some
achievements have a very low—perhaps even negative, if that is
possible—value in virtue of their other properties (e.g., their
triviality). Indeed, a second option in this regard is to allow that
not all achievements enjoy final value whilst nevertheless maintaining
that it is in the nature of achievements to have such value (e.g.,
much in the way that one might argue that it is in the nature of
pleasure to be a good, even though some pleasures are bad). Since, as
noted above, all that is required to meet the (tertiary) value problem
is to show that knowledge is generally distinctively valuable, this
claim would almost certainly suffice for the robust virtue
epistemologist’s purposes.
In any case, even if the value thesis is correct—and indeed,
even if the achievement and dimensions of evaluation theses are also
correct—the robust virtue epistemologist has not yet
satisfactorily vindicated any of the aforementioned value problems for
knowledge unless knowledge is itself a kind of achievement—and
that is the element of the proposal that is perhaps the most
controversial. There are two key problems with the claim that
knowledge involves cognitive achievement. The first is that there
sometimes seems to be more to knowledge than a cognitive achievement;
the second is that there sometimes seems to be less to knowledge than
a cognitive achievement.
As regards the first claim, notice that achievements seem to be
compatible with at least one kind of luck. Suppose that an archer hits
a target by employing her relevant archery abilities, but that the
success is ‘gettierized’ by luck intervening between the
archer’s firing of the arrow and the hitting of the target. For
example, suppose that a freak gust of wind blows the arrow off-course,
but then a second freak gust of wind happens to blow it back on course
again. The archer’s success is thus lucky in the sense that it
could very easily have been a failure. When it comes to
‘intervening’ luck of this sort, Greco’s account of
achievements is able to offer a good explanation of why the success in
question does not constitute an achievement. After all, we would not
say that the success was because of the archer’s ability in this
case.
Notice, however, that not all forms of luck are of this intervening
sort. Consider the following case offered by Pritchard (2010a: ch. 2).
Suppose that nothing intervenes between the archer’s firing of
the arrow and the hitting of the target. However, the success is still
lucky in the relevant sense because, unbeknownst to the archer, she
just happened to fire at the only target on the range that did not
contain a forcefield which would have repelled the arrow. Is the
archer’s success still an achievement? Intuition would seem to
dictate that it is; it certainly seems to be a success that is because
of ability, even despite the luckiness of that success. Achievements,
then, are, it seems, compatible with luck of this
‘environmental’ form even though they are not compatible
with luck of the standard ‘intervening’ form.
The significance of this conclusion for our purposes is that knowledge
is incompatible with both forms of luck. In order to see
this, one only needs to note that an epistemological analogue of the
archer case just given is the famous barn façade example (e.g.,
Ginet 1975; Goldman
1976). In this example,
we have an agent who forms a true belief that there is a barn in front
of him. Moreover, his belief is not subject to the kind of
‘intervening’ luck just noted and which is a standard
feature of Gettier-style cases. It is not as if, for example, he is
looking at what appears to be a barn but which is not in fact a barn,
but that his belief is true nonetheless because there is a barn behind
the barn shaped object that he is looking at. Nevertheless, his belief
is subject to environmental luck in that he is, unbeknownst to him, in
barn façade county in which every other barn-shaped object is a
barn façade. Thus, his belief is only luckily true in that he
could very easily have been mistaken in this respect. Given that this
example is structurally equivalent to the ‘archer’ case
just given, it seems that just as we treat the archer as exhibiting an
achievement in that case, so we should treat this agent as exhibiting
a cognitive achievement here. The problem, however, is that until
quite recently many philosophers accepted that the agent in the barn
façade case lacks knowledge. Knowledge, it seems, is
incompatible with environmental luck in a way that achievements, and
thus cognitive achievements, are not (see, for example, Pritchard,
e.g., 2012).
Robust virtue epistemologists have made a number of salient points
regarding this case. For example, Greco (2010, 2012) has argued for a
conception of what counts as a cognitive ability according to which
the agent in the barn façade case would not count as exhibiting
the relevant cognitive ability (see Pritchard 2010a: ch. 2 for a
critical discussion of this claim). Others, such as Sosa (e.g., 2007,
2015) have responded by
questioning whether the agent in the barn façade case lacks
knowledge, albeit, in a qualified sense. While Sosa’s
distinctive virtue epistemology allows for the compatibility of barn
façade cases with animal knowledge (roughly: true
belief because of ability), Sosa maintains that the subject in barn
façade cases lacks reflective knowledge (roughly: a
true belief whose creditability to ability or virtue is itself
creditable to a second-order ability or virtue of the agent). Other
philosophers (e.g., Hetherington (1998) have challenged the view that barn façade
protagonists in fact lack (any kind of) knowledge. In a series of
empirical studies, most people attributed knowledge in barn
façade cases and related cases (Colaco, Buckwalter, Stich &
Machery 2014; Turri,
Buckwalter & Blouw 2015; Turri 2016a). In one study, over 80% of participants attributed
knowledge (Turri 2016b).
In another study, most professional philosophers attributed knowledge
(Horvath & Wiegmann 2016). At least one theory of knowledge has
been defended on the grounds that it explains why knowledge is
intuitively present in such cases (Turri 2016c).
Even setting that issue aside, however, there is a second problem on
the horizon, which is that it seems that there are some cases of
knowledge which are not cases of cognitive achievement. One such case
is offered by Jennifer Lackey (2007), albeit to illustrate a slightly
different point. Lackey asks us to imagine someone arriving at the
train station in Chicago who, wishing to obtain directions to the
Sears Tower, approaches the first adult passer-by she sees. Suppose
the person she asks is indeed knowledgeable about the area and gives
her the directions that she requires. Intuitively, any true belief
that the agent forms on this basis would ordinarily be counted as
knowledge. Indeed, if one could not gain testimonial knowledge in this
way, then it seems that we know an awful lot less than we think we
know. However, it has been argued, in such a case the agent does not
have a true belief because of her cognitive abilities but, rather,
because of her informant’s cognitive abilities. If this
is correct, then there are cases of knowledge which are not also cases
of cognitive achievement.
It is worth being clear about the nature of this objection. Lackey
takes cases like this to demonstrate that one can possess knowledge
without it being primarily creditable to one that one’s belief
is true. Note though that this is compatible, as Lackey notes, with
granting that the agent is employing her cognitive abilities
to some degree, and so surely deserves some credit for the
truth of the belief formed (she would not have asked just anyone, for
example, nor would she have simply accepted just any answer given by
her informant). The point is thus rather that whatever credit the
agent is due for having a true belief, it is not the kind of credit
that reflects a bona fide cognitive achievement because of
how this cognitive success involves ‘piggy-backing’ on the
cognitive efforts of others.
As noted above, the main conclusion that Kvanvig (2003) draws from his
reflections on the value problem is that the real focus in
epistemology should not be on knowledge at all but on understanding,
an epistemic standing that Kvanvig does think is especially valuable
but which, he argues, is distinct from knowing—i.e., one can
have knowledge without the corresponding understanding, and one can
have understanding without the corresponding knowledge. (Pritchard
[e.g., 2010a: chs 1–4] agrees, though his reasons for taking
this line are somewhat different to Kvanvig’s). It is perhaps
this aspect of Kvanvig’s book that has prompted the most
critical response, so it is worth briefly dwelling on his claims here
in a little more detail.
To begin with, one needs to get clear what Kvanvig has in mind when he
talks of understanding, since many commentators have found the
conception of understanding that he targets problematic. The two
usages of the term ‘understanding’ in ordinary language
that Kvanvig focuses on—and which he regards as being especially
important to epistemology—are 
when understanding is claimed for some object, such as some subject
matter, and when it involves understanding that something is the case.
(Kvanvig 2003: 189) 
The first kind of understanding he calls “objectual
understanding”, the second kind “propositional
understanding”. In both cases, understanding requires that one
successfully grasp how one’s beliefs in the relevant
propositions cohere with other propositions one believes (e.g.,
Kvanvig 2003: 192, 197–8). This requirement entails that
understanding is directly factive in the case of propositional
understanding and indirectly factive in the case of objectual
understanding—i.e., the agent needs to have at least mostly true
beliefs about the target subject matter in order to be truly said to
have objectual understanding of that subject matter.
Given that understanding—propositional understanding at any
rate—is factive, Kvanvig’s argument for why understanding
is distinct from knowledge does not relate to this condition (as we
will see in a moment, it is standard to argue that understanding is
distinct from knowledge precisely because only understanding is
non-factive). Instead, Kvanvig notes two key differences between
understanding and knowledge: that understanding, unlike knowledge,
admits of degrees, and that understanding, unlike knowledge, is
compatible with epistemic luck. Most commentators, however, have
tended to focus not on these two theses concerning the different
properties of knowledge and understanding, but rather on
Kvanvig’s claim that understanding is (at least indirectly)
factive.
For example, Elgin (2009; cf. Elgin 1996, 2004; Janvid 2014) and Riggs
(2009) argue that it is possible for an agent to have understanding
and yet lack true beliefs in the relevant propositions. For example,
Elgin (2009) argues that it is essential to treat scientific
understanding as non-factive. She cites a number of cases in which
science has progressed from one theory to a better theory where, we
would say, understanding has increased in the process even though the
theories are, strictly speaking at least, false. A different
kind of case that Elgin offers concerns scientific idealizations, such
as the ideal gas law. Scientists know full well that no actual gas
behaves in this way, yet the introduction of this useful fiction
clearly improved our understanding of the behavior of actual gasses.
For a defense of Kvanvig’s view in the light of these charges,
see Kvanvig (2009a, 2009b; Carter & Gordon 2014).
 A very different sort of challenge to Kvanvig’s treatment of
understanding comes from Brogaard (2005, Other Internet
Resources). She argues that Kvanvig’s claim that understanding
is of greater value than knowledge is only achieved because he fails
to give a rich enough account of knowledge. More specifically,
Brogaard claims that we can distinguish between objectual and
propositional knowledge just as we can distinguish between objectual
and propositional understanding.  Propositional understanding, argues
Brogaard, no more requires coherence in one’s beliefs than
propositional knowledge, and so the difference in value between the
two cannot lie here. Moreover, while Brogaard grants that objectual
understanding does incorporate a coherence requirement, this again
fails to mark a value-relevant distinction between knowledge and
understanding because the relevant counterpart—objectual
knowledge (i.e., knowledge of a subject matter)—also
incorporates a coherence requirement. So provided that we are
consistent in our comparisons of objectual and propositional
understanding on the one hand, and objectual and propositional
knowledge on the other, Kvanvig fails to make a sound case for
thinking that understanding is of greater value than knowledge.
Finally, a further challenge to Kvanvig’s treatment of knowledge
and understanding focuses on his claims regarding epistemic luck, and
in particular, his insistence that luck cases show how understanding
and propositional knowledge come apart from one another. In order to
bring the luck-based challenge into focus, we can distinguish three
kinds of views about the relationship between understanding and
epistemic luck that are found in the literature: strong
compatibilism (e.g., Kvanvig 2003; Rohwer 2014), moderate
compatibilism (e.g., Pritchard 2010a; ch. 4) and
incompatibilism (e.g., Grimm 2006; Sliwa 2015). Strong compatibilism is the
view that understanding is compatible with the varieties of epistemic
luck that are generally taken to undermine propositional knowledge. In
particular, incompatibilists maintain that understanding is undermined
by neither (i) the kind of luck that features in traditional
Gettier-style cases (1963) cases, nor with (ii) purely
‘environmental luck (e.g., Pritchard 2005) of the sort that features in
‘fake barn’ cases (e.g., Goldman 1979) where the fact that
one’s belief could easily be incorrect is a matter of being in
an inhospitable epistemic environment. Moderate compatibilism, by
contrast, maintains that while understanding is like propositional
knowledge in that it is incompatible with the kind of luck that
features in traditional Gettier cases, it is nonetheless compatible
with environmental epistemic luck. Incompatibilism rejects that either
kind of epistemic luck case demonstrates that understanding and
propositional knowledge come apart, and so maintains that
understanding is incompatible with epistemic luck to the same extent
that propositional knowledge is.
The received view in mainstream epistemology, at least since Gilbert
Ryle (e.g., 1949), has been to regard knowledge-that and knowledge-how
as different epistemic standings, such that knowing how to do
something is not simply a matter of knowing propositions, viz., of
knowledge-that. If this view—known as
anti-intellectualism—is correct, then the value of
knowledge-how needn’t be accounted for in terms of the value of
knowing propositions. Furthermore, if anti-intellectualism is assumed,
then—to the extent that there is any analogous ‘value
problem’ for knowledge-how—such a problem needn’t
materialize as the philosophical problem of determining what it is
about knowledge-how that makes it more valuable than mere true
belief.
Jason Stanley & Timothy Williamson (2001) have, however,
influentially resisted the received anti-intellectualist thinking
about knowledge-how. On Stanley & Williamson’s
view—intellectualism—knowledge-how is a kind of
propositional knowledge, i.e., knowledge-that, such that
(roughly) S knows how to φ iff there is a way w such
that S knows that w is a way for S to φ.
Accordingly, if Hannah knows how to ride a bike, then this is in
virtue of her propositional knowledge—viz., her knowing of some
way w that w is the way for her (Hannah) to ride a
bike.
By reducing in this manner knowledge—how to a kind of
knowledge—that, intellectualists such as Stanley have accepted
that knowledge-how should have properties characteristic of
propositional knowledge, (see, for example, Stanley 2011: 215), of which knowledge-how is a
kind. Furthermore, the value of knowledge-how should be able to be
accounted for, on intellectualism, with reference to the value of the
propositional knowledge that the intellectualist identifies with
knowledge-how.
In recent work, Carter and Pritchard (2015) have challenged
intellectualism on this point. One such example they offer to this end
involves testimony and skilled action. For example, suppose that a
skilled guitarist tells an amateur how to play a very tricky guitar
riff. Carter and Pritchard (2015: 801) argue that though the amateur
can uncontroversially acquire testimonial knowledge from the expert
that, for some way w that w is the way to play the riff,
it might be that the expert, but not novice, knows how to
play the riff. Further, they suggest that whilst the amateur is better
off, with respect to the aim of playing the riff, than he was prior to
gaining the testimonial knowledge he did, he would likewise be better
off further—viz., he would have something even more
valuable—if he, like the expert, had the lick down cold
(something the amateur does not have simply on the basis of his
acquired testimonial knowledge) (Ibid: 801).
The conclusion Carter and Pritchard draw from this and other similar
cases (e.g., 2015: §3; see also Poston 2016) is that the value of knowledge-how cannot be accounted
for with reference to the value of the items of knowledge-that which
the intellectualist identifies with knowledge-how If this is right,
then if there is a ‘value problem’ for knowledge-how, we
shouldn’t expect it to be the problem of determining what is it
about certain items of propositional knowledge that makes these more
valuable than corresponding mere true beliefs. A potential area for
future research is to consider what an analogue value problem for
knowledge-how might look like, on an anti-intellectualist framework.
According to Carter and Pritchard’s diagnosis, the underlying
explanation for this difference in value is that knowledge-how (like
understanding, as discussed in
 §4)
 essentially involves a kind of cognitive achievement, unlike
propositional knowledge, for reasons discussed in §4. If this
diagnosis is correct, then further pressure is arguably placed on the
robust virtue epistemologist’s ‘achievement’
solution to the value problems for knowledge-that, as surveyed in
 §3.
 Recall that, according to robust virtue epistemology, the distinctive
value of knowledge-that is accounted for in terms of the value of
cognitive achievement (i.e., success because of ability) which robust
virtue epistemologists take to be essential to propositional
knowledge. But, if the presence of cognitive achievement is what
accounts for why knowledge-how has a value that is not present in the
items of knowledge-that the intellectualist identifies with
knowledge-how, this result would seem to stand in tension with the
robust virtue epistemologist’s insistence that what affords
propositional knowledge a value lacked by mere true belief is that the
former essentially involves cognitive achievement.
John Hawthorne (2004; cf. Stanley 2005; Fantl & McGrath 2002) has argued that knowledge is valuable because of the
role it plays in practical reasoning. More specifically, Hawthorne
(2004: 30) argues for the principle that one should use a proposition
p as a premise in one’s practical reasoning only if one
knows p. Hawthorne primarily motivates this line of argument by
appeal to the lottery case. This concerns an agent’s true belief
that she holds the losing ticket for a fair lottery with long odds and
a large cash prize, a belief that is based solely on the fact that she
has reflected on the odds involved. Intuitively, we would say that
such an agent lacks knowledge of what she believes, even though her
belief is true and even though her justification for what she
believes—assessed in terms of the likelihood, given this
justification, of her being right—is unusually strong. Moreover,
were this agent to use this belief as a premise in her practical
reasoning, and so infer that she should throw the ticket away without
checking the lottery results in the paper for example, then we would
regard her reasoning as problematic.
Lottery cases therefore seem to show that justified true belief, no
matter how strong the degree of justification, is not enough for
acceptable practical reasoning—instead, knowledge is required.
Moreover, notice that we can alter the example slightly so that the
agent does possess knowledge while at the same time having a
weaker justification for what she believes (where strength of
justification is again assessed in terms of the likelihood, given this
justification, that the agent’s belief is true). If the agent
had formed her true belief by reading the results in a reliable
newspaper, for example, then she would count as knowing the target
proposition and can then infer that she should throw the ticket away
without criticism. It is more likely, however, that the newspaper has
printed the result wrongly than that she should win the lottery. This
sort of consideration seems to show that knowledge, even when
accompanied by a relatively weak justification, is better (at least
when it comes to practical reasoning) than a true belief that is
supported by a relatively strong justification but does not amount to
knowledge. If this is the right way to think about the connection
between knowledge possession and practical reasoning, then it seems to
offer a potential response to at least the secondary value
problem.
A second author who thinks that our understanding of the concept of
knowledge can have important ramifications for the value of knowledge
is Edward Craig (1990). Craig’s project begins with a thesis
about the value of the concept of knowledge. Simplifying somewhat,
Craig hypothesises that the concept of knowledge is important to us
because it fulfills the valuable function of enabling us to identify
reliable informants. The idea is that it is clearly of immense
practical importance to be able to recognize those from whom we can
gain true beliefs, and that it was in response to this need that the
concept of knowledge arose. As with Hawthorne’s theory, this
proposal, if correct, could potentially offer a resolution of at least
the secondary value problem.
Recently, there have been additional attempts to follow—broadly
speaking—Craig’s project, for which the value of knowledge
is understood in terms of the functional role that
‘knowledge’ plays in fulfilling our practical needs. The
matter of how to identify this functional role has received increasing
recent attention. For example, David Henderson (2009), Robin McKenna
(2013), Duncan Pritchard (2012) and Michael Hannon (2015) have defended views about the concept of knowledge (or
knowledge ascriptions) that are broadly inspired by Craig’s
favored account of the function of knowledge as identifying reliable
informants. A notable rival account, defended by Klemens Kappel
(2010), Christoph Kelp (2011, 2014) and Patrick Rysiew (2012; cf.
Kvanvig 2012) identifies closure of inquiry as the relevant
function. For Krista Lawlor (2013) the relevant function is identified
(à la Austin) as that of providing assurance,
and for James Beebe (2012), it’s expressing epistemic
approval/disapproval.
In one sense, such accounts are in competition with one another, in
that they offer different practical explications of
‘knowledge’. However, these accounts all accept
(explicitly or tacitly) a more general insight, which is that
considerations about the function that the concept of knowledge plays
in fulfilling practical needs should inform our theories of the nature
and corresponding value of knowledge. This more general point remains
controversial in contemporary metaepistemology. For some arguments
against supposing that a practical explication of
‘knowledge’, in terms of some need-fulfilling function,
should inform our accounts of the nature or knowledge, see for example
Gerken (2015). For a more extreme form of argument in favor of
divorcing considerations to do with how and why we use
‘knows’ from epistemological theorizing altogether, see
Hazlett 2010; cf. Turri
2011b.
Laurence BonJour argues that reflecting on the value of knowledge
leads us to reject a prevailing trend in epistemology over the past
several decades, namely, fallibilism, or what BonJour calls the
“weak conception” of knowledge.
BonJour outlines four traditional assumptions about knowledge,
understood as roughly justified true belief, which he
“broadly” endorses (BonJour 2010: 58–9). First,
knowledge is a “valuable and desirable cognitive state”
indicative of “full cognitive success”. Any acceptable
theory of knowledge must “make sense of” knowledge’s
important value. Second, knowledge is “an all or nothing matter,
not a matter of degree”. There is no such thing as degrees of
knowing: either you know or you don’t. Third, epistemic
justification comes in degrees, from weak to strong. Fourth, epistemic
justification is essentially tied to “likelihood or probability
of truth”, such that the strength of justification covaries with
how likely it makes the truth of the belief in question.
On this traditional approach, we are invited to think of justification
as measured by how probable the belief is given the reasons
or evidence you have. One convenient way to measure probability is to
use the decimals in the interval [0, 1]. A probability of 0 means that
the claim is guaranteed to be false. A probability of 1 means that the
claim is guaranteed to be true. A probability of .5 means that the
claim is just as likely to be true as it is to be false. The question
then becomes, how probable must your belief be for it to be
knowledge?
Obviously it must be greater than .5. But how much greater? Suppose we
say that knowledge requires a probability of 1—that is,
knowledge requires our justification or reasons to guarantee
the truth of the belief. Call such reasons conclusive
reasons.
The strong conception of knowledge says knowledge requires
conclusive reasons. We can motivate the strong conception as follows.
If the aim of belief is truth, then it makes sense that knowledge
would require conclusive reasons, because conclusive reasons guarantee
that belief’s aim is achieved. The three components of the
traditional view of knowledge thus fit together
“cohesively” to explain why knowledge is valued as a state
of full cognitive success.
But all is not well with the strong conception, or so philosophers
have claimed over the past several decades. The strong conception
seems to entail that we know nearly nothing at all about the material
world outside of our own minds or about the past. For we could have
had all the reasons we do in fact have, even if the world around us or
the past had been different. (Think of Descartes’s evil genius.)
This conflicts with commonsense and counts against the strong
conception. But what is the alternative?
The alternative is that knowledge requires reasons that make the
belief very likely true, but needn’t guarantee it. This is the
weak conception of knowledge. Most epistemologists accept the
weak conception of knowledge. But BonJour asks a challenging question:
what is the “magic” level of probability required by
knowledge? BonJour then argues that a satisfactory answer to this
question isn’t forthcoming. For any point short of 1 would seem
arbitrary. Why should we pick that point exactly? The same
could be said for a vague range that includes points short of
1—why, exactly, should the vague range extend roughly that
far but not further? This leads to an even deeper problem for the
weak conception. It brings into doubt the value of knowledge. Can
knowledge really be valuable if it is arbitrarily defined?
A closely related problem for the weak conception presents itself.
Suppose for the sake of argument that we settle on .9 as the required
level of probability. Suppose further that you believe Q and
you believe R, that Q and R are both true, and
that you have reached the .9 threshold for each. Thus the weak
conception entails that you know Q, and you know R.
Intuitively, if you know Q and you also know R, then
you’re automatically in a position to know the
conjunction Q & R. But the weak conception cannot
sustain this judgment. For the probability of the conjunction of two
independent claims, such as
Q and R, equals the product of their probabilities.
(This is the special conjunction rule from probability theory.) In
this case, the probability of Q = .9 and the probability
of R = .9. So the probability of the conjunction (Q
& R) = .9 × .9 = .81, which falls short of the
required .9. So the weak conception of knowledge along with a law of
probability entail that you’re automatically not in a position
to know the conjunction (Q & R).  BonJour considers
this to be “an intuitively unacceptable result”, because
after all, 
what is the supposed state of knowledge really worth, if even the
simplest inference from two pieces of knowledge [might] not lead to
further knowledge? (BonJour 2010: 63)
BonJour concludes that the weak conception fails to explain the value
of knowledge, and thus that the strong conception must be true. He
recognizes that this implies that we don’t know most of the
things we ordinarily say and think that we know. He explains this
away, however, partly on grounds that knowledge is the norm of
practical reasoning, which creates strong “practical
pressure” to confabulate or exaggerate in claiming to know
things, so that we can view ourselves as reasoning and acting
appropriately, even though usually the best we can do is to
approximate appropriate action and reasoning. (BonJour 2010:
75).
So far, in common with most of the contemporary literature in this
regard, we have tended to focus on the value of knowledge relative to
other epistemic standings. A related debate in this respect,
however—one that has often taken place largely in tandem with
the mainstream debate on the value of knowledge—has specifically
concerned itself with the value of true belief and we will turn now to
this issue.
Few commentators treat truth or belief as being by themselves valuable
(though see Kvanvig 2003: ch. 1), but it is common to treat true
belief as valuable, at least instrumentally. True beliefs are clearly
often of great practical use to us. The crucial caveat here,
of course, concerns the use of the word ‘often’. After
all, it is also often the case that a true belief might actually
militate against one achieving one’s goals, as when one is
unable to summon the courage to jump a ravine and thereby get to
safety, because one knows that there is a serious
possibility that one might fail to reach the other side. In such cases
it seems that a false belief in one’s abilities—e.g., the
false belief that one could easily jump the ravine—would be
better than a true belief, if the goal in question (jumping the
ravine) is to be achieved.
Moreover, some true beliefs are beliefs in trivial matters, and in
these cases it isn’t at all clear why we should value such
beliefs at all. Imagine someone who, for no good reason, concerns
herself with measuring each grain of sand on a beach, or someone who,
even while being unable to operate a telephone, concerns herself with
remembering every entry in a foreign phonebook. Such a person would
thereby gain lots of true beliefs but, crucially, one would regard
such truth-gaining activity as rather pointless. After all, these true
beliefs do not seem to serve any valuable purpose, and so do not
appear to have any instrumental value (or, at the very least, what
instrumental value these beliefs have is vanishingly small). It would,
perhaps, be better—and thus of greater value—to have fewer
true beliefs, and possibly more false ones, if this meant that the
true beliefs that one had concerned matters of real consequence.
At most, then, we can say that true beliefs often have instrumental
value. What about final (or intrinsic) value? One might think that if
the general instrumental value of true belief was moot then so too
would be the intuitively stronger thesis that true belief is generally
finally valuable. Nevertheless, many have argued for such a claim.
One condition that seems to speak in favor of this thesis is that as
truth seekers we are naturally curious about what the truth is, even
when that truth is of no obvious practical import. Accordingly, it
could be argued that from a purely epistemic point of view, we do
regard all true belief as valuable for its own sake, regardless of
what further prudential goals we might have (e.g., Goldman 1999: 3;
Lynch 2004: 15–16; Alston 2005: 31; cf. Baehr 2012: 5).
Curiosity will only take you so far in this regard, however, since we
are only curious about certain truths, not all of them. To return to
the examples given a moment ago, no fully rational agent is curious
about the measurements of every grain of sand on a given beach, or the
name of every person in a random phonebook—i.e., no rational
person wants to know these truths independently of having some
prudential reason for knowing them.
Still, one could argue for a weaker claim and merely say that it is
prima facie or pro tanto finally good to believe the
truth (cf. David 2005; Lynch 2009), where cases of trivial truths such
as those just given are simply cases where, all things
considered, it is not good to believe the truth. After all, we
are familiar with the fact that something can be prima facie
or pro tanto finally good without being all-things-considered
good. For example, it may be finally good to help the poor and needy,
but not all-things-considered good given that helping the poor and
needy would prevent you from doing something else which is at present
more important (such as saving that child from drowning).
At this point one might wonder why it matters so much to (some)
epistemologists that true belief is finally valuable. Why not instead
just treat true belief as often of instrumental value and leave the
matter at that? The answer to this question lies in the fact that many
want to regard truth—and thereby true belief—as being the
fundamental epistemic goal, in the sense that ultimately it is only
truth that is epistemically valuable (so, for example, while
justification is epistemically valuable, it is only epistemically
valuable because of how it is a guide to truth). Accordingly, if true
belief is not finally valuable—and only typically instrumentally
valuable—then this seems to downplay the status of the
epistemological project.
There are a range of options here. The conservative option is to
contend that truth is the fundamental goal of epistemology and also
contend that true belief is finally valuable—at least in some
restricted fashion. Marian David (2001, 2005) falls into this
category. In contrast, one might argue that truth is the fundamental
goal while at the same time claiming that true belief is not
finally valuable. Sosa (see especially 2004, but also 2000a, 2003)
seems (almost) to fall into this camp, since he claims that while
truth is the fundamental epistemic value, we can accommodate this
thought without having to thereby concede that true belief is finally
valuable, a point that has been made in a similar fashion by Alan
Millar (2011: §3). Sosa often compares the epistemic domain to
other domains of evaluation where the fundamental good of that domain
is not finally valuable. So, for example, the fundamental goal of the
‘coffee-production’ domain may be great tasting coffee,
but no-one is going to argue that great tasting coffee is finally
valuable. Perhaps the epistemic domain is in this respect like the
coffee-production domain?
Another line of response against the thesis that true belief is
finally valuable is to suggest that this thesis leads to a
reductio. Michael DePaul (2001) has notably advanced such an
argument. According to DePaul, the thesis that true belief is finally
valuable implies that all true beliefs are equally epistemically
valuable. Though this latter claim, DePaul argues, is false, as is
illustrated by cases where two sets each containing an equal number of
true beliefs intuitively differ in epistemic value. Ahlstrom-Vij and
Grimm (2013) have criticized DePaul’s claim that the thesis that
true belief is finally valuable implies that two sets each containing
an equal number of true beliefs must not differ in epistemic value.
Additionally, Nick Treanor (2014) has criticized the argument for a
different reason, which is that (contra DePaul) there is no
clear example of two sets which contain the same number of true
beliefs. More recently, Xingming Hu (2017) has defended the final
value of true belief against DePaul’s argument, though Hu argues
further that neither Ahlstrom-Vij and Grimm (2013)’s nor
Treanor’s (2014) critique of DePaul’s argument is
compelling.
Another axis on which the debate about the value of true belief can be
configured is in terms of whether one opts for an epistemic-value
monism or an epistemic-value pluralism—that is, whether one
thinks there is only one fundamental epistemic goal, or several.
Kvanvig (e.g., 2005) endorses epistemic-value pluralism, since he
thinks that there are a number of fundamental epistemic goals, with
each of them being of final value. Crucial to Kvanvig’s argument
is that there are some epistemic goals which are not obviously
truth-related—he cites the examples of having an empirically
adequate theory, making sense of the course of one’s experience,
and inquiring responsibly, and more recently, Brent Madison (2017) has
argued by appealing to a new evil demon thought experiment, that
epistemic justification itself should be included in such a list. This
is important because if the range of goals identified were all
truth-related, then it would prompt the natural response that such
goals are valuable only because of their connection to the truth, and
hence not fundamental epistemic goals at all.
Presumably, though, it ought also to be possible to make a case for an
epistemic-value pluralism where the fundamental epistemic goals were
not finally valuable (or, at least, à la Sosa, where
one avoided taking a stance on this issue). More precisely, if an
epistemic-value monism that does not regard the fundamental epistemic
goal as finally valuable can be made palatable, then there seems no
clear reason why a parallel view that opted for pluralism in this
regard could not similarly be given a plausible supporting story.
In his essay, “Meno in a Digital World”, Pascal
Engel (2016) questions whether the original value problem applies to
the kind of knowledge or pseudo-knowledge that we get from the
internet? (2016: 1). One might initially think that internet and/or
digitally acquired knowledge raises no new issues for the value
problem. On this line of thought, if digitally acquired (e.g., Googled
knowledge, information stored in iPhone apps, etc.) is
genuine knowledge, then whatever goes for knowledge more
generally, vis-à-vis the value problems surveyed in
§§1–2, thereby goes for knowledge acquired from our
gadgets.
However, recent work at the intersection of epistemology and the
philosophy of mind suggests there are potentially some new and
epistemologically interesting philosophical problems associated with
the value of technology-assisted knowledge. These problems correspond
with two ways of conceiving of knowledge as extending beyond
traditional, intracranial boundaries (e.g., Pritchard, forthcoming). In particular, the kinds of
‘extended knowledge’ which have potential import for the
value of knowledge debate correspond with the extended mind
thesis (for discussion on how this thesis interfaces with the
hypothesis of extended cognition, see Carter, Kallestrup, Pritchard,
& Palermos 2014) and cases involving what Michael Lynch (2016)
calls ‘neuromedia’ intelligence augmentation.
According to the extended mind thesis (EMT), mental states
(e.g., beliefs) can supervene in part on extra-organismic elements of
the world, such as laptops, phones and notebooks, that are typically
regarded as ‘external’ to our minds. This thesis, defended
most notably by Andy Clark and David Chalmers (1998), should not be
conflated with comparatively weaker and less controversial thesis of
content externalism (e.g., Putnam 1975; Burge 1986), according to which the
meaning or content of mental states can be fixed by extra-organismic
features of our physical or social-linguistic environments.
What the proponent of EMT submits is that mental states
themselves can partly supervene on extracranial artifacts
(e.g., notebooks, iPhones) provided these extracranial artifacts play
kinds of functional roles normally played by on-board, biological
cognitive processes. For example, to borrow an (adapted) case from
Clark and Chalmers (1998), suppose an Alzheimer’s patient,
‘Otto’, begins to outsource the task of memory storage and
retrieval to his iPhone, having appreciated that his biological memory
is failing. Accordingly, when Otto acquires new information, he
automatically records it in his phone’s ‘memory
app’, and when he needs old information, he (also, automatically
and seamlessly) opens his memory app and looks it up. The iPhone comes
to play for Otto the functionally isomorphic role that biological
memory used to play for him vis-à-vis the process of
memory storage and retrieval. Just as we attribute to normally
functioning agents knowledge in virtue of their (non-occurrent)
dispositional beliefs stored in biological memory (for example, five
minutes ago, you knew that Paris is the capital of France), so, with
EMT in play, we should be prepared to attribute knowledge to Otto in
virtue of the ‘extended’ (dispositional) beliefs which are
stored in his notebook, provided Otto is as epistemically diligent in
encoding and retrieving information as he was before (e.g., Pritchard
2010b.
The import EMT has for the value of knowledge debate now takes shape:
whatever epistemically valuable properties (if any) are distinctively
possessed by knowledge, they must be properties that obtain in
Otto’s case so as to add value to what would otherwise be
mere true (dispositional) beliefs that are stored,
extracranially, in Otto’s iPhone. But it is initially puzzling
just why, and how, this should be. After all, even if we accept the
intuition that the epistemic value of traditional (intracranial)
knowledge exceeds the value of corresponding true opinion, it is, as
Engel (2016), Lynch (2016) and Carter (2017) have noted, at best not
clear that this comparative intuition holds in the extended case,
where knowledge is possessed simply by virtue of information
persisting in digital storage.
For example, consider again Plato’s solution to the value
problem canvassed in
 §1:
 knowledge, unlike true belief, must be ‘tied-down’ to the
truth. Mere true belief is more likely to be lost, which makes it less
valuable than knowledge. One potential worry is that extended
knowledge, as per EMT—literally, often times, knowledge stored
in the cloud—is by its very nature not ‘tethered’,
or for that matter even tetherable, in a way that corresponding items
of accurate information which fall short of knowledge are not. Nor
arguably does this sort of knowledge in the cloud clearly have the
kind of ‘stability’ that Olsson (2009) claims is what distinguishes
knowledge from true opinion. Perhaps even less does it appear to
constitute a valuable cognitive ‘achievement’, as per
robust virtue epistemologists such as Greco and Sosa.
EMT is of course highly controversial, (see, for example, Adams &
Aizawa 2008), and so one way to sidestep the implications for the
value of knowledge debate posed by the possibility of knowledge that
is extended via extended beliefs, is to simply resist EMT as
a thesis about the metaphysics of mind.
However, there are other ways in which the technology-assisted
knowledge could have import for the traditional value problems. In
recent work, Michael P. Lynch (2016) argues that, given the increase
in cognitive offloading coupled with evermore subtle and physically
smaller intelligence-augmentation technologies (e.g., Bostrom &
Sandberg 2009), it is just a matter of time before the majority of the
gadgetry we use for cognitive tasks will be by and large seamless and
‘invisible’. Lynch suggests that while coming to know via
such mechanisms can make knowledge acquisition much easier, there are
epistemic drawbacks. He offers the following thought experiment:
NEUROMEDIA: Imagine a society where smartphones are miniaturized and
hooked directly into a person’s brain. With a single mental
command, those who have this technology—let’s call it
neuromedia—can access information on any subject […] Now
imagine that an environmental disaster strikes our invented society
after several generations have enjoyed the fruits of neuromedia. The
electronic communication grid that allows neuromedia to function is
destroyed. Suddenly no one can access the shared cloud of information
by thought alone. […] for the inhabitants of this society,
losing neuromedia is an immensely unsettling experience; it’s
like a normally sighted person going blind. They have lost a way of
accessing information on which they’ve come to rely […]
Just as overreliance on one sense can weaken the others, so
overdependence on neuromedia might atrophy the ability to access
information in other ways, ways that are less easy and require more
creative effort. (Lynch 2016: 1–6)
One conclusion Lynch has drawn from such thought experiments is that
understanding has a value that mere knowledge lacks, a position
we’ve seen has been embraced for different reasons in
 §4
 by Kvanvig and others. A further conclusion, advanced by Pritchard
(2013) and Carter (2017), concerns the extent to which the acquisition
of knowledge involves ‘epistemic dependence’—viz.,
dependence on factors outwith one’s cognitive agency. They argue
that the greater the scope of epistemic dependence, the more valuable
it becomes to cultivate virtues like intellectual autonomy that
regulate the appropriate reliance and outsourcing (e.g., on other
individuals, technology, medicine, etc.) while at the same time
maintaining one’s intellectual self-direction.