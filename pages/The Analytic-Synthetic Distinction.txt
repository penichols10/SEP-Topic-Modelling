Compare the following two sets of sentences:
Most competent English speakers who know the meanings of all the
constituent words would find an obvious difference between the two
sets: whereas they might wonder about the truth or falsity of those of
set I, they would find themselves pretty quickly incapable of doubting
those of II. Unlike the former, these latter seem to be known
automatically, “just by virtue of knowing just what the
words mean,” as many might spontaneously put it. Indeed, a
denial of any of them would seem to be in some important way
unintelligible, very like a contradiction in terms.
Although there is, as we shall see, a great deal of dispute about
these italicized ways of drawing the distinction, and even about
whether it is real, philosophers standardly refer to sentences of the
first class as “synthetic,” those of the second as (at
least apparently) “analytic.” Many philosophers have hoped
that the apparent necessity and a priori status of the claims
of logic, mathematics and much of philosophy would prove to be due to
these claims being analytic, i.e., explaining why such claims seemed
to be true “in all possible worlds,” and knowable to be so
“independently of experience.” This view has led them to
regard philosophy as consisting in large part in the
“analysis” of the meanings of the relevant claims, words
and concepts (hence “analytic” philosophy, although the
term has long ceased to have any such specific commitment, and refers
now more generally to philosophy done in the associated closely
reasoned style); and, most importantly, this seemed to invite and
support the special methodology of “arm chair reflection”
on concepts in which philosophers traditionally engaged, independently
of any empirical research.
Although there are precursors of the contemporary notion of the
analytic in Leibniz, and in Locke and Hume in their talk of
“relations of ideas,”, the conception that currently
concerns many philosophers has its roots in the work of Kant (1781
[1998]) who, at the beginning of his Critique of Pure Reason,
wrote:
He provided as an example of an analytic judgment, “All bodies
are extended”: in thinking of a body we can’t help but
also think of something extended in space; that would seem to be just
part of what is meant by “body.” He contrasted this with
“All bodies are heavy,” where the predicate (“is
heavy”) “is something entirely different from that which I
think in the mere concept of body in general” (A7), and we must
put together, or “synthesize,” the different concepts,
body and heavy (sometimes such concepts are called
“ampliative,” “amplifying” a concept beyond
what is “contained” in it).
Kant tried to spell out his “containment” metaphor for the
analytic in two ways. To see that any of set II is true, he wrote,
“I need only to analyze the concept, i.e., become conscious of
the manifold that I always think in it, in order to encounter this
predicate therein” (A7). But then, picking up a suggestion of
Leibniz, he went on to claim:
As Katz (1988) emphasized, this second definition is significantly
different from the “containment” idea, since now, in its
appeal to the powerful method of proof by contradiction, the analytic
would include all of the (potentially infinite) deductive consequences
of a particular claim, most of which could not be plausibly regarded
as “contained” in the concept expressed in the claim. For
starters, “Bachelors are unmarried or the moon is blue” is
a logical consequence of “Bachelors are
unmarried”—its denial contradicts the latter (a denial of
a disjunction is a denial of each disjunct)—but clearly nothing
about the color of the moon is remotely “contained in” the
concept bachelor. To avoid such consequences, Katz (e.g., 1972, 1988)
went on to try to develop a serious theory based upon only the initial
containment idea, as, along different lines, does Pietroski (2005).
One reason Kant may not have noticed the differences between his
different characterizations of the analytic was that his conception of
“logic” seems to have been confined to the Aristotelian
syllogistic, and so didn’t include the full resources of modern
logic, where the differences between the two characterizations become
more glaring (see MacFarlane 2002). Indeed, he demarcates the category
of the analytic chiefly in order to contrast it with what he regards
as the more important category of the “synthetic,” which
he famously thinks is not confined, as one might initially suppose,
merely to the empirical. (That providing a serious, positive account
of the “analytic” was not Kant’s concern is perhaps
brought out by his scepticism at 1781 [1998], A727–732, at least
about definitions outside of mathematics). While some trivial a
priori claims might be analytic in this sense, for Kant the
seriously interesting ones were synthetic. He argues that even so
elementary an example in arithmetic as “7+5=12,” is
synthetic, since the concept of “12” is not contained in
the concepts of “7,” “5,” or “+,”:
appreciating the truth of the proposition would seem to require some
kind of active synthesis of the mind uniting the different constituent
thoughts. And so we arrive at the category of the “synthetic
a priori,” whose very possibility became a major
concern of his work. He tries to show that the activity of
“synthesis” was the source of the important cases of a
priori knowledge, not only in arithmetic, but also in geometry,
the foundations of physics, ethics, and philosophy generally, a view
that set the stage for much of the philosophical discussions of the
subsequent century (see Coffa 1991, pt. I). 
Apart from geometry, Kant, himself, didn’t focus much on the
case of mathematics. But, as mathematics in the 19th C. began reaching
new heights of sophistication, worries were increasingly raised about
its foundations as well. It was specifically in response to this
latter problem that Gottlob Frege (1884 [1980]) tried to improve upon
Kant’s formulations of the analytic, and presented what is
widely regarded as the next significant discussion of the topic. 
Frege (1884 [1980], §§5,88) and others noted a number of
problems with Kant’s “containment” metaphor. In the
first place, as Kant (1781 [1998], A728) himself would surely have
agreed, the criterion would need to be freed of
“psychologistic” suggestions, or claims about merely the
accidental thought processes of thinkers, as opposed to claims about
truth and justification that are presumably at issue with the
analytic. In particular, mere associations are not always matters of
meaning: someone might regularly associate bachelors with being
unharried, but this wouldn’t therefore seriously be a part of
the meaning of “bachelor” (“a harried
bachelor” is not contradictory). But, secondly, although the
denial of a genuinely analytic claim may well be a
“contradiction,” it isn’t clear what makes it so:
there is no explicit contradiction in the thought of a
married bachelor, in the way that there is in the thought of a
bachelor who is not a bachelor. “Married bachelor” has at
least the same explicit logical form as “harried
bachelor.” Rejecting “a married bachelor” as
contradictory would seem to have no justification other than the claim
that “All bachelors are unmarried” is analytic, and so
cannot serve to justify or explain that claim.
Even were Kant to have solved these problems, it isn’t clear how
his notion of “containment” would cover all the cases of
what seem to many to be as “analytic” as any of set II.
Thus, consider:
The symmetry of the marriage relation, or the transitivity of
“ancestor” and “bigger than” are not obviously
“contained in” the corresponding thoughts in the way that
the idea of extension is plausibly “contained in” the
notion of body, or male in the notion of bachelor. (14) has seemed
particularly troublesome: what else besides “colored”
could be included in the analysis? Red is colored and what else? It is
hard to see what else to “add”—except red itself!
(See §3.4 below for further discussion.)
Frege attempted to remedy the situation by completely rethinking the
foundations of logic, developing what we now think of as modern
symbolic logic. He defined a perfectly precise “formal”
language, i.e., a language characterized by the “form”
–standardly, the shape—of its expressions, and he
carefully set out an account of the syntax and semantics of what are
called the “logical constants,” such as “and”,
“or”, “not”, “all” and
“some”, showing how to capture a very wide class of valid
inferences containing them. Saying precisely how these constants are
selected is a matter of considerable difficulty (see Logical
Constants), but, at least intuitively, the constants can be
thought of as those parts of language that don’t
“point” or “function referentially,” aiming to
refer to something in the world, in the way that ordinary nouns, verbs
and adjectives seem to do: “Socrates” refers to Socrates,
“dogs” to dogs, “clever” to clever and/or
clever things, and even “Zeus” aims to refer to a Greek
god, but words like “and” and “all”
don’t seem to function referentially at all: at any rate, it
certainly isn’t clear that there are “and”s and
“all”s in the world, along with the dogs and their
properties. (Rendering this distinction fully precise, in a way that
deals with all of the many “function” words of natural
language, such as auxiliary verbs, pronouns and prepositions, is none
too easy; for purposes here, it will suffice to restrict attention to
merely the constants of standard first-order logic.)
This distinction between non-logical, “referring”
expressions and logical constants allows us to define a logical truth
as a sentence that is true no matter what non-logical expressions
occur in it. Consequently (italicizing non-logical expressions),
counts as a (strict) logical truth: no matter what non-logical
expressions we put in for “doctor”, “eyes” and
“specialize on” in (6), the sentence will remain true. For
example, substituting “cats” for “doctors”,
“mice” for “eyes” and “chase” for
“specialize on”, we get:
(Throughout this discussion, by “substitution” we shall
mean uniform substitution of one presumably univocal expression for
another in all its occurrences in a sentence.) But what about the
others of set II? Substituting “cats” for
“doctors” and “mice” for
“ophthalmologists” in
we get: 
which is patently false, as would many such substitutions render the
rest of the examples of II. (6) is a patent logical truth;
its truth depends only upon the semantic values of its logical
particles. But the truth of (7) – (10) depends upon analyticities of the
further non-logical terms. How are we to capture these?
Here Frege appealed to the notion of definition,
or—presuming that definitions preserve “meaning”
(see §3.2ff below)—synonymy: the non-logical
analytic truths are those that can be converted to (strict) logical
truths by substitution of definitions for defined terms, or synonyms
for synonyms. Since “mice” is not synonymous with
“ophthalmologist”, (16) is not a substitution of the
required sort. We need, instead, a substitution of the definition of
“ophthalmologist”, i.e., “doctor that specializes on
eyes”, which would convert (7) into our earlier purely logical
truth:
Of course, these notions of definition, meaning and
synonymy would themselves need to clarified, But they were
thought to be sufficiently obvious notions, whose clarification
didn’t seem particularly urgent until Quine raised serious
questions about them much later (see §3.6ff below).
Frege was mostly interested in formalizing arithmetic, and so
considered the logical forms of a relative minority of natural
language sentences in a deliberately spare formalism. Work on the
logical (or syntactic) structure of the full range of sentences of
natural language has blossomed since then, initially in the work of
Bertrand Russell (1905), in his famous theory of definite
descriptions, where the criterion is applied to whole phrases in
context, but then especially in the work of Noam Chomsky and other
“generative” linguists (see §4.3 below). Whether
Frege’s criterion of analyticity will work for the rest of II
and other analyticities depends upon the details of those proposals
(see, e.g., Katz, 1972, Montague, 1974, Hornstein, 1984, Harman, 1996,
and Pietroski, 2005 and forthcoming). 
Why should philosophy be interested in what would seem to be a purely
linguistic notion? Because, especially in the first half of the
Twentieth Century, many philosophers thought it could perform crucial
epistemological work, providing an account, first, of our
apparently a priori knowledge of mathematics, and
then—with a little help from British empiricism—of our
understanding of claims about the spatio-temporal world as well.
Indeed, “conceptual analysis” soon came to constitute the
very way particularly Anglophone philosophers characterized their
work. 
Many additionally thought it would perform the metaphysical
work of explaining the truth and necessity of
mathematics, showing not only how it is we could know about
these topics independently of experience, but how they could be
true in this and all possible worlds. This latter ambition
was sometimes not distinguished from the former one, although it is no
longer shared by most philosophers still interested in the analytic.
Indeed, many have wondered how could any sentence be true, much less
necessary, “by virtue of meaning alone,” since surely the
truth of any sentence depends upon the world being the way the
sentence represents it as being. Recall that Frege’s ambition
was to reduce mathematics to logic by showing how, substituting
synonyms for synonyms, every mathematical truth could be shown to be a
logical one. He didn’t go on to claim (although some later
philosophers did) that the logical truths themselves were true by
virtue of meaning alone. Thus, “Bachelors are unmarried”
might be shown to be analytic by substituting “unmarried
males” for “bachelors” and converting it thereby to
the logical truth “Unmarried males are unmarried.” But
what makes this latter true? As Devitt (1996) pointed
 out:[1]
In view of this point, in the remainder of this entry we will focus
primarily on the epistemological project.
The problem of accounting for mathematical knowledge is arguably one
of the oldest and hardest problems in Western philosophy. It is easy
enough to understand: ordinarily we acquire knowledge about the world
by our senses. If we are interested in, for example, whether
it’s raining outside, how many birds are on the beach, whether
fish sleep or stars collapse, we look and see, or turn to others who
do. It is a widespread view that Western sciences owe their tremendous
successes precisely to relying on just such “empirical”
(experiential, experimental) methods. However, it is also a patent
fact about all these sciences, and even our ordinary ways of counting
birds, fish and stars, that they depend on mathematics; and
mathematics does not seem to be known on the basis of experience.
Mathematicians don’t do experiments in the way that chemists,
biologists or other “natural scientists” do. They seem
simply to think, at most with pencil and paper as an aid to
memory. In any case, they don’t try to justify their claims by
reference to experiments: “Twice two is four” is not
justified by observing that pairs of pairs tend in all cases observed
so far to be quadruples.
But how could mere processes of thought issue in any knowledge about
the independently existing external world? The belief that it could
would seem to involve some kind of mysticism; and, indeed, many
“naturalistic” philosophers have felt that the appeals of
“Rationalist” philosophers like Plato, Descartes, Leibniz
and, more recently, Katz (1988, 1990), Bealer (1987) and Bonjour
(1998), to some special faculty of “rational intuition,”
seem no better off than appeals to “revelation” to
establish theology.
Here’s where the analytic seemed to many to offer a more
promising alternative. Perhaps all the truths of arithmetic could be
shown to be analytic by Frege’s criterion, i.e., by showing that
they could all be converted into logical truths by substitution of
synonyms for synonyms. Of course, the relevant synonyms were not quite
as obvious as “ophthalmologist” and “eye
doctor”; one needed to engage in a rigorous process of
“logical analysis” of the meanings of such words as
“number”, “plus”, “exponent”,
“limit”, “integral”, etc. But this is what
Frege set out to do, and in his train, Bertrand Russell and the young
Ludwig Wittgenstein, launching the program of logicism, often with
great insight and at least some success (see §5 below).
But why stop at arithmetic? If logical analysis could illuminate the
foundations of mathematics by showing how it could all be derived from
logic by substitution of synonyms, perhaps it could also illuminate
the foundations of the rest of our knowledge by showing how
its claims could similarly be derived from logic and
experience. Such was the hope and program of Logical
Positivism, championed by, e.g., Moritz Schlick, A.J. Ayer and,
especially, Rudolf Carnap. Of course, such a proposal did presume that
all of our concepts were “derived” either from logic or
experience, but this seemed in keeping with the then prevailing
presumptions of empiricism, which, they assumed, had been vindicated
by the immense success of the empirical sciences.
How were our concepts of, e.g., space, time, causation, or material
objects analytically related to experience? For the Positivists, the
answer seemed obvious: by tests. Interpreting
Wittgenstein’s (1922) Tractatus along the lines of the
American philosopher, C.S. Peirce, they proposed various versions of
their “Verifiability Theory of Meaning,”
according to which the meaning (or “cognitive
significance”) of any sentence was the conditions of its
empirical (dis-)confirmation. Thus, to say that the temperature of a
liquid is of a certain magnitude is to say, for example, that the
mercury in a thermometer immersed in the liquid would expand to a
certain point marked by a numeral representing that magnitude, a claim
that would ordinarily be disconfirmed if it didn’t. Closer to
“experience”: to say that there is a cat on a mat is just
to say that certain patterns of sensation (certain familiar visual,
tactile and aural appearances) are to be expected under certain
circumstances. After all, it seemed to them, as it seemed to Locke,
Berkeley and Hume centuries earlier, that all our concepts are derived
from sensory experiences, and, if so, then all our concepts must
involve some or other kind of construction from those experiences.
For the Positivists, these earlier empiricists had erred only in
thinking that the mechanism of construction was mere association. But
association can’t even account for the structure of a judgment,
such as “Salt comes in shakers,” which is not merely the
excitation of its constituent ideas, along the lines of
“salt” exciting “pepper,” but involves
combining the nouns “salt” and “shakers” with
the predicate “x comes in y” in a very particular way (see
Kant, 1781 [1998], A111–2 and Frege, 1892b [1966]). That is, our
thoughts and claims about the world have some kind of logical
structure, of a sort that seems to begin to be revealed by
Frege’s proposals. Equipped with Frege’s logic, it was
possible to provide a more plausible formulation of conceptual
empiricism: our claims about the empirical world were to be analyzed
into the (dis)confirming experiences out of which they must somehow
have been logically constructed.
The project of providing “analyses” in this way of
especially problematic concepts like those concerning, for example,
material objects, knowledge, perception, causation, freedom,
and the self, was pursued by Positivists and other
“analytic” philosophers for a considerable period (see
Carnap 1928 [1967] for some rigorous examples, Ayer 1934 [1952] for
more accessible ones). With regard to material object claims, the
program came to be known as “phenomenalism”; with regard
to the theoretical claims of science, as “operationalism”
; and with regard to the claims about people’s mental lives, as
“analytical behaviorism” (the relevant experiential basis
of mental claims in general being taken to be observations of
others’ behavior). Although these programs became extremely
influential, and some form of the verifiability criterion was often
(and sometimes still is) invoked in physics and psychology to
constrain theoretical speculation, they seldom, if ever, met with any
serious success. No sooner was an analysis, say, of “material
object” or “expectation,” proposed than serious
counterexamples were raised and the analysis revised, only to be faced
with still further counterexamples (see Chisholm 1957, and Fodor 1981,
for discussion of the failures, and note, again, Kant’s 1781
[1998], A327–32, scepticism about at least definitions outside
mathematics). Despite what seemed its initial plausibility,
philosophers came to suspect that the criterion, and with it the very
notion of analyticity itself, rested on some fundamental mistakes.
An issue that Frege’s criterion didn’t address is the
status of the basic sentences of logic themselves. Are the logical
truths themselves a priori because they, too, are
“analytic”? But what makes them so? Is it that anyone who
understands their wording just must see that they are true? If so, how
are we to make sense of people’s frequent, often apparent
violations of them in fallacious reasoning and ordinary
 speech?[2]
 What are we to make of disputes about the laws of logic of the sort
that are raised, for example, by mathematical intuitionists, who deny
the Law of Excluded Middle (“p or not p”), or, more
recently, by “para-consistent” logicians, who argue for
the toleration even of contradictions to avoid certain paradoxes (see
Priest 1987 [2006] and Williamson 2007:chapter 4, for discussion)?
Moreover, given that the infinitude of logical truths needs to be
“generated” by rules of inference, wouldn’t that be
a reason for regarding them as “synthetic” in Kant’s
sense (see Frege 1884 [1980], §88, Katz 1988, pp. 58–9 and
MacFarlane 2002)? Most worrisome is a challenge raised by Quine 1956
[1976], §II): how does claiming logical truths to be analytic
differ from merely claiming them to be obviously and universally
correct, i.e., widely and firmly held beliefs, indistinguishable in
kind from banalities like “The earth has existed for many
years” or “There have been black dogs”?
A further problem arises for the non-logical vocabulary. The sentences
reporting our experiences seemed to many to have some kind of analytic
connection with those experiences—a normal sighted person
failing to apply “looks red” in clear cases arguably fails
to understand the words. But there was a serious question about just
what “experience” should be taken to be: was it the usual
sort of encounter we have with ordinary middle-sized objects such as
tables and chairs, the weather and bodily actions, in terms of which
most people would readily describe their perceptual experience? Or was
it some sort of special “un-conceptualized” play of sense
impressions that would require careful introspection to reveal? This
latter suggestion seemed to involve a “myth of the given”
(Sellars 1956), or the dubious assumption that there was something
given in our experience that was entirely un-interpreted by our
understanding. This was a claim about which serious doubts were raised
not only by Sellars, but by psychologists (e.g., Bruner 1957) and
historians of science (e.g., Hanson 1958 and Kuhn 1962). Ordinary
“observations” can be seen to be shot through with
conceptual presuppositions: observing a meter reading “7
amps” requires conceptualizing some object as a meter, the marks
on it as numerals as indicating numbers and/or magnitudes of amperage;
observing someone kick a cat requires conceptualizing a bodily motion
as an intentional act; and even observing the sky to be blue requires
the peculiar concept of the sky. Trying to divest such
ordinary observations of all of their conceptual baggage and
reporting experience as it seems in and of itself would seem
to require at least the trained eye of a Monet and the nuanced mind of
a Proust, and it’s difficult to see why such special and
sophisticated reports should be particularly privileged. And if there
is no privileged set of sentences reporting experience, then the rug
would seem to have been pulled out from under some of the main
presumptions and motivations for the Positivist program: what would be
the significance of “analyzing” the meaning of a claim
into merely what a particular theorist had (arbitrarily?) decided to
regard as primitive?
Recent developments in psychology, however, suggest that human minds
may well contain sensory and motor “modules” whose
primitives would be epistemically distinctive, even if they do involve
some limited degree of conceptual interpretation (see Modularity
of Mind and Fodor 1983, 1984). And so the analytical Positivist
program might be recast in terms of the reduction of all concepts to
these sensorimotor primitives, a project that is sometimes implicit in
cognitive psychology and artificial intelligence.
Another problem with the entire program was raised by Langford (1942)
and discussed by Moore (1942 [1968], pp. 665–6): why should
analyses be of any conceivable interest? After all, if an analysis
consists in providing the definition of an expression, then it should
be providing a synonym for it, and this, then, should be wholly
uninformative: if “brother” is analyzed as the presumably
synonymous “male sibling,” then the claim “Brothers
are male siblings” should be synonymous with “Brothers are
brothers,” and thinking the one should be no different from
thinking the other. But, aside from such simple cases as
“brother” and “bachelor,” proposed analyses,
if successful, often seemed unobvious and philosophically informative.
The proposed reductions of, say, material object statements to sensory
ones were often fairly complex, had to be studied and learned, and so
could hardly be uninformative. So how could they count as seriously
analytic?
This is “the paradox of analysis,” which can be seen as
dormant in Frege’s own move from his (1884) focus on definitions
to his more controversial (1892a) doctrine of sense, where two senses
are distinct if and only if someone can think a thought containing the
one but not other, as in the case of the senses of “the morning
star” and “the evening star.” If analyses or
definitions preserved sense, then, unlike the case of “morning
star” and “evening star,” whenever one thought the
definiendum, one would be thereby thinking the definiens. And perhaps
one can’t think Bill is Bob’s brother without thinking
Bill is Bob’s male sibling. But few of Frege’s definitions
of arithmetic concepts are nearly so simple (see
 Gottlob Frege,
 §2.5). In their case, it seems perfectly possible to think the
definiendum, say, number, without thinking the elaborate definiens
Frege provides (see Bealer 1982, Dummett 1991, and Horty 1993, 2007,
for extensive discussions of this problem, and further conditions,
e.g., fecundity, that Frege placed on serious definitions).
A related problem, discussed by Bealer (1998), is the possible
proliferation of candidate analyses. The concept of a circle can be
analyzed as the concept of a set of co-planar points equidistant
from a given point and as a closed figure of constant
curvature. Not only do both of these analyses seem informative,
the equivalence between them would need to be shown by some serious
geometry, and, especially since the advent of non-Euclidean geometries
and Einstein’s theories of relativity, this could no longer be
assumed to be justified merely on the basis of logic and
definitions.
These problems, so far, can be regarded as relatively technical, for
which further technical moves within the program might be made. For
example, one might make further distinctions within the theory of
sense between an expression’s content and the specific
“linguistic vehicle” used for its expression, as in Fodor
(1990a) and Horty (1993, 2007); and maybe distinguish between the
truth-conditional content of an expression and its
idiosyncratic role, or “character,” in a language
system, along the lines of a distinction Kaplan (1989) introduced to
deal with indexical and demonstrative expressions (such as
“I,” “now” and “that”; see
Demonstratives, Narrow Mental Content and White
1982). Perhaps analyses could be regarded as providing a particular
“vehicle,” having a specific “character,” that
could account for why one could entertain a certain concept without
entertaining its analysis (see G. Russell, 2008, and Pietroski, 2002,
2005, and forthcoming, for different suggestive discussions).
However, the problems with the program seemed to many philosophers to
be deeper than merely technical. By far, the most telling and
influential of the criticisms both of the program, and then of
analyticity in general, were those of the American philosopher, W.V.
Quine, who began as a great champion of the program (see esp. his
1934), and whose subsequent objections therefore carry special weight.
The reader is well-advised to consult particularly his (1956 [1976])
for as rich and deep a discussion of the issues as one might find. The
next two sections abbreviate some of that discussion.
Although the pursuit of the logicist program gave rise to a great many
insights into the nature of mathematical concepts, not long after its
inception it began encountering substantial difficulties. For Frege,
the most calamitous came early on in a letter from Russell, in which
Russell pointed out that one of Frege’s crucial axioms for
arithmetic was actually inconsistent. His intuitively quite plausible
“Basic Law V” (sometimes called “the unrestricted
Comprehension Axiom”) had committed him to the existence of a
set for every predicate. But what, asked Russell, of the predicate
“x is not a member of itself”? If there were a set
for that predicate, that set itself would be a member of itself if and
only if it weren’t; consequently, there could be no such set.
Frege’s Basic Law V couldn’t be true (but see
 Frege’s theorem and foundations for arithmetic
 and recent discussion of Frege’s program in §5 below).
What was especially upsetting about “Russell’s
paradox” was that there seemed to be no intuitively satisfactory
way to repair set theory in a way that could lay claim to being as
obvious and merely a matter of logic or meaning in the way that
Positivists had hoped. Various proposals were made, but all of them
were tailored precisely to avoid the paradox, and seemed to have
little independent appeal. Certainly none of them appeared to be
analytic. As Quine (1956 [1976], §V) observed, in the actual
practice of choosing axioms for set theory, we seem to be left
“making deliberate choices and setting them forth unaccompanied
by any attempt at justification other than in terms of their elegance
and convenience,” appeals to the meanings of terms be hanged
(although see Boolos’ 1971 defense of the “iterative
conception of set”).
Perhaps, however, these “deliberate choices” could
themselves be seen as affording a basis for analytic claims. For
aren’t matters of meaning in the end really matters about the
deliberate or implicit conventions with which words are used? Someone,
for example, could invest a particular word, say,
“schmuncle,” with a specific meaning merely by stipulating
that it mean, say, unmarried uncle. Wouldn’t that afford a basis
for claiming then that “A schmuncle is an uncle” is
analytic, or “true by virtue of the (stipulated) meanings of the
words alone”? Carnap (1947) proposed setting out the
“meaning postulates” of a scientific language in just this
way. This had the further advantage of allowing terms to be
“implicitly defined” by their roles in such postulates,
which might be a theory’s laws or axioms. This strategy seems
especially appropriate for defining logical constants, as well as for
dealing with cases like (11)–(14) above, e.g. “Red is a
color,” where mere “containment” seemed not to
suffice. So perhaps what philosophical analysis is doing is revealing
the tacit conventions of ordinary language, an approach particularly
favored by Ayer (1934 [1952]).
Quine (1956, §§IV–V) goes on to address the complex
role(s) of convention in mathematics and science. Drawing on his
earlier discussion (1936 [1976]) of the conventionality of logic, he
argues that logic could not be established by such conventions,
since
This is certainly an argument that ought to give the proponents of the
conventionality of logic pause: how could one hope to set out the
general conventions for “all” or
“if…then…” without using the notions of
“all” and
“if…then…”? (“ALL universal
instantiations are valid”; “IF p is one
premise, and if p then q is another, THEN it’s
valid to conclude
 q”)[3]
Turning to set theory and then the rest of science, Quine goes on to
argue that, although stipulative definition, what he calls
“legislative postulation,”
Even if Newton, say, had himself explicitly set out “F=ma”
as a stipulated definition of “F”, this wouldn’t
really settle the interesting philosophical question of whether
“F=ma”, is justified by its being analytic, or “true
by meaning alone,” since our taking his stipulation seriously
would seem to depend upon our acceptance of his theory as a whole, in
particular, perhaps, upon “the elegance and convenience”
it brought to the rest of our physical theory of the world. If it
didn’t do so, that might be a serious reason to reject it. In a
famous discussion of Quine, Putnam (1965 [1975]) adduced numerous
cases of revisions of definitions in the history of science, for
example, the revision of the “ definition” of
“kinetic energy” as 1/2mv2 in the light of
Einstein’s Theory of Relativity (see Harman 1996, p. 399 for a
nice discussion of how “something that is true by stipulative
definition can turn out to be false”). As Quine goes on to
observe:
Carnap’s legislated “meaning postulates” should
therefore be regarded as just an arbitrary selection of sentences of a
theory, a selection perhaps useful for purposes of exposition, but no
more significant than the selection of certain towns in Ohio as
“starting points” for a journey (1953 [1980], p.
 35).[4]
 Invoking his famous holistic metaphor of the “fabric”, or
“web” of belief, Quine concludes:
These last passages express a tremendously influential view of
Quine’s that led several generations of philosophers to despair
not only of the analytic-synthetic distinction, but of the category of
a priori knowledge entirely. The view has come to be called
“confirmation holism,” and Quine had expressed it more
shortly a few years earlier, in his widely read article, “Two
Dogmas of Empiricism” (1953, ch. 2):
Indeed, the “two dogmas” that the article discusses are
(i) the belief in the intelligibility of the “analytic”
itself, and (ii), what Quine regards as the flip side of the same
coin, the belief that “each statement, taken in isolation from
its fellows, can admit of confirmation or infirmation at all”
(p. 41), i.e., the very (version of the) Verifiability Theory of
Meaning we have seen the Positivists enlisted in their effort to
“analyze” the claims of science and commonsense.
(Ironically enough, Quine, himself, continued to adhere to a
verifiability conception of meaning, his confirmation holism
leading him merely to embrace a further meaning holism and
his notorious “thesis of the indeterminacy of translation”
see his 1986, p. 155, and the next section below).
Quine bases his “confirmation holism” upon observations of
Pierre Duhem (1914 [1954]), who drew attention to the myriad ways in
which theories are supported by evidence, and the fact that an
hypothesis is not (dis)confirmed merely by some specific experiment
considered in isolation from an immense amount of surrounding theory.
Thus, to take our earlier example, a thermometer will be a good
indication of ambient temperature only if it’s made of the right
materials, calibrated appropriately, and there aren’t any other
forces at work that might disturb the measurement—and, of
course, only if the background laws of physics and other beliefs that
have informed the design of the measurement are in fact sufficiently
correct. A failure of the thermometer to measure the temperature could
be due to a failure of any of these other conditions, which is, of
course, why experimenters spend so much time and money constructing
experiments to “control” for them. Moreover, with a small
change in our theories or background beliefs, or just in our
understanding of the conditions for measurement, we might change the
tests on which we rely, but often without changing the meaning of the
sentences whose truth we might be trying to test (which, as Putnam
1965 [1975] pointed out, is precisely what practicing scientists
regularly do).
What is novel—and highly controversial—about Quine’s
understanding of these commonplace observations is his extension of
them to claims presumed by most people (e.g., by Duhem himself) to be
outside their scope, viz., the whole of mathematics and even logic! It
is this extension that seems to undermine the traditional a
priori status of these latter domains, since it appears to open
the possibility of a revision of logic or mathematics in the interest
of the plausibility of the overall resulting theory—containing
both the empirical claims and those of logic and mathematics. Perhaps
this wouldn’t be so bad should the revisability of logic and
mathematics permit their ultimately admitting of a justification that
didn’t involve experience. But this is ruled out by
Quine’s insistence that scientific theories, along with their
logic and mathematics, are confirmed “only” as
“corporate bodies.” (It’s not clear what entitles
Quine to this crucial “only,” but his doctrine has been
read as standardly including it; see Rey 1998, 2013, for discussion).
Certainly, though, as an observation about the revisability of claims
of logic and meaning, Quine’s claim can seem plausible. As
Putnam (1968 [1975]) argued, enlarging on Quine’s theme, it
could turn out to be rational to revise even elementary logic in view
of the surprising results of quantum
 mechanics.[5]
 It is certainly not hard to imagine discovering that a homely
purported analytic truth, such as “cats are animals,”
could be given up in light of discovering that the little things are
really cleverly disguised robots controlled from Mars (Putnam, 1962;
see Katz, 1990, pp. 216ff, and G. Russell, 2008, for replies).
Quine’s discussion of the role of convention in science seems
right; but how about the role of meaning in ordinary natural language?
Is it really true that in the “pale grey lore” of all the
sentences we accept, there aren’t some that are
“white” somehow “by virtue of the very meanings of
their words”? What about our examples in our earlier set II?
What about sentences of the sort that interest Juhl and Loomis (2010)
that merely link patent synonyms, as in “Lawyers are
attorneys,” or “A fortnight is a period of fourteen
days”? As Grice and Strawson (1956) and Putnam (1965 [1975])
pointed out, it is unlikely that so intuitively plausible a
distinction should turn out to have no basis at all in
fact.
Quine addresses this issue, first, in his (1953 [1980], chapters 1 and
3), and then in a much larger way in chapter 2 of his (1960) and many
subsequent writings. In his (1953) he pressed his objection to
analyticity further to the very ideas of synonymy and the linguistic
meaning of an expression, on which, we saw, Frege’s criterion of
analyticity crucially relied. His objection is that he sees no way to
make any serious explanatory sense of them. He explores plausible
explanations in terms of “definition,”
“intension,” “possibility,” and
“contradiction,”, plausibly pointing out that each of
these notions stand in precisely as much need of explanation as
synonymy itself (recall our observation in §1.2 above regarding
the lack of overt contradiction in “married
bachelor”). They form what seems to be
a—viciously?—small “closed curve in space”.
Though they might be invoked to explain one another, they could not in
the end answer the challenge of how to distinguish an analytic claim
from simply a tenaciously held belief.
To take a recent example, David Chalmers (2012) revisits
Carnap’s (1955) proposal for basing synonymy on
“intension” by way of eliciting a person’s judgments
about the extension of a term/concept in all possible
 worlds:[6]
But such a proposal only pushes the question back to how to
distinguish verdicts about “possible” cases based upon
meaning from those based upon (tenacious) belief. In the first place,
there are the likely peculiar beliefs respondents may have about
“logical possibility.” Do they mean what (some) logicians
mean, e.g., metaphysical or model-theoretic possibility, or do they
mean what people usually mean, mere “conceivability”?
Secondly, what about people’s sometimes reasonable resistance to
even standard deductive logic (again, see Williamson, 2007, chapter 4;
and 
 footnote 2
above)? And, thirdly, and most importantly, how is one
to disconfound genuine verdicts about meaning from convictions due to
mere dogmatic resistance, or to failures of imagination, as arguably
occurs when people initially resist non-Euclidean geometries, General
Relativity or quantum mechanics, where even physicists have
historically gone wrong? Well, perhaps we should limit people’s
verdicts to those involving the term or concept
“univocally,” or with “the same meaning.” But
then, of course, we’d be relying on the very notion of
“same meaning” and analyticity that the appeal to
people’s intensions was being invoked to explain. Although, to
be sure, as many have noted (e.g., Williamson, 2007, p.50), there may
be explanatory circularities in the best of theories, the circularity
here seems particularly vicious, with the relevant notions appearing
not to perform any explanatory work other than bringing in each
other’s laundry (we’ll turn to further explanatory work
that neither Quine, Carnap nor most of their followers have
considered, in §4.4 below).
Indeed, in a way the best argument that Quine at least implicitly
raises against the analytic and its kin is precisely that they perform
no serious scientific explanatory work, and this he attempts to show
by providing what he takes to be a satisfactory explanation of human
language without them. In his (1960, 1973) he sketches a behavioristic
theory of language that doesn’t rely on the postulation of
determinate meaning or reference. He argues that translation (i.e.,
the identification of two expressions from different languages as
having the same meaning) is “indeterminate”; there is
“no fact of the matter” about whether two expressions do
or do not have the same meaning (see Indeterminacy of
Translation). This would appear to imply that there are pretty
much no facts of the matter about people’s mental lives at all!
For, if there is no fact of the matter about whether two people mean
the same thing by their words, then there is no fact of the matter
about whether they ever have mental states with the same content; and
consequently no fact of the matter about the content of anyone’s
thoughts. Quine himself took this consequence in stride—he was,
after all, a behaviorist– regarding it as “of a
piece” with Brentano’s thesis of the irreducibility of the
intentional; it’s just that for him, unlike for Brentano, it
simply showed the “baselessness of intentional idioms and the
emptiness of a science of intention” (1960, p.221). Needless to
say, many subsequent philosophers have not been happy with this view,
and have wondered where Quine’s argument went wrong.
One reservation many have had about Quine’s argument is about
how to explain the appearance of the analytic. Most people,
for example, would distinguish our original two sets of sentences
(§1), by saying that sentences of the second set, such as
“All ophthalmologists are eye doctors,” could be known to
be true just by knowing the meanings of the constituent words.
Moreover, they might agree about an indefinite number of further
examples, e.g., that pediatricians are doctors for children,
grandfathers are parents of parents, that sauntering is a kind of
movement, pain a mental state, and food, stuff that nourishes living
things. Again, as Grice and Strawson (1956) and Putnam (1965 [1975])
stressed, it’s implausible to suppose that there’s
nothing people are getting at in these judgments.
Here, once again, Quine invoked his metaphor of the web of belief,
claiming that sentences are more or less revisable, depending upon how
“peripheral” or “central” their position is in
the web. The appearance of sentences being “analytic” is
simply due to their being, like the laws of logic and mathematics,
comparatively central, and so are given up, if ever, only under
extreme pressure from the peripheral forces of experience. But no
sentence is absolutely immune from revision; all sentences are thereby
empirical, and none is actually analytic.
There are a number of problems with this explanation. In the first
place, centrality and the appearance of analyticity don’t seem
to be so closely related. As Quine (1960, p.66) himself noted, there
are are plenty of central, unrevisable beliefs that don’t seem
analytic, e.g., “There have been black dogs,” “The
earth has existed for more than five years,” “Mass-energy
is conserved”; and many standard examples of what seems analytic
aren’t seriously central: “Bachelors are
unmarried” and “Aunts are female” are of no central
importance, and could easily be revised if someone really cared (cf.
Juhl and Loomis, 2010:118). 
Secondly, it’s not mere unrevisability that seems distinctive of
the analytic, but rather a certain sort of unintelligibility:
for all the unrevisability of “Some people have eyes,”
it’s perfectly possible to imagine it to be false. In
contrast, what’s peculiar about the analytic is that denials of
it often seem unintelligible: it seems impossible to imagine a married
bachelor. Indeed, far from unrevisability explaining analyticity, it
would seem to be analyticity that explains unrevisability: the only
reason one balks at denying bachelors are unmarried is that
that’s just what “bachelor” means! 
It is important to note here a crucial change that Quine (and earlier
Positivists) casually introduced into the characterization of the
a priori, and consequently into much of the now common
understanding of the analytic. Where Kant and others had traditionally
assumed that the a priori concerned beliefs
“justifiable independently of experience,” Quine and many
other philosophers of the time came to regard it as consisting of
beliefs “unrevisable in the light of experience.” And, as
we have seen, a similar status is accorded the at least apparently
analytic. However, this would imply that someone’s taking
something to be analytic or a priori would have to regard
herself as being infallible about it, forever unwilling to
revise it in light of further evidence or argument. But this is a
further claim that many defenders of the traditional notions need not
embrace. A claim might be in fact analytic and justifiable
independently of experience, but nevertheless perfectly revisable in
the light of it. Experience, after all, might mislead us, as it
(perhaps) misled Putnam when he suggested revising logic in light of
difficulties in quantum mechanics, or suggested revising “cats
are animals,” were we to discover the things were robots. Just
what claims are genuinely analytic might not be available at the
introspective or behavioral surface of our lives, in merely our
dispositions to assent or dissent from sentences, as Quine (1960)
supposes. The relevant dispositions might be hidden more deeply in our
psychology, and our access to them as fallible as our access to any
other such facts about ourselves. The genuinely analytic may be a
matter of reflective philosophical analysis or abstract linguistic
theory (see Bonjour, 1998, Rey, 1998, Field, 2000, and §4.3 below
for further discussion).
In his important commentary on Quine’s discussion, Hilary Putnam
(1962 [1975]) tried to rescue what he thought were theoretically
innocuous examples of analytic truths by appeal to what he called
“one-criterion” concepts, or concepts like, e.g.,
[bachelor], [widow], [ophthalmologist], where there seems to be only
one “way to tell” whether they apply. However, as Fodor
(1998) pointed out, so stated, this latter account won’t suffice
either, since the notion of “criterion” seems no better
off than “analytic.” Moreover, if there were just one way
to tell what’s what, there would seem, trivially, to be
indefinite numbers of different ways: look for some reliable correlate
(living alone for bachelor), or, just ask someone
who knows the one way; or ask someone who knows someone who knows;
or…, etc., and so now we would be faced with saying which of
these ways is genuinely “criterial,” which would seem to
leave us with the same problem we faced in saying which way is
“analytic.”
Fodor (1998) tries to improve on Putnam’s proposal by suggesting
that a criterion that appears to be analytic is the one on which all
the other criteria depend, but which does not depend upon
them. Thus, telling that someone is a bachelor by checking out his
gender and marriage status doesn’t depend upon telling by asking
his friends, but telling by asking his friends does depend upon
telling by his gender and marriage status; and so we have an
explanation of why “bachelors are unmarried males” seems
analytic, but, says Fodor, without it’s actually being so
(perhaps somewhat surprisingly, given his general “asymmetric
dependence” theory of content, see his 1990b and cf. Horwich,
1998, and Rey, 2009, to be discussed shortly,
§§4.2–4.3.)
However, such asymmetric dependencies among criteria alone will not
“explain (away)” either the reality or the appearance of
the analytic, since there would appear to be asymmetric dependencies
of the proposed sort in non-analytic cases. Natural kinds are dramatic
cases in point (see Putnam 1962, 1970 [1975], 1975). At some stage in
history probably the only way anyone could tell whether something was
a case of polio was to see whether there was a certain constellation
of standard symptoms; other ways (including asking others)
asymmetrically depended upon that way. But this wouldn’t make
“All polio cases exhibit the standard symptoms” remotely
analytic—after all, the standard symptoms for many diseases can
sometimes be misleading. It’s reasonable to suppose that with
further research, there could in principle come to be better ways to
tell (which is, of course, precisely what happened).
Indeed, these cases of “deep” natural kinds contrast
dramatically with cases of more superficial kinds like
“bachelor,” whose nature is pretty much exhausted by the
linguistics of the matter. Again, unlike the case of polio and its
symptoms, the reason that gender and marriage status are the best way
to tell whether someone is a bachelor is that that’s just what
“bachelor” means. Indeed, should a doctor propose
revising the test for polio in the light of better
theory—perhaps reversing the dependency of certain
tests—this would not even appear to involve a change in the
meaning. Should, however, a feminist propose, in the light of better
politics, revising the use of “bachelor” to include women,
this obviously would. If the appearance of the analytic is to be
explained away, it needs to account for such differences in our
understanding of different sorts of verbal revisions.
There has been a wide variety of responses to Quine’s attack.
Some, for example, Davidson (1980), Stich (1983) and Dennett (1987),
seem simply to accept it and try to account for our practice of
meaning ascription within its “non-factual” bounds. Since
they follow Quine in at least claiming to forswear the analytic, we
will not consider their views further here. Others, who might be
(loosely) called “neo-Cartesians,” reject Quine’s
attack as simply so much prejudice of the empiricism and naturalism
that they take to be his own uncritical dogmas (§4.1 in what
follows). Still others hope simply to find a way to break out of the
“intentional circle,” and provide an account of at least
what it means for one thing (a state of the brain, for example) to
mean (or “carry the information about”) another external
phenomenon in the world (§4.2). Perhaps the most trenchant
reaction has been that of empirically oriented linguists and
philosophers, who look to a specific explanatory role the
analytic may play in an account of thought and talk (§4.3). This
role is currently being explored in considerable detail in the now
various areas of research inspired by the important linguistic
theories of Noam Chomsky (§4.4).
The most unsympathetic response to Quine’s challenges has been
essentially to stare him down and insist upon an inner faculty of
“intuition” whereby the truth of certain claims is simply
“grasped” directly through, as Bonjour (1998) puts it:
Bealer (1987, 1999) defends similar proposals. Neither Bonjour nor
Bealer are in fact particularly concerned to defend the analytic by
such claims, but their recourse to mere understanding of propositional
content is certainly what many defenders of the analytic have had in
mind. Katz (1998, pp. 44–5), for example, made the very same
appeal to intuitions explicitly on behalf of the analytic claims
supported by his semantic theory (although he could also be
interpreted as sometimes having adopted the more sophisticated
strategy of §4.3 below). Somewhat more modestly, Peacocke (1992,
2005) claims that possession of certain logical concepts requires that
a person find certain inferences “primitively compelling,”
or compelling not by reason of some inference or in any way that takes
“their correctness…as answerable to anything else”
(1992, p.6) (see the references in 
 footnote 3 
for further discussion and 
 footnote 2
for worries about the strategy).
Perhaps the most modest reply along these lines emerges from a
suggestion of David Lewis (1972 [1980]), who proposes to implicitly
define common, e.g., psychological terms by
“platitudes”:
He later (1994, p. 416) amends this suggestion to allow for the
“folk theory” that may tacitly underlie our ordinary use
of, e.g., mental terms. Enlarging on this idea, Frank Jackson (1998)
emphasizes the role of intuitions about possible cases, as well as the
need sometimes to massage such intuitions so as to arrive at
“the hypothesis that best makes sense of [folk] responses”
(p. 36; see also pp. 34–5 and Slote
 1966).[7]
The Quinean reply to all these approaches as they stand is pretty
straightforward, and, in a way, expresses what many regard as the real
heart of his challenge to all proponents of the analytic: how in the
end are we to distinguish such claims of “rational
insight,” “primitive compulsion,” inferential
practice or folk belief, from merely some deeply held empirical
conviction, indeed, from mere dogma? Isn’t the history of
thought littered with what have turned out to be deeply mistaken
claims, inferences and platitudes that people at the time have found
“rationally” and/or “primitively compelling,”
say, with regard to God, sin, biology, sexuality, or even patterns of
reasoning themselves? Again, consider the resistance Kahneman (2011)
reports people displaying to correction of the fallacies they commit
in a surprising range of ordinary thought (cf. 
 footnote 2 
above); or
in a more disturbing vein, how the gifted mathematician, John Nash,
claimed that his delusional ideas “about supernatural beings
came to me the same way that my mathematical ideas did” (Nasar
1998, p. 11). Introspected episodes, primitive compulsions, intuitions
about possibilities, or even tacit folk theories alone are not going
to distinguish the analytic, since these all may be due as much to
people’s empirical theories as to any special knowledge of
 meaning.[8]
A particularly vivid way to feel the force of Quine’s challenge
is afforded by a recent case that came before the Ontario Supreme
Court concerning whether laws that confined marriage to heterosexual
couples violated the equal protection clause of the constitution (see
Halpern et al. 2001). The question was regarded as turning in
part on the meaning of the word “marriage”, and each party
to the dispute solicited affidavits from philosophers, one of whom
claimed that the meaning of the word was tied to heterosexuality,
another that it wasn’t. Putting aside the complex
socio-political issues, Quine’s challenge can be regarded as a
reasonably sceptical request to know precisely what the argument is
about, and how any serious theory of the world might settle it. It
certainly wouldn’t be sufficient merely to claim that marriage
is/isn’t necessarily heterosexual on the basis of
“platitudes,” much less on “an act of rational
insight [into] the propositional content itself”; or because
speakers found the inference from marriage to heterosexuality
“primitively compelling” and couldn’t imagine gay
people getting married! (In this connection see also the—for
many—equivocal data of “experimental philosophy” in
§4.4 below.) If Cartesians are to reply to Quine by appeal to
internal rules and roles, they’re going to have sort through
these and related complexities in understanding people’s
intuitive responses.
Externalist theories try to meet at least part of Quine’s
challenge by considering how matters of meaning need not rely on
connections among thoughts or beliefs, in the way that the tradition
had encouraged philosophers to suppose, but as involving relations
between words and the phenomena in the world that they pick out. This
suggestion gradually emerged in the work of Putnam (1962 [1975], 1965
[1975] and 1975), Kripke (1972 [1980]) and Burge (1979, 1986), but it
takes the form of positive theories in, e.g., the work of Dretske
(1981, 1988) Fodor (1987, 1990b, 1992) and Devitt (2015), who try to
base meaning in various actual or co-variation relations between
states of the mind/brain and external phenomena (see indicator
semantics); and in the work of Millikan (1984), Papineau (1987)
and Neander (1995, 2017), who look to mechanisms of natural selection.
Fodor (1987, 1990b), for example, claims
 that[9]
a symbol S means p if
Thus, tokenings of “horse” mean horse because
there are (say, optimal viewing) conditions under which tokenings of
“horse” co-vary with horses, and tokenings of
“horse” caused by “cows” asymmetrically depend
upon that fact. The intuitive idea here is that what makes
“horse” mean horse is that errors and other tokenings of
“horse” in the absence of horses depend upon being able to
get things right, but not vice versa: getting things right
doesn’t depend upon getting them wrong. Fodor’s and
related proposals are not without their problems (see Loewer 1996 and
the entry on
 causal theories of mental content).
 But if something like them were right, they would go some way towards
saving at least intentional psychology from Quine’s
challenge.
However, even if these strategies were to save meaning and
intentionality, they would do so only by forsaking the high hopes we
noted in §2 philosophers harbored for the analytic. For
externalists are typically committed to counting expressions as
“synonymous” if they happen to be linked in the right way
to the same external phenomena, even if a thinker couldn’t
realize that they are by reflection alone. Consequently, by
at least the Fregean criterion, they would seem to be committed to
counting as “analytic” many patently empirical sentences
as “Water is H2O,” “Salt is NaCl”
or “Mark Twain is Samuel Clemens,” since in each of these
cases, something may co-vary in the relevant way with tokenings of the
expression on one side of the identity if and only if it co-varies
with tokenings of the one on the other (similar problems and others
arise for teleosemantics; see the entry on
 teleological theories of mental content).
Of course, an externalist might cheerfully just allow that
some analytic truths, e.g., “water is H20,” are
in fact “external” and subject to empirical
(dis)confirmation. Such a view would actually comport well with an
older philosophical tradition less interested in the meanings of our
words and concepts, and more interested in the “essences”
of the worldly phenomena they pick out. Locke (1690 [1975], II, 31,
vi), for example, posited “real” essences of things rather
along the lines resuscitated by Putnam (1975) and Kripke (1972
[1980]), the real essences being the conditions in the world
independent of our thought that make something the thing it is. Thus,
being H2O is what makes something water, and (to take the
striking examples of diseases noted by Putnam, 1962) being the
activation of a certain virus is what makes something polio). But, of
course, such an external view would still dash the hopes of
philosophers looking to the analytic to explain a priori
knowledge (see Bealer 1987 and Jackson 1998 for strategies to
assimilate such empirical cases to nevertheless a priori
analysis). Such a consequence, however, might not faze an externalist
like Fodor (1998), who is concerned only to save intentional
psychology, and might otherwise share Quine’s scepticism about
the analytic and a priori.
An interesting possibility raised by an Externalist theory is that the
beliefs that are responsible for a person’s competence with a
term or concept might turn out actually to be false. Kripke (1972/80)
pointed out how the descriptions associated with the use of a term
might actually not apply to its intended referent. Thus, “the
discover of America” could have been used to introduce the name
“Columbus,” which might stick to it even if the discoverer
turned out to be someone else (as it almost surely has done). And
Putnam (1975) went on to suggest that part of the competence
conditions with a term might involve both some kind of external
relation to the term’s referent, and stereotypical beliefs,
e.g., that lemons are yellow, tigers striped, water a liquid, even
though it’s perfectly possible for there to be exceptions to
such claims. It may be essential to knowing the meaning of a term at
least that such claims are regularly believed by users of it. On this
account, then, a claim might turn out to be analytic and
 false![10]
 A competent user perhaps needs at least to “feel the
pull” of certain claims, such as that tigers are striped, which
she might ultimately nevertheless recognize to be mistaken (in
Peacocke’s 1992 phrase, they might feel a “primitive
compulsion” in this regard—even if it turned out to be a
compulsion they need to learn to resist!). Rather than understanding
“analytic” to mean “known to be true by
virtue of meaning,” one might understand it merely as
“justified by virtue of meaning,” a prima
facie justification that simply could be overridden by other,
global theoretical considerations (pace Juhl and Loomis
2010:270, the analytic may simply involve defeasible
constraints; cf., Rey 2009 and below).
A promising strategy for replying to Quine’s challenge that
might begin to provide what the neo-Cartesian wants can be
found in recent proposals of Michael Devitt (1996, 2002) and,
independently, of Paul Horwich (1998, 2005). They emphasize how the
meaning properties of a term are the ones that play a basic
explanatory role with regard to the use of a term generally, the ones
in virtue ultimately of which a term is used with that meaning. For
example, the use of “red” to refer to the color of blood,
roses, stop signs, etc,. is arguably explained by its use to refer to
certain colors in good light, but not vice versa: the latter
use is “basic” to all the other uses. Similarly, uses of
“and” explanatorily depend upon its basic use in
inferences to and from the sentences it conjoins. Devitt and Horwich
differ about the proper locus of such a strategy. Horwich thinks of it
mainly with regard to the use of terms in natural language, and only
marginally allows what Devitt (2002) argues is required, that it be
applied primarily to terms in a “language of thought.”
There are several potential problems with these strategies. The first
is that merely appealing to a “basic explanatory”
condition for the use of a word doesn’t distinguish misuses and
metaphors from etymologies, derived idioms and “dead
metaphors”: saying “Juliet is the sun” can be
explained by the use of “sun” to refer to the sun, but so
is “lobbying” explained by the use of “lobby”
for lobbies of buildings (where politicians often met) and “the
eye of a needle” by the shape of a human eye. In these latter
cases, the words seem to take on meanings of their own that, while
they are explained by original “basic” uses, they are, so
to say, no longer “governed” by them. Here it may be worth
somehow combining the Devitt-Horwich view with Fodor’s
aforementioned cousin suggestion of the synchronic asymmetric
counterfactual (cf. Rey 2009): the new “dead” uses of an
idiom or metaphor no longer asymmetrically depend upon the
explanatorily basic use. “Eye of a needle” would still
mean the hole at the end of a needle, even if “eye” no
longer referred to a human eye. 
A second problem, however, is that they still risk Quinean scepticism
about meaning and the analytic. For, if Quine (1960) is right about
the psychology of language use, then there may be no sufficiently
local explanatorily basic facts on which all other uses of a term
depend. To take the kind of case that most interested Quine, it
certainly seems unlikely that there is some small set of uses of at
least theoretic terms in science, say “electron” or
“mass,” that are explanatorily basic, on which all other
uses really asymmetrically depend: again, revision may touch any
particular claim in the interests of overall explanatory adequacy.
Uses of a term involved in the expression of belief, either in thought
or talk, will likely be explained by the same processes of
confirmation that Quine argued were dependent on the character of
one’s belief system as a whole, and not upon some local feature
of that system in the way that an “analytic” claim would
have to be (cf. Gibbard 2008). Of course, Quine might be wrong about
taking the case of theoretic terms in science to be representative of
terms in human psychology generally. But, to put it lightly, the
verdict on that issue is not quite in (see Fodor 1983, 2000 for a
perhaps surprising endorsement of Quine’s view, and the next
section for some qualified alternatives to it).
In any case, a third drawback of this strategy is that it risks
rendering matters of meaning far less “transparent” and
introspectively accessible than Cartesians have standardly supposed.
For there is little reason to suppose that what is explanatorily basic
about one’s use of a term in thought or talk is a matter that is
available to introspection or common knowledge. As in the case of
“marriage” mentioned earlier, but certainly with respect
to other philosophically problematic notions, just which properties,
if any, are explanatorily basic may not be an issue that is at all
easy to determine.
Indeed, arguably a crucial defect of much of the discussion of the
analytic we have considered so far is that it is too confined to
surface phenomena, either introspective or behavioral. This
is probably at least partly due to the traditional view that
introspection and ordinary behavior are our only access to the mind.
But suppose we thought of the analytic more on the analogy of, say,
what’s metabolic or pulmonary, where surface
phenomena, e.g., chronic fatigue, may be merely symptomatic,
not constitutive of features of one or the other system. A
sentence’s being analytic may be constituted not by
someone’s intuitive verdicts or dispositions to behave, but by
its etiology in one rather than another subsystem of the
mind. Such, at any rate, has been the strategy pursued for the last
sixty years or so by the linguist, Noam Chomsky (1965, 1986) who
insists that a theory of language in general should focus on
speakers’ underlying “competence” with the
rules of a language, not with their surface
“performance”.
Beginning in the 1950s, Chomsky (1965, 1968 [2006]) began to
revolutionize linguistics by presenting substantial evidence and
arguments for the existence of a “generative” grammar
that, he argued, was the basis for people’s underlying
competence to speak and understand natural languages. This opened up
the possibility of a response to Quine’s (1960) scepticism about
the analytic within his own naturalistic framework, just freed of its
odd behaviorism, which had been independently empirically refuted (see
Chomsky 1959, and Gleitman, Gross and Reisberg 2011, chapter 7).
The data that concerned Chomsky, himself, have largely concerned
syntactic properties of natural language, but he sometimes construes
them broadly to include at least some “analytic” examples,
as when he writes, “it seems reasonable to suppose that semantic
relations between words like persuade, intend, believe, can be
expressed in purely linguistic terms (namely: if I persuade you to go,
then you intend to go)…” (Chomsky 1977 [1998], p. 142).
Along these lines (and in arguments that could be sustained
independently of the appeals to intuition we considered in §4.1),
Katz (1972) drew attention to related semantic data, such as
subjects’ agreements about, e.g., synonymy, redundancy,
antonymy, and implication, and developed a theory systematically
relating syntactic and semantic structure to account for them (see
Pietroski 2005, and forthcoming, for more recent and cautious
suggestions along related lines). Since, as we have seen (§3.7),
the explanations offered by Quine, Putnam and Fodor in terms of
centrality and/or preferred ways of telling seem simply empirically
inadequate, perhaps the best explanation of these phenomena are to be
had in a theory of the human language faculty.
It might be thought that appeals to such data beg the question against
Quine, since, as Quine (1967) pointed out, so much as asking subjects
to say whether two expressions are synonymous, antonymous, or
implicative is simply transferring the burden of determining what is
being discussed from the theorist to the informant. Imagine, again, a
person being asked whether “2+1=3,” “Monday precedes
Tuesday,” and “Marriage entails heterosexuality” are
matters known to be true by virtue of “the meanings of the
words.” One can sympathize with someone being at a loss as to
what to say. In any case, what is the possible significance of
people’s answers? Do they manifest the analytic or merely an
entrenched belief?
The Chomskyan actually has the seed of an interesting reply. For part
of Chomsky’s view has to do with the modularity of the natural
language faculty: whether a sentence is grammatical or not depends not
on its relation to our thought and communicative projects, but
entirely on its conformity with the internal principles of that
specific faculty. It is easy for us to produce in our behavior strings
of words that may communicate information effectively, but which may
violate those principles. An ungrammatical sentence like “Who do
you wanna sneeze?” might get uttered, but go unnoticed as such
and suffice on occasion for thought and communication (of “Who
do you want to sneeze?”), but it’s a striking fact that
speakers of English—even four-year old ones!—nevertheless
don’t utter it when given the chance (see Crain and Lillo-Martin
1999). The existence of the language faculty as a separate faculty may
simply be an odd, but psychologically real fact about us, and it may
thereby supply a real basis for commitments about not only what is or
isn’t grammatical, but about what is or isn’t a matter of
natural language meaning. On this view, if one were to deny an
analytic truth, one would simply be violating a principle of
one’s natural language, which, on Chomskyan views, it’s
perfectly possible to do: people often speak in a way that appears to
violate patent analyticities (“Ann is his real mother, despite
Zoe being his biological one,” “Carl’s still really
a bachelor, even though he’s been married for years”), and
scientists regularly do so with their introduction of technical ways
of talking about, e.g., “force”, “mass” and
“energy”. Indeed, at least in some cases one might combine
a Chomskyan view with an Externalist one, and allow that some of the
meaning-constitutive rules for a term can turn out to be false
(§4.2 above).
The burden of such a reply lies, however, in actually producing a
linguistic theory that sustains a principled class of sentences that
could be isolated in this way and that, per the suggestion of
§4.3, might play the basic explanatory role of meaning. This is
something that, as yet, it is by no means obvious that it can do.
Fodor et al (1975) raised doubts about whether any kind of
“semantic decomposition” is psychologically real, and
Fodor (1970, 1998) has contested some of the most prized examples of
analyticities, such as (10) in our initial set II (see §1 above),
linking killing to death (but see Pietroski 2002 for a reply).
Moreover, many linguists (e.g., Jackendoff 1992, Pustejovsky 1995)
proceed somewhat insouciantly to include under issues of
“meaning” and “conceptual structure”, issues
that are patently matters of just ordinary belief and sometimes mere
phenomenology. For example, Jackendoff and others have called
attention to the heavy use of spatial metaphors in many grammatical
constructions. But such facts don’t entail that the concepts of
the domains to which these metaphors are applied –say, the
structure of the mind, social relations, or mathematics—are,
themselves, somehow intrinsically spatial, or really thought by anyone
to be. People may find it useful to conceive of these domains
in spatial ways. However, conceptions—ordinary beliefs,
metaphors, associations—are one thing; people’s
concepts quite another: two mathematicians, after all, can
have the thought that there is no largest prime, even if one of them
thinks of numbers spatially and the other purely algebraically.
In considering Chomskyan theories of the analytic, it is important to
bear in mind that, while the theory may be as methodologically
empiricist as any theory ought to be, the theory itself explicitly
rejects empiricist conceptions of meaning and mind themselves. Chomsky
is famous for having resuscitated Rationalist doctrines of
“innate ideas,” according to which many ideas have their
origins not in experience, but in our innate endowment. And
there’s certainly no commitment in semantic programs like those
of Katz, Jackendoff or Pustejovsky to anything like the
“reduction” of all concepts to the sensori-motor
primitives eyed by the Positivists. Of course, just how we come by the
meaning of whatever primitive concepts their theories do endorse, is a
question they would seriously have to confront, cf. Fodor (1990b,
1998).
Recently, some philosophers have offered some empirical evidence that
might be taken to undermine these efforts to empirically ground the
analytic, casting doubt on just how robust the data for the analytic
might be. The movement of “experimental philosophy” has
pointed to evidence of considerable malleability of subject’s
“intuitions” with regard to the standard kinds of thought
experiments on which defenses of analytic claims typically rely. Thus,
Weinberg, Nichols and Stich (2001) found significant cultural
differences between responses of Asians and Western students regarding
whether someone counted as having knowledge in a standard
“Gettier” (1963) example of accidental justified true
belief; and Knobe (2003) found that non-philosopher’s judgments
about whether an action is intentional depended on the (particularly
negative) moral qualities of the action, and not, as is presumed by
most philosophers, on whether the action was merely intended by the
agent. Questions, of course, could be raised about these experimental
results (How well did the subjects understand the project of assessing
intuitions? Did the experiments sufficiently control for the
multitudinous “pragmatic” effects endemic to polling
procedures? To what extent are the target terms merely polysemous,
allowing for different uses in different contexts?). However, the
results do serve to show how the determination of meaning and analytic
truths can be regarded as a more difficult empirical question than
philosophers have traditionally supposed (see Bishop and Trout 2005
and Alexander and Weinberg 2007 for extensive discussion).
Suppose linguistics were to succeed in delineating a class of analytic
sentences grounded in a special language faculty. Would such sentences
serve the purposes for which we noted earlier (§2) philosophers
had enlisted them? Perhaps some of them would. An empirical grounding
of the analytic might provide us with an understanding of what
constitutes a person’s competence with a concept. Given that
Quinean scepticism about the analytic is a source of his scepticism
about the determinacy of cognitive states (see §3.6 above), such
a grounding may be crucial for a realistic psychology.
Moreover, setting out the constitutive conditions for possessing a
concept might be of some interest to philosophers generally, since
many of the crucial questions they ask concern the proper
understanding of ordinary notions such as material object, person,
action, freedom, god, the good, or the beautiful.
Suppose, further, that a domain, such as perhaps ethics or aesthetics,
are “response dependent,” constituted by the
underlying rules of our words and concepts; suppose, that is, that
these rules exhaustthe nature of, say, the good, the funny,
or the beautiful. If so, then it might not be implausible to claim
that successful conceptual analysis could provide us with some a
priori knowledge of such domains.
But, of course, many philosophers have wanted more than these
essentially psychological gains. They have hoped that analytic claims
might provide a basis for a priori knowledge of domains that
exist independently of us and not exhausted by our concepts.
An important case in point would seem to be the very case of
arithmetic that motivated much of the discussion of the analytic in
the first place. Recent work of Crispin Wright (1983) and others on
the logicist program has shown how a version of Frege’s program
might be rescued by appealing not to his problematic Basic Law V, but
instead merely to what he calls “Hume’s Principle,”
or the claim that for the number of Fs to be equal to the number of Gs
is for there to be a “one-to-one correspondence” between
the Fs and the Gs (as in the case of the fingers of a normal right
hand and a left one). According to what is now regarded as
“Frege’s Theorem,” the Peano axioms for arithmetic
can be derived from this principle in standard second-order logic (see
 Frege’s theorem and foundations for arithmetic).
 Now, Wright has urged that Hume’s Principle might be regarded
as analytic, and perhaps this claim could be sustained by an
examination of the language faculty along the lines of §4.4. If
so, then wouldn’t that vindicate the suggestion that arithmetic
can be known a priori?
Not obviously, since Hume’s Principle is a claim not merely
about the concepts F and G, but about the presumably
concept-independent fact about the number of things that are
F and
the number of things that are G, and, we can ask, what
justifies any claim about them? As Boolos (1997) asks in
response to Wright:
Indeed, as Zalta (2013) observes, 
It would certainly seem as if justifying Hume’s Principle would
involve appealing to “the elegance and convenience which the
hypothesis brings to the containing bodies of laws and data,”
i.e., to our best overall theory of the world, precisely as Quine
claimed (§3.4). (see Wright 1999 and Horwich 2000 for further
discussion)
The problem here becomes even more obvious in non-mathematical cases.
For example, philosophers have wanted to claim not merely that our
concepts of red and green exclude the possibility of our
thinking that something is both colors all over, but that this
possibility is ruled out for the actual colors, red and
green, themselves (if such there be). It is therefore no accident that
Bonjour’s (1998, pp. 184–5) defense of a priori
knowledge turns on including the very properties of red and green
themselves as constituents of the propositions we grasp. But it
is just such a wonderful coincidence between merely our concepts and
actual worldly properties that a linguistic semantics alone does not
obviously ensure.
But suppose there in fact existed a wonderful correspondence between
our concepts and the world, indeed, a deeply reliable, counterfactual
supporting correspondence whereby it was in fact metaphysically
impossible for certain claims constitutive of those concepts not to be
true. This is, of course, not implausible in the case of logic and
arithmetic, and is entirely compatible with, e.g., Boolos’
reasonable doubts about them (after all, it’s always possible to
doubt what is in fact a necessary truth). Such necessary
correspondences between thought and the world might then serve as a
basis for claims to a priori knowledge in at least a
reliabilist epistemology, where what’s important is not
a believer’s ability to justify his claims, but merely
the reliability of the processes by which he arrived at them.
Indeed, in the case of logic and arithmetic, the beliefs might be
arrived at by steps that were not only necessarily reliable, but might
also be taken to be so by the believer, in ways that might in fact
depend in no way upon experience, but only on his competence with the
relevant concepts (Kitcher 1980, Rey 1998 and Goldman 1999 explore
this strategy).
Such a reliabilist approach, though, might be less than fully
satisfying to someone interested in the traditional analytic a
priori. For, although someone might turn out in fact to have
analytic a priori knowledge of this sort, she might not know
that she does (reliabilist epistemologists standardly forgo the
“KK Principle,” according to which if one knows that p,
one knows that knows that p). Knowledge that the relevant claims were
knowable a priori might itself be only possible by an
empirically informed understanding of, e.g., one’s language
faculty, and, à la Quine, by its consonance with the rest of
one’s theory of the world. But the trouble then is that claims
that people do have a capacity for a priori knowledge seems
quite precarious. As we noted earlier 
 (footnote 2), 
people are often
unreliable at appreciating deductively valid arguments; appreciating
the standard rules even of natural deduction is for many people often
a difficult intellectual achievement. Consequently, people’s
general competence with logical notions may not in fact consist in any
grip on valid logical rules; and so whatever rules do underlie that
competence may well turn out not to be the kind of absolutely reliable
guide to the world on which the above reliabilist defense of a
priori analytic knowledge seems to depend. In any case, in view
merely of the serious possibility that these pessimistic conclusions
are true, it’s hard to see how any appeal to the analytic to
establish the truth of any controversial claim in any mind-independent
domain could have any special justificatory force without a
sufficiently detailed empirical psychological theory to back it
up.
But even if we did have a true account of our minds and the semantic
rules afforded by our linguistic and conceptual competence, it’s
not clear it would really serve the “arm-chair” purposes
of traditional philosophy that we mentioned at the outset (§1).
Consider, for example, the common puzzle about the possibility that
computers might actually think and enjoy a mental life. In response to
this puzzle, some philosophers (e.g., Wittgenstein 1953 [1967], p.
97e, Ziff 1959, and even Chomsky 2000, p44, himself) have suggested
that it’s analytic that a thinking thing must be alive, a
suggestion that certainly seems to accord with many folk intuitions
(many people who might cheerfully accept a computational explanation
of a thought process often balk at the suggestion that an inanimate
machine engaging in that computation would actually be thinking).
Suppose this claim were sustained by a Chomskyan theory, showing that
the ordinary notion expressed by the natural language word
“thinking” is, indeed, correctly applied only to living
things, and not to artifactual computers. Should this really satisfy
the person worried about the possibility of artificial thought?
It’s hard to see why. For the serious question that concerns
people worried about whether artifacts could think concerns whether
those artifacts could in fact share the real, theoretically
interesting, explanatory properties of being a thinking thing (cf.
Jackson 1998, pp. 34–5). We might have no reason to suppose that
being alive actually figures among them, and so conclude that, despite
these (supposed) constraints of natural language, inanimate computers
could come to “think” after all. Indeed, perhaps the
belief that thinking things must be alive is an example of a false
belief that, we saw in §§4.2–4.3, an externalist
Chomskyan could claim is part of the constitutive conditions on
“think” (again, one doesn’t have the concept unless
one feels the pull).
Alternatively, one might argue that what the language faculty provides
are not sentences with truth-conditions, but merely
defeasible constraints on how the sentence might be used by
our conceptual system to express the truth conditional claims that
people make with the sentences (as in Sperber and Wilson 1995, Carsten
2016, Pietroski 2002, 2005, and forthcoming, and Rey, 2009; cf.
 footnote 10 passim above). 
Of course, one could insist on
adhering to whatever meaning constraints turn out to be imposed by
natural language and so, perhaps, deny that inanimate computers could
ever think. But, if the explanatory point were correct, it would be
hard to see how this would amount to anything more than a verbal
quibble: so computers don’t “think”; they
“think* instead.” (It’s a peculiar feature of the
whole discussion of the analytic that it can seem to turn on what may
in the end be mere verbal quibbles.)
In sum: an account of the language faculty might provide a basis for
ascribing competence with the concepts that that faculty might deploy,
and thereby a basis for intentional realism and a distinction between
analytic and synthetic claims. It might also provide a basis for
analytic a priori knowledge of claims about concept-dependent
domains, such as those of ethics and aesthetics. However, in the case
of concept-independent domains, such as logic and mathematics, or the
nature of worldly phenomena like life or mind, the prospects seem more
problematic. There may be analytic claims to be had here, but at least
in these cases they would, in the immortal words of Putnam (1965
[1975], p. 36), “cut no philosophical ice…bake no
philosophical bread and wash no philosophical windows.” We would
just have to be satisfied with theorizing about the
concept-independent domains themselves, without being able
to justify our claims about them by appeal to the meanings of
our words alone.  Reflecting on the difficulties of the past
century’s efforts on behalf of the analytic, it’s not
clear why anyone would really want to insist otherwise.