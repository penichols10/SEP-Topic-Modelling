Both the definition and the precise domain of economics are subjects
of controversy within philosophy of economics. At first glance, the
difficulties in defining economics may not appear serious. Economics
is, after all, concerned with aspects of the production, exchange,
distribution, and consumption of commodities and services. But this
claim and the terms it contains are vague; and it is arguable that
economics is relevant to a great deal more. It helps to approach the
question, “What is economics?” historically, before
turning to comments on contemporary features of the discipline.
Philosophical reflection on economics is ancient, but the conception
of the economy as a distinct object of study dates back only to the
18th century. Aristotle addresses some problems that most would
recognize as pertaining to economics, mainly as problems concerning
how to manage a household. Scholastic philosophers addressed ethical
questions concerning economic behavior, and they condemned usury
— that is, the taking of interest on money. With the increasing
importance of trade and of nation-states in the early modern period,
‘mercantilist’ philosophers and pamphleteers were largely
concerned with the balance of trade and the regulation of the
currency. There was an increasing recognition of the complexities of
the financial management of the state and of the possibility that the
way that the state taxed and acted influenced the production of
wealth.
In the early modern period, those who reflected on the sources of a
country’s wealth recognized that the annual harvest, the
quantities of goods manufactured, and the products of mines and
fisheries depend on facts about nature, individual labor and
enterprise, tools and what we would call “capital goods”,
and state and social regulations. Trade also seemed advantageous, at
least if the terms were good enough. It took no conceptual leap to
recognize that manufacturing and farming could be improved and that
some taxes and tariffs might be less harmful to productive activities
than others. But to formulate the idea that there is such a thing as
“the economy” with regularities that can be investigated
requires a bold further step. In order for there to be an object of
inquiry, there must be regularities in production and exchange; and
for the inquiry to be non-trivial, these regularities must go beyond
what is obvious to the producers, consumers, and exchangers
themselves. Only in the eighteenth century, most clearly illustrated
by the work of Cantillon, the physiocrats,
 David Hume,
 and especially Adam Smith (see the entry on 
 Smith’s moral and political philosophy),
 does one find the idea that there are laws to be discovered that
govern the complex set of interactions that produce and distribute
consumption goods and the resources and tools that produce them
(Backhouse 2002).
Crucial to the possibility of a social object of scientific inquiry is
the idea of tracing out the unintended consequences of the intentional
actions of individuals. Thus, for example, Hume traces the rise in
prices and the temporary increase in economic activity that follow an
increase in currency to the perceptions and actions of individuals who
first spend the additional currency (1752). In spending their
additional gold imported from abroad, traders do not intend to
increase the price level. But that is what they do nevertheless. Adam
Smith expands and perfects this insight and offers a systematic
Inquiry into the Nature and Causes of the Wealth of Nations.
From his account of the demise of feudalism (1776, Book II, Ch. 4) to
his famous discussion of the invisible hand, Smith emphasizes
unintended consequences. “[H]e intends only his own gain; and he
is in this, as in many other cases, led by an invisible hand to
promote an end which was no part of his intention. Nor is it always
the worse for the society that it was no part of it. By pursuing his
own interest, he frequently promotes that of the society more
effectually than when he really intends to promote it” (1776,
Book IV, Ch. 2). The existence of regularities, which are the
unintended consequences of individual choices gives rise to an object
of scientific investigation.
One can distinguish the domain of economics from the domain of other
social scientific inquiries either by specifying some set of causal
factors or by specifying some range of phenomena. The phenomena with
which economists are concerned are production, consumption,
distribution and exchange—particularly via markets. But since so
many different causal factors are relevant to these, including the
laws of thermodynamics, metallurgy, geography and social norms, even
the laws governing digestion, economics cannot be distinguished from
other inquiries only by the phenomena it studies. Some
reference to a set of central causal factors is needed. Thus, for
example,
 John Stuart Mill
 maintained that, “Political economy…[is concerned with]
such of the phenomena of the social state as take place in consequence
of the pursuit of wealth. It makes entire abstraction of every other
human passion or motive, except those which may be regarded as
perpetually antagonising principles to the desire of wealth, namely
aversion to labour, and desire of the present enjoyment of costly
indulgences.” (1843, Book VI, Chapter 9, Section 3) In
Mill’s view, economics is mainly concerned with the consequences
of individual pursuit of tangible wealth, though it takes some account
of less significant motives such as aversion to labor.
Mill takes it for granted that individuals act rationally in their
pursuit of wealth and luxury and avoidance of labor, rather than in a
disjointed or erratic way, but he has no theory of consumption, or
explicit theory of rational economic choice, and his theory of
resource allocation is rather thin. These gaps were gradually filled
during the so-called neoclassical or marginalist revolution, which
linked choice of some object of consumption (and its price) not to its
total utility but to its marginal utility. For example, water is
obviously extremely useful, but in much of the world it is plentiful
enough that another glass more or less matters little to an agent. So
water is cheap. Early “neoclassical” economists such as
William Stanley Jevons held that agents make consumption choices so as
to maximize their own happiness (1871). This implies that they
distribute their expenditures so that a dollar’s worth of water
or porridge or upholstery makes the same contribution to their
happiness. The “marginal utility” of a dollar’s
worth of each good is the same.
In the Twentieth Century, economists stripped this theory of its
hedonistic clothing (Pareto 1909, Hicks and Allen 1934). Rather than
supposing that all consumption choices can be ranked by how much they
promote an agent’s happiness, economists focused on the ranking
itself. All that they suppose concerning evaluations is that agents
are able consistently to rank the alternatives they face. This is
equivalent to supposing first that rankings are complete — that
is, for any two alternatives x and y that the agent
considers, either the agent ranks x above y (prefers
x to y), or the agent prefers y to
x, or the agent is indifferent. Second, economists suppose
that agent’s rankings of alternatives (preferences) are
transitive. To say that an agent’s preferences are transitive is
to claim that if the agent prefers x to y and
y to z, then the agent prefers x to
z, with similar claims concerning indifference and
combinations of indifference and preference. Though there are further
technical conditions to extend the theory to infinite sets of
alternatives and to capture further plausible rationality conditions
concerning gambles, economists generally subscribe to a view of
rational agents as at least possessing complete and transitive
preferences and as choosing among the feasible alternatives whichever
they most prefer. In the theory of revealed preference, economists
have attempted unsuccessfully to eliminate all reference to subjective
preference or to define preference in terms of choices (Samuelson
1947, Houtthaker 1950, Little 1957, Sen 1971, 1973, Hausman 2012,
chapter 3).
In clarifying the view of rationality that characterizes economic
agents, economists have for the most part continued to distinguish
economics from other social inquiries by the content of the motives or
preferences with which it is concerned. So even though people may seek
happiness through asceticism, or they may rationally prefer to
sacrifice all their worldly goods to a political cause, economists
have supposed that such preferences are rare and unimportant to
economics. Economists are concerned with the phenomena deriving from
rationality coupled with a desire for wealth and for larger bundles of
goods and services.
Economists have flirted with a less substantive characterization of
individual motivation and with a more expansive view of the domain of
economics. In his influential monograph, An Essay on the Nature
and Significance of Economic Science, Lionel Robbins defined
economics as “the science which studies human behavior as a
relationship between ends and scarce means which have alternative
uses” (1932, p. 15). According to Robbins, economics is not
concerned with production, exchange, distribution, or consumption as
such. It is instead concerned with an aspect of all human action.
Robbins’ definition helps one to understand efforts to
apply economic concepts, models, and techniques to other subject
matters such as the analysis of voting behavior and legislation, even as
economics maintains its connection to a traditional domain.
Contemporary economics is diverse. There are many schools and many
branches. Even so-called “orthodox” or
“mainstream” economics has many variants. Some mainstream
economics is highly theoretical, though most of it is applied and
relies on rudimentary theory. Theoretical and applied work can be
distinguished as microeconomics or macroeconomics. There is also a
third branch, econometrics which is devoted to the empirical
estimation, elaboration, and to some extent testing of microeconomic
and macroeconomic models (but see Summers 1991 and Hoover 1994).
Microeconomics focuses on relations among individuals (with firms and
households frequently counting as honorary individuals and little said
about the idiosyncrasies of the demand of particular individuals).
Individuals have complete and transitive preferences that govern their
choices. Consumers prefer more commodities to fewer and have
“diminishing marginal rates of substitution” — i. e.
they will pay less for units of a commodity when they already have
lots of it than when they have little of it. Firms attempt to maximize
profits in the face of diminishing returns: holding fixed all the
inputs into production except one, output increases when there is more
of the remaining input, but at a diminishing rate. Economists idealize
and suppose that in competitive markets, firms and individuals cannot
influence prices, but economists are also interested in strategic
interactions, in which the rational choices of separate individuals
are interdependent. Game theory, which is devoted to the study of
strategic interactions, is of growing importance in economics.
Economists model the outcome of the profit-maximizing activities of
firms and the attempts of consumers optimally to satisfy their
preferences as an equilibrium in which there is no excess
demand on any market. What this means is that anyone who wants to buy
anything at the going market price is able to do so. There is no
excess demand, and unless a good is free, there is no excess
supply.
Macroeconomics grapples with the relations among economic aggregates,
such as relations between the money supply and the rate of interest or
the rate of growth, focusing especially on problems concerning the
business cycle and the influence of monetary and fiscal policy on
economic outcomes. Many mainstream economists would like to unify
macroeconomics and microeconomics, but few economists are satisfied
with the attempts that have been made to do so, especially via so
called “representative agents” (Kirman 1992, Hoover
2001a). Macroeconomics is immediately relevant to economic policy and
hence (and unsurprisingly) subject to much more heated (and
politically-charged) controversy than microeconomics or econometrics.
Schools of macroeconomics include Keynesians (and
“new-Keynesians”), monetarists, “new classical
economics” (rational expectations theory — Begg 1982,
Carter and Maddock 1984, Hoover 1988, Minford and Peel 1983), and
“real business cycle” theories (Kydland and Prescott 1991,
1994; Sent 1998).
Branches of mainstream economics are also devoted to specific
questions concerning growth, finance, employment, agriculture,
housing, natural resources, international trade, and so forth. Within
orthodox economics, there are also many different approaches, such as
agency theory (Jensen and Meckling 1976, Fama 1980), the
Chicago school (Becker 1976), or public choice theory
(Brennan and Buchanan 1985, Buchanan 1975). These address questions
concerning incentives within firms and families and the ways that
institutions guide choices.
Although mainstream economics is dominant and demands the most
attention, there are many other schools. Austrian economists
accept orthodox views of choices and constraints, but they emphasize
uncertainty and question whether one should regard outcomes as
equilibria, and they are skeptical about the value of mathematical
modeling (Buchanan and Vanberg 1989, Dolan 1976, Kirzner 1976, Mises
1949, 1978, 1981, Rothbard 1957, Wiseman 1983, Boettke 2010, Holcombe
2014, Nell 2014a, 2014b, 2017, Boettke and Coyne 2015, Hagedorn 2015,
Horwitz 2015, Dekker 2016, Linsbichler 2017 ).
Traditional institutionalist economists question the value of
abstract general theorizing and emphasize evolutionary concepts
(Dugger 1979, Wilber and Harrison 1978, Wisman and Rozansky 1991,
Hodgson 2000, 2013, 2016, Hodgson and Knudsen 2010, Delorme 2010,
Richter 2015). They emphasize the importance of generalizations
concerning norms and behavior within particular institutions. Applied
work in institutional economics is sometimes very similar to applied
orthodox economics. More recent work in economics, which is also
called institutionalist, attempts to explain features of institutions
by emphasizing the costs of transactions, the inevitable
incompleteness of contracts, and the problems “principals”
face in monitoring and directing their agents (Coase 1937; Williamson
1985; Mäki et al. 1993, North 1990; Brousseau and
Glachant 2008).
Marxian and socialist economists traditionally articulated
and developed Karl Marx’s economic theories, but recently many
socialist economists have revised traditional Marxian concepts and
themes with tools borrowed from orthodox economic theory (Morishima
1973, Roemer 1981, 1982, Bowles 2012, Piketty 2014, Lebowitz 2015,
Auerbach 2016, Beckert 2016, Jacobs and Mazzucato 2016).
There are also socio-economists, who are concerned with the
norms that govern choices (Etzioni 1988, 2018),
behavioral economists, who study the nitty-gritty
of choice behavior (Winter 1962, Thaler 1994, Ben Ner and
Putterman 1998, Kahneman and Tversky 2000, Camerer 2003, Camerer and
Loewenstein 2003, Camerer et al. 2003, Loewenstein 2008,
Thaler and Sunstein 2008, Saint-Paul 2011, Oliver 2013),
post-Keynesians, who look to Keynes’s work and especially
his emphasis on demand (Dow 1985, Kregel 1976, Harcourt and Kriesler
2013 Rochon and Rossi 2017), evolutionary economists, who 
emphasize the importance of institutions (Witt
2008, Hodgson and Knudsen 2010, Vromen 2009, Hodgson 2013, 2016,
Carsten 2013, Dopfer and Potts 2014, Wilson and Kirman 2016),
neo-Ricardians, who emphasize relations among economic
classes (Sraffa 1960, Pasinetti 1981, Roncaglia 1978),
and even neuroeconomists, who study neurological concomitants
of choice behavior (Camerer 2007, Camerer et
al. 2005, Camerer et al. 2008, Glimcher et al.
2008, Loewenstein et al. 2008, Rusticinni 2005, 2008,
Glimcher 2010). Economics is not one homogeneous enterprise.
Although the different branches and schools of economics raise a wide
variety of epistemological and ontological issues concerning
economics, six problems have been central to methodological reflection
(in this philosophical sense) concerning economics:
Policy makers look to economics to guide policy, and it seems
inevitable that even the most esoteric issues in theoretical economics
may bear on some people’s material interests. The extent to
which economics bears on and may be influenced by normative concerns
raises methodological questions about the relationships between a
positive science concerning “facts” and a
normative inquiry into values and what ought to be. Most
economists and methodologists believe that there is a reasonably clear
distinction between facts and values, between what is and what ought
to be, and they believe that most of economics should be regarded as a
positive science that helps policy makers choose means to accomplish
their ends, though it does not bear on the choice of ends itself.
This view is questionable for several reasons (Mongin 2006, Hausman,
McPherson, and Satz 2017). First, economists have to interpret and
articulate the incomplete specifications of goals and constraints
provided by policy makers (Machlup 1969b). Second, economic
“science” is a human activity, and like all human
activities, it is governed by values. Those values need not be the
same as the values that influence economic policy, but it is debatable
whether the values that govern the activity of economists can be
sharply distinguished from the values that govern policy makers.
Third, much of economics is built around a normative theory of
rationality. One can question whether the values implicit in such
theories are sharply distinguishable from the values that govern
policies. For example, it may be difficult to hold a maximizing view
of individual rationality, while at the same time insisting that
social policy should resist maximizing growth, wealth, or welfare in
the name of freedom, rights, or equality. Fourth, people’s views
of what is right and wrong are, as a matter of fact, influenced by
their beliefs about how people in fact behave. There is evidence that
studying theories that depict individuals as self-interested leads
people to regard self-interested behavior more favorably and to become
more self-interested (Marwell and Ames 1981, Frank et al.
1993). Finally, people’s judgments are clouded by their
interests. Since economic theories bear so centrally on people’s
interests, there are bound to be ideological biases at work in the
discipline (Marx 1867, Preface). Positive and normative are especially
interlinked within economics, because economists are not all
researchers and teachers. In addition, economists work as commentators
and as it were “hired guns” whose salaries depend on
arriving at the conclusions their employers want. The bitter polemics
concerning macroeconomic policy responses to the great recession
beginning in 2008 testify to the influence of ideology.
Orthodox theoretical microeconomics is as much a theory of rational
choices as it a theory that explains and predicts economic outcomes.
Since virtually all economic theories that discuss individual choices
take individuals as acting for reasons, and thus in some way rational,
questions about the role that views of rationality and reasons should
play in economics are of general importance. Economists are typically
concerned with the aggregate results of individual choices rather than
with the actions of particular individuals, but their theories in fact
offer both causal explanations for why individuals choose as they do
and accounts of the reasons for their choices. See also the
entries on
 methodological individualism and
 reasons for action: justification, motivation, explanation.
Explanations in terms of reasons have several features that
distinguish them from explanations in terms of causes. Reasons purport to
justify the actions they explain, and indeed so called
“external reasons” (Williams 1981) only justify action,
without purporting to explain it. Reasons can be evaluated, and they
are responsive to criticism. Reasons, unlike causes, must be
intelligible to those for whom they are reasons. On grounds such as
these, many philosophers have questioned whether explanations of human
action can be causal explanations (von Wright 1971, Winch 1958). Yet
merely giving a reason — even an extremely good reason —
fails to explain an agent’s action, if the reason was not in
fact “effective.” Someone might, for example, start
attending church regularly and give as his reason a concern with
salvation. But others might suspect that this agent is deceiving
himself and that the minister’s attractive daughter is in fact
responsible for his renewed interest in religion. Donald Davidson
(1963) argued that what distinguishes the reasons that explain an
action from the reasons that fail to explain it is that the former are
also causes of the action. Although the account of rationality within
economics differs in some ways from the
 folk psychology
 people tacitly invoke in everyday explanations of actions, many of
the same questions carry over (Rosenberg 1976, ch. 5; 1980, Hausman
2012).
An additional difference between explanations in terms of reasons and
explanations in terms of causes, which some economists have
emphasized, is that the beliefs and preferences that explain actions
may depend on mistakes and ignorance (Knight 1935). As a first
approximation, economists can abstract from such difficulties caused
by the
 intentionality
 of belief and desire. They thus often assume that people have perfect
information about all the relevant facts. In that way theorists need
not worry about what people’s beliefs are. (If people have
perfect information, then they believe and expect whatever the facts
are.) But once one goes beyond this first approximation, difficulties
arise which have no parallel in the natural sciences. Choice depends
on how things look “from the inside”, which may be very
different from the actual state of affairs. Consider for example the
stock market. The “true” value of a stock depends on the
future profits of the company, which are of course uncertain. In 2006
house prices in the U.S. were extremely inflated. But whether they
were “too high” depended at least in the short run, on
what people believe. They were excellent investments if one could sell
them to others who would be willing to pay even more for them.
Economists disagree about how significant this subjectivity is.
Members of the Austrian school argue that these differences are of
great importance and sharply distinguish theorizing about economics
from theorizing about any of the natural sciences (Buchanan and
Vanberg 1989, von Mises 1981).
Of all the social sciences, economics most closely resembles the
natural sciences. Economic theories have been axiomatized, and
articles and books of economics are full of theorems. Of all the
social sciences, only economics boasts an ersatz Nobel Prize.
Economics is thus a test case for those concerned with the extent of
the similarities between the natural and social sciences. Those who
have wondered whether social sciences must differ fundamentally from
the natural sciences seem to have been concerned mainly with three
questions:
(i) Are there fundamental differences between the structure or
concepts of theories and
 explanations
 in the natural and social sciences? Some of these issues were already
mentioned in the discussion above of reasons versus causes.
(ii) Are there fundamental differences in goals? Philosophers and
economists have argued that in addition to or instead of the
predictive and explanatory goals of the natural sciences, the social
sciences should aim at providing us with understanding. Weber
and others have argued that the social sciences should provide us with
an understanding “from the inside”, that we should be able
to empathize with the reactions of the agents and to find what happens
“understandable” (Weber 1904, Knight 1935, Machlup 1969a).
This (and the closely related recognition that explanations cite
reasons rather than just causes) seems to introduce an element of
subjectivity into the social sciences that is not found in the natural
sciences.
(iii) Owing to the importance of human choices (or perhaps free will),
are social phenomena too irregular to be captured within a framework
of laws and theories? Given human free will, perhaps human behavior is
intrinsically unpredictable and not subject to any laws. But there
are, in fact, many regularities in human action, and given the
enormous causal complexity characterizing some natural systems, the
natural sciences must cope with many irregularities, too.
Economics raises questions concerning the legitimacy of severe
abstraction and idealization. For example, mainstream economic models
often stipulate that everyone is perfectly rational and has perfect
information or that commodities are infinitely divisible. Such claims
are exaggerations, and they are clearly false. Other schools of
economics may not employ idealizations that are this extreme, but
there is no way to do economics if one is not willing to simplify
drastically and abstract from many complications. How much
simplification, idealization, abstraction or “isolation”
(Mäki 2006) is legitimate?
In addition, because economists attempt to study economic phenomena as
constituting a separate domain, influenced only by a small number of
causal factors, the claims of economics are true only ceteris
paribus — that is, they are true only if there are no
interferences or disturbing causes. What are ceteris paribus
clauses, and when if ever are they legitimate in science? Questions
concerning ceteris paribus clauses are closely related to
questions concerning simplifications and idealizations, since one way
to simplify is to suppose that the various disturbing causes or
interferences are inactive and to explore the consequences of some
small number of causal factors. These issues and the related question
of how well supported economics is by the evidence have been
the central questions in economic methodology. They will be
discussed further below mainly in
 Section 3.
Many important generalizations in economics are causal claims. For
example, the law of demand asserts that a price increase will
(ceteris paribus) diminish the quantity demanded. (It does
not merely assert an inverse relationship between price and demand.
When demand increases for some other reason, such as a change in
tastes, price increases.) Econometricians have also been
deeply concerned with the possibilities of determining causal
relations from statistical evidence and with the relevance of causal
relations to the possibility of consistent estimation of parameter
values. Since concerns about the consequences of alternative policies
are so central to economics, causal inquiry is unavoidable.
Before the 1930s, economists were generally willing to use causal
language explicitly and literally, despite some concerns that there
might be a conflict between causal analysis of economic changes and
“comparative statics” treatments of equilibrium states.
Some economists were also worried that thinking in terms of causes was
not compatible with recognizing the multiplicity and mutuality of
determination in economic equilibrium. In the anti-metaphysical
intellectual environment of the 1930s and 1940s (of which logical
positivism was at least symptomatic), any mention of causation became
suspicious, and economists commonly pretended to avoid causal
concepts. The consequence was that they ceased to reflect carefully on
the causal concepts that they continued implicitly to invoke (Hausman
1983, 1990, Helm 1984, Runde 1998). For example, rather than
formulating the law of demand in terms of the causal consequences of
price changes for quantity demanded, economists tried to confine
themselves to discussing the mathematical function relating price and
quantity demanded. There were important exceptions (Haavelmo 1944,
Simon 1953, Wold 1954), and during the past generation, this state of
affairs has changed dramatically.
For example, in his Causality in Macroeconomics (2001b) Kevin
Hoover develops feasible methods for investigating large scale causal
questions, such as whether changes in the money supply (M)
cause changes in the rate of inflation P or accommodate
changes in P that are otherwise caused. If changes in
M cause changes in P, then the conditional
distribution of P on M should remain stable with
exogenous changes in M, but should change with exogenous
changes in P. Hoover argues that historical investigation,
backed by statistical inquiry, can justify the conclusion that some
particular changes in M or P have been exogenous.
One can then determine the causal direction by examining the stability
of the conditional distributions. Econometricians have made vital
contributions to the contemporary revival of philosophical interest in
the notion of causation. In addition to Hoover’s work, see for
example Geweke (1982), Granger (1969, 1980), Cartwright (1989), Sims
(1977), Zellner and Aigner (1988), Pearl (2000), Spirtes, Glymour and
Scheines (2001).
One relatively secure way to determine causal relations is via
randomized controlled experiments. If the experimenters sort subjects
randomly into experimental and control groups and vary just one
factor, then, unless by bad luck the two groups differ in some unknown
way, changes in the outcomes given the common features of the control
and treatment groups should be due to the difference in the one
factor. Indeed, in the case of quantitative variables, one can
calculate average causal effects (Deaton 2010). This makes randomized
controlled trials very attractive, though no panacea, since the
treatment and control groups may not be representative of the
population in which policy-makers hope to apply the causal
conclusions, and the causal consequences of the intervention might
differ across different subgroups within the control and treatment
groups (Worrall 2007, Cartwright and Hardie 2013).
For both practical and ethical reasons, it is often hard to experiment
in economics (though, as discussed in section 4.5, far from
impossible). But with some ingenuity and with far greater enthusiasm
for experimentation than had been the case previously, economists are
experimenting much more frequently both in the laboratory and in the
field. In addition, as a substitute for experimentation, or as a way
of stretching the limits on experimentation, economists in recent
years have become very enthusiastic about so-called
“instrumental variable” techniques. For example, merely
examining the correlation between economic growth and development aid,
even controlling for other factors known to influence economic growth
is unlikely to reveal the causal influence of aid on growth, because
aid may reciprocally depend on growth and well as many factors that
are hard to measure that also influence growth. These problems can be
to some extent circumvented if economists can find an
“instrumental” variable x upon which aid depends
that influences growth (if at all) only by its influence on aid and
which is probabilistically independent of all other determinants of
growth. In that case, one can use the effect of x on growth
to estimate the effect of aid on growth. Instrumental variable
techniques, policy experimentation, and reliance on “natural
experiments” have become widespread, though they bring with them
new problems extrapolating experimental results to the target
population (Deaton 2010; Cartwright and Hardie 2013).
In the wake of the work of
 Kuhn
 (1970) and Lakatos (1970), philosophers are much more aware of and
interested in the larger theoretical structures that unify and guide
research within particular research traditions. Since many theoretical
projects or approaches in economics are systematically unified, they
pose questions about what guides research, and many economists have
applied the work of Kuhn or Lakatos in the attempt to shed light on
the overall structure of economics (Baumberg 1977, Blaug 1976, de
Marchi and Blaug 1991, Bronfenbrenner 1971, Coats 1969, Dillard 1978,
Hands 1985b, Hausman 1992, ch. 6, Hutchison 1978, Latsis 1976,
Jalladeau 1978, Kunin and Weaver 1971, Stanfield 1974, Weintraub 1985,
Worland 1972). Whether these applications have been successful is
controversial, but the comparison of the structure of economics to
Kuhn’s and Lakatos’ schema served to highlight distinctive
features of economics and may have contributed to some of the changes
that economics has undergone. For example, asking what the
“positive heuristic” of mainstream economics consists in
permits one to see that mainstream theoretical models typically
attempted to demonstrate that an economic equilibrium will obtain, and
thus that mainstream models were unified in more than just their
common assumptions. Since the success of research projects in
economics is controversial, understanding their global structure and
strategy helped to clarify their drawbacks as well as their
advantages.
As mentioned in the previous section, the most important
methodological issue concerning economics involves the very
considerable simplification, idealization, and abstraction that
characterizes economic theory and the consequent doubts these features
of economics raise concerning whether economics is well supported.
Claims such as, “Agents prefer larger commodity bundles to
smaller commodity bundles,” raise serious questions, because if
they are interpreted as universal generalizations, they are false; and
philosophy of science has traditionally supposed that science is
devoted to the discovery of genuine laws—that is, true universal
generalizations. Even though it is false that everyone always prefers
larger commodity bundles to smaller, the generalization seems
informative and useful. Can a science rest on false generalizations?
If these claims are not universal generalizations, then what is their
logical form? And how can claims that appear in this way to be false
or approximate be tested and confirmed or disconfirmed? These problems
have bedeviled economists and economic methodologists from the first
methodological reflections to the present day.
The first extended reflections on economic methodology appear in the
work of Nassau Senior (1836) and John Stuart Mill (1836). Their essays
must be understood against the background of both the economic theory
and the philosophy of science of their times. Like Smith’s
economics (to which it owed a great deal) and modern economics, the
“classical” economics of the middle decades of the 19th
century traced economic regularities to the choices of individuals
facing social and natural constraints. But, as compared to Smith, more
reliance was placed on severely simplified models. David
Ricardo’s Principles of Political Economy (1817), draws
a portrait in which wages above the subsistence level lead to
increases in the population, which in turn require more intensive
agriculture or cultivation of inferior land. The extension of
cultivation leads to lower profits and higher rents; and the whole
tale of economic development leads to a gloomy stationary state in
which profits are too low to command any net investment, wages slide
back to subsistence levels, and only the landlords are affluent.
Fortunately for the world, but unfortunately for economic theorists of
the mid 19th century, the data consistently contradicted the trends
the theory predicted (de Marchi 1970). Yet the theory continued to
hold sway for more than half a century, and the consistently
unfavorable data were explained away as due to various
“disturbing causes.” It is consequently not surprising
that Senior’s and Mill’s accounts of the method of
economics emphasize the relative autonomy of theory.
Mill distinguishes between two main kinds of inductive methods. The
method a posteriori is a method of direct experience. In his
view, it is only suitable for phenomena in which few causal factors
are operating or in which experimental controls are possible.
Mill’s famous methods of induction provide an articulation of
the method a posteriori. In his method of difference, for
example, one holds fixed every causal factor except one and checks to
see whether the effect ceases to obtain when that one factor is
removed. The goal is to identify exceptionless causal laws.
Mill maintains that direct inductive methods cannot be used to study
phenomena in which many causal factors are in play. If, for example,
one attempts to investigate whether tariffs enhance or impede
prosperity by comparing the prosperity of nations with high tariffs
and nations without high tariffs, the results will be uninformative,
because prosperity depends on so many other causal factors. So, Mill
argues, one needs instead to employ the method a priori.
Despite its name, this too is an inductive method. However, unlike the
method a posteriori, the method a priori is an
indirect inductive method. Scientists first determine the
laws governing individual causal factors in domains in which
Mill’s methods of induction are applicable. Having then
determined the laws of the individual causes, they investigate their
combined consequences deductively. Finally, there is a role for
“verification” of the combined consequences, but owing to
the causal complications, this testing has comparatively little
weight. The testing of the conclusions serves only as a check on the
scientist’s deductions and as an indicator of whether there are
significant disturbing causes that scientists have not yet accounted
for.
Mill gives the example of the science of the tides. Physicists
determined the law of gravitation by studying planetary motion, in
which gravity is the only significant causal factor. Then physicists
develop the theory of tides deductively from that law and information
concerning the positions and motions of the moon and sun. The
implications of the theory will be inexact and sometimes badly
mistaken, because many subsidiary causal factors influence tides.
Testing theories of tides can uncover mistakes in the deductions
physicists made, and it may uncover evidence concerning the role of the
subsidiary factors. But because of the causal complexity, such testing
does little to confirm or disconfirm the law of gravitation, which has
already been established. Although Mill does not often use the
language of “ceteris paribus”, his view that the
principles or “laws” of economics hold in the absence of
“interferences” or “disturbing causes”
provides an account of how the principles of economics can be true
ceteris paribus (Hausman 1992, ch. 8, 12).
Because economic theory includes only the most important causes and
necessarily ignores minor causes, its claims, like claims concerning
tides, are inexact. Its predictions will be imprecise, and sometimes
far off. Mill maintains that it is nevertheless possible to develop
and confirm economic theory by studying in simpler domains the laws
governing the major causal factors and then deducing their
consequences in more complicated circumstances. For example, the
statistical data are ambiguous concerning the relationship between
minimum wages and unemployment of unskilled workers; and since the
minimum wage has never been extremely high, there are no data about
what unemployment would be in those circumstances. On the other hand,
everyday experience teaches economists that firms can choose among
more or less labor-intensive processes and that a high minimum wage
will make more labor-intensive processes more expensive. On the
assumption that firms try to keep their costs down, economists have
good (though not conclusive) reason to believe that a high minimum
wage will increase unemployment.
In defending a view of economics as in this way inexact and employing
the method a priori, Mill thought he was able to reconcile his
empiricism and his commitment to Ricardo’s economics. Although
Mill’s views on economic methodology were challenged later in
the nineteenth century by economists who believed that theory was too
remote from the contingencies of policy and history (Roscher 1874,
Schmoller 1888, 1898), Mill’s methodological views dominated the
mainstream of economic theory for a century (for example, Cairnes
1875). Mill’s vision survived the so-called neoclassical
revolution in economics beginning in the 1870s and is clearly
discernible in the most important methodological treatises concerning
neoclassical economics, such as John Neville Keynes’ The
Scope and Method of Political Economy (1891) or Lionel
Robbins’ An Essay on the Nature and Significance of Economic
Science (1932). Hausman (1992) argues that current methodological
practice closely resembles Mill’s methodology, despite the fact
that few economists explicitly defend it.
Although this way of interpreting Mill and the methodology of
economics is coherent and conforms to an old-fashioned empiricist
philosophy of science that finds the nomological force of
generalizations in their universality, it is not faithful to the way
in which economists see their theories. Rather than regarding
generalizations such as acquisitiveness as universal laws carrying
implicit ceteris paribus qualifications in their antecedents,
economists are much more likely to regard these generalizations as
“tendencies” that continue to operate even when defeated
by interferences and that need to be studied separately (Woodward
2003). Even Mill speaks of tendencies, though without reconciling his
talk of tendencies with his empiricism. If one sets aside metaphysical
qualms about tendencies and counterfactuals, the most natural way to
see economic theorizing is as the counterfactual investigation of
combinations of tendencies. As the discussion below of models
confirms, such views are congenial to economists and puzzling to
philosophers with empiricist scruples.
Conceptualizing of economic inquiry as the study of models and
tendencies, seems to shift the terms of the problems posed by
inexactness rather than to offer a solution. Julian Reiss has, in
effect, rediscovered the problem in an influential essay, “The
Explanation Paradox.” (2013), where he argues that the following
three propositions are inconsistent: (1) Economic models are false.
(2) Economic models are explanatory. (3) Explanation requires
truth.The formulation is a bit obscure, since models are not single
sentences or propositions that can be true or false, but it should be
clear that Reiss’s putative paradox is a reformulation of the
problem posed by the inexactness of economic theories or models.
Although some contemporary philosophers have argued that Mill’s
method a priori is largely defensible (Bhaskar 1975,
Cartwright 1989, and Hausman 1992), by the middle of the Twentieth
Century Mill’s views appeared to many economists out of step
with their understanding of contemporary philosophy of science.
Without studying Mill’s text carefully, it was easy for
economists to misunderstand his terminology and to regard his method
a priori as opposed to empiricism. Others took seriously
Mill’s view that the basic principles of economics should be
empirically established and found evidence to cast doubt on some of
the basic principles, particularly the view that firms attempt to
maximize profits (Hall and Hitch 1938, Lester 1946, 1947).
Methodologists who were well-informed about contemporary developments
in philosophy of science, such as Terence Hutchison (1938), denounced
“pure theory” in economics as unscientific.
Philosophically reflective economists proposed several ways to replace
the old-fashioned Millian view with a more up-to-date methodology that
would continue to justify much of current practice (see particularly
Machlup 1955, 1960 and Koopmans 1957). By far the most influential of
these efforts was Milton Friedman’s 1953 essay, “The
Methodology of Positive Economics.” This essay has had an
enormous influence, far more than any other work on methodology.
Friedman begins his essay by distinguishing in a conventional way
between positive and normative economics and conjecturing that policy
disputes are typically really disputes about the consequences of
alternatives and can thus be resolved by progress in positive
economics. Turning to positive economics, Friedman asserts (without
argument) that correct prediction concerning phenomena not yet
observed is the ultimate goal of all positive sciences. He
holds a practical view of science and finds the value of science in
predictions that will guide policy.
Since it is difficult and often impossible to carry out experiments
and since the uncontrolled phenomena economists observe are difficult
to interpret (owing to the same causal complexity that bothered Mill),
it is hard to judge whether a particular theory is a good basis for
predictions or not. Tendencies are not universal laws. A claim such as
“firms attempt to maximize profits” will be
“unrealistic” in the sense that it is not a true universal
generalization. Although not in these terms, Friedman objects to
criticisms of tendencies that in effect complain that they are merely
tendencies, rather than universal laws. If his criticism stopped
there, it would be sensible, although it would avoid the problems of
understanding and appraising claims about tendencies.
But Friedman draws a much more radical conclusion. In his terminology,
the mistake economists make who criticize claims such as “firms
attempt to maximize profits” lies in the attempt to test
theories by the “realism” of their
“assumptions” rather than by the accuracy of their
predictions. He maintains that the realism of a theory’s
assumptions is irrelevant to its predictive value. It does not matter
whether the assumption that firms maximize profits is realistic.
Theories should be appraised exclusively in terms of the accuracy of
their predictions. What matters is exclusively whether the theory of
the firm makes correct and significant predictions.
As critics have pointed out (and almost all commentators have been
critical), Friedman refers to several different things as
“assumptions” of a theory and means several different
things by speaking of assumptions as “unrealistic”
(Brunner 1969). Since Friedman aims his criticism to those who
investigate empirically whether firms in fact attempt to maximize
profits, he must take “assumptions” to include central
economic generalizations, such as “Firms attempt to maximize
profits,” and by “unrealistic,” he must mean, among
other things, “false.” In arguing that it is a mistake to
appraise theories in terms of the realism of assumptions, Friedman is
arguing at least that it is a mistake to appraise theories by
investigating whether their central generalizations are true or
false.
It would seem that this interpretation would render Friedman’s
views inconsistent, because in testing whether firms attempt to
maximize profits, one is checking whether predictions of theory
concerning the behavior of firms are true or false. An
“assumption” such as “firms maximize profits”
is itself a prediction. But there is a further wrinkle. Friedman is
not concerned with every prediction of economic theories. In
Friedman’s view, “theory is to be judged by its predictive
power exclusively for the class of phenomena which it is intended
to explain” (1953, p. 8 [italics added]). Economists are
interested in only some of the implications of economic theories.
Other predictions, such as those concerning the results of surveys of
managers, are irrelevant to policy. What matters is whether economic
theories are successful at predicting the phenomena that economists
are interested in. In other words, Friedman believes that economic
theories should be appraised in terms of their predictions concerning
prices and quantities exchanged on markets. In his view, what matters
is “narrow predictive success” (Hausman 2008a), not
overall predictive adequacy.
So Friedman permits economists to ignore the disquieting findings of
surveys, or the fact that people do not always prefer larger bundles
of commodities to smaller bundles of commodities. Nor do economists
need to be concerned about whether there is a tendency to prefer more
commodities to fewer. They need not be troubled that some of their
models suppose extravagantly that all agents know the prices of all
present and future commodities in all markets. All that matters is
whether the predictions concerning market phenomena turn out to be
correct. And since anomalous market outcomes could be due to any
number of uncontrolled causal factors, while experiments are difficult
to carry out, it turns out that economists need not worry about ever
encountering evidence that would strongly disconfirm fundamental
theory. Detailed models may be confirmed or disconfirmed, but
fundamental theory is safe. In this way one can understand how
Friedman’s methodology, which appears to justify the eclectic
and pragmatic view that economists should use any model that appears
to “work” regardless of how absurd or unreasonable its
assumptions might appear, has been deployed in service of a rigid
theoretical orthodoxy. For other discussions of Friedman’s
essay, see Bear and Orr 1969, Boland 1979, Hammond 1992, Hirsch and de
Marchi 1990, Mäki 1990a, Melitz 1963, Rotwein 1959, and Samuelson
1963.
Over the last two decades there has been a surge of experimentation in
economics, and Friedman’s methodological views probably do not
command the same near unanimity that they used to. But they are still
enormously influential, and they still serve as a way of avoiding
awkward questions concerning simplifications, idealizations, and
abstraction in economics rather than responding to them.
A century ago economists talked of their work in terms of
“principles,” “laws,”, and
“theories.” That language has not disappeared altogether:
economists still talk of “game theory”, “consumer
choice theory”, or the “law of demand”. But nowadays
the standard intellectual tool or form in economics is a
“model.” Econometricians speak of models and structures.
Economists are more comfortable describing the axioms concerning
rational choice as constituting a model of rational choice than as
delineating a theory of rational choice. Many of the most
distinguished commentators on models regard them as fictional worlds,
whose study informs our understanding of actual phenomena (Frigg,
2010). “Creating models is ‘world-making.’”
(Morgan 2012, pp. 95, 405). In their view, economists are able to
investigate how causal factors would operate in the absence of
interferences by constructing models —that is fictional
economies—in which the interferences are absent. Uskali
Mäki maintains that “Models are experiments. Experiments
are models.” (2005). Dani Rodrik (2015) argues that economics
consists of a collection of models, and that doing economics consists in
selecting or customizing a model from this collection. Is the ubiquity
of talk of models just a change in terminological fashion, or does the
concern with models (which is by no means unique to economics) signal
a methodological shift? What are models? These questions have been
discussed by Cartwright 1989, 1999, Godfrey Smith 2006,
Grüne-Yanoff 2009, Hausman 1992, 2015a, Kuorikoski and Lehtinen
2009, Mäki, ed. 1991, Mäki 2005, 2009a, 2009b, Morgan 2001,
2004, 2012, Morgan and Morrison 1999, Rappaport 1998, Sugden 2000,
2009, Weisberg 2007, and Lehtinen, Kuorikoski and Ylikoski 2012.
The view of models to which economists are most attracted is
philosophically problematic, because it is apparently committed to the
existence of fictional entities whose properties and causal
propensities economists can investigate. In experiments, whether
carried out in a laboratory or in the field, experimenters interact
causally with flesh and blood experimental subjects, and the outcome
may contradict the economist’s predictions. In investigating a
model, in contrast, the economist “interacts” with
fictional entities, which are arguably nothing other than his or her
own thoughts, and the logical implications of the axioms that define
the model are never disappointed. This is not to say that the logical
investigation of models never results in surprises. Humans are not
logically omniscient, and discovering the implications of a set of
axioms may be an arduous task. But it is a different task than
carrying out an experiment in the laboratory or the field, and
ontology of the “worlds” that economists allegedly
“create” and then study is deeply puzzling. Although less
faithful to economic practice, it is far more intelligible
philosophically to regard models as predicates or as definitions of
predicates (Hausman 1992). For example, when economists write down
a model of a firm with a single output and just two inputs,
they are defining a concept that they can use to describe
actual firms.
The past half century has witnessed the emergence of a large
literature devoted to economic methodology. That literature explores
many methodological approaches and applies its conclusions to many
schools and branches of economics. Much of the literature has focused
on the fundamental theory of mainstream economics — the theory
of the equilibria resulting from constrained rational individual
choice — but the tremendous importance of macroeconomics in
determining the proper responses to the great recession beginning in
2008, coupled with the rapidly increasing role of empirical and
experimental inquiries in the day-to-day work of economists have seen
echoes in methodological inquiries (Backhouse 2010). Since 1985, there
has been a journal Economics and Philosophy devoted
specifically to philosophy of economics, and since 1994 there has also
been a Journal of Economic Methodology. This section will
sample some of the methodological approaches of the past two
decades.
Karl Popper’s
 philosophy of science has been influential among economists, as among
other scientists. Popper defends what he calls a falsificationist
methodology (1968, 1969). Scientists should formulate theories that
are “logically falsifiable” — that is, inconsistent
with some possible observation reports. “All crows are
black” is logically falsifiable; it is inconsistent with (and
would be falsified by) an observation report of a red crow.
(Probabilistic claims are obviously not in this sense falsifiable.)
Popper insists on falsifiability on the grounds that unfalsifiable
claims that rule out no observations are uninformative. They provide
no guidance concerning what to expect, and there is nothing to be
learned from testing them. Second, Popper maintains that scientists
should subject theories to harsh test and should be willing to reject
them when they fail the tests. Third, scientists should regard
theories as at best interesting conjectures. Passing a test does not
confirm a theory or provide scientists with reason to believe it. It
only justifies on the one hand continuing to employ the hypothesis
(since it has not yet been falsified) and, on the other hand, devoting
increased efforts to attempting to falsify it (since it has thus far
survived testing). Popper has defended what he calls
“situational logic” (which is basically rational choice
theory) as the correct method for the social sciences (1967, 1976).
There appear to be serious tensions between Popper’s
falsificationism and his defense of situational logic, and his
discussion of situational logic has not been as influential as his
falsificationism. For discussion of how situational logic applies to
economics, see Hands (1985a).
Given Popper’s falsificationism, there seems little hope of
understanding how extreme simplifications can be legitimate or how
current economic practice could be scientifically reputable. Economic
theories and models are almost all unfalsifiable, and if they were,
the widespread acceptance of Friedman’s methodological views
would insure that they are not subjected to serious test. When models
apparently fail tests, they are rarely repudiated. Economists conclude
instead merely that they chose the wrong model for the task, or that
there were disturbing causes. Economic models, which have not been
well tested, are often taken to be well-established guides to policy,
rather than merely conjectures. Critics of neoclassical economics have
made these criticisms (Eichner 1983), but most of those who have
espoused Popper’s philosophy of science have not repudiated
mainstream economics and have not been harshly critical of its
practitioners.
Mark Blaug (1992) and Terence Hutchison (1938, 1977, 1978, 2000), who
are the most prominent Popperian methodologists, criticize particular
features of economics, and they both call for more testing and a more
critical attitude. For example, Blaug praises Gary Becker (1976) for
his refusal to explain differences in choices by differences in
preferences, but criticizes him for failing to go on and test his
theories severely (1980a, chapter 14). However, both Blaug and
Hutchison understate the radicalism of Popper’s views and take
his message to be little more than that scientists should be critical
and concerned to test their theories.
Blaug’s and Hutchison’s criticisms have sometimes been
challenged on the grounds that economic theories cannot be
tested, because of their ceteris paribus clauses and the many
subsidiary assumptions required to derive testable implications
(Caldwell 1984). But this response ignores Popper’s insistence
that testing requires methodological decisions not to attribute
failures of predictions to mistakes in subsidiary assumptions or to
“interferences.” For views of Popper’s philosophy
and its applicability to economics, see de Marchi (1988), Caldwell
(1991), Boland (1982, 1989, 1992, 1997), and Boylan and O’Gorman
(2007), Backhouse (2009), and Thomas (2017).
Applying Popper’s views on falsification literally would be
destructive. Not only neoclassical economics, but all significant
economic theories would be condemned as unscientific, and there would
be no way to discriminate among economic theories. One major problem
with a naive reading of Popper’s views is that
one cannot derive testable implications from theories by themselves.
To derive testable implications, one also needs subsidiary assumptions
concerning probability distributions, measurement devices, proxies for
unmeasured variables, the absence of interferences, and so forth. This
is the so-called “Duhem-Quine problem” (Duhem 1906, Quine
1953, Cross 1982). These problems arise generally, and Popper proposes
that they be solved by a methodological decision to regard a failure
of the deduced testable implication to be a failure of the theory. But
in economics the subsidiary assumptions are dubious and in many cases
known to be false. Making the methodological decision that Popper
requires is unreasonable and would lead one to reject all economic
theories.
Imre Lakatos (1970), who was for most of his philosophical career a
follower of Popper, offers a broadly Popperian solution to this
problem. Lakatos insists that testing is always comparative. When
theories face empirical difficulties, as they always do, one attempts
to modify them. Scientifically acceptable (in Lakatos’
terminology “theoretically progressive”) modifications
must always have some additional testable implications; otherwise they
are purely ad hoc. If some of the new predictions are
confirmed, then the modification is “empirically
progressive,” and one has reason to reject the unmodified theory
and to employ the new theory, regardless of how unsuccessful in
general either theory may be. Though progress may be hard to come by,
Lakatos’ views do not have the same destructive implications as
Popper’s. Lakatos appears to solve the problem of how to
appraise mainstream economic theory by arguing that what matters is
empirical progress or retrogression rather than empirical success or
failure. Lakatos’ views have thus been more attractive to
economic methodologists than Popper’s.
Developing Thomas Kuhn’s notion of a “paradigm”
(1970) and some hints from Popper, Lakatos also presented a view of
the global theory structure of whole theoretical enterprises, which he
called “scientific research programmes.” Lakatos
emphasized that there is a “hard core” of basic
theoretical propositions that define a research programme and that are
not to be questioned within the research programme. In addition
members of a research programme accept a common body of heuristics
that guide them in the articulation and modification of specific
theories. These views have also been attractive to economic
methodologists, since theory development in economics is sharply
constrained and since economics appears at first glance to have a
“hard core.” The fact that economists do not give up basic
theoretical postulates that appear to be false might be explained and
justified by regarding them as part of the “hard core” of
the “neoclassical research programme”.
Yet Lakatos’ views do not provide a satisfactory account of how
economics can be a reputable science despite its reliance on extreme
simplifications. For it is questionable whether the development of
neoclassical economic theory has demonstrated empirical progress. For
example, the replacement of “cardinal” utility theory by
“ordinal” utility theory (see below
 Section 5.1)
 in the 1930s, which is generally regarded as a major step forward,
involved the replacement of one theory by another that had no
additional empirical content. Furthermore, despite his emphasis on
heuristics as guiding theory modification, Lakatos still emphasizes
testing. Science is for Lakatos more empirically driven than
mainstream economics has been (Hands 1992). It is also doubtful whether
research enterprises in economics have “hard cores”
(Hoover 1991, Hausman 1992, ch. 6). For attempts to apply
Lakatos’ views to economics see Latsis (1976), and Weintraub
(1985). As is apparent in de Marchi and Blaug (1991), writers on
economic methodology have in recent years become increasingly
disenchanted with Lakatos’ philosophy (Backhouse 2009).
There is a second major problem with Popper’s philosophy of
science, which plagues Lakatos’ views as well. Both maintain
that there is no such thing as empirical confirmation (for some late
qualms, see Lakatos 1974). Popper and Lakatos maintain that evidence
never provides reason to believe that scientific claims are true, and
both also deny that results of tests can justify relying on statements
in practical endeavours or in theoretical inquiry. There is no better
evidence for one unfalsified proposition than for another. On this
view, someone who questions whether there is enough evidence for some
proposition to justify relying on it in theoretical studies or for
policy purposes would be making the methodological “error”
of supposing that there can be evidence in support of hypotheses. With
the notable exception of Watkins (1984), few philosophers within the
Popperian tradition have faced up to this challenging consequence.
One radical reaction to the difficulties of justifying the reliance on
severe simplifications is to deny that economics passes methodological
muster. Alexander Rosenberg (1992) maintains that economics can only
make imprecise generic predictions, and it cannot make progress,
because it is built around folk psychology, which is a mediocre theory
of human behavior and which (owing to the irreducibility of
intentional notions) cannot be improved. Complex economic theories are
scientifically valuable only as applied mathematics, not as empirical
theory. Since economics does not show the same consistent progress as
the natural sciences, one cannot dismiss Rosenberg’s suggestion
that economics is an empirical dead end. But his view that it has made
no progress and that it does not permit quantitative
predictions is hard to accept. For example, contemporary economists
are much better at pricing stock options or designing auctions than
economists were even a generation ago.
An equally radical but opposite reaction is Deirdre McCloskey’s,
who denies that there are any non-trivial methodological standards
that economics must meet (1985, 1992, 1994, 2000, McCloskey and Ziliak
2003, Ziliak and McCloskey 2008). In her view, the only relevant and
significant criteria for assessing the practices and products of a
discipline are those accepted by the practitioners. Apart from a few
general standards such as honesty and a willingness to listen to
criticisms, the only justifiable criteria for any conversation are
those of the participants. Economists can thus dismiss the arrogant
pretensions of philosophers to judge economic discourse. Whatever a
group of respected economists takes to be good economics is
automatically good economics. Philosophical standards of empirical
success are just so much hot air. Those who are interested in
understanding the character of economics and in contributing to its
improvement should eschew methodology and study instead the
“rhetoric” of economics — that is, the means of
argument and persuasion that succeed among economists.
McCloskey’s studies of the rhetoric of economics have been
valuable and influential (1985, esp. ch. 5–7, McCloskey and
Ziliak 2003, Ziliak and McCloskey 2008), but a great deal of her work
during the 1980s and 1990s consists of philosophical critiques of
economic methodology rather than studies of the rhetoric of economics.
Her philosophical critiques are problematic, because the position
sketched in the previous paragraph is hard to defend and potentially
self-defeating. It is hard to defend, because epistemological
standards have already influenced the conversation of economists. The
standards of predictive success which lead one to have qualms about
economics are already standards that many economists accept. The only
way to escape these doubts is to surrender the standards that gave
rise to them. But McCloskey’s position undermines any principled
argument for a change in standards. Furthermore, as Rosenberg has
argued (1988), it seems that economists would doom themselves to
irrelevance if they were to surrender standards of predictive success,
for it is upon such standards that policy decisions are made.
McCloskey does not, in fact, want to preclude the possibiity that
economists are sometimes persuaded when they should not be or are not
persuaded when they should be. For she herself criticizes the bad
habit some economists have of conflating statistical significance with
economic importance (1985, ch. 9, McCloskey and Ziliak 2003, Ziliak
and McCloskey 2008). McCloskey typically characterizes rhetoric
descriptively as the study of what in fact persuades, but sometimes
she instead characterizes it normatively as the study of what ought to
persuade (1985, ch. 2). And if rhetoric is the study of what
ought rationally to persuade, then it is methodology, not an
alternative to methodology. Questions about whether economics is a
successful empirical science cannot be conjured away.
Economic methodologist have paid little attention to debates within
philosophy of science between realists and anti-realists (van Fraassen
1980, Boyd 1984, Psillos 1999, Niniluoto 2002, Chakravarty 2010,
Dicken 2016), because economic theories rarely postulate the existence
of unobservable entities or properties, apart from variants of
“everyday unobservables,” such as beliefs and desires.
Methodologists have, on the other hand, vigorously debated the goals
of economics, but those who argue that the ultimate goals are
predictive (such as Milton Friedman) do so because of their interest
in policy, not because they seek to avoid or resolve epistemological
and semantic puzzles concerning references to unobservables.
Nevertheless there are two important recent realist programs in
economic methodology. The first, developed mainly by Uskali Mäki,
is devoted to exploring the varieties of realism implicit in the
methodological statements and theoretical enterprises of economists
(see Mäki 1990a, b, c, 2007, and Lehtinen, Kuorikoski and
Ylikoski 2012). The second, which is espoused by Tony Lawson and his
co-workers, mainly at Cambridge University, derives from the work of
Roy Bhaskar (1975) (see Lawson 1997, 2015, Bhaskar et al.
1998, Fleetwood 1999, Brown and Fleetwood 2003, Ackroyd and Fleetwood
2004, Edwards, Mahoney, and Vincent 2014). In Lawson’s view, one
can trace many of the inadequacies of mainstream economics (of which
he is a critic) to an insufficient concern with ontology. In
attempting to identify regularities on the surface of the phenomena,
mainstream economists are doomed to failure. Economic phenomena are in
fact influenced by a large number of different causal factors, and one
can achieve scientific knowledge only of the underlying mechanisms and
tendencies, whose operation can be glimpsed intermittently and
obscurely in observable relations. Mäki’s and
Lawson’s programs have little to do with one another, though
Mäki (like Mill, Cartwright, and Hausman) shares Lawson’s
and Bhaskar’s concern with underlying causal mechanisms. See
also the entry on
 scientific realism.
Throughout its history, economics has been the subject of sociological
as well as methodological scrutiny. Many sociological discussions of
economics, like Marx’s critique of classical political economy,
have been concerned to identify ideological distortions and thereby to
criticize particular aspects of economic theory and economic policy.
Since every political program finds economists who testify to its
economic virtues, there is a never-ending source of material for such
critiques. For example, in the wake of the near collapse of the
international financial system in 2008, American economists who argued
for austerity were mostly Republicans, while those who defended
efforts to increase aggregate demand were mostly Democrats.
The influence of contemporary sociology of science and social studies
of science, coupled with the difficulties methodologists have had
making sense of and rationalizing the conduct of economics, have led
to efforts at fusing economics and sociology (Granovetter 1985,
Swedberg 1990, 2007) as well as to a sociological turn within
methodological reflection itself. Rather than showing that there is
good evidence supporting developments in economic theory or that those
developments have other broadly epistemic virtues, methodologists and
historians such as D. Wade Hands (2001); Hands and Mirowski 1998),
Philip Mirowski (1990, 2002, 2004, 2013), and E. Roy Weintraub (1991)
have argued that these changes reflect a wide variety of non-rational
factors, from changes in funding for theoretical economics, political
commitments, personal rivalries, attachments to metaphors, or
mathematical interests.
Furthermore, many of the same methodologists and historians have
argued that economics is not only an object of social inquiry, but
that it can be a tool of social inquiry into science. By studying the
incentive structure of scientific disciplines and the implicit or
explicit market forces impinging on research (including of course
research in economics), it should be possible to write the economics
of science and the economics of economics itself (Hands 1995, Hull
1988, Leonard 2002, Mirowski and Sent 2002).
Exactly how, if at all, this work is supposed to bear on questions
concerning how well supported are the claims economists make is not
clear. Though eschewing traditional methodology, Mirowski’s
monograph on the role of physical analogy in economics (1990) is often
very critical of mainstream economics. In his Reflection without
Rules (2001) D. W. Hands maintains that general methodological
rules are of little use. He defends a naturalistic view of methodology
and is skeptical of prescriptions that are not based on detailed
knowledge. But he does not argue that no rules apply.
The above survey of approaches to the fundamental problems of
appraising economic theory is far from complete. For example, there
have been substantial efforts to apply structuralist views of
scientific theories (Sneed 1971, Stegmüller 1976, 1979) to
economics (Stegmüller et al. 1981, Hamminga 1983, Hands 1985c,
Balzer and Hamminga 1989). The above discussion documents the
diversity and disagreements concerning how to interpret and appraise
economic theories. It is not surprising that there is no consensus
among those writing on economic methodology concerning the overall
empirical appraisal of specific approaches in economics, including
mainstream microeconomics, macroeconomics, and econometrics. When
practitioners cannot agree, it is questionable whether those who know
more philosophy but less economics will be able to settle the matter.
Since the debates continue, those who reflect on economic methodology
should have a continuing part to play.
Meanwhile, there are many other more specific methodological questions
to address, and it is a sign of the maturity of the subdiscipline that
a large and increasing percentage of work on economic methodology
addresses more specific questions. There is plethora of work, as a
perusal of any recent issue of the Journal of Economic
Methodology or Economics and Philosophy will confirm.
Some of the range of issues currently under discussion were mentioned
above in
 Section 2.
 Here is a list of three of the many areas of current interest:
1. Although more concerned with the content of economics than with its
methodology, the recent explosion of work on feminist economics is
shot through with methodological and sociological self-reflection. The
fact that a considerably larger percentage of economists are men than
is true of any of the other social sciences and indeed than most of
the natural sciences raises questions about whether there is something
particularly masculine about the discipline. Important texts are
Ferber and Nelson (1993, 2003), Nelson (1995, 1996, 2001), Barker and
Kuiper (2003). Since 1995, there has been a journal, Feminist
Economics, which pulls together much of this work.
2. During the past decades, laboratory experimentation in economics
has expanded rapidly. Laboratory experimentation has many different
objectives (see Roth 1988) and apparently holds out the prospect of
bridging the gulf between fundamental economic theory and empirical
evidence. Some of it casts light on the way in which methodological
commitments influence the extent to which economists heed empirical
evidence. A good deal of laboratory experimentation in contemporary
economics is in the service of behavioral economics, which prides
itself on heeding experimental evidence concerning the structure and
determinants of individual choices. Although behavioral economics has
secured a foothold within mainstream economics, it remains
controversial substantively and methodologically, and its implications
for normative economics, discussed below in section 6, are
controversial.
For example, in the case of preference reversals, discussed briefly
below in Section 5.1, economists devoted considerable attention to the
experimental findings and conceded that they disconfirmed central
principles of economics. But economists have been generally unwilling
to pay serious attention to the theories proposed by psychologists
that predicted the phenomena before they were observed. The reason
seems to be that these psychological theories do not have the same
wide scope as the basic principles of mainstream economics (Hausman
1992, chapter 13). Hesitation concerning neuroeconomics (Camerer
et al. 2005, Camerer 2009, Marchionni and Vromen 2014,
Rustichini 2005, 2009, Glimcher and Fehr 2013, Reuter and Montag 2016,
Vromen and Marchionni 2018) is also common. In an extremely
influential essay, “The Case for Mindless Economics.” Gul
and Pesandorfer (2008) argue that the findings of behavioral economics
(and neuroeconomics) are irrelevant to economics. They are at most of
heuristic value. They maintain that the findings of behavioral
economics are irrelevant to economics, because they do not concern
market choices and their consequences, which are the only germane
data. Sometimes Gul and Pesandorfer appear to identify economic theory
with the empirical
consequences economists are concerned with, while at other points they
echo Milton Friedman (see section 3.2) and deny that the
“realism” of the “assumptions” of economic
models matters. They do not address sophisticated defenses of realism
concerning mental states like Dietrich and List (2016). It seems to me
that theoretical resistance to engaging
with behavioral economists like that one finds in Gul and
Pesandorfer’s essay is weakening. But it is clear that the
methodological commitments governing theoretical economics are much
more complex and more specific to economics than the general rules
proposed by philosophers such as Popper and Lakatos.
The relevance of laboratory experimentation remains controversial.
Behavioral economists are enthusiastic, while more traditional
theorists question whether experimental findings can be generalized to
non-experimental contexts and, more generally, concerning the
possibilities of learning from experiments (Caplin and Schotter 2008).
For discussions of experimental economics, see Guala (2000a, b, 2005),
Hey (1991), Kagel and Roth (1995, 2016), Plott (1991), Smith (1991),
Starmer (1999), Camerer (2003), Bardsley and Cubitt 2009, Durlauf and
Blume (2009), Branas-Garza and Cabrales (2015), Fréchette and
Schotter (2015), Jacquemet and L’Haridon (2018), and the June,
2005 special issue of the Journal of Economic Methodology. Al
Roth’s Game Theory, Experimental Economics, and Market Design
Page (http://kuznets.fas.harvard.edu/~aroth/alroth.html) is a useful
source. For recent work on behavioral economics see the Journal of
Behavioral Economics, the Review of Behavioral
Economics, and Behavioural Public Policy.
3. During the past generation, there has been a radical transformation
in the attitudes of economists toward empirical causal inquiry,
especially in the form of field experiments and natural experiments,
often employing instrumental variables. For example, about two-thirds
of the articles in the February, 2018 American Economic
Review are based on empirical studies. The titles of the first
four entries in the table of contents are: “The Effects of
Pretrial Detention on Conviction, Future Crime, and Employment:
Evidence from Randomly Assigned Judges,” “Implications of
US Tax Policy for House Prices, Rents, and Homeownership,”
“The Welfare Cost of Perceived Policy Uncertainty: Evidence from
Social Security,” “The Economic Consequences of Hospital
Admissions.” If one goes back twenty-five years, only about
one-eighth of the first issue of the 1993 American Economic
Review appear to rely on any empirical studies. The first four
entries are: “Today’s Task for Economists,”
“Trigger Points and Budget Cuts: Explaining the Effects of
Fiscal Austerity,” “Economic Policy, Economic Performance,
and Elections,” “The Macroeconomics of Dr.
Strangelove.” A Rip Van Winkle who had gone to sleep in 1983
reading the principal economics journals would be staggered when he
awoke in 2018.
Field experiments have been especially important in development
economics where the results of various foreign aid projects have too
often provided meagre benefits. One can find good introductions to
this work in Carpenter et al. (2005), Duflo and Banerjee
(2011, 2017), Gugerty and Karlan (2018), Karlan and Appel (2011,
2016), Kremer and Glennerster (2011), List and Samek (2018), and
Mullainathan and Shafir (2013). See also the
 Poverty Action Lab.
 Although field experiments appear to be hard-nosed inquiries that
establish what works and what does not work, matters are not so simple
(Deaton 2010, Cartwright and Hardie 2013). Without knowledge of the
mechanisms, it is all too easy for an intervention that works
splendidly at a specific time and place to fail abysmally when tried
elsewhere. Atheoretical inquiry, even when methodologically
sophisticated, has severe limits as a tactic of knowledge
acquisition.
The empirical turn in economics has also had the effect of increasing
the importance of economic history. With some ingenuity, especially in
identifying possible instrumental variables, history is full of
“natural experiments.” For example (J. Hausman 2016), in
1936, the American Congress voted to pay pensions to veterans of World
War I eight years before they were due to be paid. Because the
percentages of veterans differed across states, Hausman can use the
differing economic performances of states to estimate the effects of
the economic stimulus the pensions provided. Although less decisive
than randomized controlled trials (which are often impossible to carry
out), examination of historical episodes such as this one provide
significant evidence concerning economic hypotheses.
Insofar as economics explains and predicts phenomena as consequences
of individual choices, which are themselves explained in terms of alleged
reasons, it must depict agents as to some extent rational.
Rationality, like reasons, involves evaluation, and just as one can
assess the rationality of individual choices, so one can assess the
rationality of social choices and examine how they are and ought to be
related to the preferences and judgments of individuals. In addition,
there are intricate questions concerning rationality in strategic
situations in which outcomes depend on the choices of multiple
individuals. Since rationality is a central concept in branches of
philosophy such as action theory, epistemology, ethics, and philosophy
of mind, studies of rationality frequently cross the boundaries
between economics and philosophy.
The barebones theory of rationality discussed above in
 Section 1.1
 takes an agent’s
 preferences
 (rankings of states of affairs) to be rational if they are complete
and transitive, and it takes the agent’s choice to be rational
if the agent does not prefer any feasible alternative to the one he or
she chooses. Such a theory of rationality is clearly too weak, because
it says nothing about belief or what rationality implies when agents
do not know (with certainty) everything relevant to their choices. But
it may also be too strong, since, as Isaac Levi in particular has
argued (1986), there is nothing irrational about having incomplete
preferences in situations involving uncertainty. Sometimes it is
rational to suspend judgment and to refuse to rank alternatives that
are not well understood. On the other hand, transitivity is a
plausible condition, and the so-called “money pump”
argument demonstrates that if one’s preferences are intransitive
and one is willing to make exchanges, then one can be exploited.
(Suppose an agent A prefers X to Y,
Y to Z and Z to X, and that
A will pay some small amount of money $P to exchange
Y for X, Z for Y, and X
for Z. That means that, starting with Z, A
will pay $P for Y, then $P again for
X, then $P again for Z and so on. Agents
are not this stupid. They will instead refuse to trade or adjust their
preferences to eliminate the intransitivity (but see Schick 1986).
On the other hand, there is considerable experimental evidence that
people’s preferences are not in fact transitive. Such evidence
does not establish that transitivity is not a requirement of
rationality. It may show instead that people are sometimes irrational.
In the case of so-called “preference reversals,” for
example, it seems plausible that people in fact make irrational
choices (Lichtenstein and Slovic 1971, Tversky and Thaler 1990).
Evidence of persistent violations of transitivity is disquieting,
since standards of rationality should not be impossibly high.
A further difficulty with the barebones theory of rationality concerns
the individuation of the objects of preference or choice. Consider,
for example, data from multistage ultimatum games. Suppose A
can propose any division of $10 between A and B.
B can accept or reject A’s proposal. If
B rejects the proposal, then the amount of money drops to $5,
and B gets to offer a division of the $5 which A can
accept or reject. If A rejects B’s offer, then
both players get nothing. Suppose that A proposes to divide
the money with $7 for A and $3 for B. B
declines and offers to split the $5 evenly, with $2.50 for each.
Behavior such as this is, in fact, common (Ochs and Roth 1989, p.
362). Assuming that B prefers more money to less, these
choices appear to be a violation of transitivity. B prefers
$3 to $2.50, yet declines $3 for certain for $2.50 (with some slight
chance of A declining and B getting nothing). But
the objects of choice are not just quantities of money. B is
turning down $3 as part of “a raw deal” in favor of $2.50
as part of a fair arrangement. If the objects of choice are defined in
this way, there is no failure of transitivity.
This plausible observation gives rise to a serious problem. Unless
there are constraints on how the objects of choice are individuated,
conditions of rationality such as transitivity are empty.
A’s choice of X over Y, Y
over Z and Z over X does not violate
transitivity if “X when the alternative is
Y” is not the same object of choice as
“X when the alternative is Z”. John
Broome (1991) argues that further substantive principles of
rationality are required to limit how alternatives are individuated or
to require that agents be indifferent between alternatives such as
“X when the alternative is Y” and
“X when the alternative is Z.”
To extend the theory of rationality to circumstances involving
 risk
 (where the objects of choice are lotteries with known probabilities)
and uncertainty (where agents do not know the probabilities or even
all the possible outcomes of their choices) requires further
principles of rationality, as well as controversial technical
simplifications. Subjective Bayesians suppose that individuals in
circumstances of uncertainty have well-defined subjective
probabilities (degrees of belief) over all the payoffs and thus that
the objects of choice can be modeled as lotteries, just as in
circumstances involving risk, though with subjective probabilities in
place of objective probabilities. See the entries on
 Bayes’ theorem
 and
 Bayesian epistemology.
 The most important of the axioms needed for the theory of rational
choice under conditions of risk and uncertainty is the independence
condition. It says roughly that the preferences of rational agent
between two lotteries that differ in only one outcome should match
their preferences between the differing outcomes. Although initially
plausible, the independence condition is very controversial. See
Allais and Hagen (1979) and McClennen (1983, 1990).
A considerable part of rational choice theory is concerned with
formalizations of conditions of rationality and investigation of their
implications. When an agent’s preferences are complete and
transitive and satisfy a further continuity condition, then they can
be represented by a so-called ordinal utility function. What this
means is that it is possible to define a function that represents an
agent’s preferences so that U(X) >
U(Y) if and only if the agent prefers X to
Y, and U(X) = U(Y) if and
only if the agent is indifferent between X and Y.
This function merely represents the preference ranking. It contains no
information beyond the ranking. Any order-preserving transformation of
“U” would represent the agent’s preferences
just as well.
When an agent’s preferences in addition satisfy the independence
condition and some other technical conditions, then they can be
represented by an expected utility function (Harsanyi 1977b, ch. 4,
Hernstein and Milnor 1953, Ramsey 1926, and Savage 1972). Such a
function has two important properties. First, the expected utility of
a lottery is equal to the sum of the (expected) utilities of its
prizes weighted by their probabilities. Second, expected utility
functions are unique up to a positive affine transformation. What this
means is that if U and V are both expected utility
functions representing the preferences of an agent, then for all
objects of preference, X, V(X) must be
equal to aU(X) + b, where
a and b are real numbers and a is positive.
In addition, the axioms of rationality imply that the agent’s
degrees of belief will satisfy the axioms of the probability
calculus.
A great deal of controversy surrounds the theory of rationality, and
there have been many formal investigations into weakened or amended
theories of rationality. For further discussion, see Allais and Hagen
1979, Barberà, Hammond and Seidl 1999, Kahneman and Tversky
1979, Loomes and Sugden 1982, Luce and Raiffa 1957, Machina
1987, and Gilboa and Schmeidler 2001.
Although societies are very different from individuals, they have
mechanisms to evaluate alternatives and make choices, and their
evaluations and choices may be rational or irrational. It is not,
however, obvious, what principles of rationality should govern the
choices and evaluations of society. Transitivity is one plausible
condition. It seems that a society that chooses X when faced
with the alternatives X or Y, Y when faced
with the alternatives Y or Z and Z when
faced with the alternatives X or Z either has had a
change of heart or is choosing irrationally. Yet, purported
irrationalities such as these can easily arise from standard
mechanisms that aim to link social choices and individual preferences.
Suppose there are three individuals in the society. Individual One
ranks the alternatives X, Y, Z. Individual
Two ranks them Y, Z, X. Individual Three
ranks them Z, X, Y. If decisions are made
by pairwise majority voting, X will be chosen from the pair
(X, Y), Y will be chosen from (Y,
Z), and Z will be chosen from (X,
Z). Clearly this is unsettling, but are possible cycles in
social choices irrational?
Similar problems affect what one might call the logical coherence of
social judgments (List and Pettit 2002). Suppose society consists of
three individuals who make the following judgments concerning the
truth or falsity of the propositions P and Q and
that social judgment follows the majority.
The judgments of each of the individuals are consistent with the
principles of logic, while social judgments violate them. How
important is it that social judgments be consistent with the
principles of logic?
Although social choice theory in this way bears on questions of social
rationality, most work in social choice theory explores the
consequences of principles of rationality coupled with explicitly
ethical constraints. The seminal contribution is Kenneth
Arrow’s impossibility theorem (1963, 1967). Arrow assumes that
both individual preferences and social preferences are complete and
transitive and that the method of forming social preferences (or making
social choices) issues in some social preference ranking or social
choice for any possible profile of
individual preferences. In addition, Arrow imposes a weak unanimity
condition: if everybody prefers X to Y, then
Y must not be socially preferred. Third, he requires that there be no
dictator whose preferences determine social preferences or choices irrespective of
the preferences of anybody else. Lastly, he imposes the condition that
the social preference between X and Y should depend on
how individuals rank X and Y and on nothing else.
Arrow then proved the surprising result that no method of relating
social and individual preferences can satisfy all these
conditions!
In the sixty years since Arrow wrote, there has been a plethora of
work in social choice theory, a good deal of which is arguably of
great importance to ethics. For example, John Harsanyi proved that if
individual preferences and social evaluations both satisfy the axioms
of expected utility theory (with shared or objective probabilities)
and that social preferences conform to unanimous individual
preferences, then social evaluations are determined by a weighted sum
of individual utilities (1955, 1977a). Matthew Adler (2012) has
extended an approach like Harsanyi’s to demonstrate that a form
of weighted utilitarianism, which prioritizes the interests of those
who are worse off, uniquely satisfies a longer list of rational and
ethical constraints. When there are instead disagreements in
probability assignments, there is an impossibility result: the
unanimity condition implies that for some profiles of individual
preferences, social evaluations will not satisfy the axioms of
expected utility theory (Hammond 1983, Seidenfeld, et al.
1989, Mongin 1995). For further discussion of social choice theory and
the relevance of utility theory to social evaluation, see the entry on
 social choice theory, Sen (1970)
and for recent reappraisals Fleurbaey (2007) and Adler (2012).
When outcomes depend on what several agents do, one agent’s best
choice may depend on what other agents choose. Although the principles
of rationality governing individual choice still apply, arguably there
are further principles of rationality governing expectations of the
actions of others (and of their expectations concerning your actions
and expectations, and so forth). Game theory occupies an increasingly
important role within economics, and it is also relevant both to
inquiries concerning rationality and inquiries concerning ethics. For
further discussion see the entries on
 game theory,
 game theory and ethics, and
 evolutionary game theory.
As discussed above in
 Section 2.1
 most economists distinguish between positive and normative economics,
and most would argue that economics is relevant to policy mainly
because of the (positive) information it provides concerning the
consequences of policy. Yet the same economists also offer their
advice concerning how to fix the economy, and there is a whole field
of normative economics.
Economic outcomes, institutions, and processes may be better or worse
in several different ways. Some outcomes may make people better off.
Other outcomes may be less unequal. Others may restrict individual
freedom more severely. Economists typically evaluate outcomes
exclusively in terms of welfare. This does not imply that they believe
that only welfare is of moral importance. They focus on welfare,
because they believe that economics provides an excellent set of tools
to address questions of welfare and because they hope that questions
about welfare can be separated from questions about equality, freedom,
or justice. As sketched below, economists have had some things to say
about other dimensions of moral appraisal, but welfare takes center
stage. Indeed normative economics is standardly called “welfare
economics.”
One central question of moral philosophy has been to determine what
things are intrinsically good for human beings. This is a central
question, because all plausible moral views assign an important place
to individual welfare or
 well-being.
 This is obviously true of utilitarianism (which holds that what is
right maximizes total or average welfare), but even non-utilitarian
views are concerned with welfare, if they recognize the virtue of
benevolence, or if they are concerned with the interests of
individuals or with avoiding harm to individuals.
There are many ways to think about well-being, and the prevailing view
among economists has shifted from hedonism (which takes the good to be
a mental state such as pleasure or happiness) to the view that welfare
should be measured by the satisfaction of preferences. A number of
prominent economists are currently arguing for a return to hedonism,
but they remain a minority. (See Bavetta et al. 2014. Clark
Flèche 2018, Dolan and Kahneman 2014, Frey 2010, 2018, Frey and
Stutzer 2001, Kahneman 1999, 2000a, 2000b, Kahneman and Krueger 2006,
Kahneman and Sugden 2005, Kahneman and Thaler 2006, Layard 2006,
Ormerod 2008, Radcliff 2013, Weimann and Knabe 2015 and for criticism
Davies 2015, Etzioni 2018, and Hausman 2010.) Unlike hedonism, taking
welfare to be preference satisfaction specifies how to find out what
is good for a person rather than committing itself to any substantive
view of a person’s good. Note that equating welfare with the
satisfaction of preferences is not equating welfare with any
feeling of satisfaction. If welfare can be measured by the
satisfaction of preferences, then a person is better off if what he or
she prefers comes to pass, regardless of whether that occurrence makes
the agent feel satisfied.
Since mainstream economics attributes a consistent preference ordering
to all agents, and since more specific models typically take agents to
be well-informed and self-interested, it is easy for economists to
accept the view that an individual agent A will prefer
X to Y if and only if X is in fact better
for A than Y is. This is one place where positive
theory bleeds into normative theory. In addition, the identification
of welfare with the satisfaction of preferences is attractive to
economists, because it prevents questions about the justification of
paternalism (to which most economists are strongly opposed) from even
arising.
Welfare and the satisfaction of preferences may coincide because the
satisfaction of preferences constitutes welfare or because people are
self-interested and good judges of their own interests and hence
prefer what is good for them. There are many obvious objections to the
view that the satisfaction of preferences constitutes welfare.
Preferences may be based on mistaken beliefs. People may prefer to
sacrifice their own well-being for some purpose they value more
highly. Preferences may reflect past manipulation or distorting
psychological influences (Elster 1983). In addition, if preference
satisfaction constitutes welfare, then policy makers can make people
better off by molding their wants rather than by improving conditions.
Furthermore, it seems unreasonable that social policy should attend to
extravagant preferences. Rather than responding to these objections
and attempting to defend the view that preference satisfaction
constitutes well-being, economists can blunt these objections by
taking preferences in circumstances where people are self-interested
and good judges of their interests to be merely good evidence of what
will promote welfare (Hausman and McPherson 2009, Hausman 2012). There
are some exceptions, most notably Amartya Sen (1987a,b,c, 1992), but
most economists take welfare to coincide with the satisfaction of
preference.
Because the identification of welfare with preference satisfaction
makes it questionable whether one can make interpersonal welfare
comparisons, few economists defend a utilitarian view of policy as
maximizing total or average welfare. (Harsanyi is one exception, for
another see Ng 1983). Economists have instead explored the possibility
of making welfare assessments of economic processes, institutions,
outcomes, and policies without making interpersonal comparisons.
Consider two economic outcomes S and R, and suppose
that some people prefer S to R and that nobody
prefers R to S. In that case S is
“Pareto superior” to R, or S is a
“Pareto improvement” over R. Without making any
interpersonal comparisons, one can conclude that people’s
preferences are better satisfied in S than in R. If
there is no state of affairs that is Pareto superior to S,
then economists say that S is “Pareto optimal” or
“Pareto efficient.” Efficiency here is efficiency with
respect to satisfying preferences rather than minimizing the number of
inputs needed to produce a unit of output or some other technical
notion (Le Grand 1991). If a state of affairs is not Pareto efficient,
then society is missing an opportunity costlessly to satisfy some
people’s preferences better. A Pareto efficient state of affairs
avoids this failure, but it has no other obvious virtues. For example,
suppose nobody is satiated and people care only about how much food
they get. Consider two distributions of food. In the first, millions
are starving but no food is wasted. In the second, nobody is starving,
but some food is wasted. The first is Pareto efficient, while the
second is not.
The notions of Pareto improvements and Pareto efficiency might seem
useless, because economic policies almost always have both winners and
losers. Mainstream economists have nevertheless found these concepts
useful in two ways. First, they have proved two theorems concerning
properties of perfectly competitive equilibria (Arrow 1968). The first
theorem says that equilibria in perfectly competitive markets are
Pareto optimal, and the second says that any Pareto optimal
allocation, with whatever distribution of income policy makers might
prefer, can be achieved as a perfectly competitive market equilibrium,
provided that one begins with just the right distribution of
endowments among economic agents. The first theorem has been regarded
as underwriting Adam Smith’s view of the invisible hand (Arrow
and Hahn 1971, preface; Hahn 1973). This interpretation is
problematic, because no economy has ever been or will ever be in
perfectly competitive equilibrium. The second theorem provides some
justification for the normative division of labor economists prefer,
with economists concerned about efficiency and others concerned about
justice. The thought is that the second theorem shows that theories of
just distribution are compatible with reliance on competitive markets.
The two fundamental theorems of welfare economics go some way toward
explaining why mainstream economists, whether they support
laissez-faire policies or government intervention to remedy
market imperfections, think of perfectly competitive equilibria as
ideals. But the significance of the theorems is debatable, since
actual markets differ significantly from perfectly competitive markets
and, when there are multiple market imperfections, the “theory
of the second best” shows that fixing some of the imperfections
may lead the society away from a perfectly competitive equilibrium
(and diminish efficiency and welfare) rather than toward one (Lipsey
and Lancaster 1956–7).
The other way that economists have found to extend the Pareto
efficiency notions leads to cost-benefit analysis, which is a
practical tool for policy analysis (Mishan 1971; Sugden and Williams
1978; Adler and Posner 2000, 2006; Broadman et al. 2010;
Boadway 2016). Suppose that S is not a Pareto improvement
over R. Some members of the society would be losers in a
shift from R to S. Those losers prefer R to
S, but there are enough winners — enough people who
prefer S to R — that the winners
could compensate the losers and make the preference for
S′ (S with compensation paid) over R
unanimous. S is a “potential Pareto improvement”
over R. In other terms, the amount of money the winners would
be willing to pay to bring about the change is larger than the amount
of money the losers would have to be compensated so as not to object
to the change. (Economists are skeptical about what one learns from
asking people how much they would be willing to pay, and they attempt
instead to infer how much individuals are willing to pay indirectly
from market phenomena.) When S is a potential Pareto
improvement over R, there is said to be a “net
benefit” to the policy of bringing about S. According
to cost-benefit analysis, among eligible policies (which satisfy legal
and moral constraints), one should, other things being equal, employ
the one with the largest net benefit. Note that the compensation is
entirely hypothetical. Potential Pareto improvements result in winners
and losers, the justice or injustice of which is irrelevant to
cost-benefit analysis. Justice or beneficence may require that the
society do something to mitigate distributional imbalances. Because
there is a larger “pie” of goods and services to satisfy
preferences (since compensation could be paid and everybody’s
preferences better satisfied), selecting policies with the greatest
net benefit serves economic efficiency (Hicks 1939, Kaldor 1939).
Despite the practical importance of cost-benefit analysis, the
technique and the justification for it sketched in the previous
paragraph are problematic. One technical difficulty is that it is
possible for S to be a potential Pareto improvement over
R and for R to be a potential Pareto improvement
over S (Scitovsky 1941, Samuelson 1950)! That means that the
fact that S is a potential Pareto improvement over R
does not imply that there is a larger economic “pie” in
S than in R, because there cannot, of course, be a
larger economic pie in S than in R and a larger
economic pie in R than in S. A second problem is
that willingness to pay for some policy and the amount one would
require in compensation if one opposes the policy depend on how much
wealth one has as well as on one’s attitude to the policy.
Cost-benefit analysis weights the preferences of the rich more than
the preferences of the poor (Baker 1975). It is possible to compensate
roughly for the effects of income and wealth (Harburger 1978,
Fankhauser et al. 1997), but it is bothersome to do so, and
cost-benefit analysis is commonly employed without any adjustment for
wealth or income.
A further serious difficulty for traditional welfare economics, which
has been as it were hiding in plain sight, is the fact that choices
are imperfect indicators of preferences, which are in turn imperfect
indicators of what enhances well-being. The same facts that show that
preference satisfaction does not constitute well-being (false beliefs,
lack of information, other-directed and non-rational preferences) show
that choices and preferences are sometimes misleading indicators of
well-being. Moreover, once one recognizes that preferences are good
indicators of welfare only if agents are good judges of what will
benefit them, one is bound to recognize that agents are not always
good judges of what will benefit themselves, even when they have all
the information they need. In some contexts, these problems may be
minor. For example, people’s preferences among new automobiles
are largely self-interested, thoughtful, and well-informed. In other
contexts, such as environmental protection, preferences for ignoring
the problems are often badly informed, while preferences to take
action are typically not self-interested. Either way, popular
preferences among policies to address environmental problems are
unlikely to be a good guide to welfare.
Ignoring these problems has been a great convenience to normative
economics. If what people choose reveals their preferences, which in
turn indicate what is good for them, then, as noted before, government
action to steer someone’s choices can never make that person
better off, and so questions about whether to endorse paternalistic
policies cannot arise. But whether or not it is advisable, successful
paternalism is not impossible; and recent work by behavioral
economists, which document a wide variety of systematic deliberative
foibles, has put questions concerning paternalism back on the table
(Ariely 2009, Kahneman 2011). Some economists have searched for ways to
identify an agent’s “true” preferences (as described
by Infante et al. 2016). Others have argued that policy
makers must respect the preferences of agents among their ends or
objectives, while overruling preferences among means when these are
distorted by bad judgment or false beliefs (Thaler and Sunstein 2008,
Le Grand and New 2015). Moreover, Thaler and Sunstein’s proposal
that government explore non-coercive methods of influencing people to
make better choices (“nudges”) has been popular among
policy makers and has arguably shifted philosophical discussion of
paternalism away from Mill’s (1859) focus on avoiding coercion
(Shiffrin 2000, Hausman and Welch 2010, Le Grand and New 2015).
Although welfare economics and concerns about efficiency dominate
normative economics, they do not exhaust the subject, and in
collaboration with philosophers, economists have made important
contributions to contemporary work in ethics and normative social and
political philosophy.
 Section 5.2
 and
 Section 5.3
 gave some hint of the contributions of social choice theory and game
theory. In addition economists and philosophers have worked on the
problem of providing a formal characterization of freedom so as to
bring tools of economic analysis to bear (Pattanaik and Xu 1990, Sen
1988, 1990, 1991, Carter 1999, Sugden 2018). Others have developed
formal characterizations of social welfare functions that prioritize
the interests of those who are less well off or that favor equality of
resources, opportunity, and outcomes and that separate individual and
social responsibility for inequalities (Pazner and Schmeidler 1974,
Varian 1974, 1975, Roemer 1986b, 1987, Fleurbaey 1995, 2008, Fleurbaey
and Maniquet 2014, Greaves 2015, McCarthy 2015, 2017). John Roemer has
put contemporary economic modeling to work to offer precise
characterizations of exploitation (1982). Amartya Sen and Martha
Nussbaum have not only developed novel interpretations of the proper
concerns of normative economics in terms of capabilities (Sen 1992,
Nussbaum and Sen 1993, Nussbaum 2000), which Sen has linked to
characterizations of egalitarianism and to operational measures of
deprivation (1999). There are many lively interactions between
normative economics and moral philosophy. See also the entries on
 libertarianism,
 paternalism,
 egalitarianism,
 and
 economics [normative] and economic justice.
The frontiers between economics and philosophy concerned with
methodology, rationality, ethics and normative social and political
philosophy are buzzing with activity. This activity is diverse and
concerned with very different questions. Although many of these are
related, philosophy of economics is not a single unified enterprise.
It is a collection of separate inquiries linked to one another by
connections among the questions and by the dominating influence of
mainstream economic models and techniques.