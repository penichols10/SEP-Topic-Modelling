A priori justification is a certain kind of justification
often contrasted with empirical, or a posteriori,
justification. Roughly speaking, a priori justification
provides reasons for thinking a proposition is true that comes from
merely understanding, or thinking about, that proposition. In
contrast, a posteriori justification requires more than
merely understanding a proposition. Observations based on our senses,
or introspection about our current mental state, are needed for us to
be empirically, or a posteriori, justified in believing that
some proposition is true. Examples below bring out the contrast. The
first proposition in each group is a prime candidate for being a
priori justified, if justified at all, while the other
propositions are prime candidates for being a posteriori
justified, if justified at all. Some of the propositions are false,
but that does not mean that we could not be justified in believing
them before we had evidence that they are false.
In each example, it is possible for someone to be justified in
believing the first member in a way that is different from how it is
possible for someone to be justified in believing the other members of
the example. The way the first members can be justified is called
a priori; the way the other members can be justified is
called a posteriori (or empirically).
The first question to discuss is what sorts of propositions can be
a priori justified and known.
Philosophers generally agree that we can be justified in believing
 15bi
 and
 15biii
 only empirically. Yet many believe that they are necessarily true. If
they are necessarily true, that would mean that it’s false that
we can be justified in believing necessary truths only a
priori. But some philosophers think that
 15bi
 and
 15biii
 are not necessary truths and the relevant necessary truth that we can
know a priori is that the essence of any type of matter is
given by the basic elements of which it is composed. On this view, in
the case of water and rubies, we discover empirically what those basic
elements are and the propositions that state those discoveries are
contingent. Philosophers who hold that
 15bi
 and
 15biii
 do express necessary truths usually think that there are descriptions
that fix the reference of the terms, for example, for water, the
description, 
the stuff, whatever it is, that, in the actual world, has the
properties of quenching thirst, putting out certain fires, falling
from the clouds as rain, filling the lakes and rivers, etc. 
While the meaning of “water” is given by this
reference-fixing description, and can be known a priori, the
essence of water must be discovered empirically. The meaning of
natural kind terms does not give the essence of the kind directly in
the way it does with “bachelor” and “vixen”.
One might think that
 15a
 can be justified only empirically, but gemologists seem to think that
it is conceptually necessary that rubies are red, that is,
that the meaning of “ruby” requires that rubies be red. So
given how gemologists use “ruby”,
 15a
 is knowable a priori. The notion of a ruby seems to be a
hybrid notion: its color is knowable a priori but its
material essence as given in
 15bi
 is knowable only empirically.
While it is widely believed that some necessary truths are capable of
justification and can be known only empirically (e.g., “Water is
H2O”), some contingent truths also seem justifiable, and
knowable, a priori. Saul Kripke proposed that “the
standard meter stick, S, in Paris is a meter long at
\(t_0\)” is such an example (Kripke 1972: 274–275).
“The length of S in the actual world at
\(t_0\)” rigidly designates that length, that is, it refers to
length L in every possible world. The reference of “one
meter” is given by that reference-fixing description, so
“one meter” rigidly designates L. However,
“the length of S at \(t_0\)” does not rigidly
designate any particular length since at \(t_0\) in other possible
worlds S will be longer or shorter than L. So the
proposition that “S is a meter long at \(t_0\)” is
contingent because in other possible worlds that very same stick will
be shorter or longer than it was in the actual world at that time.
Still, we can know a priori, that is, independent of any
empirical evidence, that “S is a meter long at
\(t_0\)” is true in the actual world given that we know how the
reference of “one meter” is fixed by a description that
refers to the length of S in the actual world. If empirical
evidence plays any role, it is only insofar as we need it to know that
there really is a stick, S, that was designated as the meter at
some particular time and place. 
A second candidate for being a contingent proposition that is knowable
a priori comes from John Turri. He claims that the
proposition, “The most unlikely possible event is not presently
occurring”, is contingent yet can be known simply in virtue of
understanding its content, and hence is knowable a priori
(2011: 337–338). “The most unlikely possible event”
refers to an event that is maximally improbable. So we know a
priori that no one could have sufficient reason to believe that
an event that fits that description is now occurring. Still, it is
possible that such an event is presently occurring. Thus we can know
a priori that the contingent proposition that says that a
maximally improbable event is now occurring is false, and that its
denial is true.
A third candidate for being a contingent proposition that is knowable
a priori is offered by Gareth Evans. He thinks that we can be
a priori justified in believing, and know, propositions of
the form, “If actually p, then p”, and particular
instantiations of that form. Consider, “if any post is actually
red, then it is red”. This proposition is contingent because the
post could be red in the actual world but not red in some other
possible world. So in some other possible world, \(w_2\), its
antecedent can be true (because its antecedent is about the color of
the post in the actual world, \(w_1\)) and it’s consequent false
(because the post is not red in \(w_2\) and the consequent is
about the color of the post in that world). A conditional that is
necessarily true cannot have a true antecedent and a false consequent
in any possible world. However, we can know independently of
experience (that is, a priori) that if the post is actually
red, then it’s red since it is true in the actual world (cf.,
Evans 1979: 83–85, for his discussion of this topic).
Another candidate for the contingent a priori is the
proposition expressed by, “I am here now”. That sentence
expresses a contingent proposition, since I do not have to exist, much
less do I have to be where I actually am at the present time. Yet a
person can know it is true wherever and whenever she utters it
regardless of the experiences she is currently having or has had in
the past, and so independently of experience.
Leaving aside now the question of whether there can be contingent
propositions that are knowable a priori, there seems to be a
difference within the class of necessarily true propositions that can
be known, or justifiably believed, a priori. The propositions
expressed by
 10a–14a
 seem different from the propositions expressed by
 1a–8a.
 Each of the latter propositions seem to be analytic, that is, in each
case the sentence that expresses the proposition will express a
logical truth if relevant terms and expressions in it are replaced by
appropriate synonyms. So, for instance, “all vixens are
female” will express a logical truth of the form if \(A \amp
B\), then A if we substitute for “vixen”,
“female fox”, for it will then say: if something is a
female fox, it is a female. But no substitution of synonyms for terms
or expressions in
 10a–14a
 will yield a logical truth. The propositions expressed by
 10a–14a
 are often said to be synthetic a priori propositions because
they are not analytic (they are not true in virtue of their meaning,
as it is sometimes put) but are a priori knowable and
justifiable. 
A type of justification (say, via perception) is fallible if and only
if it is possible to be justified in that way in holding a false
belief. A type of justification is defeasible if and only if that
justification could be overridden by further evidence that goes
against the truth of the proposition or undercut by considerations
that call into question whether there really is justification (say,
poor lighting conditions that call into question whether vision
provides evidence in those circumstances).
Just as we can be empirically justified in believing a false
proposition (e.g.,
 9b:
 two quarts of water plus two quarts of carbon tetrachloride do not
combine to yield four quarts of liquid), philosophers argue that we
can also be a priori justified in believing a false
proposition. Perhaps Kant was a priori justified in believing
that every event has a cause. He thought that the proposition had that
status. Yet many physicists believe that there are genuinely random
events at the subatomic level, and reasonably believe it false that
every event has a cause. You might initially be a priori
justified in believing that no matter how happiness has been produced
it is intrinsically good
 (12a),
 or that it is always wrong to punish an innocent person
 (13a).
 You might later think of counterexamples to such claims (e.g., by
considering happiness produced through the suffering of others or
punishing an innocent person to prevent some evil men from punishing
him and many other innocent people). Then your initial a
priori justification would be defeated. John Hawthorne notes how
even paradigmatic instances of a priori justification, such
as someone’s carefully working through a mathematical proof, can
be undercut if the person gets empirical evidence that he is mad or
that his proof is probably mistaken (based on evidence provided by
expert testimony, a bad track record, or of distorting background
conditions, etc.) (Hawthorne 2013: 2009). These examples seem to show
that a priori justification is fallible and defeasible (i.e.,
it can be defeated by further a priori or empirical
evidence).
Consider another example that makes this point. A sorites paradox
involving heaps consists of the general claim that if you take one
bean away from a heap of beans, you still have a heap, and a more
specific claim that, say, any cone-shaped stack of a thousand beans is
a heap. These two premises will lead you, bean by bean, to the
conclusion that one, or even no beans, is a heap! It seems that we are
a priori justified in believing both the general and the more
specific claim are true, but at least one of them must not be true
(perhaps the general claim is false, or even neither true nor false)
because together they lead to an absurd conclusion. So this is another
reason to think that a priori justification is fallible. (See
Sosa 1998: 258–259, for an example about heaps.) George Bealer
argues that philosophical paradoxes show that intuition is fallible
(1998: 202). With a paradox, you are justified in believing each of a
set of propositions taken separately, but at least one of them must be
false because the set is inconsistent.
Why have some thought that a proposition that is a priori
justified cannot be defeated by empirical evidence? Kant said that
a priori knowledge is “knowledge that is absolutely
independent of all experience” (Kant 1787 [1965: 43(B3)]). But
it might be that the requirement that a priori knowledge be
absolutely independent of all experience is
too stringent. Enabling experiences may be required. It avoids this
difficulty to hold instead that a priori knowledge and
justification are independent of all experience beyond what is
needed to grasp the relevant concepts involved in the relevant
proposition (see, below,
 sec. 4.1).
 The fact that a priori knowledge is not independent of all
experience does not show that it is empirically defeasible, but it
does defeat the argument that it is not empirically defeasible
because it is independent of all experience.
When it is just a matter of a priori justification, not
knowledge, Philip Kitcher thinks that if there is such a thing as all
things considered a priori justification, then “a
person is entitled to ignore empirical information about the type of
world she inhabits” (Kitcher 1983: 30; see, also, 24,
80–87). This view seems to rest on Kant’s idea but applied
to justification, not just knowledge. If a priori
justification is independent of all empirical experience,
then no such experience can count either for or against a
proposition that is justified a priori. Hilary Putnam thinks
that if there is a priori justification, then there are
“truths which it is always rational to believe” (Putnam
1983: 90). On Kitcher’s understanding of a priori
justification, it is not defeasible by empirical information;
on Putnam’s, it is not defeasible at all.
It’s hard to see how either view is defensible in light of the
objections by Sosa, Bealer, and Hawthorne. Insofar as justification is
relative to the evidence a person has, or should have, it seems
possible for further evidence, either empirical or from intuition or
rational insight, to override or undercut a person’s current
evidence and thereby destroy that person’s current justification
and knowledge. Nothing in the nature of a priori
justification rules out that possibility. (See the discussion of
Hartry Field, in
 Section 4.5
 below, for more on why it is possible for empirical evidence
in particular to defeat a priori justification.)
Up to this point, the discussion has focused on the sorts of
propositions that can be justified, or known, a priori, and
whether a priori justification is fallible and defeasible.
But what does it mean to say that someone is a priori
justified in believing propositions like those expressed by each of
the first sentences in the fifteen examples above, that is, by
 1a–15a?
 The discussion will now focus on that question.
Then I will turn to the three main views about the nature of a
priori justification. One view is that a priori
justification is not significantly different from empirical
justification. A second view is that it rests on a distinct type of
internal mental state often called rational intuition or rational
insight and that those intuitions or insights can provide evidence for
or against certain propositions. A third view is that a person can be
a priori entitled to believe certain propositions
independently of any evidence, or can be default reasonable in
accepting a proposition independent of any evidence.
A standard answer to the question about the difference between a
priori and empirical justification is that a priori
justification is independent of experience and empirical justification
is not, and this seems to explain the contrasts present in the fifteen
examples above. But various things have been meant by
“experience”. On a narrow account,
“experience” refers to sense experience, that is, to
experiences that come from the use of our five senses: sight, touch,
hearing, smell, and taste. However, this narrow account implies that
justification based on introspection, proprioception (our kinesthetic
sense of the position and movements of our body), memory, and
testimony are kinds of a priori justification. And if we had
different senses, like those of bats (echolocation) and duck-billed
platypuses (electrolocation), experiences based on those senses would
provide a priori, not empirical, justification on this
account which takes a priori justification to be independent
of experiences based on the senses we have.
Given these considerations, perhaps “experience” should be
taken to mean “sense experience of any sort, introspection,
proprioception, memory, and testimony”. This sounds like a
hodgepodge of various sources of justification but perhaps what unites
them is that, leaving aside memory and testimony, these sources
provide us with information either about the physical world or our
inner world, either the outer world through perception or the inner
world of what we are feeling or thinking, or information about our
bodies, through introspection and proprioception. Memory and testimony
are not primary sources of justification; their primary epistemic
function is to transmit either a priori or empirical
justification. So the proposal should be seen as a way of
distinguishing the primary sources of justification into two
categories of justification: a priori and empirical.
As noted above (see,
 sec. 3)
 and below
 (secs. 4.4 and 4.5),
 “independent of experience” should not be taken to mean
independent of all experience, but, as a first approximation,
to mean “independent of all experience beyond what is needed
to grasp the relevant concepts involved in the
proposition”. It is sometimes said that a priori
justification can depend on experience insofar as it enables
the person to acquire the concepts needed to grasp the meaning of the
proposition which is the object of justification, but experience
cannot play an evidential role in that justification
(Williamson 2013: 293). Later we will see that the notion of enabling
experience might better be expanded to include experience needed to
acquire certain intellectual skills such as those needed to construct
certain proofs or create counterexamples (see,
 secs. 4.4 and 4.5,
 below).
Suppose there is a significant difference between a priori
and empirical justification. This still does not tell us what the
basis of a priori justification is. One view is that rational
intuitions or insights are the bases of a priori
justification; experiences, as construed above, the bases of empirical
justification. Before discussing the nature of rational intuitions or
insights, we should first distinguish between intuitions and
intuitive judgments and consider what the content of
intuitive judgments evoked in thought experiments is.
Anna-Sara Malmgren holds that intuitions are certain kinds of
mental states some of which are candidates as justifiers of
intuitive judgments that are made in response to
philosophical thought experiments (2011: 267–268). What is
the content of such intuitive judgments? Malmgren notes that
there are several different ways to characterize intuitive judgments,
but because they are all controversial, she characterizes them by
reference to examples. For her, “an intuitive judgment is any
judgment relevantly similar to certain paradigms or examples”
(Malmgren 2011: 268). Her paradigm examples are of judgments that are
evoked in Gettier cases where a person is in some sense lucky to have
a true belief given his evidence, Twin Earth cases where a term or
phrase does not refer to the same thing in different possible worlds,
and the trolley case where a heavy man is pushed in front of a trolley
to stop it from running over five people further down the tracks.
Others offer as examples the judgment that it is morally permissible
to unhook a violinist who has been connected to your kidneys without
your consent, even if that will kill him (an example made famous by
Judith Thomson in the abortion debate), the judgment that it is
irrational for a man who grants that his life in the future will be
happy, not a burden on others, virtuous, productive, with many friends
and adventures, and will otherwise be worthwhile, to refuse to take a
life-saving pill (Derek Parfit’s Early Death 2011:
270-71), and the judgment that it is irrational for a person now not
to care about his suffering on any future Tuesday just because
it’s a Tuesday (Parfit’s Future Tuesday
Indifference 1984: 124).
Malmgren argues against Timothy Williamson’s view that the
content of intuitive judgments involves counterfactual judgments.
Williamson says that in typical Gettier cases we make two judgments: a
judgment that such a case is possible and a counterfactual judgment
that if the case had occurred, it would be a case of a justified true
belief without knowledge. These two judgments entail that it is
possible for a person to have a justified true belief without
knowledge in a situation like that described in the Gettier example
(Williamson 2004: 110). While Malmgren agrees that a possibility
judgment is the content of the intuitive judgments in Gettier cases
(2011: 281), she denies that it need be reached via the counterfactual
judgment that Williamson proposes.
Malmgren thinks that descriptions of cases in thought experiments are
incomplete, and that certain ways of completing them are deviant
because they involve interpretations of the cases that misunderstand
what is intended (2011: 274–275). In the famous Nogot/Havit
Gettier case, the issue is whether Smith knows that someone in his
office owns a Ford. Smith sees Nogot driving around in a Ford and,
say, believes that Nogot has shown him current ownership papers to a
Ford. But Nogot actually drives a rental car, does not own a Ford, and
has shown Smith ownership papers to a Ford he used to own. It would be
a deviant understanding of the example to assume also that Smith has
good independent evidence that Havit, who also works in his office,
owns a Ford. Of course, in that case Smith would know that someone in
his office owns a Ford. Malmgren thinks that the interpretation that
assumes that Smith is hallucinating and has a poor memory of what
papers he has seen is also deviant. In that case, Smith would not be
justified in believing that Nogot, and so someone in his office, owns
a Ford.
The intuitive judgment in the case is: it is possible that a person in
a situation like that described in the example has a justified true
belief without knowledge. Williamson thinks that this judgment is
based on the counterfactual: if the case had occurred, it would be a
case of justified true belief without knowledge. But in the deviant
cases, it would not be a case of justified true belief without
knowledge, either because it would be a case of knowledge (the extra
reasons case where Smith has evidence that Havit owns a Ford) or not a
case of justified belief (where Smith is hallucinating, has a poor
memory, etc.). However, those deviant cases could occur in the
possible world that is most similar to the actual world, sometimes
called the “nearest possible world” by philosophers.
Because of this, as counterfactuals are usually understood by
philosophers, what Williamson takes to be the relevant counterfactual
would be false. In the nearest possible world where the standard
description of the case holds, the consequent of the counterfactual
would be false. So the case would offer no support for the intuitive
modal judgment: it is possible that a person has a justified true
belief without knowledge. It seems clear to Malmgren that the case
does support that possibility judgment regardless of whether nearby
worlds are deviant (making the consequent of the relevant
counterfactual false) or not (Malmgren 2011: 278–279). So
Williamson must be mistaken in thinking that some counterfactual
judgment must be the basis of the modal intuitive judgment: it is
possible to have a justified true belief without knowledge in a case
like the one described in the example.
One way to answer the question about the nature of a priori
justification and knowledge is to adopt a bottom up approach. Start
with contrasting examples like the fifteen above and construct a
theory that explains the difference. Timothy Williamson objects to
this approach on the grounds that it may result “in a
distinction of no special significance like a taxonomy of plants and
animals based on color” or the classification of plants into
bushes and non-bushes (2013: 291 and 309). Ultimately, that is what he
argues: the difference between a priori and a
posteriori knowledge is insignificant.
Williamson imagines that through perceptual experiences and relevant
feedback a person has acquired the ability to reliably judge distances
in terms of inches, and separately, by the same means, to judge them
in terms of centimeters. But she has not yet realized that there is a
relationship between distance in inches and distance in centimeters.
Then one day she uses her perceptual capacity to judge distances in
inches and centimeters “offline” by forming side-by-side
visual images of marks nine inches apart and nineteen centimeters
apart and sees that D is true: If two marks had been nine
inches apart, they would have been at least nineteen centimeters
apart. She has never measured how far apart the front and back
legs of an ant are, but in a similar way she uses her imagination and
sees that A is true: If two marks had been nine inches
apart, they would have been further apart than the front and back legs
of an ant.
In both cases, experience is the basis of a capacity to make judgments
in imagination and what goes on in imagination is what provides the
justification for those judgments.
Williamson’s argument against the significance of the
distinction between a priori and a posteriori
justification rests on comparing how D and A (and other
similar pairs of propositions like 4a and 4b in the examples above)
are justified. He contends that they are both justified by relevant
manipulations in imagination. But on traditional accounts of
justification, D would be a paradigm case of some proposition
that can only be a priori justified and A a paradigm
case of some proposition that can only be a posteriori
justified. Williamson seems happy to concede that there is some sort
of difference (2013: 294–295, 296–297) between these two
types of justification but to deny that it is a significant difference
given the way that each type relies on manipulations in imagination.
He might grant that the difference is like the difference between
seeing something through a microscope or telescope as opposed to
seeing something with the naked eye. There is a difference, but it is
not a significant difference since these three types of seeing all
rely on visual perceptions.
Defenders of a significant distinction between a priori and
a posteriori justification could grant that there is no
significant difference insofar as imagination plays the role in
justification that Williamson proposes. And sometimes it does play
that role in a priori justification as Elijah Chudnoff
illustrates with many examples involving geometric propositions and
accompanying figures (2011a: 636–38; 2013a: 370–372).
However, there are other ways to justify propositions a
priori. Some seemingly a priori propositions
can be justified by reflection. One example that Chudnoff often
appeals to involves the proposition: if \(a\lt 1\), then \(2 -2a \gt
0\). To justify that proposition, you might first let \(a = 1\) and
see that \(2 - 2a = 0\). You might then reflect that when
“a” is a number less than one but greater than or
equal to zero, \((2 - 2a)\) is greater than zero. Finally, you might
reflect that if “a” is a negative number, \((-2a)\)
will be a positive number, so \((2 - 2a)\) will be a number larger
than 2, and so greater than zero. So by reflection on a few relevant
cases, we can come to see a priori that if \(a\lt 1\), then
\((2 - 2a) \gt 0\). This way is much different than the way we might
come via imagination to see A = If two marks had been nine
inches apart, they would have been further apart than the front and
back legs of an ant.
In the case of proposition D, we might learn that one inch
equals 2.54 centimeters, do the math and see that nine inches equals
22.86 centimeters, and thereby see that nine inches is greater than
nineteen centimeters. There are other ways to be a priori
justified in believing some proposition is true than by what
Williamson calls the method of simulation. And those ways of
justifying a proposition a priori are significantly different
from a posteriori ways of justifying a proposition.
In a forthcoming essay in a book in which Williamson and Paul
Boghossian debate the a priori (forthcomingb), Boghossian
defends three different ways (none of which involve the method of
simulation) by which we might be a priori justified in
believing a proposition: two ways in which our understanding might be
the source of a priori justification, and a third way that
appeals to rational intuitions that do not have a distinctive
phenomenology and, according to Boghossian, are not the product of our
understanding concepts.
In many essays and a book, Elijah Chudnoff argues that intuitions have
what he calls a “presentational phenomenology” that
parallels that of perception. For him, intuitions are intellectual
perceptions that sometimes reveal abstract reality in the way that
sensory perceptions sometimes reveal concrete reality. So on his view,
a priori justification is similar to, but significantly
different from, a posteriori justification. For Chudnoff,
intuitions can be evoked through imagination, reflection, and even
reasoning from premises to a conclusion, but it is their nature, not
their source, that is the basis of their ability to provide
justification. His argument parallels an argument that says
perceptions justify because they are the mental states they are, not
because of their source. That is why they can provide justification in
a demon world or the Matrix, even though their source is a demon or
super computers and not real objects.
Like Boghossian and Chudnoff, and unlike Williamson, Albert Casullo
thinks that there is a significant difference between a
priori and a posteriori justification based on the
difference between support by nonexperiential and
experiential evidence. He also thinks that there is something
like justification (namely, positive epistemic status) that does not
rest on evidence at all (2012c: 318–326). For Casullo and
others, positive epistemic status can stem from what you are entitled
to accept given certain ends or projects. This sort of view will be
discussed in
 Section 4.5
 below.
Suppose a priori justification rests on output (evidence)
from some nonexperiential source. What sort of evidence could
that be? A standard answer is that intuition, or rational insight, is
the basis of a priori justification. And what are intuitions,
or rational insights?
As we’ve seen, Malmgren distinguishes between intuitions and
intuitive judgments, where an intuition is a distinctive type of
mental state that can justify a judgment (2011: 267–268). But
not everyone means the same thing by “intuition”. In
Thinking, Fast and Slow, Daniel Kahneman argues that
intuitions often lead us to accept false beliefs. He offers Herbert
Simon’s definition of an intuition, “Intuition is nothing
more and nothing less than recognition [of some cue stored in
memory]” (2011: 11, 237). But Kahneman is thinking of fast,
automatic, immediate judgments when he writes of intuitions and
intuitive judgments based on them. He often thinks of them as issuing
from “gut feelings”, as in his example of “the chief
investment officer of a large financial firm” who decided to
invest tens of millions of dollars in Ford Stock after recently
attending an auto show where Ford vehicles were on display (2011: 12).
And he describes an intuitive answer as “the first one that
comes to mind” (2011: 6). Elijah Chudnoff has a different
conception of intuitions because he thinks that “there are
hard-won intuitions which take deliberate effort to have” and
other intuitions that require an expert to guide a person before she
can have them (Chudnoff forthcoming).
Philosophers do not mean what Kahneman means when they refer to the
intuitions people typically have when considering Gettier cases and
the other paradigmatic cases listed above. While intuitions are
non-inferential, some can appear only after much reflection and effort
(see, again, Chudnoff forthcoming). Nor are they what George Bealer
means by a “physical intuition”, such as the one that
founds the intuitive judgment that a house undermined will fall
(Bealer 1992: 102; 1998: 207, 211). They are some sort of intellectual
seeming (Bealer) or rational insight (BonJour). For Bealer and
BonJour, taken in the broadest sense, intuitions are non-inferential
in that they are not the conclusion of some piece of reasoning. For
Chudnoff, intuitions can be produced by reasoning though their
justificatory force does not come from that reasoning. The reasoning
just leads you to a proposition that seems true in itself. Like
sensations, intuitions must be occurrent, and so are unlike beliefs,
which need not be. You can have a belief that P while not
considering P, but you cannot have an intuition that P
while not considering P. 
When it is a matter of perception, in the Mueller-Lyer figure the line
with the arrowheads pointing inward appears longer than the
one with them pointing outward even if you know it is not really
longer. To some people at least, in the Monty Hall example it
seems that there is a 50-50 chance that the grand prize is
behind either of the two doors that are left unopened after Monty has
opened one of them, even though they know that the probability it is
behind the door the contestant did not choose is 2/3 (see Russell
2010: 464, for the Monty Hall example). So intuitions are a type of
appearing; physical and philosophical intuitions have this in common.
George Bealer characterizes a rational intuition as an
intellectual seeming that some proposition is
necessarily, or possibly, true (Bealer 1998:
207–208). He contrasts this with the physical intuition that a
house undermined will fall which is not about what is necessarily or
possibly true. Also, philosophical intuitions are based solely on
understanding the proposition which is their object while physical
intuitions are based on understanding something about the physical
world. Bealer contrasts intuitions with “judgments, guesses, and
hunches” (1998: 210–211), common sense, belief, and even
an inclination to believe (1998: 208–209). And, of course, they
are not just “gut feelings”, which are not based solely on
understanding some proposition,
Laurence BonJour thinks that a rational insight is an immediate,
non-inferential grasp, apprehension, or “seeing” that some
proposition is necessarily true (BonJour 1998: 106). He goes on to
argue that a proposition’s appearing to be necessarily
true is the foundation of a priori justification, because he
wants to allow that such justification can be fallible and defeasible.
So for BonJour it is apparent rational insights that are the
evidence on which a priori justification rests, not rational
insights themselves (1998: 112–113, 1998: §§4.5, 4.6).
After publishing In Defense of Pure Reason (1998), and in
response to comments by Paul Boghossian (2001), BonJour wrote that
these appearances are not propositional, that is, they are not
appearances that something is the case (BonJour 2001a:
677–678). In this respect, they are unlike beliefs and more like
perceptual sensations.
John Hawthorne questions whether apparent rational insights or
rational intuitions as understood by BonJour and Bealer, respectively,
provide evidence for the beliefs which are based on them. He assumes
that these intellectual seemings manifest themselves to inner
consciousness “by a special kind of phenomenology”
(Hawthorne 2013: 215). He then wonders whether any of the following
would provide evidence: a seeming without the relevant phenomenology
he calls Glow, a seeming with a Glow of which the person is unaware
(if this is even possible), a seeming with a known Glow which is
unreliable. He seems to think that good answers to these questions
would require abandoning the “internalist mandate” that
drives these views that “allow only that which is
‘accessible’ from the inside to count as relevant to
justification” (Hawthorne 2013: 216). As we’ve seen,
Chudnoff thinks that intuitions have a distinctive phenomenology that
provides reason to believe that the propositions which are their
objects are true (2011b, esp. secs. 6 & 7); others think that they
need not have a distinctive phenomenology (Sosa 2013; Boghossian
forthcomingb). One might maintain that at least in certain
circumstance, being in the mental state with the relevant
phenomenology necessarily gives you prima facie reason to
believe the proposition consideration of which caused that intuition,
that is, gives you a reason to believe that proposition even though
that reason might be undermined or overridden by further
considerations.
Further, Bealer may have an answer for those who think that
reliability is a necessary condition of justification because he
argues that intellectual seemings are necessarily reliable when had in
certain conditions. He calls his view modal reliabilism (1998:
215–217), which holds that a certain kind of concept possession
(namely, full understanding of the concept) in ideal conditions
guarantees the sort of reliability that some think evidence requires.
On this view, it does not matter what, if any, phenomenology is
associated with the relevant intellectual seemings (cf. Sosa 2013).
What matters is whether the person fully understands the relevant
concepts involved. That could even be the basis for justification of
intuitive mathematical judgments that are not
accompanied by any intuitions with Glow (a possibility
mentioned by Hawthorne above (2013: 217)). So a defender of views like
Bonjour’s and Bealer’s can answer Hawthorne’s
questions by arguing that the relevant intuitions or insights are
reliable whether they are accompanied by Glows, unknown Glows, or no
Glows at all.
Those who hold that intuitions can justify because they are based on
the understanding think, for instance, that our understanding the
concept knowledge is the source of our intuition that a correct lucky
guess is not knowledge. Hawthorne’s criticisms of basing a
priori justification on the understanding (as Boghossian
forthcomingb proposes) is that there seem to be instances of a
priori justification that require skill in “sophisticated
proof techniques that are quite obviously not preconditions of
anything in the domain” (Hawthorne 2013: 213). For instance,
sophisticated proof techniques were required to prove Fermat’s
Last Theorem even though it is easy to understand what the theorem
says, namely, that the equation \(x^n + y^n = z^n\) has no solutions
when n is a positive integer greater than two. A possible
response to this objection is to expand the notion of enabling
experiences to include those needed to acquire intellectual
skills which are needed to employ intellectual seemings in reasoning
(see, secs.
 4.1
 above and
 4.5
 below) and are different from perceptual skills. But possessing those
techniques without also understanding the connections between the
premises would not yield justification. It is possible to hold that
the important difference between a priori and a
posteriori justification is that once the concepts and the
relevant techniques are acquired, nothing more is needed for
a priori justification (that is the sense in which a
priori justification is independent of experience), but further
experience is needed for a posteriori justification. Further,
Hawthorne’s criticism seems not to affect whether intellectual
intuitions that are evoked by thought experiments (as in standard
Gettier cases) can provide evidence since no special techniques are
required there.
While Hawthorne questions whether intuitions provide any evidence for
or against philosophical theories, Brian Weatherson grants that they
do but questions how much evidential weight they have. Gettier
examples are taken by many to be a conclusive refutation of the view
that having a justified true belief is sufficient for knowledge, but
not by Weatherson. He says, 
In short, the true theory of knowledge is the one that does best at
(a) accounting for as many as possible of our intuitions about
knowledge while (b) remaining systematic. (2003: 7) 
He thinks that it may be best to accept the JTB theory of knowledge
even in the face of Gettier examples if no other systematic theory of
knowledge is available. Systematic theories should not have too many
unacceptable (that is, counterintuitive) theoretical consequences,
should involve the analysis of a theoretically significant concept in
theoretically significant terms, and should be simple (2003:
8–9). Weatherson says that, 
While a theory can be reformist, it can’t be revolutionary. A
theory that disagreed with virtually all intuitions about possible
cases is, for that reason, false.
Stopped Clock is a case in which a person correctly believes
that the time is, say, 1:00 p.m. on the basis of looking at a clock
that reads 1:00 o’clock, and which he is justified in thinking
is working properly. However, the clock stopped working exactly
twenty-four hours earlier. Still, that person has a justified true
belief that it is 1:00 p.m. Sheep is a case where a jokester
farmer breeds poodles to look like sheep, and grooms them so they are
indistinguishable from real sheep. He puts them in his field for
tourists to see, and his real sheep are in that field but out of sight
behind some large boulders where he feeds them. Jones drives by and
forms the justified true belief that there are sheep in the field. It
seems that the intuitions that knowledge is absent, but JTB present,
in Stopped Clock and Sheep are enough to make it
reasonable to reject the JTB theory of knowledge. A few really strong
intuitions seem enough by themselves to make it reasonable to reject a
theory. Contra Weatherson, reasonable rejection does not require that
the theory disagree with virtually all intuitions.
Theoretical virtues are not enough to overcome such intuitive
shortcomings even if there is not a competing virtuous theoretical
analysis available. 
A promising account of a priori justification in terms of a
nonexperiential source of evidence is one that sees
intellectual intuition, rational insight, or apparent
rational insight, as providing the relevant a priori evidence
with its source being reason. This rational capacity is not some
special faculty of intuition analogous, say, to sight, which is a
source of empirical evidence. One function of reason involves
“seeing” how evidence supports a conclusion, and
in deductive reasoning, “seeing” how conclusions
follow from premises. This same ability is exercised when
reason “sees” that some proposition is true, or
necessarily true, simply in virtue of the person’s understanding
the proposition. However, this intellectual “seeing” need
not have distinctive conscious qualities, qualia, associated with it,
unlike perceptual seeing, which does. Apparent rational
insights need not be accompanied by appearances, if
“appearances” necessarily involve qualia. The metaphor of
“seeing” logical connections or that certain propositions
are true should not mislead us into thinking that there is a special,
quasi-perceptual faculty along with sight, touch, hearing, etc. It is
plausible to hold that reason can “grasp” and
“see” without there being any analogue to having certain
touch or visual sensations. (In several essays, Chudnoff disagrees:
2011a, 2011b.)
Recently some philosophers have thought that a person can be justified
in believing, or accepting, a proposition without having any evidence
to support it, and so even if there is no nonexperiential
source of evidence for that belief or acceptance. As we have
seen, Timothy Williamson has argued that certain acquired
skills can be used to provide justification for believing a
proposition for which the person does not have evidence, namely, the
skill of bringing ideas together in imagination. His proposal is that
in the case of the inches/centimeters proposition it is this
skill at making comparisons of length in imagination, and
then observing the results, not a person’s perceptual evidence,
that justifies him in believing that proposition.
Even if true, it seems that we can distinguish empirically based from
understanding based employment of a skill. Manipulating in imagination
two circles of unequal radii can bring a person to understand that
they cannot intersect in more than two points. Creating an
image of a line nine inches long next to an image of a typical ant can
bring a person to believe that the distance between the front and back
legs of a typical ant is less than nine inches, but not that it
must be. Science fiction films sometimes depict giant ants that
could have been actual. Further, skills at judging, say, that
in Sheep you do not know that there are sheep in the field is
based on your understanding the concept “knowledge”. But
your skill in judging that sheep have wool requires more to qualify as
knowledge than understanding that proposition: you need to know what
sheep in fact are like. A detective’s skill at deducing via
disjunctive syllogism that Jones is the murderer is similar to a
geometer’s deducing that a quadrilateral has four interior
angles or that the Pythagorean Theorem is true, but the nature of the
premises can make all the difference between whether the reasoning is
a posteriori or a priori. So even if the exercise of
relevant skills can provide justification apart from evidence, how the
skill is used, and in particular on what subject matter, seems to be a
basis for distinguishing a priori from a posteriori
(empirical) justification.
Another view that rejects the idea that a justified belief must be
founded on evidence says that all of our beliefs are
prima facie justified so all of them are what one might call
“default reasonable”, that is, justified barring reasons
to reject them (this is what Gilbert Harman (2001) calls
“general foundationalism”). On some accounts of a
priori justification, namely those that hold that a
priori justification is justification independent of
empirical evidence, general foundationalism would imply that all
of a person’s beliefs are prima facie (or weakly) a
priori justified since that justification would stem merely from
the fact that the person believes them, not from any empirical
evidence that supports them. On this view, and contrary to
initial appearances, there is really no difference in the way the
propositions at the start of this essay are prima facie
justified since they are all weakly a priori justified if you
accept them. The general foundationalist view might add that, if some
are all things considered less justified than others, it is
because of the relationships between them. Coherence considerations
account for all things considered justification and are what upset
initially equal prima facie justification. Further, this view
has the implication that you could be prima facie justified
in believing extremely bizarre propositions, say, beliefs about what
happens on the planet Gliese 581d, a planet scientists have
judged may be “friendly to life” (Russell 2012: 100), even
though you have no empirical or testimonial evidence to support your
beliefs about this alien planet. You may, but need not, also believe
that the Gliesians are in touch with you (but not others) via
telepathy because you are “the chosen one”. Insofar as you
have no defeating evidence, you could even be all things
considered justified in believing all those things about the
Glieseans, despite having no evidence to support your beliefs. But it
seems that a coherent set of beliefs about Gliese 581d would not
provide a priori justification of all of them even if it
provided some sort of justification for them. That would be drawing
the boundaries of the a priori too broadly.
Hartry Field also holds that belief in certain propositions can be
“default reasonable”, that is, justified but not on the
basis of evidence. He seems to think that if a belief’s being
“default reasonable” were sufficient for its being a
priori justified, too many beliefs would count as being a
priori justified. That’s because he thinks, for example,
that “People usually tell the truth” is default reasonable
but not a priori justified. So he adds the requirement that
an a priori justified belief cannot be empirically
defeasible (Field 2000: 119–120; cited in Casullo 2012c:
318–320). But we have seen above that paradigm cases of a
priori justification can be defeated by empirical considerations
(see above,
 sec. 3).
 So by adding the requirement of no empirical defeat, Field’s
view will imply that there are no a priori justifiable
propositions. On the other hand, if he drops that requirement, he
faces the same problem as Harman in drawing the boundaries of a
priori justification too broadly.
A final view of a priori justification according to which it
does not rest on nonexperiential evidence holds that we are
entitled to accept certain propositions on no evidence and
that entitlement on no grounds or evidence is what a priori
justification amounts to. To be entitled to accept, or trust, some
presupposition is for it to be rational to accept or trust
it, though this is supposed to be different from being justified in
believing it. Crispin Wright proposes that the laws of logic
and the presupposition that we are not now in the midst of a coherent
and continuing dream, not now brains-in-a vat, etc., are rational
presuppositions, some of which are standard presuppositions of
science. That’s because certain “cognitive projects”
(i) could not be pursued without presupposing those things, (ii) there
is no evidence to think that those presuppositions are false (even if
also none to think them true), and (iii) nothing will be lost, and
something may be gained, by accepting these presuppositions (see
Jenkins 2007). The gains and losses must not be pragmatic gains and
losses such as gains and losses in happiness, prestige,
accomplishments, wealth and the like. Otherwise all that would follow
is that it is practically rational to accept the
presuppositions. The gains and losses must be epistemic, that is,
having to do with truth, or probable truth, or with evidence because
Wright wants the rational acceptance of such presuppositions to be an
answer to the skeptic about knowledge and epistemic justification.
Carrie Jenkins has questioned whether the project-relative rationality
of a presupposition that Wright proposes is enough to make it rational
to accept that presupposition (Jenkins 2007). For instance, when
conducting certain inquiries, it might be rational relative to
some project or kind of inquiry to accept that the world is a
pretty orderly place, yet not epistemically rational to accept the
presupposition itself. Maybe we should suspend judgment about that
until we go look at the world.
We might think of these presuppositions as heuristics, rules that if
followed usually aid us in the pursuit of truth but in certain
contexts can be rationally doubted. Perhaps they do not necessarily
determine what it is rational to believe or accept. In moral
philosophy, anti-utilitarians often claim that there are many moral
rules that prohibit lying, cheating, stealing, torturing, etc, and
that these rules sometimes require people not to maximize utility. Act
utilitarians often respond by saying that these are useful guides to
doing what has the best consequences, but they are not definitive of
what makes actions right or wrong. Wright’s presuppositions seem
to be analogous to what act utilitarians see as heuristics or
secondary rules.
In summary, it seems that accounts of a priori justification
that do not hold that it rests on evidence provided by a
nonexperiential source are in danger of counting certain beliefs or
acceptances as a priori justified that, intuitively, do not
seem to be. They are in danger of drawing the circle of a
priori justification too broadly (Harman), to include
propositions that are “default reasonable” (Field), or are
presuppositions of science (Wright) that may be justified but do not
seem to be a priori justified. The attempt by Field to narrow
that circle seems to rest on a doubtful assumption, namely, that a
priori justification cannot be defeated by empirical
evidence.
If one thinks that some sort of justification can derive from what is
default reasonable or through relevant entitlements, one might adopt
Casullo’s view that there are different types of knowledge or
justification, broadly construed: a priori which rests on
nonexperiential evidence; a posteriori which rests on
empirical evidence; and a third type of justification that does not
rest on any evidence (Casullo 2012c: 324–326). This section has
raised some problems for this third conception of justification.
We turn next to considerations that seem to count for the view that
intellectual intuitions are evidence for the propositions that are
their objects.
The answer to this question requires first answering another question:
what are intuitions? As noted above, Bealer distinguishes between
physical intuitions, such as the intuition that a house undermined
will fall (1998: 207, 211, 213; 1992: 102, 104), and rational
intuitions. Here are several of Bealer’s examples of rational
intuitions from (1998): if P, then not not P (207); if
P or Q, then it is not the case that both not P
and not Q (210); that Gettier situations are possible (207:
211–12); that phenomenal colors are incompatible (211); that if
spatial region x is a part of spatial region y and
spatial region y is part of spatial region z, then
spatial region x is part of spatial region z (212). At
one point Bealer says that the difference between a physical and a
rational intuition is that a rational intuition “presents itself
as necessary”, but he immediately goes on to say that he does
not know exactly how to analyze this notion. A proposal he offers is
the following: if x (rationally) intuits P, then it
seems to x that P and also that necessarily P.
But later he says that in Gettier cases there are rational intuitions
about the situation described being possible (1998: 206, 207,
211–12), and he explicitly says, “Without possibility
intuitions, philosophy would be fatally flawed” (1998: 212;
my italics). It seems that what Bealer holds is that a rational
intuition that P is one where it either seems that P and
also necessarily that P, OR it seems that it is possible that
P. As we have seen, Malmgren argued that in Gettier cases the
relevant intuition is that it is possible that a person in
the relevant circumstances have a justified true belief but lack
knowledge. Bealer’s remark about an intuition’s presenting
itself as necessary was only meant as a way of contrasting the
physical intuition that a house undermined will fall with some other
rational intuitions. For Bealer, rational intuitions involve modal
seemings, either about what is necessary or possible.
Bealer offers a complicated multi-stage argument for why intuitions,
so understood, provide evidence. Part of his argument involves
distinguishing basic from derivative sources of evidence. Some
contingent sources of evidence provide justification but only because
some basic source justifies their use. Perhaps perception is a basic
source of evidence and testimony derivative. But what makes a source
of evidence basic? For Bealer, a source of evidence is basic if and
only if its deliverances have an appropriate kind of modal
tie to the truth (1998: 218). His view is that a source has the
appropriate modal tie if and only if, necessarily, its deliverances
would be true for the most part, that is, would be reliable, when that
source is employed by someone in cognitive conditions of suitable high
quality (for short, in ideal conditions) (1998: 219). In short, the
appropriate modal tie to the truth is the source’s being
necessarily reliable when the person using it is in ideal cognitive
circumstances. This account of a basic source of evidence explains why
guessing is not a basic source of evidence for a person who happens to
be a reliable guesser: guessing in that special world would be
reliable but not in all other possible worlds. But is rational
intuition a basic source of evidence on this account?
Bealer argues that rational intuitions depend on concept possession
and if one fully understands a concept, they will be necessarily
reliable in ideal cognitive conditions in applying that concept. A
person can misunderstand a concept such as arthritis and apply it to
pains in the thigh, or incompletely understand it by not knowing
whether it applies to a certain case or not. For example, someone
might not understand the concept of a contract well enough to know
whether it applies to any oral agreements (1998: 221). But full
understanding of concepts is incompatible with any misunderstanding or
incomplete understanding.
Bealer says, “Our intuitions are what seem to be so concerning
the applicability of concepts to cases presented to pure
thought” (1998: 231). And what seems to be so is modal,
something’s being possible or necessary. For instance, if a
person who fully understands the concept knowledge is presented a
Gettier case, the relevant intuition for Bealer will be that it seems
possible for the person in the Gettier scenario to have a
justified true belief but lack knowledge. If a person who fully
understands “spatial part” is asked whether it’s
true that if x is a part of y, and y a part of
z, then x is a part of z, the relevant intuition
for Bealer will be that it seems necessarily true.
Bealer further maintains that we are not now in the relevant ideal
conditions. However, he does say that, 
if we limit ourselves to suitably elementary propositions, then
relative to them we approximate ideal cognitive conditions,
and that 
the deliverances of our basic sources would provide in an approximate
way the kind of pathway to the truth they would have generally in
ideal conditions. (1998: 219) 
He is saying that even in our current non-ideal cognitive condition
the deliverances of our basic sources, which include rational
intuitions, can be somewhat reliable even if not as reliable as they
would be in ideal conditions. He also thinks that for many of us the
class of elementary propositions “would not be
inconsiderable” (1998: 219). Bealer is probably thinking of the
many readily accessible conceptual connections such as those in
 1a–15a
 given near the beginning of this entry.
Casullo recommends a different approach to defending rationalism. He
thinks rationalists should start from common ground and that they
should “enlist empirical support for the existence of a priori
knowledge” (2012a: 248–249). This may be because he thinks
that nonexperiential mental states are the basis of a priori
justification and “nonexperiential mental state” is a
natural kind term. This seems plausible because Casullo thinks that
“experience” is a natural kind term (see, below,
 sec. 6.4).
 He may think that the reference of all natural kind terms must be
discovered empirically and so think that what he takes as the basis of
a priori justification must be discovered empirically.
Suppose the nonexperiential mental states that Casullo thinks are the
bases of a priori justification are what other philosophers
call “intuitions”. If a priori knowledge rests
partly on a priori justification, and that rests on
“intuitions”, that could explain why Casullo recommends
empirical inquiry as a means to discover what intuitions are like as a
first step in explaining how they can provide a priori
justification.
Bealer seems to disagree with Casullo about the nature of intuitions.
He has written that empirical investigation into people’s
“intuitions” is irrelevant because they do not investigate
intuitions in the relevant sense, that is, intuitions understood as
responses to fully understanding propositions (1998: 202). Casullo
seems to understand intuitions differently, as a certain kind of
mental state whose nature must be discovered empirically. Insofar as a
defense of rationalism involves a defense of the epistemic role of
intuitions, it is not surprising that Bealer and Casullo suggest
different ways of defending rationalism given that they have different
views about the nature of intuitions.
We have seen that Bealer thinks that a rational intuition is a modal
seeming: either a seeming to be true and necessarily true, or a
seeming to be possible. In other places Russell (2017: 232) defines an
a priori intuition as the psychological state people are in
when some proposition seems true to them solely on the basis
of their understanding that proposition. This definition of an a
priori intuition allows us to distinguish between what Bealer
called a physical intuition that a house undermined will fall, because
it does not seem true to us solely on the basis of understanding what
it says, and the intuition that if P, then not not P, or
that if someone knows P, then she believes P and
P is true. Unlike on Bealer’s account of rational
intuitions, this account of intuition does not require that the
propositions that are the objects of intuitions be modal. It provides
a way of distinguishing a priori justifiable necessary
propositions such as Necessarily, all bachelors are unmarried
males from empirically justifiable necessary propositions such as
Necessarily, water is H2O since an intuition that
the former proposition is true can be based solely on a person’s
understanding it but an intuition that the latter is true must be
based partly on understanding how things are in the external world.
This account of intuition also allows that what are called synthetic
a priori proposition (like
 10a–14a)
 can be the objects of a priori intuitions since they can
seem true to a person solely on the basis of her understanding
them.
Several philosophers appeal to the understanding in their accounts of
a priori justification: Bealer in all his many essays;
BonJour 1998; Jackson 2000; Peacocke 2000; Sosa 2013: 199; Boghossian:
forthcomingb. But the view also has its critics. Though Paul
Boghossian thinks that some a priori justification stems from
that source, he thinks that a priori intuitions about
substantive normative propositions can provide justification but they
do not rest on our understanding those propositions (forthcomingb).
Consider the proposition that It is always wrong to torture
children just for the fun of it. His argument is that if such
intuitions were based on understanding the concept
“wrong”, then it would not make sense to ask whether that
sort of act merits disapproval or should be punished, assuming for the
sake of argument that the correct account of the non-substantive
meaning of “wrong” is in terms of what merits disapproval
or should be punished. But he thinks that this question always makes
sense. So it follows that a priori normative intuitions of
this sort are not based on understanding the relevant normative
concepts. Boghossian seems to think that this argument generalizes to
apply to all a priori intuitions whose objects are synthetic
propositions, not just to intuitions about substantive normative
propositions.
A possible response to Boghossian is that full or
deep understanding of normative concepts like
“wrong” requires understanding that certain paradigm cases
are wrong, though a more superficial understanding which can be
captured by non-substantive account of wrong does not. An analogy with
causation might help. A superficial understanding of why opium causes
sleep is that it has dormative powers. But a deeper, more detailed
understanding would involve understanding how the chemicals in opium
affect the neurons in the brain and how those in turn cause sleep.
Problems will remain with the “lack of deep understanding”
reply to Boghossian’s argument: how does one explain the fact
that professional moral philosophers sometimes have different
intuitions about substantive claims about what is wrong? One would
expect them to have equally deep understanding of the relevant
normative concepts and so to have the same a priori
intuitions on the understanding-based account of intuitions that
Boghossian argues against. But sometimes they do not, as Boghossian
notes (forthcomingb). At the same time, he offers an explanation of
why the intuitions of philosophers diverge: the theories they hold can
affect the intuitions they have.
A new branch of philosophy called experimental philosophy (X-phi for
short) has studied the intuitive judgments of people (often
students) when presented with well-known examples in epistemology and
ethics. They ask these people (often from different ethnic, cultural,
economic, and educational backgrounds) whether someone in a
hypothetical scenario knows, or only believes, that some proposition
is true, say, in Sheep whether the person knows, or only
believes, that there are sheep in the field. In ethics they may
present the subjects with a case and ask them if it is wrong, or not
wrong, to do what is described. In a case often called
Transplant, five innocent people are desperately in need of
certain vital organs, and the only way to save them is to cut up some
innocent person and distribute his organs to the five (transplant
surgery has been perfected and our potential donor is a perfect match
to all five). Experimental philosophers will ask their subjects
whether it is wrong, or not wrong, to cut up the one to save the five,
and then record their intuitive judgments. In another case
often called Trolley, a runaway trolley is on track A
and headed for five innocent people who are trapped on that track. All
person S can do to keep the trolley from running over the five
is to turn the trolley down track B where one innocent person
is trapped. If S does nothing, five will die; if he throws the
switch via a remote device, the one on track B will be killed.
Or what if someone pushed a heavy person in front of the trolley to
stop it from running over the five? Experimental philosophers ask
whether it would be wrong, or not wrong, for S to throw the
switch or push the man. They record the data, which they take to be
intuitive judgments on the cases, and note differences in the
responses, say, between different ethnic or economic groups.
Some of the initial studies that seemed to show that there are
differences along ethnic, cultural, and economic lines in response to
examples have not been replicated (see Turri 2018; Wykstra 2018 for an
overview of the work in X-Phi.). Other studies have been criticized
because of their experimental design. Apart from these experimental
flaws, claims about disagreements in intuition have been criticized as
epistemically irrelevant because the so-called
“intuitions” of subjects are not what philosophers have in
mind when they refer to a priori or rational intuitions
(Bealer 1998: 202, 213). If what philosophers mean by
“intuitions” requires that they stem from full
understanding of concepts in ideal cognitive circumstances, then the
“intuitions” that experimental subjects have do not
qualify, for they lack full understanding and the cognitive
circumstances they are in probably do not qualify as ideal.
One might think that from an epistemic standpoint, the
“intuitions” that philosophers have when considering
“suitably elementary propositions” are what should be
studied because, as Bealer said, “if we limit ourselves to
suitably elementary propositions, then relative to them we
approximate ideal cognitive conditions”, and
philosophers come nearer to having a full understanding of the
relevant concepts. Studies of that sort are being done (see
Schwitzgebel & Cushman 2012, 2015). Some results suggest that
philosophers’ intuitions, like those of non-philosophers, are
affected by how an example is described (called “framing
effects”) and by the order in which the examples are presented
(“ordering effects”). This suggests that the intuitions of
philosophers are no more reliable than those of non-philosophers. But
perhaps the experimental situation is not ideal and that ideal
conditions are the ordinary settings in which philosophers do their
work. (See, Kahneman’s description (2011: 234–235) of the
approach taken by Gary Klein and his followers who criticize
artificial experiments and recommend studying “real people doing
things that matter” (Kahneman 2011: 235).
A different sort of objection to intuitions as a source of a
priori evidence assumes that a source of justification must be
capable of being calibrated to determine whether it is accurate
(Cummins 1998: 116–118). What we see through a telescope
justifies us in believing that the moon has mountains because we have
done things like looking through telescopes at distant mountains on
earth and then gone to them and discovered that the telescopes
presented an accurate picture of the mountains. But what, the
objection goes, can intuitions be checked against? Other intuitions?
But that is like checking a crystal ball against itself.
BonJour has argued that many errors involving apparent rational
insights (intuitions) can be corrected internally by further
reflection, or by appealing to coherence (BonJour 1998:
116–119). Others have replied that neither perception nor memory
(Goldman 2007: 5) can be checked either, except against themselves,
but that does not prevent these sources from providing justification
in certain circumstances.
In reply to this sort of response, critics of intuition-based views of
a priori justification have said that at least different
types of perception can be checked against each other, say, vision
against touch (Weatherson 2003: 4). The critics of intuition add that
while we can distinguish circumstances where, say, vision is
unreliable from circumstance where it is not, nothing similar can be
done when it is a matter of intuitions. For instance, we can
distinguish conditions where the lighting conditions, or the
person’s eyesight, are bad from ones where they are not. We can
know whether we are in a desert where optical illusions occur and
whether we are not. At least sometimes we can tell whether we are
hallucinating or not.
First, the thought that a potential source of justification must be
capable of being calibrated if it is to provide justification seems
false. The people inside Plato’s cave who can only see shadows
cast on the wall in front of them can be justified in believing that
those shadows have a certain shape based on what they see and the
reports of others. A priori intuitions involve a kind of
intellectual “seeing”, and they can be checked against
other people’s reports of their intuitions. That one type of
perception can be checked against another (say, sight against touch)
does not seem to count for much epistemically. Perhaps a ouija board
can be checked against a crystal ball, but without some further
explanation, neither agreement, nor disagreement, between them would
have significant epistemic implications. Perhaps intellectual or
rational intuitions produced under certain circumstances should be
discounted, viz., those produced by people who are angry, depressed,
drunk, tired, etc., or who are not impartial, have something at stake
in the outcome, or have not reflected carefully on the relevant
concept. But that does not mean that all of them should be discounted.
Calibration may not be necessary for justification. And in some
circumstances it seems insufficient, as when there is good reason to
think that agreement is accidental or the result of causes irrelevant
from an epistemic standpoint.
There are other objections to the reliance on intuitions in philosophy
that do not call into question their reliability. They call into
question their relevance. Casullo (2003) proposes to treat
“experience” as a natural kind term, and Hilary Kornblith
and Philip Kitcher propose to treat epistemic terms such as
“knowledge” and “justification” in that way
too. Kornblith thinks that intuitions can help direct us to the
appropriate objects, or phenomena, of investigation but not much more.
For instance, we have an intuition that knowledge is not a type of
furniture so we should not start our empirical investigation into the
essential nature of knowledge by looking at furniture (Kornblith 1998,
2005, 2006). If we think of normative terms such as
“wrong” as natural kind terms, and so as analogous to a
natural kind term like “water”, there would be some
reference-fixing description associated with “wrong” as
there is for “water”. For “water” that
description is something like: the stuff, whatever it is,
that in the actual world has the properties of quenching
thirst, putting out certain fires, falling from the clouds as rain,
filling the lakes and rivers, etc., on the planet on which we live.
Empirical investigation is then needed to discover what this
reference-fixing description in fact refers to. On Kornblith’s
view, there is little room for rational intuitions to play in
discovering the essential nature of knowledge or normative kinds. They
do not play a role in determining the content of any relevant
reference-fixing description and, at most, tell us where not
to look to find what does fulfill a given description.
It would be a mistake to take “cube” to be a natural kind
term understood through some reference-fixing description such as: a
three-dimensional solid that looks such-and-such a way when looked at
from various angles and that feels so-and-so when turned around in
your hands; is able to fit snugly through square holes cut out of a
board, etc. “Cube” is not a natural kind term and we
understand what a cube is through understanding its definition,
namely, a three-dimensional solid with six faces all of which are
squares.
Rational intuitions seem relevant to testing proposed definitions of
“cube”, but not proposed reference-fixing descriptions of
“water”. If someone thought that the correct definition of
“cube” is: a three-dimensional solid with six faces
all of which are parallelograms with equal sides, we could show
it is not a correct definition of “cube” by imagining a
“squished” cube that satisfies that definition but,
intuitively, is not a cube. None of the properties mentioned in the
reference-fixing description for water are either necessary, or taken
singly or together, sufficient conditions of a liquid’s being
water. So it does not seem that rational intuitions could play much of
a role in determining what the essential nature of knowledge is if
“knowledge” were a natural kind term whose reference is
fixed by some description. People would have to empirically discover
the nature of knowledge with the aid of its reference-fixing
description, just as they had to empirically discover the nature of
water. The same thing would seem to apply to normative terms like
“right” or “what there is most reason to do (or
believe)” if they were natural kind terms.
On the basis of thinking about these examples involving
“water” and “cube”, a person might think that
whether rational intuitions have a small or a large role in
discovering the essential nature of normative concepts, and other
concepts of interest to philosophers, depends on whether those
concepts are like the concept of water or instead like that
of cube. But Peter Railton’s view that normative terms
are natural kind terms allows for a large role for rational intuitions
in determining their reference-fixing descriptions.
Railton calls a reference-fixing description a “job
description”. He is interested in normative concepts like
right and what there is most reason to do, and
describes in general terms what a job description might include.
Railton says that there may not be much to say about “the
concept of a reason full stop”. Perhaps all we can say
in that regard is that a reason is a consideration that counts in
favor of something: an action, a desire, an emotion, a belief, etc.
But Railton thinks that the concept most reason to do has
a distinctive, all-important role in your conceptual scheme—it
expresses “stops the buck” in deliberating and deciding
what we ought to do, what ultimately matters. 
He goes on to add that the relevant “job description”
includes reference to paradigm cases. For example, it is assumed that
agony gives everyone some reason to avoid performing actions that
produce it, that vengeance is not itself a reason to do something, and
that acrophobia sometimes is not a sufficient reason to avoid doing
something that will save your life (Railton 2017a: 51).
In another essay on Parfit’s On What Matters, Vol III,
Railton says that the job description of rightness is 
necessarily connected to the guidance of deliberation,…,has
analytic connections to ought claims about action and
motivation,…,has certain paradigm cases, etc. 
He thinks that the job description of minimizing suffering is
completely different (Railton 2017b: 118–119). Nevertheless,
Railton thinks that the two concepts might refer to the same thing in
the way that water and H2O refer to the
same thing despite being different concepts. That will be true if the
acts that have the naturalistic property of minimizing suffering
uniquely (or best) fulfill the job description associated with the
normative concept rightness.
Rational intuitions might play a role in Railton’s view that
normative terms are natural kind terms by supplying the paradigm cases
that are elements of the job descriptions associated with normative
concepts. He says that it is “inconceivable” that there
not be reason to stop prolonged agony that is being inflicted on
someone just for amusement (2017a: 56). On Railton’s view, to
determine what the natures of right, reason, most reason, etc., are
you need to consider more than just what rational intuitions might
reveal. They can help determine what paradigm cases should be included
in the relevant “job description”, but that description
includes more than just paradigm cases. On Railton’s view,
insofar as “old style” analytic philosophy only considered
the data supplied by rational intuitions, it mistakenly left important
data aside. This is true of attempts to analyze normative concepts but
also true of attempts to analyze other concepts that have been of
interest to philosophers, for example, knowledge, causality,
personal identity, justice, being morally responsible, acting
freely, etc.
Railton’s view is that normative concepts are hybrid concepts,
somewhat like the concept of ruby as a red gemstone
with such-and-such chemical structure (see
 example 15)
 or of an ice cube. “Ice” is a natural kind term,
or at least its definition as “frozen water” is partly
given by the natural kind term, “water”. But, as we have
seen, “cube” is not a natural kind terms. So “ice
cube” is partly a natural kind term and partly not.
Another approach that discounts the role of intuitions in philosophy,
especially in epistemology, is pragmatic. The idea is to first
determine what epistemic goals we want principles to serve, and then
to discover empirically which epistemic principles, if adhered to,
will best serve those goals (Weinberg 2006). For instance, your goal
might be to have lots of true beliefs or, alternatively, to have few
false ones. Or your goal might be to have beliefs that make you happy.
Probably the best set of rules to follow to obtain lots of true
beliefs will be different from, and more lenient than, the best set of
rules to follow to avoid having false beliefs. Probably those sets of
rules will be different from the set of rules you should adopt if you
are interested in having beliefs that make you happy. It’s
reasonable to think that intuitions will have to be appealed to in
determining what makes a goal an epistemic goal rather than
some other sort of goal, and what precisely that epistemic goal is.
Lehrer (1986: 6–7) holds that the epistemic goal is not
to maximize true beliefs or minimize false ones. For him, it is the
following: for any proposition, P, that a person is
considering, believe P if and only if it is true. Intuition
must be relied on to determine what the epistemic goal is.
Intuitively, Pascal’s Wager is about whether belief in God pays,
not about whether there is good evidence to believe that God exists or
does not exist. The goal of the argument is not epistemic but
pragmatic in a narrow sense, namely, to believe what will make your
life, including your afterlife, go best for you. Intuitively, the goal
of having beliefs that will make your life go well is not an epistemic
goal. Epistemic goals have to do with truth, fitting your beliefs to
the evidence, having evidentially justified beliefs, etc.
The pragmatic approach that sketched here seems doomed at the outset:
it cannot avoid appealing to intuitions in order to determine what the
correct epistemic goal is. And if it is appropriate to appeal to
intuitions to determine the correct epistemic goal, why not also other
epistemic intuitions to determine what knowledge, justification, etc.,
are?
Suppose, for the sake of argument, we grant that intuitions
properly understood and had under ideal conditions by people with
a deep understanding of the relevant concepts can justify certain
propositions. But can they yield knowledge about the external
world? Carrie Jenkins has argued that they can insofar as the
concepts that play a role in a priori justification have been
shaped by experience. She thinks that for knowledge (not
justification) our concepts must be grounded. By this she
means that they must accurately and non-accidentally represent the
world. So the concept table can be grounded for a person in a
world where there are tables but not for a brain-in-a-vat (BIV)
(Jenkins 2008a: 128–29). For a concept to be
justified for Jenkins is for it to be
“respectable” for us to rely on it (by which, I believe,
she means that we would be epistemically blameless in relying on it)
as “a relevantly accurate guide to the world” (Jenkins
2008a: 129). So a BIV can have a justified, though not a grounded
concept, about things existing in the external world.
Jenkins thinks that our concepts are grounded. Her argument for
thinking this is that our basic concepts are useful, and in that
respect they are sort of like maps. If they did not fit the world
(weren’t grounded) even though they are founded on sensory
input, their usefulness would be a miracle. They would be like a map
that fits the world that was based on a dream. Since we should not
believe in miracles, those concepts must fit the world. The best
explanation of the usefulness of our concepts is that they accurately
represent features of the world that produce our sensory inputs that
allow us to navigate successfully in the world. She thinks that this
No-Miracles Argument shows that it is reasonable to think that our
concepts (or groups of concepts) mirror the world’s structure
(Jenkins 2008a: 139). If we have justified concepts, ones we
have reason to think fit the world, we can examine them to see what
they involve and then have a priori justification for
believing that certain propositions that involve them are true of
the world. So, on her view, we (but not BIVs) could know a
priori, merely on the basis of examining our concepts,
that all vixens are female and that there are (or at least
were) vixens, and that all bachelors are unmarried and that
there are (or at least were) bachelors. If we have grounded
concepts, we (but not BIVs) can have a priori knowledge that
all of these propositions are true. Yet gaining this sort of knowledge
about our external environment a priori seems impossible.
Further, it is not obvious that all a priori knowledge rests
on grounded concepts. Normative or mathematical concepts might map the
normative and mathematical domains but not the external world. We can
know a priori that it is wrong to torture children just for
the fun of it and that two is the only even prime regardless of what
the external world is like. Perhaps we can also know a priori
that some general normative principles are true, such as the principle
of inference to the best explanation (IBE). Roughly, this principle
says that we are justified in believing some hypothesis if it is the
best explanation of what we observe. For instance, it says that we are
justified in believing that someone recently walked along the beach
because that best explains our observation of footprints in the sand.
But we could not be justified in accepting IBE because it is useful
and the best explanation of its usefulness is that it fits the way the
world is. That would be a circular argument for accepting IBE. Lastly,
it seems possible for even a BIV to know certain conditional
propositions, for instance, to know that that IF something is a vixen,
it is a female fox and IF someone is bachelor, he is an unmarried
male.
Jenkins allows that some concepts can be grounded, even if they are
not directly grounded, provided they are constituted by grounded
concepts, but it is hard to see how the concepts spiritual
and immaterial could be so constituted. Still, it seems that
we can know a priori that if there are angels, there are
spiritual beings and if there are immaterial beings, they do
not occupy space.
It is one thing to hold that a priori knowledge requires
enabling empirical experience to acquire the concepts that are the
basis of that sort of knowledge, and quite another thing to hold that
those concepts must be grounded in such experience. The latter rules
out some seemingly obvious kinds of a priori knowledge (viz.,
some mathematical and normative knowledge, and knowledge of certain
conditional propositions which seem merely to be about the
relationship of concepts), and so seems too strong. It also seems to
allow in a priori knowledge of the existence of, say, foxes
and bachelors, and so seems too weak.
It is widely, though not universally, held that knowledge is partly
analyzable in terms of justified true belief. But, as we’ve
seen, Gettier examples show that having a justified true belief is not
sufficient for knowledge. We need some anti-luck condition in addition
to JTB to rule out cases where there is a JTB but not knowledge
because, in some sense, the person in the Gettier situation is lucky
to have a true belief given the way his evidence is related to the
truth of his belief.
The Lottery Paradox suggests that even more than JTB and an anti-luck
condition are required for knowledge. The chances that you hold the
winning ticket in a one million ticket lottery is one in a million,
and that you hold a losing ticket, 999,999 in a million. Suppose you
know what the probability of your holding a losing ticket is and that
you in fact have a losing ticket. Then you seem to have a justified
belief that your ticket is a loser (because you know that’s very
likely true), and it is true that it is a loser. Assume, also, that
you are not in a Gettier situation. Still, you do not seem to know
that your ticket is a losing one. It seems that you need further
confirmation from a trustworthy source to know your ticket has
lost.
If knowledge in general is justified true belief plus some condition
to handle Gettier cases and another to handle the Lottery Paradox,
then on the account of knowledge that requires you to have a justified
true belief, a priori knowledge will be a priori
justified true belief plus some conditions to deal with Gettier and
Lottery Paradox cases. Specific versions of this view of a
priori knowledge will depend on specific versions of a
priori justification.
But there are rival accounts of knowledge that reject the view that
knowledge is partly analyzable in terms of justification. One such
view is called knowledge reliabilism; the other, the “knowledge
first” view. Knowledge reliabilism is the view that a person
knows P if and only if she has a reliably produced true belief,
and a priori knowledge reliabilism would say a similar thing
about a priori knowledge. Perhaps just having reliable
intuitions would be enough to have a priori knowledge
regardless of whether they provided justification or not.
There are well-known examples that count against the idea that
reliably produced true belief is sufficient for knowledge. Let
Truenorth be a person who has true beliefs about what direction is
north, south, etc., even when blindfolded. He has a kind of internal
compass like the ones found in migratory birds. But assume that
Truenorth has no reason to think that his beliefs about compass
directions are accurate; he has never received confirmation of their
accuracy, neither from the testimony of others nor by checking things
out himself. Nevertheless, he is confident that his beliefs about what
direction is north, etc., are correct. Assume, also, that he has no
reason to think that others in his society have, nor that they lack,
his directional ability. In general, assume that there are no
undefeated defeaters of Truenorth’s beliefs about what direction
is north, etc. Intuitively, it seems that if he believes that some
direction he points to is north, he is not justified in believing,
nor does he know, that it is north, even if what he believes
regarding compass directions is always true.
If this is a problem for reliabilists about empirical
knowledge, it may also be a problem for reliabilists when it comes to
a priori knowledge. Mere reliability does not seem sufficient
for knowledge. What seems missing in the case of Truenorth is any
reason for him to think that his beliefs about compass directions are
reliable. Perhaps what is missing on reliabilist accounts of a
priori knowledge is similar, namely, that the subject lacks any
reason to think that her a priori intuitions are reliable
even if they are.
Brian Weatherson offers an example involving a person he calls
“Tamati”, a young mathematician who has a sudden strong
conviction that there is no largest prime upon noticing that as primes
get larger the gap between them also gets larger (2019: 125–26).
Tamati believes that there is no largest prime on the basis of his
strong conviction, and Weatherson explains how Tamati’s strong
convictions about mathematical propositions are reliable. But,
intuitively, Tamati is not justified in believing, nor does he know,
that there is no largest prime without a proof that it’s true.
So reliability is not sufficient for justification or knowledge even
in the realm of the a priori.
Views that see knowledge as resting on justification, whether
empirical or a priori, might be said to make justification
first. A “knowledge first” view sees justification as
derivative at best. It equates one’s total evidence with
one’s total knowledge (Williamson 2014: 8; see, also, 4). If
justification is a function of evidence, knowledge implies
justification, but according to Williamson justification is not part
of what knowledge is. He holds that knowledge is not analyzable even
partly in terms of justification.
There seem to be clear counterexamples to the knowledge first view.
Suppose you are driving out in the country and first pass by one of
many fields where sheep are grazing, and then a little later pass by
the field with the poodles that look just like sheep. In the first
cases, you knew there were sheep in the field, but in the last case
you did not. Still, weren’t you just as justified, didn’t
you have the same sort of evidence, in the last case as in the first
ones? No, says Williamson, a defender of the knowledge first view. You
are just as epistemically blameless in the last case as in
the earlier ones because, for all you know, you are looking at real
sheep. You have a legitimate excuse for believing that you are looking
at sheep, but you don’t have evidence, nor are you justified in
believing, that you are looking at sheep when you are looking at
poodles (Williamson 2014: 4–5).
Williamson’s criticism of any justified true belief account of
knowledge would rest on the fact that no one has yet been able to
solve the Gettier problem (2014: 1–2), nor give a good account
of what it is for beliefs to be justified because they fit the
evidence. According to him, the attempt to analyze knowledge is in a
shambles, and the knowledge first approach promises to shed light on
the nature of indiscriminability, norms of assertion, and epistemic
logic (2014: 6–7). So it promises to be fruitful while the old
approach of analyzing knowledge has left behind a path strewn with
failures. This, says Williamson, is a good reason to change horses.
But Williamson’s view seems to have its own liabilities. On the
knowledge-first approach that he develops, you don’t have any
evidence that there are sheep in the field when you are looking at the
poodles, and human footprints in the sand are not evidence that
someone recently walked there if they were made by a monkey wearing
rubber feet. The new horse bucks.