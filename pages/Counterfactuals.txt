This section begins with some terminological issues
 (§1.1).
 It then provides two broad surveys of research that places
counterfactuals at the center of key philosophical issues.
 Section 1.2
 covers the role of counterfactuals in theories of rational agency,
mental representation, and knowledge.
 Section 1.3
 focuses on the central role of counterfactuals in metaphysics and the
philosophy of science.
 Section 1.4
 will then bring a bit of drama to the narrative by explaining how
counterfactuals are deeply puzzling from the perspective of classical
and modal logics alike.
In philosophy and related fields, counterfactuals are taken to be
sentences like: 
This entry will follow this widely used terminology to avoid
confusion. However, this usage also promotes a confusion worth
dispelling. Counterfactuals are not really conditionals with
contrary-to-fact antecedents. For example
 (2)
 can be used as part of an argument that the antecedent is true (Anderson
1951):
On these grounds, it might be better to speak instead of
subjunctive conditionals, and reserve the term
counterfactual for subjunctive conditionals whose antecedent
is assumed to be false in the
 discourse.[1]
 While slightly more enlightened, this use of the term does not match
the use of counterfactuals in the sprawling philosophical and
interdisciplinary literature surveyed here, and has its own drawbacks
that will be discussed shortly. This entry will use counterfactual
conditional and subjunctive conditional interchangeably,
hoping to now have dispelled the suggestion that all counterfactuals,
in that sense, have contrary-to-fact antecedents.
The terminology of indicative and subjunctive conditionals is also
vexed, but it aims to get at a basic contrast which begins between two
different forms of conditionals that can differ in truth value.
 (3)
 and
 (4)
 can differ in truth-value while holding fixed the world they are
being evaluated
 in.[2]
It is easy to imagine a world where
 (3)
 is true, and
 (4)
 false. Consider a world like ours where Kennedy was assassinated.
Further suppose Oswald didn’t do it, but some lone fanatic did
for deeply idiosyncratic reasons. Then
 (3)
 is true and
 (4)
 false. Another aspect of the contrast between indicative and
subjunctive conditionals is illustrated in
 (5)
 and
 (6).
 
Indicatives like
 (5)
 are infelicitous when their antecedent has been denied, unlike the
subjunctives like
 (6)
 and
 (7)
 (Stalnaker 1975; Veltman 1986).
The indicative and subjunctive conditionals above differ from each
other only in particular details of their linguistic form. It is
therefore plausible to explain their contrasting semantic behavior in
terms of the semantics of those linguistic differences. Indicatives,
like
 (3)
 and
 (5),
 feature verbs in the simple past tense form, and no modal auxiliary
in the consequent. Subjunctives, like
 (4)
 and
 (6),
 feature verbs in the past perfect (or “pluperfect”) with
a modal would in the consequent. Something in the
neighborhood of these linguistic and semantic differences constitutes
the distinction between indicative and subjunctive
conditionals—summarized in
 Figure 1.[3]
Figure 1: Rough Guide to Indicative and
Subjunctive Conditionals
As with most neighborhoods, there are heated debates about the exact
boundaries and the names—especially when future-oriented
conditionals are included. These debates are surveyed in the
supplement
 Indicative and Subjunctive Conditionals.
 The main entry will rely only on the agreed-upon paradigm examples
like
 (3)
 and
 (4).
 The labels indicative and subjunctive are also
flawed since these two kinds of conditionals are not really
distinguished on the basis of whether they have indicative or
subjunctive mood in the antecedent or
 consequent.[4]
 But the terminology is sufficiently entrenched to permit this
distortion of linguistic reality.
Much recent work has been devoted to explaining how the semantic
differences between indicative and subjunctive conditionals can be
derived from their linguistic differences—rather than treating
them as semantically unrelated. Much of this work has been done in
light of Kratzer’s (1986, 2012)
general approach to modality according to which all conditionals are
treated as two-place modal operators. This approach is also discussed
in the supplement
 Indicative and Subjunctive Conditionals.[5]
 This entry will focus on the basic logic and truth-conditions of
subjunctive conditionals as a whole, and will use the following
notation for them (following Stalnaker
 1968).[6]
This project and notation has an important limitation that should be
highlighted: it combines the meaning of the modal would and
if…then… into a single connective
“\(>\)”. This makes it difficult to adequately
represent subjunctive conditionals like: 
Conditionals like
 (8a)
 have figured in debates about the semantics of counterfactuals and
have been modeled either as a related connective (D.
Lewis 1973b: §1.5) or a normal
would-subjunctive conditional embedded under might
(Stalnaker 1980, 1984: Ch.7). But the
more complex examples
 (8b)–(8d)
 highlight the need for a more refined compositional analysis, like
those surveyed in
 Indicative and Subjunctive Conditionals.
 So, while this notation will be used in
 §1.4
 and throughout
 §2
 and
 §3,
 it should be regarded as an analytic convenience rather than a
defensible assumption.
Counterfactuals have played prominent and interconnected roles in
theories of rational agency. They have figured prominently in views of
what agency and free will amount to, and played important roles in
particular theories of mental representation, rational decision
making, and knowledge. This section will outline these uses of
counterfactuals and begin to paint a broader picture of how
counterfactuals connect to central philosophical questions.
A defining feature of agents is that they make choices. Suppose a
citizen votes, and in doing so chooses to vote for X rather
than Y. It is hard to see how this act can be a choice without
a corresponding counterfactual being true: 
The idea that choice entails the ability to do otherwise has been
taken by many philosophers to underwrite our practice of holding
agents responsible for their choices. But understanding the precise
meaning of the counterfactual could have claim in
 (9)
 requires navigating the classic problem of free will: if we live in a
universe where the current state of the universe is determined (or
near enough) by the prior state of the universe and the physical laws,
then it seems like every action of every agent, including their
“choices”, are predetermined. So interpreting this
intuitively plausible counterfactual
 (9)
 leads quite quickly to a deep philosophical dilemma. One can
maintain, with some Incompatibilists, that
 (9)
 is a false claim about what’s physically possible, and revisit
the understanding of agency, choice, and responsibility
above—the entry
 incompatibilist theories of free will
 explores this
 further.[7]
 Alternatively, one can maintain that
 (9)
 is a true claim about some non-physical sense of possibility, and
explain how that is appropriate to our understanding of choice and
responsibility—the entry
 compatibilism
 explores this further. It is wrong to construe debates about free
will as just debates about the meaning of counterfactuals.
But, the semantics of counterfactuals can have a substantive impact on
delimiting the space of possible solutions, and perhaps even deciding
between them. The same is true for research on counterfactual thinking
in psychology.
Experiments in social psychology suggest that belief in free will is
linked to increased counterfactual thinking (Alquist
et al. 2015). Further, they have
shown that counterfactually reflecting on past events and choices is
one significant way humans imbue life experiences with meaning and
create a sense of self (Galinsky et al. 2005;
Heintzelman et al. 2013; Kray et al. 2010). Incompatibilists
might be able to cite this result as an explanation for why so many
people believe they have free will. It is a specific form of wishful
thinking: it is interwoven with the practices of counterfactual
reflection that give our lives meaning. Seto et
al. (2015) support this idea by showing that variation in
subjects’ belief in free will predicts how much meaning they
derive from relevant instances of counterfactual reflection. This
might even be used as part of a pragmatic argument for believing in
free will: roughly, belief in free will is so practically important,
and our knowledge of the world so incomplete, that it is rational to
believe that it
 exists.[8]
Counterfactual reflection is not just used for the
“sentimental” purposes discussed above, but as part of
what Byrne (2005) calls rational
imagination. This capacity is implicated in many philosophical
definitions of rational agency. According to the standard model,
agency involves intentional action—see entries
 agency
 and
 action.
 While choices are intentional actions, intentional actions are a more
general class of actions which, on most views, are in part caused by
intentions—see entry
 intention.
 One prominent understanding of intentions is that they are
prospective (forward looking) mental states that play a crucial role
in planning actions. Byrne (2005, 2016:
138) details psychological evidence showing that counterfactual
thinking is central to forming rational intentions. People use
counterfactual thinking after particular events to formulate plans
that will improve the outcome of their actions in related scenarios.
Examples include aviation pilots thinking after a near-accident
“if I had understood the controller’s words accurately, I
wouldn’t have initiated the inappropriate landing
attempt”, and blackjack players thinking “If I’d
gotten the 2, I would have beaten the dealer”. People who reason
in this way show more persistence and improved performance in related
tasks, while those who dwell on how things could have been worse, or
do not counterfactually reflect at all, show less persistence and no
improvement in performance. Finally, human rationality can become
disordered when counterfactual thinking goes astray, e.g., in
depression, anxiety, and schizophrenia (Byrne
2016: 140–143).
This psychological research shows that rational human agents
do learn from the past and plan for the future engaging in
counterfactual thinking. Many researchers in artificial intelligence
have voiced similar ideas (Ginsberg 1985; Pearl
1995; Costello & Mccarthy 1999). But, this view is distinct
from a stronger philosophical claim: that the nature of rational
agency consists, in part, in the ability to perform counterfactual
thinking. Some versions of causal decision theory make precisely this
claim, and do so to capture similar patterns of rational behavior.
Newcomb’s Problem (Nozick 1969)
consists of a decision problem which challenges the standard way of
articulating the idea that rational agents maximize expected utility,
and, according to some philosophers (Stalnaker
1972 [1980]; Gibbard & Harper 1978), shows that causal or
counterfactual reasoning must be included in rational decision
procedures—see the entry
 causal decision theory
 for further details. In a similar vein, work on belief revision
theory explores how a rational agent should revise their beliefs when
they are inconsistent with something they have just learned—much
like a counterfactual antecedent demands—and uses structures
that formally parallel those used in the semantics of counterfactuals
(Harper 1975; Gärdenfors 1978, 1982; Levi
1988). See
 formal representations of belief
 for further discussion of this literature.
The idea that counterfactual reasoning is central to rational agency
has surfaced in another way in cognitive science and artificial
intelligence, where encoding counterfactual-supporting relationships
has emerged as a major theory of mental representation (Chater
et al. 2010). These disciplines also
study how states of mind like belief, desire, and intention explain
rational agency. But they are not satisfied with just showing that
certain states of mind can explain certain choices and actions. They
aim to explain how those particular states of mind lead to
those choices and actions. They do so by characterizing those states
of mind in terms of representations, and formulating particular
algorithms for using those representations to learn, make choices and
perform
 actions.[9]
 Many recent advances in cognitive science and artificial intelligence
share a starting point with Bayesian epistemology: agents must learn
and decide what to do despite being uncertain what exactly the world
is like, and these processes can be modeled in the probability
calculus. On a simple Bayesian approach, an agent represents the world
with a probability distribution over binary facts or variables that
represent what the world is like. But even for very simple domains the
probability calculus does not provide computationally tractable
representations and algorithms for implementing Bayesian intelligence.
The tools of Bayesian networks, structural equations
and causal models, developed by Spirtes,
Glymour, and Scheines (1993, 2000)
and Pearl (2000, 2009) address this
limitation, and also afford simple algorithms for causal and
counterfactual reasoning, among other cognitive processes. This
framework represents an agent’s knowledge in a way that puts
counterfactuals and causal connections at the center, and the tools it
provides have been influential beyond cognitive science and AI. It has
also been applied to topics covered later in this entry: the semantic
analyses of counterfactuals
 (§3.2)
 and metaphysical dependence, causation and scientific explanation
 (§1.3).
 For this reason, it will be useful to describe its basics now, though
still focusing on its applications to mental representation. What
follows is a simplified version of the accessible introduction in
Sloman (2005: Ch.4). For a more thorough
introduction, see Pearl (2009:
Ch.1).
In a Bayesian framework, probabilities are real numbers between 0 and
1 assigned to propositional variables A, B,
C,…. These probabilities reflect an agent’s
subjective credence, e.g., \(P(A)=0.6\) reflects that they think
A is slightly more likely than not to be
 true.[10]
 At the heart of Bayesian Networks are the concepts of conditional
probability and two variables being probabilistically
independent. \(P(B \mid A)\) is the credence in B
conditional on A being true and is defined as follows:
Conditional probabilities allow one to say when B is
probabilistically independent of A: when an agent’s
credence in B is the same as their credence in B
conditional on A and conditional on \(\neg A\).
Bayesian networks represent relations of probabilistic dependence. For
example, an agent’s knowledge about a system containing eight
variables could be represented by the directed acyclic graph and
system of structural equations between those variables in
 Figure 2.
Figure 2: Bayesian Network and
Structural Equations. [An
 extended description of figure 2
 is in the supplement.]
While the arrows mark relations of probabilistic dependence, the
equations characterize the nature of the dependence, e.g.,
“\(H\dequal F\lor G\)” means that the value of H is
determined by the value of \(F\lor G\) (but not vice versa).[11]
 This significantly reduces the number of values that must be
 stored.[12]
 But it also stores information that is useful to agents. It
facilitates counterfactual reasoning—e.g., if C had been
true then G would have been true—reasoning about
actions—e.g., if we do A then C will be
true—and explanatory reasoning—e.g., H is true in
part because C is true (Pearl
2002).
The usefulness of Bayesian networks is evidenced by their many
applications in psychology (e.g., Glymour 2001;
Sloman 2005) and artificial intelligence (e.g., Pearl
2009, 2002)). They are among the key
representations employed in autonomous vehicles (Thrun
et al. 2006; Parisien & Thagard
2008), and have been applied to a wide range of cognitive
phenomena:
As Sloman (2005: 177) highlights, this
form of representation fits well with a guiding idea of embodied
cognition: mental representations in biological agents are constrained
by the fact that their primary function is to facilitate successful
action despite uncertain information and bounded computational
resources. Bayesian networks have also been claimed to address a deep
and central issue in artificial intelligence called the frame problem
(e.g., Glymour 2001: Ch. 3). For the
purposes of this entry, it is striking how fruitful this approach to
mental representation has been, since counterfactual dependence is at
its core.
Counterfactual dependence has also featured prominently in theories of
mental content, which explain how a mental representation like the
concept dog comes to represent dogs.
Informational theories take their inspiration from natural
representations like tree rings, which represent, in some sense, how
old the tree is (Dretske 2011). While
some accounts in this family are called “causal theories of
mental content”, it is somewhat limiting to formulate the view
as: X represents Y just in case Y causes
X. Even for the tree rings, it is metaphysically controversial
to claim that the tree rings are caused by the age of the tree, rather
than thinking they have a common cause or are merely causally related
via a number of laws and factors, e.g., rainfall, seasons, growth
periods. For this and other reasons, Dretske
(1981, 1988, 2002) formulates the relationship in terms of
conditional probabilities:
On this view, the state of the tree rings carries the information that
the tree is a certain age, since given the background conditions in
our world the relevant conditional probability is 1. As argued by
Loewer (1983: 76) and Cohen
and Meskin (2006), this formulation
introduces problematic issues in how to interpret the probabilities
involved and these problems are avoided by a counterfactual
formulation:
Even this theory of information requires several elaborations to
furnish a plausible account of mental content. For example, Dretske
(1988, 2002) holds that a mental
representation r represents that a is F just in
case r has the function of indicating that a is
F. The teleological (“function”) component is added
to explain how a deer on a dark night can cause tokens of the concept
dog without being part of the information
carried by thoughts that token dog. Fodor
(1987, 1990) pursues another,
non-teleological solution, the asymmetric dependence theory.
Counterfactuals feature here in another way:
This approach also appeals to laws, which are another key
philosophical concept connected to counterfactuals—see
 §1.3
 below.
Counterfactuals are not just used to analyze how a given mental state
represents reality, but also when a mental state counts as knowledge.
Numerous counterexamples, like Gettier cases, make the identification
of knowledge with justified true belief problematic—for further
details see
 the analysis of knowledge.
 But some build on this analysis by proposing further conditions to
address these counterexamples. Two counterfactual conditions are
prominent in this literature:
Both concepts are ways of articulating the idea that S’s
beliefs must be formed in a way that is responsive to p being
true. The semantics of counterfactuals have interacted with this
project in a number of ways: in establishing their non-equivalence,
refining them, and adjudicating putative counterexamples.
Counterfactuals have played an equally central role in metaphysics and
the philosophy of science. They have featured in metaphysical theories
of causation, supervenience, grounding, ontological dependence, and
dispositions. They have also featured in issues at the intersection of
metaphysics and philosophy of science like laws of nature and
scientific explanation. This section will briefly overview these
applications, largely linking to related entries that cover these
applications in more depth. But, this overview is more than just a
list of how counterfactuals have been applied in these areas. It helps
identify a cluster of inter-related concepts (and/or properties) that
are fruitfully studied together rather than in isolation.
Many philosophers have proposed to analyze causal concepts in terms of
counterfactuals (e.g., D. Lewis 1973a,
Mackie 1974). The basic idea is that
 (10)
 can be understood in terms of something like
 (11)
 (see
 counterfactual theories of causation
 for further discussion). 
This basic idea has been elaborated and developed in several ways.
D. Lewis (1973a, c) refines it using his
similarity semantics for counter­factuals—see
 §2.3.
 The resulting counterfactual analysis of causation faces a number of
challenges—see
 counterfactual theories of causation
 for discussion and references. But this has simply inspired a new
wave of counterfactual analyses that use different tools.
Hitchcock (2001, 2007) and Woodward
(2003: Ch.5) develop counterfactual
analyses of causation using the tools of Bayesian networks (or
“causal models”) and structural equations described back
in
 §1.2.3.
 The rough idea of the analysis is as follows. Given a graph like the
one in
 Figure 2,
 X can be said to be a cause of Y just in case there is
a path from X to Y and changing just the value of
X changes the value of Y. According to Hitchcock
(2001) and Woodward
(2002, 2003), this analysis of
causation counts as a counterfactual analysis because the basic
structural equations, e.g., \(C\dequal A\land B\), are best understood
as primitive counterfactual claims, e.g., if A and B had
been true, C would have been true. While not all theories of
causation that employ structural equations are counterfactual
theories, structural equations are central to many of the contemporary
counterfactual theories of
 causation.[13]
 See
 counterfactual theories of causation
 for further developments and critical reactions to this account of
causation.
Recently, Schaffer (2016) and Wilson
(2018) have also used structural
equations to articulate a counterfactual theory of metaphysical grounding.[14]
 Metaphysical grounding is a concept widely employed in metaphysics
throughout its history, but has been the focus of intense attention
only recently—see entry
 metaphysical grounding
 for further details. As Schaffer (2016)
puts it, the fact that Koko the gorilla lives in California is not a
fundamental fact because it is grounded in more basic facts about the
physical world, perhaps facts about spacetime and certain physical
fields. Statements articulating these grounding facts constitute
distinct metaphysical explanations. So conceived, metaphysical
grounding is among the most central concepts in metaphysics. The key
proposals in Schaffer (2016) and Wilson
(2018) are to use structural equations
to model grounding relations, and not just causal relations, and in
doing so capture parallels between causation and grounding. Indeed,
they define grounding in terms of structural equations in the same way
as the authors above defined causation in terms of structural
equations. The key difference is that the equations articulate what
grounds what. While this approach to grounding has its critics (e.g.,
Koslicki 2016), it is worth noting here
since it places counterfactuals at the center of metaphysical explanations.[15]
 Counterfactuals have been implicated in other key metaphysical
debates. Work on dispositions is a prominent example. A glass’s
fragility is a curious property: the glass has it in virtue of
possibly shattering in certain conditions, even if those
conditions are never manifested in the actual world, unlike say, the
glass’s shape. This dispositional property is quite naturally
understood in terms of a counterfactual claim: 
Early analyses of this form were pursued by Ryle
(1949), Quine
(1960), and Goodman (1955), and
have remained a major position in the literature on dispositions. See
 dispositions
 for further discussion and references.
It is not just metaphysical explanation where counterfactuals
have been central. They also feature prominently in accounts of
scientific explanation and laws of nature. Strict empiricists
have attempted to characterize scientific explanation without reliance
on counterfactuals, despite the fact that they tend to creep
in—for further background on this see
 scientific explanation.
 Scientific explanations appeal to laws of nature, and laws of nature
are difficult to separate from counterfactuals. Laws of nature are
crucially different from accidental generalizations, but how? One
prominent idea is that they “support counterfactuals”. As
Chisholm (1955: 97) observed, the
counterfactual
 (14)
 follows from the corresponding law
 (13)
 but the counterfactual
 (16)
 does not follow from the corresponding accidental generalization
 (15).
 
A number of prominent views have emerged from pursuing this
connection. Woodward (2003) argues that
the key feature of an explanation is that it answers
what-if-things-had-been-different questions, and integrates
this proposal with a structural equations approach to causation and
 counterfactuals.[16]
Lange (1999, 2000, 2009) proposes an
anti-reductionist account of laws according to which they are
identified by their invariance under certain counterfactuals. Maudlin
(2007: Ch.1) also proposes an
anti-reductionist account of laws, but instead uses laws to define the
truth-conditions of counterfactuals relevant to physical explanations.
For more on these views see
 laws of nature.
It should now be clear that a wide variety of central philosophical
topics rely crucially on counterfactuals. This highlights the need to
understand their semantics: how can we systematically specify what the
world must be like if a given counterfactual is true and capture
patterns of valid inference involving them? It turns out to be rather
difficult to answer this question using the tools of classical logic,
or even modal logic. This section will explain why.
Logical semantics (Frege 1893; Tarski 1936;
Carnap 1948) provided many useful analyses of English
connectives like and and not using Boolean
truth-functional connectives like \(\land\) and \(\neg\).
Unfortunately, such an analysis is not possible for counterfactuals.
In truth-functional semantics, the truth of a complex sentence is
determined by the truth of its parts because a connective’s
meaning is modeled as a truth-function—a function from one or
more truth-values to another. Many counterfactuals have false
antecedents and consequents, but some are true and others false.
 (17a)
 is false—given Joplin’s critiques of
consumerism—and
 (17b)
 is true.
It may be useful to state the issue a bit more precisely.
In truth-functional semantics, the truth-value (True/False: 1/0) of a
complex sentence is determined by the truth-values of its parts and
particular truth-function expressed by the connective. This is
illustrated by the truth-tables for negation \(\neg\), conjunction
\(\land\), and the material conditional \(\supset\) in
 Figure 3.
Figure 3: Negation (\(\neg\)),
Conjunction (\(\land\)), Material Conditional (\(\supset\))
Truth-functional logic is inadequate for counterfactuals not just
because the material conditional \(\supset\) does not capture the fact
that some counterfactuals with false antecedents like
 (17a)
 are false. It is inadequate because there is, by definition, no
truth-functional connective whatsoever that simultaneously combines
two false sentences to make a true one like
 (17b)
 and combines two false ones to make a false one like
 (17a).
 In contemporary philosophy, this is overwhelmingly seen as a failing
of classical logic. But there was a time at which it fueled skepticism
about whether counterfactuals really make true or false claims about
the world at all. Quine (1960: §46, 1982:
Ch.3) voices this skepticism and supports it by highlighting
puzzling pairs like
 (18)
 and
 (19):
 
Quine (1982: Ch.3) suggests that no
state of the world could settle whether
 (19a)
 or
 (19b)
 is true. Similarly he contends that it is not the world, but
sympathetically discerning the speaker’s imagination and purpose
in speaking that matters for the truth of
 (18b)
 versus
 (18a)
(Quine 1960: §46). Rather than
promoting skepticism about a semantic analysis of counterfactuals,
Lewis (1973b: 67) took these examples as
evidence that their truth-conditions are
context-sensitive: the possibilities that are
considered when evaluating the antecedent are constrained by the
context in which the counterfactual is asserted, including the
intentions and practical ends of the speaker. All contemporary
accounts of counterfactuals incorporate some version of this
 idea.[17]
Perhaps the most influential semantic puzzle about counterfactuals was
highlighted by Goodman (1947), who
noticed that adding more information to the antecedent can actually
turn a true counterfactual into a false one. For example,
 (20a)
 could be true, while
 (20b)
 is false.
Lewis (1973c: 419; 1973b: 10) dramatized
the problem by considering sequences such as
 (21),
 where adding more information to the antecedent repeatedly flips the
truth-value of the counterfactual.
The English discourse
 (21)
 is clearly consistent: it is nothing like saying I shirked my
duty and I did not shirk my duty. This property of
counterfactual antecedents is known by a technical name,
non-monotonicity, and is one of the features all contemporary
accounts are designed to capture. As will be discussed in
 §2.2,
 even modal logic does not have the resources to capture semantically
non-monotonic operators.
Goodman (1947) posed another influential
problem. Examples
 (20a)
 and
 (20b)
 show that the truth-conditions of counterfactuals depend on assumed
background facts like the presence of oxygen. However, a
moment’s reflection reveals that specifying all of these
background facts is quite difficult. The match must be dry, oxygen
must be present, wind must be below a certain threshold, the friction
between the striking surface and the match must be sufficient to
produce heat, that heat must be sufficient to activate the chemical
energy stored in the match head, etc. Further, counterfactuals like
 (20a)
 also rely for their truth on physical laws specific to our world,
e.g., the conservation of energy. Goodman’s problem is this: it
is difficult to adequately specify these background conditions and
laws without further appealing to counterfactuals. This is clearest
for laws. As discussed in
 §1.3,
 some have aimed to distinguish laws from accidental generalizations
by noting that only the former support counterfactuals. But if this is
a defining feature of laws, and laws are part of the definition of
when a counterfactual is true, circularity becomes a concern. Explicit
analyses of laws in terms of counterfactuals, like Lange
(2009), would make an analysis of
counterfactuals in terms of laws circular.
The potential circularity for background conditions takes a bit more
explanation. Suppose one claims to have specified all of the
background conditions relevant to the truth of
 (20a),
 as in
 (22a).
 Then it is tempting to say that
 (20a)
 is true because
 (22c)
 follows from
 (22a),
 (22c), and the physical laws.
But now suppose there is an agent seeing to it that a fire is not
started, and will only strike the match if it is wet. In this case the
counterfactual
 (20a)
 is intuitively false. However, unless one adds the counterfactual,
if the match were struck, it would have to be wet, to the
background conditions,
 (22c)
 still follows from
 (22a),
 (22c), and the physical laws. That would incorrectly predict
the counterfactual to be true. In short, it seems that the background
conditions must themselves consist of counterfactuals. Any analysis of
counterfactuals that captures their sensitivity to background facts
must either eliminate these appeals to counterfactuals, or show how
this appeal is non-circular, e.g., part of a recursive, non-reductive
analysis.
To summarize, this section has identified three key theses about the
semantics of counterfactuals and a central problem:
These theses, along with Goodman’s Problem, were once grounds
for skepticism about the coherence of counterfactual discourse. But
with advances in semantics and pragmatics, they have instead become
the central features of counterfactuals that contemporary analyses aim
to capture.
This section will survey two semantic analyses of counterfactuals: the
strict conditional analysis and the
similarity analysis. These conceptually related
analyses also have a shared explanatory goal: to capture logically
valid inferences involving counterfactuals, while treating them
non-truth-functionally, leaving room for their context dependence, and
addressing the non-monotonic interpretation of counterfactual
antecedents. Crucially, these analyses abstract away Goodman’s
Problem because they are not primarily concerned with the
truth-conditions of particular counterfactuals—just as classical
logic does not take a stand on which atomic sentences are actually
true. Instead, they say only enough about truth-conditions to settle
matters of logic, e.g., if \(\phi\) and \(\phi>\psi\) are true,
then \(\psi\) is true. Sections
 2.5
 and
 2.6
 will revisit questions about the truth-conditions of particular
counterfactuals, Goodman’s Problem and the philosophical
projects surveyed in
 §1.
The following subsections will detail strict conditional and
similarity analyses. But it is useful at the outset to consider
simplified versions of these two analyses alongside each other. This
will clarify their key differences and similarities. Both analyses are
also stated in the framework of possible world semantics developed in
Kripke (1963) for modal logics. The
following subsection provides this background and an overview of the
two analyses.
The two key concepts in possible worlds semantics are possible worlds
and accessibility spheres (or relations). Intuitively, a possible
world w is simply a way the world could be or could have been.
Formally, they are treated as primitive points in the set of all
possible worlds W. But their crucial role comes in assigning
truth-conditions to sentences: a sentence \(\phi\) can only said to be
true given a possible world w, but since w is genuinely
possible, it cannot be the case that both \(\phi\) and \(\neg\phi\)
are true at w. Accessibility spheres provide additional
structure for reasoning about what’s possible: for each world
w, \(R(w)\) is the set of worlds accessible from
 w.[18]
 This captures the intuitive idea that given a possible world
w, a certain range of other worlds \(R(w)\) are possible, in a
variety of senses. \(R_1(w)\) might specify what’s nomologically
possible in w by including only worlds where w’s
natural laws hold, while \(R_2(w)\) specifies what’s
metaphysically possible in w.
These tools furnish truth-conditions for a formal language including
non-truth-functional necessity (\({{\medsquare}}\)) and possibility
(\({{\meddiamond}}\))
 operators:[19]
In classical logic, the meaning of \(\phi\) is simply its truth-value.
But in modal logic, it is the set of possible worlds where \(\phi\) is
true: \({\llbracket}\phi{\rrbracket}\). So \(\phi\) is true in
w, relative to v and R, just in case
\(w\in{\llbracket}\phi{\rrbracket}^R_v\):
Only clauses 6 and 7 rely crucially on this richer notion of meaning.
\({{\medsquare}}\phi\) says that in all accessible worlds \(R(w)\),
\(\phi\) is true. \({{\meddiamond}}\phi\) says that there are some
accessible worlds where \(\phi\) is true. Logical concepts like
consequence are also defined in terms of relations between sets of
possible worlds. The intersection of the premises must be a subset of
the conclusion (i.e., every world where the premises are true, the
conclusion is true):
Given this framework, the strict analysis can be formulated very
simply: \(\phi > \psi\) should be analyzed as
\({{\medsquare}}(\phi\supset\psi)\). This says that all accessible
\(\phi\)-worlds are \(\psi\)-worlds. This analysis can be depicted as
in
 Figure 4.[20]
Figure 4: Truth in \(w_0\) relative to
R. [An
 extended description of figure 4
 is in the supplement.] 
The red circle delimits the worlds accessible from \(w_0\), the
x-axis divides \(\phi\) and \(\neg\phi\)-worlds, and the
y-axis \(\psi\) and \(\neg\psi\)-worlds.
\({{\medsquare}}(\phi\supset\psi)\) says that there are no worlds in
the blue shaded region.
It is crucial to highlight that this semantics does not
capture the non-monotonic interpretation of counterfactual
antecedents. For example, \({\llbracket}\mathsf{A}\land
\mathsf{B}{\rrbracket}^R_v\) is a subset of
\({\llbracket}\mathsf{A}{\rrbracket}\), and this means that any time
\({{\medsquare}}(\mathsf{A\supset C})\) is true, so is
\({{\medsquare}}(\mathsf{(A\land B)\supset C})\). After all, if all
\(\mathsf{A}\)-worlds are in the red quadrant of
 Figure 4,
 so are all of the \(\mathsf{A\land B}\)-worlds, since the
\(\mathsf{A\land B}\)-worlds are just a subset of the
\(\mathsf{A}\)-worlds. A crucial point here is that on this semantics
the domain of worlds quantified over by a counterfactual is constant
across counterfactuals with different antecedents. As will be
discussed in
 §2.2,
 advocates of strict conditional analyses aim to instead capture the
non-monotonic behavior of antecedents pragmatically by incorporating
it into a model of their context-sensitivity. The most important
difference between strict analyses and similarity analyses is that
similarity analyses capture this non-monotonicity semantically.
On the similarity analysis, \(\phi >\psi\) is true in \(w_0\),
roughly, just in case all the \(\phi\)-worlds most similar to \(w_0\)
are \(\psi\)-worlds. To model this notion of similarity, one needs
more than a simple accessibility sphere. One way to capture it is with
with a nested system of spheres \(\mathcal{R}\) around a possible
world \(w_0\) (D. Lewis 1973b:
§1.3)—this is just a particular kind of set of
accessibility spheres. As one goes out in the system, one gets to less
and less similar worlds. This analysis can be depicted as in
 Figure 5.[21]
Figure 5: Truth in \(w_0\) relative to
\(\mathcal{R}\). [An
 extended description of figure 5
 is in the supplement.]
The most similar \(\phi\)-worlds are in the innermost gray region. So,
this analysis excludes any worlds from being in the shaded
innermost blue region. Comparing Figures
 4
 and
 5,
 one difference stands out: the similarity analyses does not require
that there be no \(\phi\land\neg\psi\)-worlds in any sphere,
just in the innermost sphere. For example, world \(w_1\) does not
prevent the counterfactual \(\phi >\psi\) from being true. It is
not in the \(\phi\)-sphere most similar to w. This is the key
to semantically capturing the non-monotonic interpretation of
antecedents. The truth of \(\mathsf{A > C}\) does not guarantee the
truth of \(\mathsf{(A\land B)> C}\) precisely because the most
similar \(\mathsf{A}\)-worlds may be in the innermost sphere, and the
most similar \(\mathsf{A\land B}\) may be in an intermediate sphere,
and include worlds like \(w_1\) where the consequent is false. In this
sense, the domain of worlds quantified over by a similarity-based
counterfactual varies across counterfactuals with different
antecedents, though it does express a strict conditional over this
varying domain. For this reason, D. Lewis
(1973b) and many others call the similarity analysis a
variably-strict analysis.
Since antecedent monotonicity is the key division between strict and
similarity analyses, it is worthwhile being a bit more precise about
what it is, and what its associated inference patterns are.
The crucial patterns associated with antecedent monotonicity are:
AS and SDA clearly follow from antecedent monotonicity. By contrast,
Transitivity and a plausible auxiliary assumption entail antecedent
 monotonicity,[22]
 and the same is true for
 Contraposition.[23]
 With these basics in place, it is possible to focus in on each of
these analyses in more detail. In doing so, it will become clear that
there are important differences even among variants of the similarity
analysis and variants of the strict analysis. This entry will focus on
what these analyses predict about valid inferences involving
counterfactuals.
The strict conditional analysis has a long history, but its
contemporary form was first articulated by
 Peirce:[24]
“If A is true then B is true”… is
expressed by saying, “In any possible state of things,
[w], either \([A]\) is not true [in w], or \([B]\) is
true [in w]”. (Peirce 1896:
33)
C.I. Lewis (1912, 1914) defended the
strict conditional analysis of subjunctives and developed an axiomatic
system for studying their logic, but offered no semantics. A precise
model-theoretic semantics for the strict conditional was first
presented in Carnap (1956: Ch. 5).
However, that account did not appeal to accessibility relations, and
ranged only over logically possible worlds. Since counterfactuals are
often non-logical, it it was only after Kripke
(1963) introduced a semantics for modal logic featuring an
accessibility relation, that the modern form of the strict analysis
was precisely
 formulated:[25]
Just as the logic of \({{\medsquare}}\) will vary with constraints
 that can be placed on R, so too will the logic of strict
 conditionals.[26]
 For example, if one does not assume that
\(w\in R(w)\) then modus ponens will not hold for the strict
conditional: \(\psi\) will not follow from \(\phi\) and
\({{\medsquare}}(\phi\supset\psi)\). But even without settling these
constraints, some basic logical properties of the analysis can be
 established. The discussion to follow is by no means
 exhaustive.[27]
 Instead, it will highlight the logical
patterns which are central to the debates between competing
analyses.
 The core idea of the
 basic strict analysis
 leads to the following validities.
  In these validities, some see a plausible and attractive
  logic (C.I. Lewis 1912, 1914). Others
  see them as “so utterly devoid of rationality [as to be]
  a reductio ad absurdum of any view which involves
  them” (Nelson 1933: 271),
  earning them the title paradoxes of strict
  implication. Patterns 3 and 4 are more central to debates about
  counterfactuals, so they will be the focus here. Pattern 3 clearly
  follows from the core idea of the basic
  strict analysis: the premise guarantees that there are no
  accessible \(\phi\)-worlds, from which it vacuously follows that all
  accessible \(\phi\)-worlds are \(\psi\)-worlds. Much the same is
  true of pattern 4: if all the accessible worlds are \(\psi\)-worlds
  then all the accessible \(\phi\)-worlds are \(\psi\)-worlds. Both 3
  and 4 are seem incorrect for English counterfactuals. 
Contrary to pattern 3, the false (23b) does not intuitively follow from the true (23a). Similarly, for pattern 4. Suppose one’s origin from a particular sperm and egg is an essential feature of oneself. Then (24a) is true. 
And, yet, many would hesitate to
infer (24b) on the basis
of (24a). Each of these patterns follow
from the core idea of the strict analysis. While these counterexamples
may not constitute a conclusive objection, they do present a problem
for the basic strict analysis. The second wave strict analyses
surveyed in §2.2.1 are
designed to solve it, however. They are also designed to address
another suite of validities that are even more problematic.
The strict analysis is widely criticized for validating antecedent
monotonic patterns. It is worth saying a bit more precisely,
using Definition 9
and Figure 6,
why antecedent monotonicity holds for the strict
conditional.
Figure 6: Strict Conditionals are Antecedent Monotonic. [An extended description of figure 6 is in the supplement.]
If \(\phi_1\strictif\psi\) is true, then the shaded blue region is empty, and the position of \(\phi_2\) reflects the fact that \({\llbracket}\phi_2{\rrbracket}^R_v\subseteq{\llbracket}\phi_1{\rrbracket}^R_v\)—recall that all worlds above the x-axis are \(\phi_1\)-worlds. Since the shaded blue region within \(\phi_2\) is also empty, all \(\phi_2\) worlds in \(R(w)\) are \(\psi\)-worlds. That is, \(\phi_2\strictif \psi\) is true.
Recall that Transititivity  and Contraposition  entail antecedent monotonicity, so it remains to show that both hold for the strict conditional. To see why Contraposition  holds for the strict conditional, note again that if \(\phi\strictif\psi\) is true in w, then all \(\phi\)-worlds in \(R(w)\) are \(\psi\)-worlds, as depicted in the left Venn diagram in Figure  7. Now suppose w is a \(\neg\psi\)-world in \(R(w)\). As the diagram makes clear, w has to be a \(\neg\phi\)-world, and so \(\neg\psi\strictif\neg\phi\) must be true in w. Similarly, if \(\neg\psi\strictif\neg\phi\) is true in w, then all \(\neg\psi\)-worlds in \(R(w)\) are \(\neg\phi\)-worlds, as depicted in the right Venn diagram in Figure  7. Now suppose w is a \(\phi\)-world in \(R(w)\). As depicted, w has to be a \(\psi\)-world, and so \(\phi\strictif\psi\) must be true in w.
Figure 7: \(w\in {\llbracket\phi\strictif\psi\rrbracket}^R_v \iff w\in {\llbracket\neg\psi\strictif\neg\phi\rrbracket}^R_v\) (Contraposition).  [An extended description of figure 7 is in the supplement.]
The validity of Transititivity  for the strict conditional is also easy to see with a Venn diagram.
Figure 8: \(w\in{\llbracket\phi_2\strictif\phi_1\rrbracket}^R_v\cap{ \llbracket\phi_1\strictif\psi\rrbracket}^R_v\Leftrightarrow w\in{\llbracket\phi_2\strictif\psi\rrbracket}^R_v\) (Transitivity). [An extended description of figure 8 is in the supplement.]
The premises guarantee that all \(\phi_2\)-worlds in \(R(w)\) are
\(\phi_1\)-worlds, and that all \(\phi_1\)-worlds in \(R(w)\) are
 \(\psi\)-worlds. That gives one the relationships depicted
 in Figure 8. To show that
 \(\phi_2\strictif\psi\) follows, suppose that w is a
 \(\phi_2\)-world in \(R(w)\). As
 Figure 8
 makes evident, w must then be a \(\psi\)-world.
Antecedent monotonic patterns are an ineliminable part of a strict
conditional logic. Examples of them often sound compelling. For
 example, the transitive inference
 (25)
 sounds perfectly reasonable, as does the antecedent strengthening
 inference
 (26).
 Similar examples for
 SDA
 are easy to find. However,
 counterexamples to each of the four patterns have been offered.
 Counterexamples to
 Antecedent Strengthening
 were already discussed back in
 §1.4.
 Against Transititivity,
 Stalnaker (1968: 48) points out that
 (27c)
 does not intuitively follow from
 (27a)
 and
 (27b).
 
 

Contra Contraposition, D. Lewis
(1973b: 35) presents (28). 
Suppose Boris wanted to go, but stayed away to avoid
Olga. Then (28b) is false. Further suppose
that Olga would have been even more excited to attend if Boris had. In
that case (28a) is
true. Against SDA, Mckay
& van Inwagen (1977: 354) offer:
(29b) does not intuitively follow
 from (29a).
These counterexamples have been widely taken to be conclusive evidence
against the strict analysis (e.g., D. Lewis
1973b; Stalnaker 1968), since they follow from the core
assumptions of that analysis. As a
result, D. Lewis (1973b)
and Stalnaker (1968) developed
similarity analyses which build the non-monotonicity of antecendents
into the semantics of
counterfactuals—see §2.3. However,
there was a subsequent wave of strict analyses designed to
systematically address these counterexamples. In fact, they do so by
unifying two features of counterfactuals: the non-monotonic
interpretation of their antecedents and their context-sensitivity.
Beginning with Daniels and Freeman
(1980) and Warmbrōd
(1981a,b), there was a second wave of strict analyses developed
explicitly to address the non-monotonic interpretation of
counterfactual antecedents. Warmbrōd
(1981a,b), Lowe (1983, 1990),
and Lycan (2001) account for the
counterexamples to antecedent monotonic patterns within a systematic
theory of how counterfactuals are context-sensitive. More
recently, Gillies (2007) has argued that
a strict analysis along those lines is actually preferable to an
account that builds the non-monotonicity of counterfactual antecedents
into their semantics, i.e., similarity analyses. This section will
outline the basic features of these second wave strict conditional
analyses.
The key idea in Warmbrōd (1981a,b)
is that the accessibility sphere in the basic strict analysis should
be viewed as a parameter of the context. Roughly, the idea is that
\(R(w)\) corresponds to background facts assumed by the participants
of a discourse context. For example, if they are assuming propositions
(modeled as sets of possible worlds) A, B, and C
then \(R(w)=A\cap B\cap C\). The other key idea is that trivial strict
conditionals are not pragmatically useful in conversation. If a strict
conditional \(\mathsf{A\strictif C}\) is asserted in a context with
background facts \(R(w)\) and \(\mathsf{A}\) is inconsistent with
\(R(w)\)—\({\llbracket}\mathsf{A}{\rrbracket}^R_v\cap
R(w)={\emptyset}\), then asserting \(\mathsf{A\strictif C}\) does not
provide any information. If there are no \(\mathsf{A}\)-worlds in
\(R(w)\), then, trivially, all \(\mathsf{A}\)-worlds in \(R(w)\) are
\(\mathsf{C}\)-worlds. Warmbrōd
(1981a,b) proposes that conversationalists adapt a pragmatic
rule of charitable interpretation to avoid trivialization:
On this view, \(R(w)\) may very well change over the course of a
discourse as a result of conversationalists adhering
to (P). This part of the view is central to
explaining away counterexamples to antecedent monotonic
validities.
Consider again the example from Goodman
1947 that appeared to be a counterexample
to Antecedent Strengthening.
 

Now note that if (30a) is going to come out
true, the proposition that there is oxygen in the room O must
be true in all worlds in the initial accessibility sphere
\(R_0(w)\). However, if (30b) is interpreted
against \(R_0(w)\), the antecedent will be inconsistent with
\(R_0(w)\) and so express a trivial, uninformative
proposition. Warmbrōd (1981a,b)
proposes that in interpreting (30b) we are
forced by to adopt a new, modified accessibility sphere \(R_1(w)\)
where O is no longer assumed. But if this is
right, (30a) and (30b)
don’t constitute a counterexample to Antecedent
Strengthening because they are interpreted against different
accessibility spheres. It’s like saying All current
U.S. presidents are intelligent doesn’t entail All
current U.S. presidents are unintelligent because this sentence
before Donald Trump was sworn in was true, but uttering it afterwards
was false. There is an equivocation of context, or
so Warmbrōd (1981a,b) contends.
Warmbrōd (1981a,b) outlines
parallel explanations of the counterexamples presented
to SDA, Contraposition,
and Transititivity. This significantly
complicates the issue of whether antecedent monotonicity is the key
issue in understanding the semantics of counterfactuals. It appears
that the non-monotonic interpretation of counterfactual antecedents
can either be captured pragmatically in the way that accessibility
spheres change in context (Warmbrōd
1981a,b), or it can be captured semantically as we will see
from similarity analyses in §2.3. There
are significant limitations to Warmbrōd’s
((1981a,b)) analysis: it does not
capture nested conditionals, and does not actually predict how
\(R(w)\) evolves to
satisfy (P). Fintel
(2001) and Gillies (2007) offer
accounts that remove these limitations, and pose a challenge for
traditional similarity analyses.
Fintel (2001)
and Gillies (2007) propose analyses
where counterfactuals have strict truth-conditions, but they also have
a dynamic meaning which effectively changes \(R(w)\)
non-monotonically. They argue that such a theory can better explain
particular phenomena. Chief among them is reverse Sobel
sequences. Recall the sequence of
counterfactuals (21) presented by Lewis
(1973b, 1973c: 419), and attributed to
Howard Sobel. Reversing these sequences is not felicitous: 
Fintel (2001)
and Gillies (2007) observe that
similarity analyses render sequences
like (31) semantically
consistent. Their theories predict this infelicity by providing a
theory of how counterfactuals in context can change
\(R(w)\). Unlike Fintel
(2001), Gillies (2007) does not
rely essentially on a similarity ordering over possible worlds to
compute these changes to \(R(w)\), and so clearly counts as a second
wave strict analysis.[28] The debate over whether counterfactuals are
best given a strict or similarity analysis is very much
ongoing. Moss
(2012), Starr (2014),
and K. Lewis (2018) have proposed three
different ways of explaining reverse Sobel sequences within a
similarity analysis. But Willer (2015, 2017,
2018) has argued on the basis of other data that a dynamic
second wave strict analysis is preferable. This argument takes one
into a logical comparison of strict and similarity analyses, which
will be taken up in §2.4 after the
similarity analysis has been presented in more detail.
Recall the rough idea of the similarity analysis sketched
in §2.1: worlds can be ordered by
their similarity to the actual world, and counterfactuals say that the
most similar—or least different—worlds where the
antecedent is true are worlds where the consequent is also true. This
idea is commonly attributed to David Lewis and Robert Stalnaker, but
the actual history is a bit more nuanced. Although publication dates
do not tell the full story, the approach was developed roughly
contemporaneously by Stalnaker
(1968), Stalnaker and Thomason
(1970), D. Lewis
(1973b), Nute (1975b),
and Sprigge
(1970).[29] And, there is an even earlier statement of
the view:
When we allow for the possibility of the antecedent’s being true
in the case of a counterfactual, we are hypothetically substituting a
different world for the actual one. It has to be supposed that this
hypothetical world is as much like the actual one as possible so that
we will have grounds for saying that the consequent would be realized
in such a world. (Todd 1964: 107)
Recall the major difference between this proposal and
the basic strict analysis: the similarity
analysis uses a graded notion of similarity instead of an absolute
notion of accessibility. It also allows most similar worlds to vary
between counterfactuals with different antecedents. These differences
invalidate antecedent monotonic inference patterns. This section will
introduce similarity analyses in a bit more formal detail and describe
the differences between analyses within this family.
The similarity analysis has come in many varieties and formulations,
including the system of spheres approach informally described
in §2.1. That formulation is
easiest for comparison to strict analyses. But there is a different
formulation that is more intuitive and better facilitates comparison
among different similarity analyses. This formulation appeals to a
(set) selection function f, which takes a world w, a
proposition p, and returns the set of p-worlds most
similar to w: \(f(w,p)\).[30] \(\phi>\psi\) is then said to be true
when the most f-similar \(\phi\)-worlds to w are
\(\psi\)-worlds, i.e., every world in
\(f(w,{\llbracket}\phi{\rrbracket}^f_v)\) is in
\({\llbracket}\psi{\rrbracket}^f_v\). The basics of this approach can
be summed up thus.
As noted, this formulation makes the limit assumption: \(\phi\)-worlds
do not get indefinitely more and more similar
to w. While D. Lewis (1973b)
rejected this assumption, adopting it will serve exposition. It is
discussed at length in the supplement Formal
Constraints on Similarity. The logic of counterfactuals generated
by a similarity analysis will depend on the constraints imposed
on f. Different theorists have defended different
constraints. Table 1 lists them, where
\(p,q\subseteq W\) and \(w\in W\):
Table 1: Candidate Constraints on Selection Functions
Modulo the limit assumption, Table
2 provides an overview of which analyses have adopted which
constraints.
Table 2: Similarity Analyses, modulo Limit Assumption
simply enforces that \(f(w,p)\) is indeed a set
of p-worlds. Recall that \(f(w,p)\) is supposed to be the set
of most similar p-worlds to w. The other constraints
correspond to certain logical validities, as detailed in the
supplement Formal Constraints on
Similarity. This means that Pollock
(1976) endorses the weakest logic for counterfactuals
and Stalnaker (1968) the strongest. It
is worth seeing how, independently of constraints (b)–(d), this
semantics invalidates an antecedent monotonicity
pattern like Antecedent Strengthening.
Consider an instance of Antecedent Strengthening
involving \(\mathsf{A > C}\) and \(\mathsf{(A\land B)>C}\), and
where the space of worlds is that given in Table
3.
Table 3: A space of worlds W, and truth-values at each world
Now evaluate \(\mathsf{A > C}\) and \(\mathsf{(A\land B)>C}\) in \(w_{5}\) using a selection function \(f_1\) with the following features:
\(f_1(w_{5},{\llbracket}\mathsf{A}{\rrbracket}^{f_1}_v)=\{w_{2}\}\)
\(f_1(w_{5},{\llbracket}\mathsf{A}\land\mathsf{B}{\rrbracket}^{f_1}_v)=\{w_{1}\}\)
Since \(\mathsf{C}\) is true in \(w_{2}\), \(\mathsf{A > C}\) is
true in \(w_{5}\) according to \(f_1\). But, since \(\mathsf{C}\) is
false in \(w_{1}\), \(\mathsf{(A\land B) > C}\) is false in
\(w_{5}\) according to \(f_1\). No constraints are needed here other
than success. While \(f_1\)
satisfies uniqueness, the
counterexample works just as well if, say,
\(f_1(w_{5},{\llbracket}\mathsf{A}{\rrbracket}^{f_1}_v)=\{w_{2},w_0\}\). Accordingly,
all similarity analyses allow for the non-monotonic interpretation of
counterfactual antecedents.
While Stalnaker (1968)
and D. Lewis (1973b) remain the most
popular similarity analyses, there are substantial logical issues
which separate similarity analyses. These issues, and the constraints
underlying them, are detailed in the
supplement Formal Constraints on
Similarity. Table 4 summarizes
which validities go with which constraints.
Table 4: Selection Constraints & Associated Validities
A few comments are in order here, though.  Strong centering is
sufficient but not necessary for Modus Ponens, weak centering would
do: \(w\in f(w,p)\) if \(w\in p\). LT and LAS follow from SSE, and
allow similarity theorists to say why some instances
of Transititivity
and Antecedent Strengthening are intuitively
compelling.
The issue of whether a second wave strict analysis
(§2.2.1) or a similarity
analysis provides a better logic of counterfactuals is very much an
open and subtle issue. As
sections 2.2.1
and 2.3 detailed, both analyses have their own
way of capturing the non-monotonic interpretation of antecedents. Both
analyses also have their own way of capturing instances of monotonic
inferences that do sound good. Perhaps this issue is destined for a
stalemate.[31]
But before declaring it such, it is important to investigate two
patterns that are potentially more
decisive: Simplification of Disjunctive
Antecedents, and a pattern not yet discussed
called Import-Export.
Both SDA
and Import-Export are valid in a strict
analyses and invalid on standard similarity analyses. Crucially, the
counterexamples to them that have been offered by similarity theorists
are significantly less compelling than those offered to patterns
like Antecedent Strengthening. Import-Export
relates counterfactuals like (33a)
and (33b). 
It is hard to imagine one being true without the
other. The basic strict analysis agrees:
it renders them equivalent.
 But it is not valid on a
 similarity analysis.[32]
 While Import-Export is generally regarded
as a plausible principle, some have challenged
it. Kaufmann (2005: 213) presents an
example involving indicative conditionals which can be adapted to
subjunctives. Consider a case where there is a wet match which will
light if tossed in the campfire, but not if it is struck. It has not
been lit. Consider now: 
One might then deny (34a). This match would
not have lit if it had been struck, and if it had lit it would have to
have been thrown into the campfire. (34b),
on the other hand, seems like a straightforward logical
truth. However, it is worth noting that this intuition
about (34a) is very fragile. The slight
variation of (34a)
in (35) is easy to hear as
true.
This subtle issue may be moot, however. Starr
(2014) shows that a dynamic semantic implementation of the
similarity analysis can
validate Import-Export, so it may not be
important for settling between strict and similarity analyses.
 As for the
 Simplification of Disjunctive Antecedents (SDA),
 Fine
(1975), Nute
(1975b), Loewer (1976),
and Warmbrōd (1981) each object to
the similarity analysis predicting that this pattern is
invalid. Counterexamples like (29)
from Mckay & van Inwagen 1977: 354)
have a suspicious feature.
Starr (2014: 1049)
and Warmbrōd (1981a: 284) observe
 that
 (29a)
 seems to be another way of saying
that Spain would never have fought for the
Allies. While Warmbrōd (1981a: 284)
uses this to pragmatically explain-away this counterexample to his
strict analysis, Starr (2014: 1049)
makes a further critical point: it sounds inconsistent to
 say
 (29a)
 after asserting that Spain could have fought for the Allies.
Starr (2014: 1049) argues that this
makes it inconsistent for a similarity theorist to regard this as a
 counterexample to
 SDA. On a similarity analysis
of the could claim, it follows that there are no worlds in
which Spain fought for the Allies most similar to the actual world:
\(f(w_@,{\llbracket}\mathsf{Allies}{\rrbracket})={\emptyset}\). But if
 that’s the case, then
 (29b)
 is vacuously
true on a similarity analysis, and so a similarity theorist cannot
consistently claim that this is a case where the premise is true and
conclusion false. It is, however, too soon for the strict theorist to
declare victory. Nute
(1980a), Alonso-Ovalle (2009),
and Starr (2014: 1049) each develop
similarity analyses where disjunction is given a non-Boolean
 interpretation to validate
 SDA
 without validating
the other antecedent monotonic patterns. But even this is not the end
 of the
 SDA
 debate.
Nute (1980b: 33) considers a similar
antecedent simplification pattern involving negated conjunctions:
Nute (1980b: 33) presents
 (37)
 in favor of SNCA. 
Note that \(\mathsf{\neg(N\land A)}\) and 
\(\mathsf{\neg N\lor\neg A}\) are Boolean equivalents. However, 
non-Boolean analyses like Nute (1980a), 
Alonso-Ovalle (2009),
and Starr (2014: 1049) designed to
 capture
 SDA
 break this equivalence, and so fail
 to predict that
 SNCA
 is valid. Willer (2015, 2017) develops a
dynamic strict analysis which validates both
 SDA
 and SNCA. Fine (2012a,b) advocates for a
departure from possible worlds semantics altogether in order to
capture both
 SDA and SNCA. However, these
 accounts also face counterexamples. Fine
(2012a,b) and Willer (2015, 2017)
render \((\neg\phi_1\lor\neg\phi_2)>\psi\) and
\(\neg(\phi_1\land\phi_2)>\psi\) equivalent,
while Champollion, Ciardelli, and Zhang
(2016) present a powerful counterexample to this
equivalence.
Champollion, Ciardelli, and Zhang (2016)
consider a light which is on when switches A and B are
both up, or both down. Currently, both switches are up, and the light
is on. Consider
 (38a)
 and
 (38b)
 whose antecedents are Boolean equivalents: 
While
 (38a)
 is intuitively true,
 (38b)
 is
 not.[33]
 This is not a counterexample to
 SNCA,
 since the premise of that pattern is false. But such a counterexample 
is not hard to think
 up.[34] 
Suppose the baker’s apprentice completely failed at baking our
cake. It was burnt to a crisp, and the thin, lumpy frosting came out
puke green. The baker planned to redecorate it to make it at least
look delicious, but did not have time. We may explain our extreme
dissatisfaction by asserting
 (39a).
 But the
baker should not infer
 (39b)
 and assume that his redecoration plan would have worked. 
Willer (2017: §4.2) suggests that
 such a counterexample trades on interpreting 
\(\mathsf{\neg(B\land U)>H}\) 
as 
\(\mathsf{\neg B\land\neg U)>H}\), 
and provides an
independent explanation of this on the basis of how negation and
conjunction interact. If this is right, then an analysis which
 validates
 SDA
 and
 SNCA
 without rendering \(\neg(\phi_1\land\phi_2)>\psi\) and
\(\neg\phi_1\lor\neg\phi_2>\psi\) equivalent is what’s
needed. Ciardelli, Zhang, and Champollion
(forthcoming) develop just such an
analysis. As Ciardelli, Zhang, and Champollion
(forthcoming: §6.4) explain, SDA
and SNCA turn out to be valid for very different
reasons. Champollion, Ciardelli, and Zhang
(2016) and Ciardelli, Zhang, and Champollion (forthcoming)
also argue that the falsity of (38b)
cannot be predicted on a similarity analysis. This example must be
added to a long list of examples which have been presented not as
counterexamples to the logic of the similarity analysis, but to what
it predicts (or fails to predict) about the truth of particular
counterfactuals in particular contexts. This will be the topic
 of
 §2.5,
 where it will also be
explained why the strict analysis faces similar challenges.
Where does this leave us in logical the debate between strict and
similarity analyses of counterfactuals?
Even Import-Export
and SDA fail to clearly identify one analysis as
superior. It is possible to capture SDA on either
analysis. Existing similarity analyses that
validate SDA, however, also
invalidate SNCA (Alonso-Ovalle
2009; Starr 2014). By contrast existing strict analyses that
validate SDA also
validate SNCA (Willer 2015,
2017). However, this is far from decisive. The validity of SNCA
is still being investigated, and it is far from clear that it is
impossible to have a similarity analysis that validates
both SDA and SNCA, or a strict analysis that
validates only SDA (perhaps using a non-Boolean
semantics for disjunction). So even SNCA may fail to be the conclusive
pattern needed to separate these analyses.
In their own ways, Stalnaker (1968,
1984) and D. lewis (1973b) are
candid that the similarity analysis is not a complete analysis of
counterfactuals. As should be clear
from §2.3, the formal constraints they
place on similarity are quite minimal and only serve to settle matters
of logic. There are, in general, very many possible selection
functions—and corresponding conceptions of similarity—for
any given counterfactual. To explain how a given counterfactual
like (40) expresses a true proposition, a
similarity analysis must specify which particular conception of
similarity informs it.
 

Of course, the strict analysis is in the same position. It cannot
predict the truth of (40) without specifying
a particular accessibility relation. In turn, the same question
arises: on what basis do ordinary speakers determine some worlds to be
accessible and others not? This section will overview attempts to
answer these questions, and the many counterexamples those attempts
have invited. These counterexamples have been a central motivation for
pursuing alternative semantic analyses, which will be covered
in §3. While this section follows
the focus of the literature on the similarity analysis
(§2.5.1), §2.5.2
will briefly detail how parallel criticisms apply to strict
analyses.
What determines which worlds are counted as most similar when
evaluating a counterfactual? Stalnaker
(1968) explicitly sets this issue aside,
but D. Lewis (1973b: 92) makes a clear
proposal:
Just as counterfactuals are context-dependent and vague, so is our
intuitive notion of overall similarity. In comparing cost of living,
New York and San Francisco may count as similar, but not in comparing
topography. And yet, Lewis’ (1973b: 92)
Proposal has faced a barrage of counterexamples. Lewis and
Stalnaker parted ways in their responses to these counterexamples,
though both grant that Lewis’ (1973b: 92)
Proposal was not viable. Stalnaker (1984:
Ch.7) proposes the projection strategy: similarity is
determined by the way we “project our epistemic policies onto
the world”. D. Lewis 1979)
proposes a new system of weights that amounts to a kind of
curve-fitting: we must first look to which counterfactuals are
intuitively true, and then find ways of weighting respects of
similarity—however complex—that support the truth of
counterfactuals. Since Lewis’ (1973b: 92)
Proposal and Lewis’ (1979)
system of weights are more developed, and have received extensive
critical attention, they will be the focus of this
section.[35]
It will begin with the objections to Lewis’
(1973b: 92) Proposal that motivated Lewis’
(1979) system of weights, and then some
objections to that approach.
Fine (1975: 452) presents
the future similarity objection
to Lewis’ (1973b: 92)
Proposal. (41) is plausibly a true
statement about world history.
 

Suppose, optimistically, that there never will be a nuclear
holocaust. Then, for every \(\mathsf{B\land H}\)-world, there will be
a more similar \(\mathsf{B\land\neg H}\)-world, one where a small
difference prevents the holocaust, such as a malfunction in the
electrical detonation system. In short, a world where Nixon presses
the button and a malfunction prevents a nuclear holocaust is more like
our own than one where there is a nuclear holocaust that changes the
face of the planet. But then Lewis’ (1973b: 92)
Proposal incorrectly predicts
that (41) is false.
Tichý (1976: 271) offers a
similar
counterexample. Given
 (42a)–(42c),
 (42d)
 sounds false. 
Lewis’ (1973b: 92) Proposal  does not seem to predict the falsity of (42d). After all, Jones is wearing his hat in the actual world, so isn’t a world where it’s not raining and he’s wearing his hat more similar to the actual one than one where it’s not raining and he isn’t wearing his hat?
(1979: 472) responds to these examples by proposing a ranked system of weights that give what he calls the standard resolution of similarity, which may be further modulated in context:
While weight 2 gives high importance to keeping particular facts fixed up to the change required by the counterfactual, weight 4 makes clear that particular facts after that point need not be kept fixed. In the case of (42d) the fact that Jones is wearing his hat need not be kept fixed. It was a post-rain fact, so when one counterfactually supposes that it had not been raining, there is no reason to assume that Jones is still wearing his hat. Similarly, with example (41). A world where Nixon pushes the button, a small miracle occurs to short-circuit the equipment and the nuclear holocaust is prevented will count as less similar than one where there is no small miracle and a nuclear holocaust results. A small-miracle and no-holocaust world is similar to our own only in one insignificant respect (particular matters of fact) and dissimilar in one important respect (the small miracle).
It is clear, however, that Lewis’ (1979) System of Weights  is insufficiently general. Particular matters of fact often are held fixed. 
Example (43) crucially holds fixed the outcome of a highly contingent particular fact: the coin outcome. Cases of this kind are discussed extensively by Edgington (2004). Example (44) shows that a chancy outcome is not an essential feature of these cases. Noting the existence of recalcitrant cases, (1979: 472) simply says he wishes he knew why they came out differently. Additional counterexamples to the Lewis’ (1979) System of Weights  have been proposed by Bowie (1979), Kment (2006), and Wasserman (2006).[36] Kment (2006: 458) proposes a new similarity metric to handle this example which is sensitive to the way particular facts are explained, and is integrated into a general account of metaphysical modality in Kment (2014). Ippolito (2016) proposes a new theory of how context determines similarity for counterfactuals which aims to make the correct predictions about many of the above cases.
Another response to these counterexamples has been to develop alternative semantic analyses of counterfactuals such as premise semantics (Kratzer 1989, 2012; Veltman 2005) and causal models (Schulz 2007 2011;  Briggs 2012; Kaufmann 2013). These accounts start from the observation that the counterexamples can be easily explained in a model where matters of fact depend on each other. In (42), when we counterfactually retract the fact that it rained, we don’t keep the fact that the man was wearing his hat because that fact depended on it raining. Hence, (42d) is false. In (43), when we counterfactually retract that you didn’t bet on heads, we keep the fact that the coin came up heads because it is independent of the fact that you didn’t bet on heads. These accounts offer models of how laws, and law-like generalizations, make facts dependent on each other, and argue that once this is done, there is no work left for similarity to do in the semantics of counterfactuals. While these accounts are the focus of §3, it is worth presenting one of the additional counterexamples to the similarity analysis that has emerged from this literature.
Recall (38) from §2.4. Champollion, Ciardelli, and Zhang (2016) and Ciardelli, Zhang, and Champollion (forthcoming) argue on the basis of this example that any similarity analysis will make incorrect predictions about the truth-conditions of counterfactuals. In this example a light is on either when Switch A and B are both up, or they are both down. Otherwise the light is off. Suppose both switches are up and the light is on.
Intuitively, (38a) is true, as are \(\mathsf{\neg A >\neg L}\) and \(\mathsf{\neg B >\neg L}\), but (38b) is false. Champollion, Ciardelli, and Zhang (2016: 321) argue that a similarity analysis cannot predict \(\mathsf{\neg A >\neg L}\) and \(\mathsf{\neg B >\neg L}\) to be true, while (38b) is false. In order for \(\mathsf{\neg A >\neg L}\) to be true, the particular fact that Switch B is up must count towards similarity. Similarly, for \(\mathsf{\neg B >\neg L}\) to be true, the particular fact that Switch A is up must count towards similarity. But then it follows that (38b) is true on a similarity analysis: the most similar worlds where A and B are not both up have to either be worlds where Switch B is down but Switch A is still up, or Switch A is down and Switch B is still up. In those worlds, the light would be off, so the similarity analysis incorrectly predicts (38b) to be true. Champollion, Ciardelli, and Zhang (2016) instead pursue a semantics in terms of causal models where counterfactually making \(\neg \mathsf{(A\land B)}\) true and making \(\mathsf{\neg A\lor\neg B}\) true come apart.
Do strict analyses avoid the troubles faced by similarity analyses when it comes to truth-conditions? This question is difficult to answer, and has not been explicitly discussed in the literature. Other than the theory of Warmbrōd (1981a,b), strict theorists have not made proposals for the accessibility relation analogous to Lewis’ (1973b: 92) Proposal  for similarity. And, Warmbrōd’s proposal about the pragmatics of the accessibility relation is this:
All subsequent second wave strict analyses have ended up in similar
territory. The dynamic analyses developed
by Fintel
(2001), Gillies (2007),
and Willer (2015, 2017, 2018) assign
strict truth-conditions to counterfactuals, but have them induce
changes in an evolving space of possible worlds. These changes must
render the antecedent consistent with an evolving body of
discourse. While Fintel (2001)
and Willer (2018) explicitly appeal to a
similarity ordering for this purpose, Gillies
(2007) and Willer (2017) do
not. Nevertheless, the formal structures used
by Gillies (2007)
and Willer (2017) for this purpose give
rise to the same question: which facts stay and which facts go when
rendering the counterfactual antecedent consistent? Accordingly, at
present, it does not appear that the strict analysis avoids the kinds
of concerns raised for the similarity analysis
in §2.5.1.
Recall Goodman’s Problem
from §1.4: the truth-conditions of
counterfactuals intuitively depend on background facts and laws, but
it is difficult to specify these facts and laws in a way that does not
itself appeal to counterfactuals. Strict and similarity analyses make
progress on the logic of conditionals without directly confronting
this problem. But the discussion
of § 2.5 makes salient a
related problem. Lewis’ (1979) System of
Weights amounts to reverse-engineering a similarity relation to
fit the intuitive truth-conditions of counterfactuals. While
Lewis’ (1979) approach avoids
characterizing laws and facts in counterfactual
terms, Bowie (1979: 496–497)
argues that it does not explain why certain counterfactuals are true
without appealing to counterfactuals. Suppose one asks why certain
counterfactuals are true and the similarity theorist replies with
Lewis’ (1979) recipe for
similarity. If one asks why those facts about similarity make
counterfactuals true, the similarity theorist cannot reply that they
are basic self-evident truths about the similarity of worlds. Instead,
they must say that those similarity facts make those counterfactuals
true. Bowie’s (1979:
496–497) criticism is that this is at best uninformative,
and at worst circular.
A related concern is voiced by Horwich (1987:
172) who asks “why we should have evolved such a baroque
notion of counterfactual dependence”, namely that captured
by Lewis’ (1979) System of
Weights. The concern has two components: why would humans find it
useful, and why would human psychology ground counterfactuals in this
concept of similarity rather than our ready-at-hand intuitive concept
of overall similarity? These questions are given more weight given the
centrality of counterfactuals to human rationality and scientific
explanation outlined in §1. Psychological
theories of counterfactual reasoning and representation have found
tools other than similarity more fruitful
(§1.2). Similarly, work on
scientific explanation has not assigned any central role for
similarity (1.3), and
as Hájek (2014: 250) puts it:
Science has no truck with a notion of similarity; nor does
Lewis’ (1979) ordering of what
matters to similarity have a basis in science.
Morreau (2010) has recently argued on
 formal grounds that similarity is poorly suited to the task assigned
 to it by the similarity analysis. The similarity analysis, especially
 as elaborated by D. Lewis (1979), tries
 to weigh some similarities between worlds against their differences
 to arrive at a notion of overall comparative similarity between those
 worlds. Morreau (2010: 471) argues
 that:
[w]e cannot add up similarities or weigh them against differences. Nor
can we combine them in any other way… No useful comparisons of
overall similarity result. (Morreau 2010:
§4)
articulates this argument formally via a reinterpretation of
Arrow’s Theorem in social choice theory. Arrow’s Theorem
shows that it is not possible to aggregate individuals’
preferences regarding some alternative outcomes into a coherent
“collective preference” ordering over those outcomes,
given minimal assumptions about their rationality and autonomy. As
summarized in §6.3
of Arrow’s
theorem, Morreau (2010) argues that
the same applies to aggregating respects of similarity and difference:
there is no way to add them up into a coherent notion of overall
similarity.
Strict and similarity analyses of counterfactuals showed that it was
possible to address the semantic puzzles described
in §1.4 with formally explicit
logical models. This dispelled widespread skepticism of
counterfactuals and established a major area of interdisciplinary
research. Strict analyses have been revealed to provide a stronger,
more classical, logic, but must be integrated with a pragmatic
explanation of how counterfactual antecedents are interpreted
non-monotonically. Similarity analyses provide a much weaker, more
non-classical, logic, but capture the non-monotonic interpretation of
counterfactual antecedents within their core semantic model. It is now
a highly subtle and intensely debated question which analysis provides
a better logic for counterfactuals, and which version of each kind of
analysis is best. This intense scrutiny and development has also
generated a wave of criticism focused on their treatment of
truth-conditions, Goodman’s Problem, and
integration with thinking about counterfactuals in psychology and the
philosophy of science
(§2.5, §2.6). None
of these criticisms are absolutely conclusive, and these two analyses,
particularly the similarity analysis, remain standard in philosophy
and linguistics. However, the criticisms are serious enough to merit
exploring alternative analyses. These alternative accounts take
inspiration from a particular diagnosis of the counterexamples
discussed in §2.5: facts
depend on each other, so counterfactually assuming p involves
not just giving up not-p, but any facts which depended
on not-p. The next section will examine analyses of this
kind.
Similarity and strict analyses nowhere refer to facts, or
propositions, depending on each
other. Indeed, 1979 was primarily
concerned with explaining which true counterfactuals, given a
similarity analysis, manifest a relation of counterfactual
dependence. Other analyses have instead started with the idea that
facts depend on each other, and then explain how these relations of
dependence make counterfactuals true. As will become clear, none of
these analyses endorse the naive idea that \(\mathsf{A > B}\) is
true only when B counterfactually depends on A. The
dependence can be more complex, indirect, or B could just be
true and independent of A. Theories in this family differ
crucially in how they model counterfactual dependence. In premise
semantics (§3.1) dependence is modeled in
terms of how facts, which are modeled as parts of worlds, are
distributed across a space of worlds that has been constrained by
laws, or law-like generalizations. In probabilistic semantics
(§3.2), this dependence is modeled as
some form of conditional probability. In Bayesian networks, structural
equations, and causal models
(§3.3), it is modeled in
terms of the Bayesian networks discussed at the beginning
of §1.2.3. Because theories of
these three kinds are very much still in development and often involve
even more sophisticated formal models than those covered
in §2, this section will have to be more
cursory than §2 to ensure breadth and
accessibility.
Veltman (1976)
and Kratzer (1981b) approached
counterfactuals from a perspective closer
to Goodman (1947): counterfactuals
involve explicitly adjusting a body of premises, facts or propositions
to be consistent with the counterfactual’s antecedent, and
checking to see if the consequent follows from the revised premise
set—in a sense of “follow” to be articulated
carefully. Since facts or premises hang together, changing one
requires changing others that depend on it. The function of
counterfactuals is to allow us to probe these connections between
facts. While D. Lewis (1981) proved that
the Kratzer (1981b) analysis was a
special case of similarity semantics, subsequent refinements of
premise semantics in Kratzer (1989, 1990, 2002,
2012) and Veltman (2005)
evidenced important differences. Kratzer (1989:
626) nicely captures the key difference:
[I]t is not that the similarity theory says anything false about [particular] examples… It just doesn’t say enough. It stays vague where our intuitions are relatively sharp. I think we should aim for a theory of counterfactuals that is able to make more concrete predictions with respect to particular examples.
From a logical point of view, premise semantics and similarity semantics do not diverge. They diverge in the concrete predictions made about the truth-conditions of counterfactuals in particular contexts without adding additional constraints to the theory like Lewis’ (1979) System of Weights.
How does premise semantics aim to improve on the predictions of similarity semantics? It re-divides the labor between context and the semantics of counterfactuals to more accurately capture the intuitive truth-conditions of counterfactuals, and intuitive characterizations of how context influences counterfactuals. In premise semantics, context provides facts and law-like relations among them, and the counterfactual semantics exploits this information. By contrast, the similarity analysis assumes that context somehow makes a similarity relation salient, and has to make further stipulations like Lewis’ (1979) System of Weights  about how facts and laws enter into the truth-conditions of counterfactuals in particular contexts. This can be illustrated by considering how Tichý’s (1976) example (42) is analyzed in premise semantics. This illustration will use the Veltman (2005) analysis because it is simpler than Kratzer (1989, 2012)—that is not to say it is preferable. The added complexity in Kratzer (1989, 2012) provides more flexibility and a broader empirical range including quantification and modal expressions other than would-counterfactuals.
Recall Tichý’s (1976) example, with the intuitively false counterfactual (42d): 
 Veltman (2005) models how the sentences leading up to the counterfactual (42d) determine the facts and laws relevant to its interpretation. The law-like generalization in (42a) is treated as a strict conditional which places a hard constraint on the space of worlds relevant to evaluating the counterfactual.[37] The particular facts introduced by (42c) provide a soft constraint on the worlds relevant to interpreting the counterfactual. Figure  9 illustrates this model of the context and its evolution, including a third atomic sentence \(\mathsf{H}\) for reasons that will become clear shortly.
\(\hspace{15px}\underrightarrow{\medsquare(\mathsf{R\supset W})}\)
\(\quad\underrightarrow{\mathsf{R\land W}}\)
Figure 9: Context for (42), Facts in Bold, Laws Crossing out Worlds
On this model a context provides a set of worlds compatible with the facts, in \(C_2\) \(\textit{Facts}_{C_2}={\{w_6,w_7\}}\), and the set of worlds compatible with the laws, in \(C_2\) \(\textit{Universe}_{C_2}={\{w_0,w_1,w_2,w_3,w_6,w_7\}}\). This model of context is one essential component of the analysis, but so too is the way Veltman (2005) models worlds, situations, and dependencies between facts. These further components allow Veltman (2005) to offer a procedure for “retracting” the fact that \(\mathsf{R}\) holds from a world.
Veltman’s (2005) analysis of counterfactuals identifies possible worlds with atomic valuations (functions from atomic sentences to truth-values) like those depicted in Figure  9. So \(w_6={\{{\langle \mathsf{R},1\rangle},{\langle \mathsf{W},1\rangle},{\langle \mathsf{H},0\rangle}\}}\). This makes it possible to offer a simple model of situations, which are parts of worlds: any subset of a world.[38] It is now easy to think about one fact (sentence having a truth-value) as determining another fact (sentence having a truth value). In context \(C_3\), \(\mathsf{R}\) being 1 determines that \(\mathsf{W}\) will be 1. Once you know that \(\mathsf{R}\) is assigned to 1, you know that \(\mathsf{W}\) is too. Veltman’s (2005) proposal is that speakers evaluate a counterfactual by retracting the fact that the antecedent is false from the worlds in the context, which gives you some situations, and then consider all those worlds that contain those situations, are compatible with the laws, and make the antecedent true. If the consequent is true in all of those worlds, then we can say that the counterfactual is true in (or supported by) the context. So, to evaluate \(\neg \mathsf{R>W}\), one first retracts the fact that \(\mathsf{R}\) is true, i.e., that \(\mathsf{R}\) is assigned to 1, then one finds all the worlds consistent with the laws that contain those situations and assign \(\mathsf{R}\) to 0. If all of those worlds are also \(\mathsf{W}\) worlds, then the counterfactual is true in (or supported by) the context. For Veltman (2005), the characterization of this retraction process relies essentially on the idea of facts determining other facts.
According to Veltman (2005), when you are “retracting” a fact from the facts in the context, you begin by considering each \(w\in \textit{Facts}_C\) and find the smallest situations in w which contain only undetermined facts—he calls such a situation a basis for w. This is a minimal situation which, given the laws constraining \(\textit{Universe}_C\), determines all the other facts about that world. For example, \(w_6\) has only one basis, namely \(s_0={\{{\langle \mathsf{R},1\rangle},{\langle \mathsf{H},0\rangle}\}}\), and \(w_7\) has only one basis, namely \(s_1={\{{\langle \mathsf{R},1\rangle},{\langle \mathsf{H},1\rangle}\}}\). Once you have the bases for a world, you can retract a fact by finding the smallest change to the basis that no longer forces that fact to be true. So retracting the fact that \(\mathsf{R}\) is true from \(s_0\) produces \(s'_0={\{{\langle \mathsf{H},0\rangle}\}}\), and retracting it from \(s_1\) produces \(s'_1={\{{\langle \mathsf{H},1\rangle}\}}\). The set consisting of these two situations is the premise set.
To evaluate \(\mathsf{\neg R>W}\), one finds the set of worlds from \(\textit{Universe}_{C_3}\) that contains some member of the premise set \(s'_0\) or \(s'_1\): \({\{w_0,w_1,w_2,w_3\}}\)—these are the worlds consistent with the premise set and the laws. Are all of the \(\neg \mathsf{R}\)-worlds in \({\{w_0,w_1,w_2,w_3\}}\) also \(\mathsf{W}\)-worlds? No, \(w_2\) and \(w_3\) are not. Thus, \(\neg \mathsf{R>W}\) is not true in (or supported by) the context \(C_3\). This was the intuitively correct prediction about example (42). Of course, the similarity analysis supplemented with Lewis’ (1979) System of Weights  also makes this prediction. But consider again example (43), which is not predicted: 
This example relies seamlessly on three pieces of background knowledge about how betting works:
If you don’t bet, you don’t win: \(\mathsf{\medsquare(\neg B\supset\neg W)}\)
If you bet and it comes up heads, you win: \(\mathsf{\medsquare((B\land H)\supset W)}\)
If you bet and it doesn’t come up heads, you don’t win: \(\mathsf{\medsquare((B\land\neg H)\supset\neg W)}\)
And it specifies facts: \(\mathsf{\neg B\land H}\). The resulting context is detailed in Figure  10:
Figure 10: Context for (43)
Now, consider the counterfactual \(\mathsf{B>W}\). The first step is to retract the fact that \(\mathsf{B}\) is false from each world in \(\textit{Facts}_{C_{(43)}}\). That’s just \(w_2\). This world has two bases—minimal situations consisting of undetermined facts—\(s_0={\{{\langle \mathsf{B},0\rangle},{\langle \mathsf{H},1\rangle}\}}\) and \(s_1={\{{\langle \mathsf{H},1\rangle},{\langle \mathsf{W},0\rangle}\}}\).[39] The next step is to retract the fact that \(\mathsf{B}\) is false from both bases. For \(s_0\) this yields \(s'_0={\{{\langle \mathsf{H},1\rangle}\}}\) and for \(s_1\) this also yields \(s'_0\)—since the fact that you didn’t win together with the fact that the coin came up heads, forces it to be false that you bet. Given this situation, the premise set consists of the two worlds in Universe(43) that contain \(s'_0\): \({\{w_2,w_7\}}\). Now, are all of the \(\mathsf{B}\)-worlds in this set also \(\mathsf{W}\)-worlds? Yes, \(w_7\) is the only \(\mathsf{B}\)-world, and it is also a \(\mathsf{W}\)-world. So Veltman (2005) correctly predicts that (43) is true in (supported by) its natural context.
It should now be more clear how premise semantics delivers on its promise to be more predictive than similarity semantics when it comes to counterfactuals in context, and affords a more natural characterization of how a context informs the interpretation of counterfactuals. This analysis was crucially based on the idea that some facts determine other facts, and that the process of retracting a fact is constrained by these relations. However, even premise semantics has encountered counterexamples.
Schulz (2007: 101) poses the following counterexample to Veltman (2005). 
Intuitively, (45d) is true in the context. Figure  11 details the context predicted for it by Veltman (2005).
Figure 11: Context for (45d)
There are two bases for \(w_4\): \(s_0={\{{\langle \mathsf{A},1\rangle},{\langle \mathsf{L},0\rangle}\}}\)—the fact that Switch A is up and the light is off determines that Switch B is down—and \(s_1={\{{\langle \mathsf{A},1\rangle},{\langle \mathsf{B},0\rangle}\}}\)—the fact that Switch A is up and the fact that B is down determines that the light is off. (No smaller situation would determine the facts of \(w_4\).) Retracting \(\mathsf{B}\)’s falsity from \(s_0\) leads to trouble. \(s_0\) forces \(\mathsf{B}\) to be false, but there are two ways of changing this. First, one can remove the fact that the light is on, yielding \(s'_0={\{{\langle \mathsf{A},1\rangle}\}}\). Second, one can eliminate the fact that Switch A is up, yielding \(s''_0={\{{\langle \mathsf{L},0\rangle}\}}\). Because of \(s''_0\), the premise set will contain \(w_2\), meaning it allows that in retracting the fact that Switch B is down one can give up the fact that Switch A is up. But then there is a \(\mathsf{B}\)-world where \(\mathsf{L}\) is false, and \(\mathsf{B>L}\) is incorrectly predicted to be false.
Intuitively, the analysis went wrong in allowing the removal of the fact that Switch A is up when retracting the fact that Switch B is down. Schulz (2007: §5.5) provides a more sophisticated version of this diagnosis: although the fact that Switch A is up and the fact that the light is off together determine that Switch B is down, only the fact that the light is off depends on the fact that Switch B is down. If one could articulate this intuitive concept of dependence, and instead only retract facts that depend on the fact you are retracting (in this case the fact that B is down), then the error could be avoided. It is unclear how to implement this kind of dependence in Veltman’s (2005) framework. Schulz (2007: §5.5) goes on show that structural equations and causal models provide the necessary concept of dependence—for more on this approach see §3.3 below. After all, it seems plausible that the light being off causally depends on Switch B being down, but Switch A being up does not causally depend on Switch B being down. It remains to be seen whether the more powerful framework developed by Kratzer (1989, 2012) can predict (45).
While premise semantics has been prominent among linguists, probabilistic theories have been very prominent among philosophers thinking about knowledge and scientific explanation.[40] Adams (1965, 1975) made a seminal proposal in this literature:
However, Adams (1970) was also aware
that indicative/subjunctive pairs
like (3)/(4)
differ in their assertability. To explain this, he proposed
the prior probability analysis of
counterfactuals (Adams 1976):
It would seem that this analysis accurately predicts our intuitions
in (45) about \(\mathsf{B>L}\). Let
\(P_0\) be an agent’s credence before learning that Switch B is
down. (45a) requires that
\(P_0(\mathsf{L}\mid \mathsf{A\land B})\) is (or is close to)
1, (45b) requires that \(P_0(\mathsf{\neg
L}\mid \mathsf{\neg A\lor \neg B})\) is (or is close to) 1. The agent
also learns that Switch A is up, so \(P_0(\mathsf{A})\) is (or is
close to) 1. All of this together seems to guarantee that
\(P_0(\mathsf{B\mid L})\) is also very high. However, this is due to
an inessential artifact of the example: the agent learned that Switch
B was down after learning that Switch A is up. This detail
does not matter to the intuition. As was seen with
example (43), we often hold fixed facts that
happen after the antecedent turns out false. Indeed, Adams’
Prior Probability Analysis makes the incorrect prediction
that (43) is unassertible in its natural
context.
This problem for Adams’ Prior Probability Analysis is addressed in Edgington (2003, 2004: 21) who amends the analysis: \(P_0\) may also reflect any facts the agent learns after they learn that the antecedent is false, provides that those facts are causally independent of the antecedent. This parallels the idea pursued by Schulz (2007: Ch.5) to integrate causal dependence into the analysis of counterfactuals. This idea was also pursued in a probabilistic framework by Kvart (1986, 1992). Kvart (1986, 1992), however, does not propose a prior probability analysis and does not regard the probabilities as subjective credences: they are instead objective probabilities (propensity or objective chance). Skyrms (1981) also proposes a propensity account, but pursues a prior propensity account analogous to the subjective one proposed by Adams (1976).
Objective probability analyses have been popular among philosophers trying to capture the way that counterfactuals feature in physical explanations, and why they are so useful to agents like us in worlds like ours. Loewer (2007) is a good example of such an account, who grounds the truth of certain counterfactuals regarding our decisions like (46) in statistical mechanical probabilities.
 Loewer (2007) proposes that (46) is true just in case (where \(P_{\textit{SM}}\) is the statistical mechanical probability distribution and \(M(t)\) is a description of the macro-state of the universe at t): 
Loewer (2007) acknowledges that this analysis is limited to counterfactuals like (46). He argues that it can address the philosophical objections to the similarity analysis discussed in §2.6, namely why counterfactuals are useful in scientific explanations, and for agents like us in a world like our own.
Conditional probability analyses do not proceed by assigning
truth-conditions to (all) counterfactuals. They instead associate them
with certain conditional
probabilities.[41] This makes it difficult to integrate the
theory into a comprehensive compositional semantics and logic for a
natural language. Kaufmann (2005 2008)
makes important advances here, but it remains an open issue for
conditional probability analyses. Leitgeb
(2012a,b) thoroughly develops a new conditional probability
analysis which regards \(\mathsf{\phi>\psi}\) as true when the
relevant conditional probability is sufficiently
high.[42] But
conditional probability analyses have other limitations. Without
further development, these analyses are limited in their ability to
explain how humans judge particular counterfactuals to be true. There
is a large literature in psychology, beginning
with Kahneman, Slovic, and Tversky 1982,
showing that human reasoning diverges in predictable way from precise
probabilistic reasoning. Even if these performance differences
didn’t turn up in counterfactuals and conditional probabilities,
there is an implementation issue. As discussed
in §1.2.3, directly implementing
probabilistic knowledge makes unreasonable demands on memory. Bayesian
Networks are one proposed solution to this implementation issue. They
are also used in the analysis of causal dependence
(§1.3), which conditional
probability analyses must appeal to anyway. Since Bayesian Networks
can also be used to directly formulate a semantics of counterfactuals,
they provide an worthwhile alternative to conditional probability
analyses despite proceeding from similar assumptions.
Recall from §1.2.3 the basic idea of a Bayesian Network: rather than storing probability values for all possible combinations of some set of variables, a Bayesian Network represents only the conditional probabilities of variables whose values depend on each other. This can be illustrated for (45). 
Sentences (45a)-(45c) can be encoded by the Bayesian Network and structural equations in Figure  12.
Figure
12: Bayesian Network and Structural Equations for
 (45)
 Recall that \(L\dequal A\land B\) means that the value of
L equals the value of \(A\land B\), but also asymmetrically
depends on the value of \(A\land B\): the value of \(A\land B\)
determines the value of L, and not vice-versa. How, given the
network in
 Figure 12,
 does one evaluate the counterfactual \(\mathsf{B>N}\)? Several
different answers have been given to this question.
Pearl (1995, 2000, 2009, 2013: Ch.7)
proposes:
On this approach, one simply deletes the assignment \(B=0\), replaces
it with \(B=1\), and solves for L using the equation \(L\dequal
A\land B\). Since the deletion of \(B=0\) does not effect the
assignment \(A=1\), it follows that \(L=1\) and that the
counterfactual is true. This simple recipe yields the right result.
Pearl nicely sums up the difference between this kind of analysis and
a similarity analysis:
In contrast with Lewis’s theory, counterfactuals are not based
on an abstract notion of similarity among hypothetical worlds;
instead, they rest directly on the mechanisms (or “laws,”
to be fancy) that produce those worlds and on the invariant properties
of those mechanisms. Lewis’s elusive “miracles” are
replaced by principled [interventions] which represent the minimal
change (to a model) necessary for establishing the antecedent…
Thus, similarities and priorities—if they are ever
needed—may be read into the [interventions] as an
afterthought… but they are not basic to the analysis. (Pearl
2009: 239–240)
As interventionism is stated above, it does not apply to conditionals
with logically complex antecedents or consequents. This limitation is
addressed by Briggs (2012), who also
axiomatizes and compares the resultant logic to D.
Lewis (1973b) and Stalnaker
(1968)—significantly extending
the analysis and results in Pearl (2009:
Ch.7). Integrations of causal models with premise semantics
(Schulz 2007, 2011; Kaufmann 2013; Santorio
2014; Champollion, Ciardelli, & Zhang 2016; Ciardelli, Zhang,
& Champollion forthcoming) provide another way of
incorporating an interventionist analysis into a fully compositional
semantics. However, interventionism does face other limitations.
Hiddleston (2005) presents the following
example.
(48c)
 is intuitively true in this context. The network for
 (48)
 is given in
 Figure 13.
Figure 13: Bayesian Network and
Structural Equations for
 (48)
Hiddleston (2005) observes that
interventionism does not predict \(\mathsf{F>B}\) to be true. It
tells one to delete the arrow going in to F, set its value to
1, and project the consequences of doing so. However, none of the
other values depend on F so they keep their actual values:
\(L=0\) and \(B=0\). Accordingly, \(\mathsf{F>B}\) is false,
contrary to intuition. Further, because the intervention on F
has destroyed its connection to B, it’s not even possible
to tweak interventionism to allow values to flow backwards (to the
left) through the
 network.[43]
 Hiddleston’s (2005)
counterexample highlights the possibility of another kind of
counterexample featuring embedded conditionals. Consider again the
network in
 Figure 12.
 The following counterfactual seems true (Starr
2012: 13).
And, considering a simple match, Fisher (2017b:
§1) observes that
 (50b)
 is intuitively false.
In both cases, interventionism is destined to make the wrong
prediction. With
 (49),
 the intervention in the first antecedent removes the connection
between Switch A and the light, so when the antecedent of the
consequent is made true by intervention, it does not result in
L’s value becoming 0. And so the whole counterfactual
comes out false. Similarly with
 (50b),
 when the first antecedent is made true by intervention, it stays true
even after the second antecedent is evaluated. Hence the whole
conditional is predicted to be true. Fisher
(2017a) also observes that interventionism also has no way of
treating counterlegal counterfactuals like if Switch A had alone
controlled the light, the light would be on.
These counterexamples to interventionism have stimulated alternative
accounts like Hiddleston’s (2005)
minimal network analysis and further developments of that
analysis (Rips 2010; Rips & Edwards 2013;
Fisher 2017b). Instead of modifying an existing network to make
the antecedent true, this analysis considers alternate networks where
only the parent nodes of the antecedent which directly influence it
are changed to make the antecedent come true. However, Pearl’s
(2009) interventionist analysis has also
been incorporated into the extended structural models
analysis (Lucas & Kemp 2015). This
analysis aims to capture interventions as a special case of a more
general proposal about how antecedents are made true. One important
aspect of this proposal is that interventions often involve inserting
a hidden node that amounts to an unknown cause of the antecedent. The
analysis of Snider and Bjorndahl (2015)
pursues a third idea: counterfactuals are not interpreted by
manipulating a background network, but instead serve to constrain the
class of possible networks compatible with the information shared in a
conversation, as in Stalnaker’s (1978)
theory of
 assertion.[44]
 Among these relations can be cause-to-effect networks as in
 (45d),
 but also networks that involve the antecedent and consequent having a
common cause, as in
 (48c).
 As should be clear, this is a rapidly developing area of research
where it is not possible to identify one analysis as standard or
representative. It does bear emphasizing that this literature is
driven not only by precise formal models, but also by experimental
data which is brought to bear on the predictions of these
analyses.
A few final philosophical remarks are in order about the kinds of
analyses discussed here. If one follows Woodward
(2002) and Hitchcock
(2001) in their interpretation of
these networks, a structural equation should be viewed as a primitive
counterfactual. It follows that this is a non-reductive analysis of
counterfactual dependence: it only explains how the truth of
arbitrarily complex counterfactual sentences are grounded in basic
relations of counterfactual dependence. However, note in the earlier
quotation above from Pearl (2009:
239–240) that he interprets structural equations as basic
mechanisms or laws, and so arguably counts as an analysis of
counterfactuals in terms of laws. These amount to two very different
philosophical positions that interact with the philosophical debates
 surveyed in
 §1.3.
It is also worth noting that while many working in this framework
apply these networks to causal relations, there is no reason to assume
that the analysis would not apply to other kinds of dependence
relations. For example, constitutional dependence is at the heart of
counterfactuals like: 
From a Bayesian Network approach to mental representation
 (§1.2.3),
 this makes perfect sense: the networks encode probabilistic
dependence which can come from causal or constitutional facts.
Finally, it is worth highlighting that the philosophical objections
directed at the similarity analysis in
 §2.6
 are addressed, at least to some degree, by structural equation
analyses. Because the central constructs of this
analysis—structural equations and Bayesian Networks—are
also employed in models of mental representation, causation, and
scientific explanation, it grounds counterfactuals in a construct
already taken to explain how creatures like us cope with a world like
the one we live in.
Premise semantics
 (3.1),
 conditional probability analyses
 (§3.2)
 and structural equation analyses
 (§3.3)
 all aim to analyze counterfactuals by focusing on certain relations
between facts, rather than similarities between worlds. These accounts
make clearer and more accurate predictions about particular
counterfactuals in context than similarity analyses. But, ultimately,
both premise semantics and conditional probability analyses had to
incorporate causal dependence into their theories. Structural equation
analyses do this from the start, and improve further on the
predictions of premise semantics and conditional probability analyses.
Another strength of this analysis is that it integrates elegantly into
the broader applications of counterfactuals in theories of
rationality, mental representation, causation, and scientific
explanation surveyed in
 §1.1.
 There is still rapid development of structural equation analyses,
though, so it is too early to say where the analysis will stabilize,
or how it will fair under thorough critical examination.
Philosophers, linguists, and psychologists remain fiercely divided on
how to best understand counterfactuals. Rightly so. They are at the
center of questions of deep human interest
 (§1).
 The renaissance on this topic in the 1970s and 1980s focused on
addressing certain semantic puzzles and capturing the logic of
counterfactuals
 (§2).
 From this seminal literature, similarity analyses (D.
Lewis 1973b; Stalnaker 1968) have enjoyed
the most widespread popularity in philosophy
 (§2.3).
 But the logical debate between similarity and strict analyses is
still raging, and strict analyses provide a viable logical alternative
 (§2.4).
 Criticisms of these logical analyses have focused recent debates on
our intuitions about particular utterances of counterfactuals in
particular contexts. Structural equation analyses
 (§3.3)
 have emerged as a particularly prominent alternative to similarity
and strict analyses, which claims to improve on both in significant
respects. These analyses are now being actively developed by
philosophers, linguists, psychologists, and computer scientists.