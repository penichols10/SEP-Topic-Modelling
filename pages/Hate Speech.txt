The term ‘hate speech’ is more than a descriptive concept
used to identify a specific class of expressions. It also functions as
an evaluative term judging its referent negatively and as a candidate
for censure. Thus, defining this category carries serious
implications. What is it that designates hate speech as a distinctive
class of speech? Some claim the term ‘hate speech’ itself
is misleading because it wrongly suggests “virulent dislike of a
person for any reason” as a defining feature (Gelber 2017, 619).
That is not, however, the way in which the term is understood among
most legal theorists and philosophers. Perhaps it would be useful to
start with some examples.
Bhikhu Parekh (2012) lists the following instances as examples
different countries have either punished or sought to punish as hate
speech:
Robert Post’s four bases for defining hate speech might help us
organize the features of Parekh’s list:
The four definitional bases are in terms of: (1) harm, (2) content,
(3) intrinsic properties, i.e., the type of words used, and (4)
dignity. One could also attempt a hybrid definition by combining the
ways mentioned. But, as is made clear in Post’s remarks,
definitions of this sort are relative to the interests of the definer;
“We must evaluate the status of ‘hate speech’ so
defined in order to determine whether it achieves what we wish to
accomplish and whether the harms of the definition will outweigh its
advantages” (Herz and Molnar 2012, 31). The upshot is a
rejection of a univocal definition that captures “the
essence” of hate speech as a phenomenon.
It is important to note that many definitions of hate speech will not
fall squarely within the categories Post outlines. For instance, the
UN’s International Convention on the Elimination of All
Forms of Racial Discrimination identifies hate speech both in
terms of its content and its harmful consequences. Most definitions
tend to characterize hate speech in multiple ways.
Harm-based definitions conceive of hate speech in terms of the harms
to which targets are subjected. Things like discrimination or
linguistic violence are candidates, though some (Gelber, 2017) argue
that hate speech can harm one’s ability to participate in
democratic deliberation. Susan Brison (1998a) offers a disjunctive
definition that centers on a kind of abuse to targets. She defines
hate speech as “speech that vilifies individuals or groups on
the basis of such characteristics as race, sex, ethnicity, religion,
and sexual orientation, which (1) constitutes face-to-face
vilification, (2) creates a hostile or intimidating environment, or
(3) is a kind of group libel” (313). ‘Harm’ as used
by Brison refers to what Joel Feinberg describes “as a wrongful
setback to (or invasion of) someone’s interests” (Brison,
1998b, 42).
Perhaps an immediate reaction to disjunctive definitions of the sort
Brison offers is skepticism about the definitiveness of the purported
list. When we go to test the definition’s application, we
invariably find contestable inclusions and exclusions. Recall the
examples from Parekh at the start of this section. Something like
“Arabs out of France” might be included as an instance of
hate speech on Brison’s account on the grounds that it creates a
hostile or intimidating environment. Should statements that
communicate a similar message in a less abrasive manner also be
included? Suppose “Only French Nationals should occupy
France” is roughly equivalent content-wise to “Arabs out
of France.” If the former is indeed a less abrasive presentation
though communicating the same content as the latter, what are we to
make of its status? Many will find the statement odious; many will
not. And since it is certainly not a face-to-face vilification or form
of group libel, classifying it as hate speech will depend on how
likely it is to create an intimidating or hostile environment.
The previous objection might entice one to opt for a content-based
view. Content-based views define hate speech as that which
“expresses, encourages, stirs up, or incites hatred
against a group of individuals distinguished by a particular feature
or set of features such as race, ethnicity, gender, religion,
nationality, and sexual orientation” (Parekh, 2012, 40). This
version makes it easier to conceive of semantically equivalent
statements that differ in manner of presentation as instances of hate
speech.
Content-based accounts face the challenge of determining which
contents meet this standard. If the content that distinguishes hate
speech from other types of speech must express, encourage, or incite
hatred towards groups or individuals based on certain features, then
the proponent of this view will need an account of expression. Is the
speech in view that which signals the presence of a particular mental
state in the speaker (i.e., hate) or that which is likely to prime
feelings of animosity in a specific audience?
Another issue facing content-based approaches concerns distinguishing
between speech that “respects ‘the decencies of
controversy’” and that “which is outrageous and
therefore hate inducing” (Post, 2009, 128). The ability to
express a wide range of views, even contentious ones, is a cherished
aspect of democratic societies. Failure to observe this distinction
would broaden the scope of what counts as hate speech perhaps too
much. In order to make this distinction, one could follow Post in
tying it to “ambient social norms” that distinguish
outrageous and respectful behavior. One challenge though is in
determining the content of those social norms. For instance, a
minority group whose opinions have little impact on the makeup of
norms are unjustifiably excluded from influencing the shape of their
society’s civility norms.
Definitions of hate speech based on intrinsic properties generally
refer to those that emphasize the type of the speech uttered. What is
at issue is the use of speech widely known to instigate offense or
insult among a majority of society. Explicitly derogatory expressions
like slurs are paradigmatic examples of this type of view. In general,
the type of speech identified on this account is inherently
derogatory, discriminatory, or vilifying.
Though attractive at first glance, classifying hate speech along these
lines might prove to fall short in two ways. First, defining hate
speech in this way might be too constricting. Some of the examples in
our initial list would seem not to count as hate speech since they
arguably lack the intrinsic features. “Arabs out of
France,” for example, does not contain explicitly slurring
terms. And second, this definition might prove too expansive. In cases
where slurs are reappropriated by members of the target group or where
artists incorporate them into a creative work, it would appear odd to
count these as instances of hate speech. The concern is tied
specifically to locating the issue in the terms themselves, as opposed
to the use to which the terms are put.
Perhaps a final challenge to intrinsic property views can be derived
from the work of Judith Butler (1997). On Butler’s account, hate
speech is a kind of performative that is “always delivered
twice-removed, that is, through a theory of the speech act
that has its own performative power” (96). More specifically,
“[w]hat hate speech does … is to constitute the subject
in a subordinate position” (19). Butler locates the trouble with
hate speech in its perlocutionary effects, a concept
introduced by J.L. Austin that refers to the effects a speech act can
have on its audience. An example of a perlocutionary effect is feeling
amused at a joke or frightened from the telling of a ghost story.
Unlike with intrinsic property definitions, Butler shifts focus to the
nature of the acts performed rather than the terms in use. (For a
critical look at Butler’s account, see Schwartzman (2002).)
Lastly, dignity-based conceptions focus primarily on the role of harms
to the dignity of targets of hate speech. For instance, both Steven
Heyman (2008) and Jeremy Waldron (2014) appeal to dignity in their
accounts. Broadly speaking, hate speech on this kind of conception
amounts to speech that undermines its target’s “basic
social standing, the basis of [their] recognition as social equals and
as bearers of human rights and constitutional entitlements”
(Waldron, 2014, 59). This conception of hate speech will also include
characterizations in terms of group defamation or group libel. Section
130 of Germany’s penal code is an example of legislation that
incorporates a dignity-based conception of hate speech, prohibiting
“attacks on human dignity by insulting, maliciously maligning,
or defaming part of the population” (see Waldron, 2014,
8).
Worries about application follow dignity-based conceptions as well.
Firstly, there may be questions about how we, in particular instances,
are to distinguish between false statements about a group as a whole
and those about a particular member of a group (Brown, 2017a).
Presumably, only the former is consistent with an understanding of
hate speech as a group-based phenomenon. Secondly, an implication of
the view appears to be that it expands the range of things that would
count as hate speech. Any speech that calls into question the basic
standing of certain groups falls under this notion, which may make it
more difficult to distinguish between contentious political speech and
hate speech.
Perhaps a lesson to draw from the profusion of disjunctive definitions
is a general skepticism about a definitive description of hate speech.
We might concur with Alexander Brown that ‘hate speech’ is
an equivocal term denoting a family of meanings (Brown 2017b, 562).
According to Brown, ‘hate speech’ isn’t just a term
with contested meanings, but rather, it is “systematically
ambiguous; which is to say, it carries a multiplicity of different
meanings” (2017b, 564). Because the expression is what is
typically referred to as an essentially contested term, the hunt for a
univocal or universal definition is futile.
The harms that have been attributed to hate speech comprise a long and
varied list, ranging from the immediate psychological harms
experienced in the moment by the person(s) targeted by an instance of
hate speech, to much more long-term impacts that affect not only those
targeted but whole communities, and even the strength of an entire
nation.
A distinction between “assaultive hate speech” and
“propagandistic hate speech” is helpful when discussing
these harms (Langton 2012; 2018a; see also Gelber and McNamara (2016)
who discuss “face-to-face encounters” and
“incidences of general circulation”). Hate speech yelled
at an individual on the street, or from a passing car, is a
face-to-face encounter, and an assaultive speech act. This is,
moreover, most often inter-group hate speech, where the speaker(s)
are, for example, white, and the targets are non-white. On the other
hand, propagandistic hate speech is often intra-group speech,
spoken by members of one group to fellow ingroup members (e.g., a
white person to other white people). The newsletter of the KKK,
therefore, would fit into this category.
While this distinction is helpful to keep in mind, it should also not
be overstated. Summarizing the results of their study which surveyed
the experiences of the victims of hate speech, Katharine Gelber and
Luke McNamara conclude that “the distinction between
face-to-face encounters and general circulation hate speech is not
always clear in the everyday experiences of racism endured by
targets” (2016, 326). Any one instance of hate speech might fall
into both categories. For example, it may occur in its first instance
as an assaultive speech act, and then reports of the event may then
take on a propagandistic aspect, as it is spread among the community.
Similarly, even if an instance of hate speech is intended as a piece
of propaganda, it may, when encountered by a member of the community
it disparages, be akin to assaultive speech.
Still, this distinction helps reveal the wide range of the types
of speech acts that are plausibly harmful, and also offers
insight into how they harm. For example, Waldron (2014)
focuses mainly on hate speech in its propagandistic mode, which he
argues undermines the public assurance of equal social standing that
members of non-dominant communities are entitled to—in his
terms, their assurance of dignity. On this view, public hate
speech—e.g., flyers that read ‘Muslims
Out!’—is “an environmental threat to social peace, a
sort of slow-acting poison, accumulating here and there, word by
word” (2014, 4). Its harm is therefore one that attacks the
broader society, and not just individuals targeted by hate speech.
On the other hand, the essays in the classic Words that Wound
tend to focus more on what its authors term “assaultive
speech,” that is, “words that are used as weapons to
ambush, terrorize, wound, humiliate, and degrade” (Matsuda et
al. 1993, 1). This leads them to focus more on hate speech’s
ability to produce “direct, immediate, and substantial
injury” (Lawrence, 1993, 57), such as “immediate mental or
emotional distress” (Delgado, 1993, 93–94). On this
approach, the most evident harms of hate speech are psychological.
These psychological injuries scale up, however, when hate speech is
endemic, and so result in the types of community or social harms
highlighted by authors like Waldron. For this reason, the distinction
between these approaches may be thought of as more a matter of
emphasis.
This relationship between individual harms and broader social harms is
also evident once we acknowledge the long-term effects of hate speech
on victims, in addition to its more immediate impacts (Delgado and
Stefancic, 2004, 14). Victims of hate speech may first experience
“psychological symptoms and emotional distress” like
heightened stress and fear in the immediate aftermath of assaultive
hate speech, but they may also experience far-ranging consequences if
they “modify their behavior and demeanor” to avoid
receiving further hate messages, limiting their ability to participate
fully in society (Matsuda, 1993, 24). Gelber and McNamara’s
interview subjects confirm this complex web of effects that hate
speech may cause, highlighting how “harms are often enduring and
not ephemeral” (2016, 336). In this way, hate speech is both an
immediate attack on one’s health and dignity, along with a
threat to their community’s position in society. The cumulative
effect of hate speech events, therefore, is a collection of harms
located both in individuals and communities, which blurs the
distinction between assaultive and propagandistic hate speech
events.
Another distinction which is similarly helpful, but also fraught, is
the distinction between constitutive and
consequential harms—that is, harms that occur
in the saying of some utterance of hate speech, and those
that are its downstream results (see Maitra and McGowan, 2012, 6).
This distinction draws on the speech act theory of J.L. Austin (1962)
and has served an important role in the examination of hate speech
from feminist philosophers of language (see, e.g., Langton, 1993;
2012; Maitra and McGowan, 2012; Maitra, 2012; McGowan, 2004; 2009;
2012; 2019; and others). Constitutive harms are those that correspond
to what Austin called the illocutionary act, the act
performed in saying X, while consequential harms correspond
to perlocutionary effects, the results brought about by
saying X. Most (though not all) of the harms surveyed above
comprise consequential harms, as items such as psychological injury,
feelings of fear, and societal withdrawal all most naturally fall into
the perlocutionary effects category.
However, philosophers have also drawn attention to how hate speech can
injure in a different way by indirectly affecting the positions of the
social groups targeted by hate in a social hierarchy. That is,
“by fixing facts about the distribution of social power,
including facts about who has this power, and who lacks it” hate
speech harms in a way not captured in the above account of individual
injuries and their cumulative effects (Maitra and McGowan, 2012, 7).
This is an immediate harm that occurs in the saying of the
speech act, which (given appropriate circumstances and uptake)
produces a shift in the normative landscape. It is in this way that an
instance of hate speech may not only cause the injuries surveyed above
but may also, for example, rank Indigenous Peoples as
inferior, legitimate discriminatory behavior towards them
(perhaps via incitement), or potentially silence them. (We
return to the notion of silencing as an illocutionary harm of hate
speech in Section 4 below.)
One reason to direct our attention towards the constitutive harms of
hate speech is its potential to productively advance the debate over
the legitimacy of potential restrictions. Mary Kate McGowan (2009) has
made this case most explicitly. “Rather than focus on what a
certain category of speech causes,” she writes, we ought to be
“interested in what such speech actually does, in and of
itself” (2009, 389–90). The idea here is that by focusing
only on the harms caused by hate speech, we are inevitably
drawn into a debate about balancing the costs and benefits of
permitting or regulating speech, which often leads to an impasse.
Alternatively, turning our attention to the acts hate speech
constitutes can reveal features that help us avoid question of
balancing harms, and opens the door to regulation. On this approach,
some instances of hate speech can be seen to constitute acts of
(verbal) discrimination, and should be considered analogous to other
acts of discrimination—like posting a ‘Whites Only’
sign up at a hotel—that US law recognizes as illegal. As a
speech act, hate speech can enact discriminatory rules in much the
same way the physical sign does, and so ought to similarly be
restricted (McGowan, 2012). This argument proceeds by a development of
Austin’s notion of “exercitives,” which are speech
acts that enact rules in a given domain, and is one example of the
fruitful use of speech act theory to the philosophy of hate
speech.
At the same time, however, it’s worth acknowledging that the
distinction that this analysis relies on—between illocutionary
acts and perlocutionary effects—is one that some argue is
untenable (for one example, see Kukla, 2014). As illocutionary acts
are indeterminate or incomplete without some form of audience uptake,
it is difficult to articulate precisely how we ought to distinguish a
speech act’s effects from its inherent qualities. Furthermore,
the testimonials of victims of hate speech “suggests that there
is a close and complex relationship between constitutive and
consequential harms, and the harms are experienced cumulatively”
(Gelber and McNamara 2016, 336–37). As such, any attempt to draw
too neat of a distinction between these two types of harm risks
misrepresenting victims’ experiences, and might tie the attempt
to restrict hate speech unhelpfully to a philosophically contested
distinction.
As a result, some caution must be applied when marking too stark of a
contrast between these harms. Much like the distinction between
assaultive and propagandistic hate speech, then, we can consider the
distinction between consequential and constitutive harms to be
analytically helpful in exploring the variety of harms attributable to
hate speech, while recognizing that it is at the same time an
abstraction from the on-the-ground realities of hate speech.
Religious belief is sometimes the source of putative cases of hate
speech, and sometimes its target. In both cases, assessing the
conceptual addition of religion to hate speech is a difficult task.
Speech rooted in religious conviction is sometimes subjected to
scrutiny to determine whether instances should count as hate speech or
not. For instance, the Westboro Baptist Church’s demonstrations
often make use of slurs and other explicitly defamatory language. This
is an extreme case, which can be accommodated by extant hate speech
legislation. Other cases, however, involve religious leaders making
contentious statements—for instance, questioning the legitimacy
or recognition of LGBT+ individuals, while claiming these are
statements of love, not hate. Questions about religious speech of this
sort concern whether it is simply contentious speech liberal
democratic societies must tolerate or speech that runs afoul of deeply
held norms that ought to be proscribed.
Some wonder whether religious sensibilities should be afforded special
protection from offense. Amnon Reichman (2009), for instance, notes
that some Israeli scholars have argued that providing special
protection for religious beliefs is a good idea “so as not to
push [religious] believers into having to choose between the authority
of the state and the authority of their religion (namely, the
authority of God)” (338). This relies on an assumption that
religion is an institutionalized normative regime in competition with
a legal regime where clashes over religious beliefs threaten the
social fabric of society. It is in turn prudent to mitigate such
clashes in order to avoid situations of unrest like the incidents
involving comedic cartoons of Mohammed in the Dutch newspaper
Jyllands-Posten and the French publication Charlie
Hebdo.
It is not clear, however, that religious beliefs warrant special
protection over other forms of belief that may be just as strongly
held. Clashes over deeply held political beliefs can pose a similar
threat to the social fabric as religious beliefs. Thus, there is no
reason to think the same concern should not apply quite broadly.
Providing certain types of speech special protection on these grounds
would threaten to introduce quite repressive legislation on speech in
general.
Holocaust denial, denial of the Armenian Genocide, and the denial of
other crimes against humanity have also been the subject of special
legislation, especially in Europe. As Michael Whine (2009) notes, 16
European states, as well as Israel, have criminalized Holocaust denial
(543). In these contexts, at least one rationale for banning speech
that denies or trivializes the Holocaust concerns its role in inciting
hatred (Altman, 2012). One possible justification for such legislation
rests on claims about what denial speech is. According to Martin
Imbleau (2011), denial speech poses as an historical endeavor but is
really propaganda. The denier’s aim is to “eradicate the
awareness of the truth that prevents the resurgence of past criminal
ideologies” (2011, 238). But if this is the rationale, it
potentially opens up justifications for much broader application since
similar claims might be made of other forms of propaganda. (For a
general overview on Holocaust denial, see Robert Wistrich (2012) and
Behrens et. al (2017).)
As Parekh, Brison, and others have noted, hate speech can be expressed
both explicitly and subtly. We can identify a few different
expression-types that map onto the explicit and subtle instances,
i.e., slurs, code words, and dogwhistles.
The subtler forms may fall outside the scope of narrower conceptions
of hate speech.
Perhaps the type of expression most often cited as the paradigm case
of hate speech is slurs. Slurs are typically characterized as a type
of insult that targets race, gender, sexual orientation, nationality,
ability, politics, immigrant status, geographic region, and other
categories. Much of the literature on slurs focuses primarily on the
semantic and pragmatic properties of this linguistic class, with the
expectation that such analyses also provide an account of how they in
fact derogate their targets. There are, of course, competing accounts,
some of which may be better suited than others for the purposes of
legal and ordinary concepts of hate speech.
Before delving into competing accounts, it is good to put a working
definition of ‘slur’ on the table. Typically, slurs are
understood as conventionalized ways of demeaning and derogating
individuals or groups of individuals and are contrasted with a
co-referring neutral counterpart (Jeshion, 2013a; 2013b; Camp, 2013;
Cepollaro, 2015). For instance, the following differ in regard to
offense but are otherwise taken to make similar claims,
For many, (3.1) is regarded as offensive whereas (3.2) is simply a
descriptive statement. The expression ‘cracker’ in (3.1)
is a slur, while ‘white people’ in (3.2) is its purported
neutral counterpart.
Though there seems to be widespread consensus that slurs have or could
have neutral counterparts, not everyone shares this sentiment. Lauren
Ashwell (2016), for example, denies that neutral counterparts (which
she refers to as ‘neutral correlates’) play an essential
role in identifying slurs. Ashwell claims that gendered slurs like
‘bitch,’ ‘slut,’ and ‘sissy’
derogate in ways similar to racial and ethnic slurs like
‘n***er,’ ‘k*ke,’ ‘cracker,’ and
‘sp*c,’ yet lack neutral counterparts. As a result, a
definition need not include reference to neutral counterparts. In
fact, making neutral counterparts central to defining slurs renders
one incapable of accounting for terms that function similarly to slurs
yet lack this purportedly central feature.
Ashwell makes a compelling case for the claim that gendered slurs lack
neutral counterparts. Her larger claim that counterparts’
inessentiality for defining slurs has implications for pragmatic and
semantic accounts that are also worth taking seriously. According to
Ashwell, both sorts of accounts depend on the existence of neutral
counterparts in their explanations of slurs.
For Ashwell, pragmatic and semantic accounts of slurs structurally
require neutral counterparts, and so simply cannot jettison them.
One response proponents of these kinds of accounts could give is that
the gendered insults Ashwell highlights might exhibit properties that
call their status as slurs into question. It could be open to these
theorists to suggest that the terms they have identified as a matter
of fact do carry neutral counterparts, that this is part of what
distinguishes them as a class. And while the expressions Ashwell
identifies seem to pattern in some ways like slurs, they also exhibit
features that make them dissimilar. Thus, there is no need to wedge
all insulting expressions into one class; there is room to expand our
classifications in a way that preserves clarity.
Another important issue about slurs is their power to offend. Part of
what makes them prime candidates for paradigmatic instances of hate
speech is a widespread belief in their offensive potency. Indeed, much
of the literature on slurs simply assumes they are offensive without
offering much (if any) defense of that claim. It is not always clear
whether the reader is supposed to understand offense as the
provocation of a disliked mental state or as the violation of
widely-accepted public norms.
Renée Bolinger (2017) discusses three ways to understand the
claim that slurs are offensive:
The sense of ‘offense’ in (1) tracks how audiences
actually respond at the moment of utterance. This could not be the
sense in which offense is understood for at least two reasons. First,
doing so would make the claim ‘slurs are offensive’ too
strong. Since we would be tracking cases of actual offense, we would
be focusing on particular uses of slurs, explaining what
makes those utterances offensive rather than explicating the
offensiveness of a linguistic class. As a result, the most natural
interpretation of the claim would be that slurring utterances are
invariably offensive, i.e., the use of slurs always provokes disliked
mental states.
This, of course, raises a couple of questions. To begin with, does the
strong claim deny the existence of non-offensive slur uses? Given
things like linguistic reappropriation, some instances of indirect
reports, and even instances of direct reports—especially by
members of the slur’s targeted group—in which it is
possible to utter slurs without provoking a disliked mental state in
the speaker’s audience, the claim is obviously false. Further,
there are also questions about who constitutes the audience.
Is the relevant audience the one intended by the speaker? Everyone who
witnesses the utterance? Only those who are present in the utterance
situation? Because the claim must now be understood to be about
particular slur utterances rather than the linguistic type, the claim
must reflect the diversity of reactions provoked by different
tokenings of slurs. A second reason is related to the questions about
the audience: does everyone in the audience have to be offended, or is
it sufficient if one, some, or a few are? What is the scope of the
claim with respect to offended reactions? The answers to these
questions will likely render the strong version of the claim untenable
and weaker versions suspect. Thus, it is probably not the sense of
‘offense’ one should start with.
The sense expressed in (2) concerns moral justification for taking
offense. Bolinger identifies three grounds for warranted offense at an
utterance: intention, inappropriateness, and associations. A speaker
may intend to offend, often doing so with expressions that are taboo,
and thus considered inappropriate. Vulgar expletives like
‘fuck,’ ‘dick,’ or ‘shithead’ are
typically viewed as inappropriate terms, at least in certain
“polite” settings. Some expressions, like slurs, are not
only inappropriate, but also carry associated attitudes and/or
practices that amplify their offense. The swastika and confederate
flag, for example, are both deeply associated with oppressive and
genocidal practices towards Jewish people and African Americans,
respectively.
This sense of offense still concerns one’s response to
something, though it is not simply about how one reacts but
one’s warrant to do so: “An utterance may warrant, but
fail to actually generate offense merely because either there is no
hearer, or the hearer fails to find the utterance offensive (perhaps
because she shares the offensive attitude, fails to take it seriously,
or misinterprets the utterance)” (Bolinger, 2017, 441). Bolinger
notes that the associational offense category in particular is the one
that is often the subject of hate crime legislation (ibid., 442). Such
terms are often backed by formal social institutions,
“adequately visible practices,” or a combination of
both.
In (3), Bolinger uses ‘rational’ or ‘license’
to refer to the epistemic justification an audience has in
taking offense at a slurring utterance. Here a gap opens up between
what an audience member may be warranted in taking offense at as
opposed to when it may be rational to do so. For instance, if a
non-native speaker used a slur to refer to someone and we come to find
out they were ignorant of the expression’s status as a slur, the
target would still have been rational to take offense even if
unwarranted. Undoubtedly, any of the three senses discussed may factor
into an explanation of a given slur’s offense. However, theories
of slurs are more appropriately aimed at capturing warranted and
rational offense.
Consider again the following pair of statements:
The most straightforward explanation of the difference between (3.1)
and (3.2) is that ‘cracker’ differs in some
semantic respect from ‘white people’. Two of the
most well-known versions of this approach are from Chris Hom (2008)
and Elisabeth Camp (2013). On Hom’s account,
‘cracker’ as opposed to ‘white people,’
contains derogatory content. Slurs’ derogatory content is
determined by the social institutions that undergird them, which
consists of two components: an ideology and a set of
practices. Hom defines an ideology as “a set of (usually)
negative beliefs about a particular group of people” (431). As
for the set of practices, these are racist practices that “can
range from impolite social treatment to genocide” (ibid.). The
two components combine to produce slurs’ semantic content, which
contains a normative claim about the way individuals ought to be
treated, because of possessing certain characteristics in virtue of
being a member of an identifiable social group. (For alternative
accounts of the relationship between slurs and ideology, see Kukla
(2018) and Swanson (2015, Other Internet Resources).)
The pair of sentences in the example used here is illustrative of an
observation many will have noticed when considering different
examples. The slur in (3.1) is typically experienced as less offensive
than ones that target members of marginalized groups. Language users
recognize variation in offensive potency among slurs, some being more
offensive than others. Hom refers to this as derogatory
variation. Difference in the virulence of those backing racist
institutions explains variation in offense on Hom’s account.
Thus, ‘cracker’ is less offensive than slurs like
‘n***er,’ ‘sp*c,’ and ‘f*g’
because the racist and homophobic institutions backing them are much
more virulent. (One might also wonder if there is any racist
institution backing slurs for members of dominant groups at all.)
One objection raised against Hom’s view is that the semantic
content he proposes of slurs is overwrought (Jeshion, 2013b). Robin
Jeshion argues that Hom’s view “attributes highly specific
sets of ideologies and modes of treating the group, yet it is doubtful
that anything so semantically rich and well defined is semantically
encoded in the slur” (318). That is, it is doubtful the racist
means anything this racialized. Jeshion denies that slurs
express anything as robust as Hom claims.
Camp offers an alternative semantic account in which slurs bear a
close relationship to a perspective, which are
“open-ended ways of thinking, feeling, and more generally
engaging with the world and certain parts thereof” (2013,
335–336). According to Camp, a speaker’s slur use
“signals a commitment to an overarching perspective on the
targeted group as a whole” (ibid., 337). The perspective is a
negative one that highlights certain characteristics or properties
specifically associated with particular groups, ones that are presumed
to warrant certain affective and evaluative responses.
What makes slurring perspectives a semantic feature for Camp is that
they do not “merely signal … allegiance to a certain
perspective,” but do so “in an overt and nondefeasible
way, precisely in virtue of employing that expression” (ibid.,
340). The use of a slur inserts a willful and noncancelable way of
thinking about the target into a conversation. This is codified in the
expression itself, and not something audiences “figure
out” through the use of pragmatic mechanisms. This appears to be
bolstered by the fact that one typically cannot erase a slur’s
derogation by following up with a statement intending to do so,
e.g.,
The tension of the contrast is one an audience might generally think
finds its source in the meaning of the slur itself, rather than from
features that emerge from the way language is used in a particular
context. Further, as we saw in Jeshion’s objection to
Hom’s view, the information slurs manage to convey isn’t
very specific. This point is consistent with the open-ended nature of
the perspectives Camp associates with slurs.
Though Camp’s account represents a marked improvement, critics
still see shortcomings they believe should give us pause. Geoff
Nunberg (2018), for instance, argues that Camp’s
characterization of perspectives is too vague to capture the more
specific colorings of slurs for specific groups: “Whatever
distinguishes redskin from injun or nigger
from coon, it’s more precise and richer than simply a
disposition to think about the referents in certain ways”
(Nunberg, 2018, 260–261). According to Nunberg, what is central
for how slurs work is not the perspective the user employs to think
about their target, but the allegiance it signals to a group or
community disposed to think negatively of the target.
For some theorists, the accounts offered by Hom and Camp leave out
what they regard as an important aspect of slurring, namely, the role
attitudinal expression plays in their derogatory power. These views
agree that the difference between slurs and their purported
counterparts is located in the realm of semantics; the previous
accounts just leave out an important aspect. Jeshion (2013a)
identifies three components of slurs’ semantics: (i) a
truth-conditional component, (ii) an expressivist
component, and (iii) an identifying component. The
truth-conditional component of slurs corresponds to the same group
referenced by its purported neutral counterpart. The expressivist
component captures slurs’ ability to express contempt towards
members of socially relevant groups in virtue of their group
membership. Finally, the identifying component ascribes a property to
the group that is seen as central to its identity. Mark Richard (2010)
also proposes a view in which negative attitudes are included in the
explanation of what slurs express. Jeshion and Richard’s
accounts are typically referred to as expressivist views.
One issue expressivist views have been thought to have trouble with is
derogatory variation. Derogatory variation refers to the
sociolinguistic datum that slurs vary in their offensive potency. If
we represent degrees of offense on a scale, slurs like
‘n***er’ and ‘k*ke’ are higher up on the scale
than slurs like ‘cracker’ and ‘wop.’
Expressivist views have typically attributed one sort of attitude to
slurs—contempt—which seems inadequate to capture
the complexity of their offense profiles. For instance, consider
co-referring slurs that vary in offense. Expressivist accounts appear
to lack the resources to account for this variation. Thus,
expressivism fails as an account of slurs for this reason.
Jeshion (2013a) attempts to answer this objection by arguing that her
expressivist view “is only incompatible with versions of
derogatory variation that stipulate that the variation derives from
the semantics” (243). Jeshion maintains that focusing on
slurring terms rather than particular utterances of those terms causes
us to reflect on various factors at play that contribute to their
power to offend. In effect, such focusing obscures the various factors
brought to bear on judgments of offensiveness. Thus, Jeshion claims we
ought to think our intuitive judgments about varying offense support
the following thesis:
Jeshion argues that this thesis is compatible with her account because
weaponized uses of slurs are offensive for several reasons: semantic,
pragmatic, sociocultural, and historical. As a result, there should be
no expectation that a semantic view like hers need explain derogatory
variation semantically.
Inferentialism describes slurs in terms of the kinds of
inferences they license. Proponents of this kind of view include
Robert Brandom (1994), Michael Dummett (1993), Lynne Tirrell (1999)
and Daniel Whiting (2008). Tirrell, for instance, remarks that the
“meaning of a word or expression is a matter of its various
actual and possible sentential roles” (1999, 46). In
characterizing the meaning of the now-outdated slur
‘boche,’ Dummett remarks,
On Dummett’s account, to know the meaning of ‘boche’
is to make the inference from the referent being German to his being
barbarous and more prone to cruelty than other Europeans.
Inferentialism also has its challenges. Timothy Williamson (2009), for
example, opposes inferentialism by charging that it has difficulty
explaining how non-bigots, who are not disposed to draw negative
inferences, still understand their use. “We find racist and
xenophobic abuse offensive because we understand it, not because we
fail to do so” (257). We should note the inferentialist is not
without resources to respond to Williamson’s charge. For
example, Brandom’s (1994) inferentialism determines
understanding in terms of grasping the broad network of inferential
connections in which an expression is situated. An important
implication is thought to be that different speakers will understand
the expression similarly while associating it with different
inferential roles, escaping Williamson’s charge that one must be
disposed to draw slurring inferences to understand the term (see
Steinberger and Murzi, 2017). However, Brandom’s view is itself
controversial (For further objections to inferentialism, see Anderson
and Lepore (2013b); Hornsby (2001).)
The last view we mention here is a stark alternative to the previous
accounts, opting for a socioculturally-driven explanation. According
to Luvell Anderson and Ernie Lepore, slurs are prohibited expressions
whose tokenings provoke offense from those who value and respect their
prohibitions: “What’s clear is that no matter what its
history, no matter what it means or communicates, no matter who
introduces it, regardless of its past associations, once relevant
individuals declare a word a slur, it becomes one” (2013a,
39). The prohibition is meant to apply not only to uses but
mentions of expressions as well, including direct and
indirect reports.
One objection raised against prohibitionism comes from Camp (2018).
Camp asserts that though the view is simple and powerful, “it
threatens to work too well” by failing to account for some
complexities. In particular, Camp claims “slur’s
truth-assessibility and projective behavior are more variable than
[prohibitionism] predicts” (2018, 33). She believes, for
instance, that it is sometimes easy to “quarantine” a
slur’s offensiveness within a report like,
The offense of the slur in this statement is judged to be relativized
to John rather than the person reporting it.
Which view of slurs one adopts has implications for how one conceives
of their harm. For instance, adopting a content-based view of slurs
may encourage one to adopt a content-based definition of hate speech,
which suggests that the harm produced is in the message being
communicated. Adopting an expressivist view, on the other hand, could
lead one to lean more towards an intrinsic property account. (For
further alternative accounts to the ones mentioned in this section,
see Popa-Wyatt & Wyatt (2017), Bach (2018), Croom (2011),
Kirk-Giannini (2019), and Neufeld (2019).)
In addition to slurs, which are explicitly derogatory, researchers
have also focused on more implicit forms of derogatory communication.
Tali Mendelberg (2001), Ian Haney Lopez (2015), Jennifer Saul (2018)
and Justin Khoo (2017) detail the use of racially coded
language—dogwhistles—to access existing racial
resentment while making surreptitious racial appeals. Saul provides a
useful set of distinctions for thinking about dogwhistles: they can be
explicit or implicit, and further,
intentional or unintentional. Saul uses the work of
linguist Kimberly Witten to define an overt intentional
dogwhistle as,
Saul illustrates this kind of dogwhistle with an example from George
W. Bush’s 2003 State of the Union speech:
The phrase ‘wonder-working power’ is meant as an overt
intentional dogwhistle for Evangelical Christians. According to Saul,
there are two possible messages Evangelicals can take away from
Bush’s utterance. The first message is simply a translation:
The second message is that Bush identifies with them, that he speaks
their language. Saul thinks both are instances of overt intentional
dogwhistles.
A covert dogwhistle, according to Saul, is “a
dogwhistle that people fail to consciously recognize” (2018,
365). She is particularly interested in how covert intentional
dogwhistles work in tandem with what psychologists have referred to as
racial resentment, a belief system that is measured by the
degree to which participants agree to the following four claims:
According to Mendelberg, racial resentment remains widespread among
white Americans even though explicitly racist appeals have come to be
viewed as outside the bounds of acceptable political speech. (At
least, that seemed to be the case up until the 2016 presidential
election cycle.) White voters, on this model, tend to shy away from
accepting explicitly racist proposals because they do not want to
think of themselves as racist. The existence of racial resentment
allows for the skilled intentional use of utterances that are
unrelated to race on the surface yet access negative racial attitudes
in a targeted audience, nudging them towards a particular course of
action--e.g., voting for a preferred candidate.
An example of a covert intentional dogwhistle is the infamous Willie
Horton ad used by the George H. W. Bush campaign in 1988. The ad
targeted a prison furlough program in place during Michael
Dukakis’s term as governor of Massachusetts. It presented a
picture of Horton, an African American man, who while out on furlough
raped a white woman and stabbed her husband. Though there was no
explicit mention of race, it was clear to many that the ad drew on
racial tropes about Blackness and criminality to stoke fear in white
voters. In support of the interpretation that this was a
covert dogwhistle, Saul notes that once the specter of race
was raised about the ad, its effectiveness started to wane (2018,
366). The implication is that while the explicit appeal to racial
resentment was a losing strategy, implicit appeal in the form of
covert dogwhistles could be put to powerful use.
The unintentional dogwhistle is defined as an “unwitting use of
words and/or images that, used intentionally, constitute an
intentional dogwhistle, where this use has the same effect as an
intentional dogwhistle” (2018, 368). Dogwhistles of this sort
are passed on by unwitting others while achieving similar effects of
the original intentional one. A special case of unintentional
dogwhistles, what Saul calls amplifier dogwhistles, occurred
when reporters and TV producers played the Willie Horton ad
repeatedly. Presumably, the repeated presentations continued to make
the associations between Blackness and criminality and, thus,
continued to stoke fear and racial anxiety in significant portions of
the white viewing public. For Saul, dogwhistles are therefore best
understood functionally, and the difference in speaker-intentions
between intentional and unintentional dogwhistles matters only insofar
as we define them—their effects, in other words, are often
identical.
The use of implicit means like dogwhistling—in both its covert
and overt forms—can make the conceptualization and detection of
hate speech more difficult. Undoubtedly, this poses a challenge for
defining hate speech since dogwhistles are often designed to be
innocuous. But what is it that explains the effects often attributed
to dogwhistles? That is, how is it possible for language to work in
this way?
Perhaps there is good reason to think something about
dogwhistles’ meaning explains their effects. Consider, first, an
ambiguity thesis that states code words have at least two meanings, a
racial and a non-racial meaning. The expression ‘inner
city’ in
purportedly expresses two meanings: (i) densely populated, high crime,
urban areas, or (ii) poor African American (Khoo, 2017, 40). An
ambiguous expression can be used in an utterance to produce a
statement that leaves undetermined which interpretation is intended by
the speaker.
One worry, however, is that terms like ‘inner city’ are
not actually ambiguous. Khoo argues these terms do not behave like
genuinely ambiguous expressions. Compare the following two
sentences,
A reading of (3.6) is supposed to sound coherent given that
‘funny’ can mean ‘humorous’ or
‘strange’ whereas (3.7) is supposed to sound odd, even
contradictory. If ‘inner-city’ were genuinely ambiguous in
the way described above, we should be able to use it to mean
‘African American’ and get a coherent reading of
(3.7).
A second view posits two dimensions of meaning for code words,
at-issue and not-at-issue content. At-issue content
is the main point of a speaker’s utterance, the directly
asserted content that is foregrounded whereas not-at-issue content is
projective, meaning it is able to survive embedding under
operators like negation and modals (Tonhauser, 2012). Consider,
The at-issue content of (3.8) is represented by (a) and the
not-at-issue by (b):
Note the difficulty in directly denying the not-at-issue content. If
one were to follow an utterance of (3.8) with,
you would presumably find this odd and incoherent. A much more
elaborate statement is needed to deny the not-at-issue content.
Applying this to view to ‘inner-city’ in (3.5), we end up
with:
Because the racial component of (3.5) is not-at-issue, we have a
reasonable explanation for why the following pair of sentences
clash,
An objection to this view is that code words do not display
non-cancelability the way not-at-issue content typically
does; “someone cannot disavow commitment to the
not-at-issue content of a sentence S that she utters merely
by following up her utterance by asserting the negation of that
content” (Khoo, 45). Consider,
The juxtaposition of sentences in (3.11) is supposed to strike the
reader as contradictory while those in (3.12) should not.
According to a third view, code words are neither ambiguous nor
multidimensional, but possess only nonracial meaning. What explains
the phenomenon associated with terms like ‘inner city’ is
the presence of an antecedent belief in the audience member that then
allows them to infer the racial component. For example, an audience
member may already believe
so that when hearing a politician proclaim (3.5), the audience member
comes to infer
A contrasting view that draws on the same simple semantics is what
Khoo calls the association-driven theory of code words. On
this view, there is “an association between ‘inner
city’ (or the concept INNER CITY) and the concept AFRICAN
AMERICAN (or maybe just RACE) which then primes racist beliefs and
prejudices” (2017, 50).
Khoo’s account is simple and compelling, but we may still wonder
whether it is too liberal. For instance, expressions like
‘thug,’ ‘illegal alien,’ ‘welfare
queen,’ and ‘terrorist’ seem to behave like the
terms Khoo identifies as code words, yet they are generally understood
to be explicitly racial in nature. Patrick O’Donnell (2017)
argues that the aforementioned expressions are not code words but
racialized terms. O’Donnell characterizes the
difference between racialized terms and code words in the following
way:
O’Donnell agrees with Khoo that code words are picked out
according to their contextual cognitive-pragmatic role, while claiming
that this role differs between code words and racialized terms.
Determining whether dogwhistles or coded language count as merely
contentious claims that must be tolerated or as hate speech subject to
regulation has implications for broader discussions. The subtlety of
coded language, for instance, calls its status as hate speech into
question. The impact coded language has on an audience lacks the kind
of immediacy often attributed to hate speech. Lawrence (1993), for
example, notes that hate speech is often experienced by targets as a
slap in the face. On the other hand, Mendelberg’s account
suggests coded speech can incite racial resentment, and so it may be
more aptly considered similar to propagandistic hate speech, discussed
above. (For more on this point, see Jason Stanley (2015).) This would
appear to get us closer to how hate speech is purported to function,
namely, by inciting racial hatred. Whether it is close enough is of
course open for debate.
That hate speech and pornography are discussed so frequently together
in philosophy might, at first glance, seem surprising. But given the
overlap made in the arguments made by anti-porn feminist about
pornography and anti-racist theorists about racist hate speech, the
two are now intimately linked—for better or for worse. (One
important fact that led to this development is, of course, the ruling
that pornography is protected by the US first amendment as speech [see
Miller v. California (1973)].) According to anti-porn
feminists, much of what is said of racist hate speech and the harms
that befall its targets also applies, with the appropriate changes, to
pornography and women—including, it’s worth emphasizing,
women of color.
Many of the important initial moves in this literature were crafted by
feminist legal scholar Catherine MacKinnon, along with Andrea Dworkin.
One of MacKinnon’s most significant claims that has received
sustained philosophical attention is the idea that (degrading and
misogynist) pornography silences women. With some
modifications, a similar claim may be applied to hate speech, namely,
that hate speech silences its targets. However, as the
literature has focused on the case of pornography and women,
it’s worth examining these arguments in detail first.
This silencing argument begins with MacKinnon’s observation that
there are “words that set conditions” for other speech
acts’ successes or failures (1993, 63–68; see also Hornsby
and Langton, 1998, 27). That is, there are some speech acts that fix
the possibility of other speech acts. In other words, they make it
possible for some persons to perform some speech acts, and make it
impossible for others. This is most evident in formal settings, like a
legislature, where the formal rules determine who may speak when, and
in what manner. Pornography, the argument continues, does just this.
It sets rules of behavior that, in effect, inhibit the speech of
women. The result of which is that the speech acts of
pornography—performed by those who produce and distribute
it—create a climate that undermines women’s capacity to
perform certain speech acts of their own. The speech of some
(pornographers), therefore, curtails the speech of others (women).
In an influential account of the phenomena of silencing, Langton
(1993) deploys speech act theory to examine the case of sexual
refusal. According to the silencing argument, pornography depicts
women as not (genuinely) refusing sexual advances with utterances of
‘no.’ Indeed, according to the myths perpetuated by
pornography (among other social influences), a woman’s
‘no’ is not a refusal, but rather part of an elaborate
sexual script. As a result, when a woman says ‘no’ in a
non-pornographic context, intending to refuse a man’s sexual
advances, she may find herself unable to be heard—that is, her
words won’t have the force and effect she intends, and her
hearer will not take her to be refusing. She may find herself silenced
in this particularly horrendous way, unable to use the standard
methods of refusing another’s sexual advances. The claim is that
this occurs as a result of pornography silencing women’s
refusals in the context of sex. It renders their words powerless.
In making this argument, Langton relies on the distinction between
locutionary, illocutionary, and perlocutionary acts, and,
correspondingly, locutionary, illocutionary, and perlocutionary
silencing. A couple examples will explain these distinctions
quickly:
To be clear, these three acts—locutionary, illocutionary, and
perlocutionary—all occur as part of a single utterance and serve
to bring out different aspects of any speech act. Austin (and many
after him) paid particular attention to the illocutionary act of an
utterance, as this, he said, corresponds to the force of an
utterance. That is, what someone is doing with their words.
With this in mind, we can see that there are, in fact, many ways one
could silence someone. You could literally gag or threaten someone to
prevent them from speaking at all, which would achieve a type of
locutionary silencing. Alternatively, you could let them say what they
wish, recognize what act they are performing, but prevent them
achieving their goals, and in doing so achieve a type of
perlocutionary silencing. Finally, a third alternative occurs when one
speaks and is prevented not only from achieving their intended
effects, but also is prevented from performing the very action they
intend to perform (Langton, 1993, 315). It is this third
alternative—illocutionary silencing—that is said to occur
when a man fails to even recognize a woman’s ‘no’ as
a refusal, owing at least partially to the influence of
pornography.
The specific mechanics of silencing—along with the underlying
theory that best explains the phenomena—is subject to much
dispute in the literature, and numerous accounts with different
essential features have been offered (see Langton (1993); Langton and
West (1999); Hornsby (1994); Hornsby and Langton (1998); Maitra
(2009); McGowan (2004, 2009, 2014); Mikolla (2011; 2019), among
others).
Laura Caponetto (2021) distinguishes four different types of
silencing, demonstrating the breadth of the concept. First, there is
essential silencing, which consists in the hearer’s
failure to recognize the illocutionary point of a speech act. Second,
there is authority silencing, where a hearer fails to
acknowledge a speaker’s authority in a relevant domain. Third,
there is sincerity silencing, when the speaker’s
utterance is inaccurately taken as insincere. Fourth and finally,
there is seriousness silencing, which consists in the
hearer’s failure to acknowledge the speaker’s words as
appropriately serious. Given these fine-grained ways of understanding
silencing, a broad, comprehensive definition of silencing may be put
as follows:
In nearly all discussions of silencing, one common piece of contention
concerns the notion of ‘uptake.’ On different
understanding of what uptake consists in—ranging from the
hearer’s recognition of a speaker’s intent, or the type of
speech act being performed, up to the material consequences of a
speech act—we are led to different conclusions about whether a
speaker was silenced or not. Disagreement about the conditions of
uptake poses difficulty, therefore, for many accounts of silencing.
Drawing on these difficulties, Samia Hesni (2018) has argued that the
standard account of silencing needs significant retooling, in part
because the necessary distinction between illocutionary silencing and
perlocutionary silencing cannot hold, as it relies on a
problematic—and arguably conceptually untenable—notion of
uptake (Hesni, 2018, 957). In an attempt to avoid these difficulties,
we might prefer an account of silencing that uses a Gricean, rather
than Austinian or Searlian framework, bypassing the need to fully
differentiate the illocutionary from the perlocutionary (see Maitra,
2009).
While much of this literature is explicitly focused on
pornography’s potential to silence women in the realm of sexual
refusal, the notion that racist hate speech may similarly play a
silencing function has also been put forward. For example, in a
classic paper on the topic, Lawrence wrote that:
Using the above framework, we might therefore say that racist hate
speech can itself constitute words that set conditions for the success
of other speech acts, and in doing so undermines the speech of its
targets—and in some cases, effectively silencing them. That is,
racist hate speech may, in cultivating an environment hostile to the
voices (and lives) of many, can lead to both locutionary and
illocutionary silencing in a way that threatens their freedom of
expression. And as is noted above in the section on the harms of hate
speech, one long-term consequence of racist hate speech may be the
target’s partial withdrawal from certain aspects of public life,
including public discourse (West, 2012, 237). One further harmful
effect of hate speech, then, is its targets’ silence.
Another way in which racist hate speech might silence is more
immediate. Returning to the distinction between propagandistic hate
speech on the one hand, and assaultive hate speech on the other, where
the latter consists in hate speech uttered directly to its target, we
may note that hate speech often serves as a type of attack. So,
despite the common refrain of ‘more speech’ offered as
advice, conceiving hate speech as a personal attack demonstrates how
it, in fact, threatens the speech rights of its targets. As Lawrence
puts it: “The visceral emotional response to personal attack
precludes speech” (1993, 68). He goes on:
So, in both cultivating an environment in which the speech of
marginalized groups is systematically devalued, or in serving as an
immediate threat, hate speech can be said to silence its targets.
As is the case with pornography and silencing, the details of the
mechanisms that sustain this type of silencing, along with what
particular type of silencing racist hate speech results in, are
subject to dispute. But, just like in the pornography debate, the
plausibility of the silencing argument lies partly in how it reframes
the overall question surrounding regulation. Rather than simply being
a source of harm that merely infringes on the equality rights of its
targets, if hate speech silences then it also infringes on the speech
rights of its targets (West, 2012). As a result, it is not simply a
question of balancing the speech rights of hate speakers against the
wellbeing of their targets, but of competing claims to (substantive,
and not just formal) freedom of expression. And given the importance
that most liberal democracies place on freedom of expression, the
challenge presented from hate speech is of central importance. For
this reason, the silencing question is one of the most disputed
aspects of hate speech and has generated great attention.
On the presumption that hate speech is harmful—both particularly
harmful for the members of targeted groups, and also generally harmful
to democracy—the natural question that follows is: what should
we do about it? This question, however, rests on several
sub-questions—some empirical, some conceptual—that
themselves admit of rich dispute. For example, depending on how one
conceives of the value and point of free expression—to better
seek the truth, to respect autonomy, to ensure democracy,
etc.—different answers to the hate speech question will seem
more worthwhile than others. The same consideration applies to
empirical matters as well, which are often difficult to properly
assess in the absence of uncontroversial data. This means that
relatively straightforward empirical questions—does genocidal
speech pave the way to actual genocidal violence; do governments abuse
hate speech regulation to punish political rivals and disfavored
minorities; and others—rarely receive unanimous agreement.
Despite these challenges, many theorists have addressed the question
of how to counteract hate speech, and what form that response ought to
take.
We can divide the most common answers into three broad categories: (1)
legally restrict it in some form, as a justified exception to free
expression; (2) permit it on the basis of free expression, holding
that the harms of censorship outweigh the harms of hate speech; or (3)
permit it, but take explicit measures to undo the harm of hate
speech.
First, the case for banning hate speech. While this position may be
anathema to many (especially in the United States), it is the
consensus position of most democratic nations around the globe, as
well as the explicit position of the United Nations. In the
International Covenant on Civil and Political Rights, Article
20 requires a ban on hate speech—or, in their words, “any
advocacy of national, racial or religious hatred that constitutes
incitement to discrimination, hostility or violence shall be
prohibited by law” (Covenant on Civil and Political
Rights; see also, Article 4 of Convention on Racial
Discrimination). It is worth noting the position of the United
Nations and other democracies on hate speech in part because of the
contrast they serve for the dominant position in the United States,
which recognizes some exceptions to the right to free expression
(e.g., obscenity, libel, child sexual abuse material), but not
generally on the basis of (racial) hate. Moreover, these exhortations
to criminalize hate speech from the United Nations sit alongside
commitments that maintain the importance of freedom of expression. For
instance, Article 20, quoted above, is immediately preceded by Article
19, which affirms right to freedom of expression (Covenant on
Civil and Political Rights).
The standard justification offered for restrictions on freedom of
expression are based on the necessity of (a) respect of the rights or
reputations of others; and (b) reasons of national security or of
public order. In other words, a ban on hate speech may be thought to
follow from the recognition of the harms it presents, both to the
dignity of minority-members of a nation, as well as their physical
safety. This position maintains, then, that restrictions on hate
speech are a legitimate—and necessary—exception to an
otherwise wider understanding of free expression. (For some theorists,
it’s worth noting, hate speech is best not understood as the
type of speech that free speech protections are meant to
include—e.g., it serves no purpose in the pursuit of
truth—and so is not in fact an exception to a free
speech principle, but simply not included in a proper understanding of
the scope of free speech.) This view naturally follows from the
understanding that multiple values and rights must be balanced against
each other. This is true both of countries that explicitly prohibit
hate speech in order to protect minority rights, as well as in more
‘speech-friendly’ nations like the United States, where
speech that is aimed at and likely to result in “imminent
lawless action” may be legitimately restricted (see
Brandenburg v. Ohio).
However, most advocates for legally restricting hate speech believe
that its proper scope is wider than what US law currently allows.
Parekh, for example, rejects the position that hate speech may only be
restricted when there is “imminent danger” of violence on
the grounds that this understanding is too short-sighted. Moreover, he
says,
On the understanding that the threat of hate speech is not exhausted
by cases that concern “imminent danger,” we might then
ground the prohibition of hate speech on the basis that this may
reduce speech that causes harm to its targets, beyond those most
immediately affected. Of course, there is also an important role to be
played by non-legal means (e.g., moral and social pressure) in erasing
or reducing these harms, so legal bans are best understood as part of
a broader approach to the ills of hate speech. Furthermore, advocates
of bans describe the expressive dimension of these laws as themselves
providing a reason in favor of legislation (Waldron, 2014). The law,
in this sense, serves as a public statement on a community’s
values, and has educational and symbolic importance in itself (Parekh,
2012, 46). (For an overview of expressive theories of law, see
Anderson and Pildes, 2000.) A ban on hate speech, therefore, is
intended both to reduce harms directly, by decreasing instances of
hate by the threat of law, as well as indirectly, by shaping the
community’s moral norms through an expression of value.
Though many would agree that hate speech can have destructive effects,
and that there is a moral imperative on the state to cultivate
something like respectful relations between its members, objections to
hate speech bans abound. In a wide-ranging response to these concerns,
Parekh (2012) considers (and rejects) six common objections to the
prohibition of hate speech. These six objections are: (1) that the
harm of hate speech, while real, is relatively minor and a small price
to pay given the interest of democratic nations; (2) that bans are not
the answer, but rather “better ideas” and “more
speech” are; (3) that a prohibition would have a dangerous
“chilling effect” and that hate speech bans are a slippery
slope to all sorts of unwanted restrictions; (4) that bans give the
state too much power to judge the content of speech and decide what
can or cannot be said, threatening state-neutrality, skewing political
debate, and infringing on individual liberty; (5) that bans are an
objectionable form of paternalism or moral authoritarianism, and is
incompatible with the assumption that humans are responsible and
autonomous individuals and that society is made up of free and equal
citizens; and finally, (6) that bans are ineffective at changing
attitudes and removing the hate from the hate speaker’s heart,
with the result that bans have the effect of moving extremists
underground, alienating them from wider society, and in doing so
rendering us ignorant of their violent potential and impotent to
engage in effective de-radicalization.
Each of these concerns merits more space than can be given to them
here. Still, considering these objections to bans and the responses
available, even briefly, is illustrative of the theoretical concerns
bans on hate speech bring forth (see the list of references for fuller
development of the relevant theoretical and empirical issues). Again
following Parekh (2012, 47–54), we can approach these objections
as follows.
In response to (1), the objection that the interests of a vibrant
democracy outweigh the harms imposed by hate speech, it may be argued
that hate speech does not embody the values of free speech but, in
fact, undermines them by promoting irrational fears and hatred over
reasoned arguments and public scrutiny. How powerful one takes this
response to be depends directly on what one takes the value and
justification of a right to free expression to be, which is of course
a matter of dispute.
One response to (2), the common ‘more speech’ objection,
is to note that the “marketplace of ideas” is not neutral,
and likely requires some regulation (just like a marketplace of other
goods). This is what a ban does, and so may be considered to be
helping ensure ‘fair competition’ by countering prevailing
prejudices, and encouraging greater participation from the members of
communities targeted by hate speech. In other words, bans on hate
speech may promote greater freedom of expression, by preventing the
type of silencing considered above.
While acknowledging the worries of (3), namely that of a
‘chilling effect’ or a ‘slippery slope,’
represent an important objection, we may respond by noting that the
problems these signal rest on the vague wording and inconsistent or
biased application of hate speech bans. They are not, therefore,
direct objections to hate speech bans as such. The remedy, therefore,
lies in correcting these aspects of a ban, rather than abandoning it
altogether. Moreover, the appeal to a ‘slippery slope’ may
be inapt, as it implies that once one type of speech is prohibited,
society cannot help but prohibit even more types. But we have no clear
reason to suppose that this is the case, as existing bans on
defamation have not led to bans on fair critical comment, for
example.
The worries at the core of objection (4) represents a well-founded
fear of the state, and so must be taken seriously. But, to defenders
of hate speech bans, its understanding of the threat that hate speech
bans pose to state-neutrality is nonetheless flawed. It fails to
recognize that the state often already judges the content of
speech (e.g., in banning commercial fraud, criminal solicitation,
public displays of obscenity) and often elides neutrality when it
speaks in favor of certain positions (e.g., the value of human
dignity, equality, liberty). While any defense of hate speech bans
must reckon with the possibility of further empowering the state,
opponents ought not misrepresent the status quo, exaggerating the
reality of state-neutrality.
Objections grounded on the threat of paternalism or moral
authoritarianism, like (5), are similarly serious. However, one
response on behalf of bans would be to point out how autonomy is
always exercised under certain conditions and requires various
external circumstances for its development and use. When appealing to
personal autonomy, therefore, we should not idealize too greatly so
that its real-world exercise is ignored. Rather, the threats that
racism and bigotry pose for autonomy must also be acknowledged,
alongside praise for our rational faculties.
One response to (6), that bans are ineffective at changing attitudes,
is to admit the law cannot change attitudes (like hatred) directly and
maintain that this is no knock against the law, and indeed is no
problem for hate speech bans. The aim of these bans, in most cases, is
not to prevent hatred but to prevent the harm that the public
expression of hate can cause. The indirect effects of such a law,
however, are an empirical matter, and it is unlikely they admit of a
single, general answer, but are highly context-dependent. The subject
of the practicability of hate speech bans deserves special attention,
however. Opponents to bans may worry that the suppression of hate
speech is likely to backfire, not only by failing to reduce hatred,
but by increasing the sense of oppression and victimization
that many bigots thrive on, leading to an escalation of racist
violence (Baker, 2012, 77). Again, as an empirical hypothesis, it
cannot be settled simply from the armchair. Still, a further response
available on behalf of hate speech bans would be to question the
legitimacy of this objection. If, by hypothesis, bans generated an
increase in violence, it would still be the responsibility of the
state to manage this violence effectively. The role of the state is
not exhausted by implementing a ban, but must be seen alongside its
enforcement.
This, however, leads to a slightly different objection. The opponent
of bans may worry that the enforcement of laws against hate speech
would divert the state’s energies away from more effective
measures against hated, such as “those directed at changing
material conditions in which racism festers, material conditions of
both the purveyors and targets of hate” (Baker, 2012, 77). That
is, the energies and resources that would be directed towards
establishing and enforcing hate speech bans may be better spent on
alternative policies. The guiding thought rests on two important
points. First, that the intended ends of hate speech bans (e.g.,
reduction in the harms of hate speech that fall on those targeted by
it, mitigation of the expansion of racist attitudes, lessening
occurrences of violent hate crimes) may be more effectively achieved
via different means, such as reducing inequality, improving social
safety nets, political empowerment, and more. Second, though the state
can do more than one thing at once, it is nonetheless working with
limited resources, and efficiency is a value. That these alternative
policy options may indeed be more effective is an unresolved empirical
matter. And it remains an open question whether indirect approaches
like this would fail to achieve the expressive ends of hate speech
bans, which more directly communicate to those targeted by hate speech
that they are valued members society.
Many of the claims made above, both on behalf of bans and in
opposition, raise theoretical and empirical issues whose proper
examination spans many articles and books. Suffice to say that the
debate over bans is a highly contested one, and each position rests on
an understanding of such issues as the value of free expression, the
harm of hate speech, the likely effects a ban might have in a
particular context, and so on. For instance, one who believes that
free expression is valuable in part because of its role in democratic
decision-making may maintain that specifically political
speech deserves increased protections, and that some of what others
regard as hate speech might fall into this category, escaping
regulation. Alternatively, one may view the immunity for political
speech as perhaps a red herring. On the speech act theoretic framework
outlined above, some forms of racist hate speech are functionally
identical to a ‘Whites Only’ sign hanging in a public
restaurant (McGowan 2012; McGowan and Maitra 2009). The latter
expresses a political opinion in the same way as the former expression
does, but it is also regarded as unlawful racially discriminatory. The
same considerations—legal sanction—might therefore apply
to the verbal utterance as the written sign, and the appeal to the
political content of the message is irrelevant.
The preceding summarizes the two main positions in the debate over
hate speech: on the one hand, there are those who defend prohibitions,
and on the other, those who maintain hate speech as protected under a
wide conception of freedom of expression, and so oppose laws that aim
at its prohibition. A third position aims to avoid some of the
impasses that haunt this debate. On this view, this impasse is the
result of a failure by those who oppose hate speech bans (and, as a
result, tend to favor ‘more speech’) to acknowledge the
strength of one of the main arguments from those who advocate for
bans, namely, that hate speech is a type of assault that often renders
one unable to respond. This, along with a failure of those who defend
bans from considering non-punitive options for mitigating the harms of
hate speech, leads to stalemate. On this understanding, both sides of
the debate over bans see the only alternatives as either increased
governmental powers to punish, or absent that,
‘unsupported’ counterspeech on the part of those targeted
by hate speech (see Gelber, 2012a; 2012b).
By contrast, the “supported counterspeech” alternative
aims to recognize the specific harms inflicted by hate speech and
provide state support to empower those who are harmed. Gelber, an
advocate for this alternative, places it within the capabilities
approach originally developed by Amartya Sen (1992) and Martha
Nussbaum (2000; 2003). “If hate-speech acts harm their
targets’ capacity to develop human capabilities,” Gelber
says, then “this is what needs to be remedied” (2012a,
54). The impetus for this approach therefore begins from the idea that
we must think about remedies to hate speech beyond restrictions and
punishment, as neither of these approaches achieve the goal of
empowering the target of hate speech. (This is especially true of the
latter, punishment, which also carries with it all the negative
consequences that anti-carceral advocates have noted.) The supported
counterspeech policy is therefore not focused on hate speakers, but
rather the targets of hate speech more directly.
The core of this approach lies in an enlarged conception of
counterspeech as well as a commitment by the state to provide the
material conditions necessary for this speech. In practice, this would
mean that the state is committed to responding to an incident of hate
speech by empowering its targets to engage in more speech, after the
fact. The specific forms this support may take will depend on the
conditions of different contexts, along with calibration for the
specifics of the incident it is meant as a response to, as well as the
needs of the particular communities. Still, to give a sense of what
this may entail, examples of the sort of supported counterspeech that
this position recommends include things such as: assistance in the
production of a community newsletters, op-eds, radio broadcasts, or
television advertisements; the development of antiracism awareness
programs, or anti-hate-speech workshops; subsidizing community-led art
projects; etc.
In each case, the aim of supported counterspeech is to empower the
targets of hate speech, and to increase their capacity for engaging in
counterspeech. The goal is thus to undo (as much as one can) the
specific harms of hate speech, while avoiding the pitfalls of
“private remedies” (as critiqued by Matsuda, 1993). While
supported counterspeech could be taken as either an alternative to
bans or a supplement to them, it remains an under-explored avenue for
considering responses tailored to the particular harms of hate
speech.