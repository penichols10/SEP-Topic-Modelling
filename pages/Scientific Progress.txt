The idea that science is a collective enterprise of researchers in
successive generations is characteristic of the Modern Age (Nisbet
1980). Classical empiricists (Francis Bacon) and rationalists
(René Descartes) of the seventeenth century urged that the use
of proper methods of inquiry guarantees the discovery and
justification of new truths. This cumulative view of scientific
progress was an important ingredient in the optimism of the eighteenth
century Enlightenment, and it was incorporated in the 1830s in Auguste
Comte’s program of positivism: by accumulating empirically
certified truths science also promotes progress in society. Other
influential trends in the nineteenth century were the Romantic vision
of organic growth in culture, Hegel’s dynamic account of
historical change, and the theory of evolution. They all inspired
epistemological views (e.g., among Marxists and pragmatists) which
regarded human knowledge as a process. Philosopher-scientists with an
interest in the history of science (William Whewell, Charles Peirce,
Ernst Mach, Pierre Duhem) gave interesting analyses of some aspects of
scientific change.
In the early twentieth century, analytic philosophers of science
started to apply modern logic to the study of science. Their main
focus was the structure of scientific theories and patterns of
inference (Suppe 1977). This “synchronic” investigation of
the “finished products” of scientific activities was
questioned by philosophers who wished to pay serious attention to the
“diachronic” study of scientific change. Among these
contributions one can mention N.R. Hanson’s Patterns of
Discovery (1958), Karl Popper’s The Logic of Scientific
Discovery (1959) and Conjectures and Refutations (1963),
Thomas Kuhn’s The Structure of Scientific Revolutions
(1962), Paul Feyerabend’s incommensurability thesis (Feyerabend
1962), Imre Lakatos’ methodology of scientific research
programmes (Lakatos and Musgrave 1970), and Larry Laudan’s
Progress and Its Problems (1977). Darwinist models of
evolutionary epistemology were advocated by Popper’s
Objective Knowledge: An Evolutionary Approach (1972) and
Stephen Toulmin’s Human Understanding (1972). These
works challenged the received view about the development of scientific
knowledge and rationality. Popper’s falsificationism,
Kuhn’s account of scientific revolutions, and Feyerabend’s
thesis of meaning variance shared the view that science does not grow
simply by accumulating new established truths upon old ones. Except
perhaps during periods of Kuhnian normal science, theory change is not
cumulative or continuous: the earlier results of science will be
rejected, replaced, and reinterpreted by new theories and conceptual
frameworks. Popper and Kuhn differed, however, in their definitions of
progress: the former appealed to the idea that successive theories may
approach towards the truth, while the latter characterized progress in
terms of the problem-solving capacity of theories. 
Since the mid-1970s, a great number of philosophical works have been
published on the topics of change, development, and progress in
science (Harré 1975; Stegmüller 1976; Howson 1976; Rescher
1978; Radnitzky and Andersson 1978, 1979; Niiniluoto and Tuomela 1979;
Dilworth 1981; Smith 1981; Hacking 1981; Schäfer 1983; Niiniluoto
1984; Laudan 1984a; Rescher 1984; Pitt 1985; Radnitzky and Bartley
1987; Callebaut and Pinxten 1987; Balzer et al. 1987; Hull 1988;
Gavroglu et al. 1989; Kitcher 1993; Pera 1994; Chang 2004; Maxwell
2017). These studies have also led to many important novelties being
added to the toolbox of philosophers of science. One of them is the
systematic study of inter-theory relations, such as reduction (Balzer
et al. 1984; Pearce 1987; Balzer 2000; Jonkisz 2000; Hoyningen-Huene
and Sankey 2001), correspondence (Krajewski 1977; Nowak 1980; Pearce
and Rantala 1984; Nowakowa and Nowak 2000; Rantala 2002), and belief
revision (Gärdenfors, 1988; Aliseda, 2006). Another was the
recognition that, besides individual statements and theories, there is
also a need to consider temporally developing units of scientific
activity and achievement: Kuhn’s paradigm-directed normal
science, Lakatos’ research programme, Laudan’s research
tradition, Wolfgang Stegmüller’s (1976) dynamic theory
evolution, Philip Kitcher’s (1993) consensus practice. A new
tool that is employed in many defenses of realist views of scientific
progress (Niiniluoto 1980, 2014; Aronson, Harré, and Way 1994;
Kuipers 2000, 2019) is the notion of truthlikeness or verisimilitude
(Popper 1963, 1970).
Lively interest about the development of science promoted close
co-operation between historians and philosophers of science. For
example, case studies of historical examples (e.g., the replacement of
Newton’s classical mechanics by quantum theory and theory of
relativity) have inspired many philosophical treatments of scientific
revolutions. Historical case studies were important for philosophers
who started to study scientific discovery (Hanson 1958; Nickles 1980).
Historically oriented philosophers have shown how instruments and
measurements have promoted the progress of physics and chemistry
(Chang 2004). Experimental psychologists have argued that the strive
for broad and simple explanations shapes learning and inference
(Lombrozo 2016). Further interesting material for philosophical
discussions about scientific progress is provided by quantitative
approaches in the study of the growth of scientific publications (de
Solla Price 1963; Rescher 1978) and science indicators (Elkana et
al. 1978). Sociologists of science have studied the dynamic
interaction between the scientific community and other social
institutions. With their influence, philosophers have analyzed the
role social and cultural values in the development of science (Longino
2002). One of the favorite topics of sociologists has been the
emergence of new scientific specialties (Mulkay 1975; Niiniluoto
1995b). Sociologists are also concerned with the pragmatic problem of
progress: what is the best way of organizing research activities in
order to promote scientific advance. In this way, models of scientific
change turn out to be relevant to issues of science policy (Böhme
1977; Schäfer 1983).
Science is a multi-layered complex system involving a community of
scientists engaged in research using scientific methods in order to
produce new knowledge. Thus, the notion of science may refer to a
social institution, the researchers, the research process, the method
of inquiry, and scientific knowledge. The concept of progress can be
defined relative to each of these aspects of science. Hence, different
types of progress can be distinguished relative to science:
economical (the increased funding of scientific research),
professional (the rising status of the scientists and their
academic institutions in the society), educational (the
increased skill and expertise of the scientists), methodical
(the invention of new methods of research, the refinement of
scientific instruments), and cognitive (increase or
advancement of scientific knowledge). These types of progress have to
be conceptually distinguished from advances in other human activities,
even though it may turn out that scientific progress has at least some
factual connections with technological progress (increased
effectiveness of tools and techniques) and social progress
(economic prosperity, quality of life, justice in society).
All of these aspects of scientific progress may involve different
considerations, so that there is no single concept that would cover
all of them. For our purposes, it is appropriate here to concentrate
only on cognitive progress, i.e., to give an account of advances of
science in terms of its success in knowledge-seeking or
truth-seeking.
“Progress” is an axiological or a normative concept, which
should be distinguished from such neutral descriptive terms as
“change” and “development” (Niiniluoto 1995a).
In general, to say that a step from stage \(A\) to stage \(B\)
constitutes progress means that \(B\) is an improvement over
\(A\) in some respect, i.e., \(B\) is better than \(A\)
relative to some standards or criteria. In science, it is a normative
demand that all contributions to research should yield some cognitive
profit, and their success in this respect can be assessed before
publication by referees (peer review) and after publication by
colleagues. Hence, the theory of scientific progress is not merely a
descriptive account of the patterns of developments that science has
in fact followed. Rather, it should give a specification of the
values or aims that can be used as the constitutive
criteria for “good science.” 
The “naturalist” program in science studies suggests that
normative questions in the philosophy of science can be reduced to
historical and sociological investigations of the actual practice of
science. In this spirit, Laudan has defended the project of testing
philosophical models of scientific change by the history of science:
such models, which are “often couched in normative
language,” can be recast “into declarative statements
about how science does behave” (Laudan et al. 1986; Donovan et
al. 1988). It may be the case that most scientific work, at least the
best science of each age, is also good science. But it is also evident
that scientists often have different opinions about the criteria of
good science, and rival researchers and schools make different choices
in their preference of theories and research programs. Therefore, it
can be argued against the naturalists that progress should not be
defined by the actual developments of science: the definition
of progress should give us a normative standard for appraising the
choices that the scientific communities have made, could have made,
are just now making, and will make in the future. The task of finding
and defending such standards is a genuinely philosophical one which
can be enlightened by history and sociology but which cannot be
reduced to empirical studies of science. For the same reason,
Mizrahi’s (2013) empirical observation that scientists talk
about the aim of science in terms of knowledge rather than merely
truth cannot settle the philosophical debate about scientific progress
(cf. Bird, 2007, Niiniluoto, 2014).
For many goal-directed activities it is important to distinguish
between quality and progress. Quality is primarily
an activity-oriented concept, concerning the skill and competence in
the performance of some task. Progress is a result-oriented concept,
concerning the success of a product relative to some goal. All
acceptable work in science has to fulfill certain standards of
quality. But it seems that there are no necessary connections between
quality and progress in science. Sometimes very well-qualified
research projects fail to produce important new results, while less
competent but more lucky works lead to success. Nevertheless, the
skillful use of the methods of science will make progress highly
probable. Hence, the best practical strategy in promoting scientific
progress is to support high-quality research. 
Following the pioneering work of Derek de Solla Price (1963) in
“scientometrics,” quantitative science indicators
have been proposed as measures of scientific activity (Elkana et
al. 1978). For example, output measures like publication
counts are measures of scholarly achievement, but it is
problematic whether such a crude measure is sufficient to indicate
quality (cf. Chotkowski La Follette 1982). The number of articles in
refereed journals is an indicator of the quality of their author, but
it is clear that this indicator cannot yet define what progress means,
since publications may contribute different amounts to the advance of
scientific knowledge. “Rousseau’s Law” proposed by
Nicholas Rescher (1978) marks off a certain part (the square root) of
the total number of publications as “important”, but this
is merely an alleged statistical regularity.
Another example of a science indicator, citation index, is an
indicator for the “impact” of a publication and for the
“visibility” of its author within the scientific
community. Martin and Irvine (1983) suggest that the concept of
scientific progress should be linked to the notion of impact,
i.e., the actual influence of research to the surrounding scientific
activities at a given time. It is no doubt correct that one cannot
advance scientific knowledge without influencing the epistemic state
of the scientific community. But the impact of a publication as such
only shows that it has successfully “moved” the scientific
community in some direction. If science is goal-directed, then we must
acknowledge that movement in the wrong direction does not
constitute progress.
The failure of science indicators to function as definitions of
scientific progress is due to the fact that they do not take into
account the semantic content of scientific publications. To
determine whether a work \(W\) gives a contribution to scientific
progress, we have to specify what \(W\) says (alternatively: what
problems \(W\) solves) and then relate this content of \(W\) to the
knowledge situation of the scientific community at the time of the
publication of \(W\). For the same reason, research assessment
exercises may use science indicators as tools, but ultimately they
have to rely on the judgment of peers who have substantial knowledge
in the field.
Progress is a goal-relative concept. But even when we
consider science as a knowledge-seeking cognitive enterprise, there is
no reason to assume that the goal of science is one-dimensional. In
contrast, as Isaac Levi’s classic Gambling With Truth
(1967) argued, the cognitive aim of scientific inquiry has to be
defined as a weighted combination of several different, and even
conflicting, epistemic utilities. As we shall see in Section
3, alternative theories of scientific progress can be understood as
specifications of such epistemic utilities. For example, they might
include truth and information (Levi 1967; see also Popper 1959, 1963)
or explanatory and predictive power (Hempel 1965). Kuhn’s (1977)
list of the values of science includes accuracy, consistency, scope,
simplicity, and fruitfulness.
A goal may be accessible in the sense that it can be reached
in a finite number of steps in a finite time. A goal is
utopian if it cannot be reached or even approached. Thus,
utopian goals cannot be rationally pursued, since no progress can be
made in an attempt to reach them. Walking to the moon is a utopian
task in this sense. However, not all inaccessible goals are utopian:
an unreachable goal, such as being morally perfect, can function as a
regulative principle in Kant’s sense, if it guides our
behavior so that we are able to make progress towards it.
The classical sceptic argument against science, repeated by Laudan
(1984a), is that knowing the truth is a utopian task. Kant’s
answer to this argument was to regard truth as a regulative principle
for science. Charles S. Peirce, the founder of American pragmatism,
argued that the access to the truth as the ideal limit of scientific
inquiry is “destined” or guaranteed in an
“indefinite” community of investigators. Almeder’s
(1983) interpretation of Peirce’s view of scientific progress is
that there is only a finite number of scientific problems and they
will all be solved in a finite time. However, there does not seem to
be any reason to think that truth is generally accessible in this
strong sense. Therefore, the crucial question is whether it is
possible to make rational appraisals that we have made progress in the
direction of the truth (see Section 3.4).
A goal is effectively recognizable if there are routine or
mechanical tests for showing that the goal has been reached or
approached. If the defining criteria of progress are not recognizable
in this strong sense, we have to distinguish true or real
progress from our perceptions or estimations of
progress. In other words, claims of the form ‘The step from
stage \(A\) to stage \(B\) is progressive’ have to be
distinguished from our appraisals of the form ‘The step from
stage \(A\) to stage \(B\) seems progressive on the available
evidence’. The latter appraisals, as our own judgments, are
recognizable, but the former claims may be correct without our knowing
it. Characteristics and measures that help us to make such appraisals
are then indicators of progress.
Laudan requires that a rational goal for science should be accessible
and effectively recognizable (Laudan 1977, 1984a). This requirement,
which he uses to rule out truth as a goal of science, is very strong.
The demands of rationality cannot dictate that a goal has to be given
up, if there are reasonable indicators of progress towards it. 
A goal may be backward-looking or forward-looking:
it may refer to the starting point or to the destination point of an
activity. If my aim is to travel as far from home as possible, my
success is measured by my distance from Helsinki. If I wish to become
ever better and better piano player, my improvement can be assessed
relative to my earlier stages, not to any ideal Perfect Pianist. But
if I want to travel to San Francisco, my progress is a function of my
distance from the destination. Only in the special case, where there
is only one way from \(A\) to \(B\), the backward-looking and the
forward-looking criteria (i.e., distance from \(A\) and
distance to \(B)\) determine each other. 
Kuhn and Stegmüller were advocating backward-looking criteria of
progress. In arguing against the view that “the proper measure
of scientific achievement is the extent to which it brings us closer
to” the ultimate goal of “one full, objective true account
of nature,” Kuhn suggested that we should “learn to
substitute evolution-from-what-we-know for
evolution-toward-what-we-wish-to-know” (Kuhn 1970, p. 171). In
the same spirit, Stegmüller (1976) argued that we should reject
all variants of “a teleological metaphysics” defining
progress in terms of “coming closer and closer to the
truth.”
A compromise between forward-looking and backward-looking criteria can
be proposed in the following way. If science is viewed as a
knowledge-seeking activity, it is natural to define real progress in
forward-looking terms: the cognitive aim of science is to know
something that is still unknown, and our real progress depends on our
distance from this destination. But, as this goal is unknown to us,
our estimates or perceptions of progress have to be based on
backward-looking evidential considerations. This kind of view of the
aims of science does not presuppose the existence of one
unique ultimate goal. To use Levi’s words, our goals may be
“myopic” rather than “messianic” (Levi 1985):
the particular target that we wish to hit in the course of our inquiry
has to be redefined “locally,” relative to each cognitive
problem situation. Furthermore, in addition to the multiplicity of the
possible targets, there may be several roads that lead to the same
destination. The forward-looking character of the goals of inquiry
does not exclude what Stegmüller calls “progress
branching.” This is analogous to the simple fact that we may
approach San Francisco from New York along two different
ways—via Chicago or St Louis. 
Some philosophers use the concepts of progress and rationality as
synonyms: progressive steps in science are precisely those that are
based upon the scientists’ rational choices. One possible
objection is that scientific discoveries are progressive when they
introduce novel ideas, even though they cannot be fully explained in
rational terms (Popper 1959; cf. Hanson 1958; Kleiner 1993). However,
another problem is more relevant here: By whose lights should such
steps be evaluated? This question is urgent especially if we
acknowledge that standards of good science have changed in history
(Laudan 1984a). 
As we shall see, the main rival philosophical theories of progress
propose absolute criteria, such as problem-solving capacity
or increasing truthlikeness, that are applicable to all developments
of science throughout its history. On the other hand, rationality is a
methodological concept which is historically relative: in
assessing the rationality of the choices made by the past scientists,
we have to study the aims, standards, methods, alternative theories
and available evidence accepted within the scientific community at
that time (cf. Doppelt, 1983, Laudan, 1987; Niiniluoto 1999a). If the
scientific community \(SC\) at a given point of time \(t\) accepted
the standards \(V\), then the preference of \(SC\) for theory \(T\)
over \(T'\) on evidence \(e\) was rational just in case the
epistemic utility of \(T\) relative to \(V\) was higher than that of
\(T'\). But in a new situation, where the standards were different
from \(V\), a different preference might have been rational. 
A major controversy among philosophers of science is between
instrumentalist and realist views of scientific theories (Leplin 1984;
Psillos 1999; Niiniluoto 1999a; Saatsi 2018). The
instrumentalists follow Duhem in thinking that theories are
merely conceptual tools for classifying, systematizing and predicting
observational statements, so that the genuine content of science is
not to be found on the level of theories (Duhem 1954). Scientific
realists, by contrast, regard theories as attempts to describe
reality even beyond the realm of observable things and regularities,
so that theories can be regarded as statements having a truth value.
Excluding naive realists, most scientists are fallibilists in
Peirce’s sense: scientific theories are hypothetical and always
corrigible in principle. They may happen to be true, but we cannot
know this for certain in any particular case. But even when theories
are false, they can be cognitively valuable if they are closer to the
truth than their rivals (Popper 1963). Theories should be testable by
observational evidence, and success in empirical tests gives inductive
confirmation (Hintikka 1968; Kuipers 2000) or non-inductive
corroboration to the theory (Popper 1959).
It might seem natural to expect that the main rival accounts of
scientific progress would be based upon the positions of
instrumentalism and realism. But this is only partly true. To be sure,
naive realists as a rule hold the accumulation-of-truths view of
progress, and many philosophers combine the realist view of theories
with the axiological thesis that truth is an important goal of
scientific inquiry. A non-cumulative version of the realist view of
progress can be formulated by using the notion of truthlikeness. But
there are also philosophers who accept the possibility of a realist
treatment of theories, but still deny that truth is a relevant value
of science which could have a function in the characterization of
scientific progress. Bas van Fraassen’s (1980) constructive
empiricism takes the desideratum of science to be empirical
adequacy: what a theory says about the observable should be true.
The acceptance of a theory involves only the claim that it is
empirically adequate, not its truth on the theoretical level. Van
Fraassen has not developed an account of scientific progress in terms
of his constructive empiricism, but presumably such an account would
be close to empiricist notions of reduction and Laudan’s account
of problem-solving ability (see Section 3.2).
An instrumentalist who denies that theories have truth values usually
defines scientific progress by referring to other virtues theories may
have, such as their increasing empirical success. In 1906 Duhem
expressed this idea by a simile: scientific progress is like a
mounting tide, where waves rise and withdraw, but under this
to-and-fro motion there is a slow and constant progress. However, he
gave a realist twist to his view by assuming that theories classify
experimental laws, and progress means that the proposed
classifications approach a “natural classification” (Duhem
1954).
Evolutionary epistemology is open to instrumentalist (Toulmin 1972)
and realist (Popper 1972) interpretations (Callebaut and Pinxten 1987;
Radnitzky and Bartley 1987). A biological approach to human knowledge
naturally gives emphasis to the pragmatist view that theories function
as instruments of survival. Darwinist evolution in biology is not
goal-directed with a fixed forward-looking goal; rather, species adapt
themselves to an ever changing environment. In applying this account
to the problem of knowledge-seeking, the fitness of a theory can be
taken to mean that the theory is accepted by members of the
scientific community. But a realist can reinterpret the evolutionary
model by taking fitness to mean the truth or truthlikeness of
a theory (Niiniluoto 1984).
For a constructive empiricist, it would be natural to think that among
empirically adequate theories one theory \(T_{2}\) is better than
another theory \(T_{1}\) if \(T_{2}\) entails more true observational
statements than \(T_{1}\). Such a comparison makes sense at least if
the observation statements entailed by \(T_{1}\) are a proper subset
of those entailed by \(T_{2}\). Kemeny and Oppenheim (1956) gave a
similar condition in their definition of reduction: \(T_{1}\) is
reducible to \(T_{2}\) if and only if \(T_{2}\) is at least as well
systematized as \(T_{1}\) and \(T_{2}\) is observationally stronger
than \(T_{1}\), i.e., all observational statements explained by
\(T_{1}\) are also consequences of \(T_{2}\). Variants of such an
empirical reduction relation has been given by the structuralist
school in terms of set-theoretical structures (Stegmüller 1976;
Scheibe 1986; Balzer et al. 1987; Moulines 2000). A similar idea, but
applied to cases where the first theory \(T_{1}\) has been falsified
by some observational evidence, was used by Lakatos in his definition
of empirically progressive research programmes: the new superseding
theory \(T_{2}\) should have corroborated excess content relative to
\(T_{1}\) and \(T_{2}\) should contain all the unrefuted content of
\(T_{1}\) (Lakatos and Musgrave 1970). The definition of Kuipers
(2000) allows that even the new theory \(T_{2}\) is empirically
refuted: \(T_{2}\) should have (in the sense of set-theoretical
inclusion) more empirical successes, but fewer empirical
counter-examples than \(T_{1}\). 
Against these cumulative definitions it has been argued that
definitions of empirical progress have to take into account an
important complication. A new theory often corrects the
empirical consequences of the previous one, i.e., \(T_{2}\) entails
observational statements \(e_{2}\) which are in some sense close to
the corresponding consequences \(e_{1}\) of \(T_{1}\). Various models
of approximate explanation and approximate reduction
have been introduced to handle these situations. An important special
case is the limiting correspondence relation: theory
\(T_{2}\) approaches theory \(T_{1}\) (or the observational
consequences of \(T_{2}\) approach those of \(T_{1})\) when some
parameter in its laws approaches a limit value (e.g., theory of
relativity approaches classical mechanics when the velocity of light c
grows without limit). Here \(T_{2}\) is said to be a concretization of
the idealized theory \(T_{1}\) (Nowak 1980; Nowakowa and Nowak 2000).
However, these models do not automatically guarantee that the step
from an old theory to a new one is progressive. For example, classical
mechanics can be related by the correspondence condition to an
infinite number of alternative and mutually incompatible theories, and
some additional criteria are needed to pick out the best among
them.
Kuhn’s (1962) strategy was to avoid the notion of truth and to
understand science as an activity of making accurate predictions and
solving problems or “puzzles”. Paradigm-based normal
science is cumulative in terms of the problems solved, and even
paradigm-changes or revolutions are progressive in the sense that
“a relatively large part” of the problem-solving capacity
of the old theory is preserved in the new paradigm. But, as Kuhn
argued, it may happen that some problems solved by the old theory are
no longer relevant or meaningful for the new theory. These cases are
called “Kuhn-losses.” A more systematic account of these
ideas is given by Laudan (1977): the problem-solving
effectiveness of a theory is defined by the number and importance
of solved empirical problems minus the number and importance of the
anomalies and conceptual problems that the theory generates. Here the
concept of anomaly refers to a problem that a theory fails to solve,
but is solved by some of its rivals. For Laudan the solution of a
problem by a theory \(T\) means that the “statement of the
problem” is deduced from \(T\). A good theory is thus
empirically adequate, strong in its empirical content,
and—Laudan adds—avoids conceptual problems. 
One difficulty for the problem-solving account is to find a proper
framework for identifying and counting problems (Rescher 1984; Kleiner
1993). When Newton’s mechanics is applied to determine the orbit
of the planet Mars, this can be counted as one problem. But, given an
initial position of Mars, the same theory entails a solution to an
infinite number of questions concerning the position of Mars at time
\(t\). Perhaps the most important philosophical issue is whether one
may consistently hold that the notion of problem-solving may be
entirely divorced from truth and falsity: the realist may admit that
science is a problem-solving activity, if this means the attempt to
find true solutions to predictive and explanatory questions
(Popper, 1972; Niiniluoto 1984). Bird’s (2007) main criticism
against the “functional account” of Kuhn and Laudan is its
consequence that the cumulation of false solutions from an entirely
false theory counts as scientific progress (e.g. Oresme in the
fourteenth century believed that hot goat’s blood could split
diamonds).
According to Shan (2019), “science progresses if more useful
research problems and their corresponding solutions are
proposed”. This definition involves both problem-defining and
problem-solving, as illustrated by the development of early genetics
from Darwin to Bateson. Shan gives up the typical Kuhn-Laudan
assumption that the scientific community is able to know whether it
makes progress or not, and is open to the introduction of the notions
of know-how and perspectival truth, so that his “new functional
approach” is a compromise with what Bird (2007) calls the
“epistemic view” of progress.
A different view of problem-solving is involved in those theories
which discuss problems of decision and action. A
radical pragmatist view treats science as a systematic method of
solving such decision problems relative to various kinds of practical
utilities. According to the view called behavioralism by the
statistician L J. Savage, science does not produce knowledge, but
rather recommendations for actions: to accept a hypothesis is always a
decision to act as if that hypothesis were true. Progress in science
can then be measured by the achievement of the practical utilities of
the decision maker. An alternative methodological version of
pragmatism is defended by Rescher (1977) who accepts the realist view
of theories with some qualifications, but argues that the progress of
science has to be understood as “the increasing success of
applications in problem-solving and control.” Similarly, Douglas
(2014), after suggesting that the distinction between pure and applied
science should be relinquished, defines progress “in terms of
the increased capacity to predict, control, manipulate, and intervene
in various contexts.” In this view, the notion of scientific
progress is in effect reduced to science-based technological progress
(cf. Niiniluoto 1984).
Already the ancient philosophers regarded explanation as an important
function of science. The status of explanatory theories was
interpreted either in an instrumentalist or realist way: Plato’s
school started the tradition of “saving the appearances”
in astronomy, while Aristotle took theories to be necessary truths.
Both parties can take explanatory power to be a criterion of
a good theory, as shown by van Fraassen’s (1980) constructive
empiricism and Wilfrid Sellars’ scientific realism (Pitt 1981;
Tuomela 1985). When it is added that a good theory should also yield
true empirical predictions, the notions of explanatory and predictive
power can be combined within the notion of systematic power
(Hempel 1965). If the demand of systematic power simply means that a
theory has many true deductive consequences in the observational
language, this concept is essentially equivalent to the notion of
empirical success and empirical problem-solving ability discussed in
Section 3.2, but normally explanation is taken to include additional
structural conditions besides mere deduction (Aliseda 2006). Inductive
systematization should also be taken into account (Hempel 1965;
Niiniluoto and Tuomela 1973).
One important idea regarding systematization is that a good theory
should unify empirical data and laws from different domains
(Kitcher 1993; Schurz 2015). For Whewell, the paradigm case of such
“consilience” was the successful unification of
Kepler’s laws and Galileo’s laws by means of
Newton’s theory.
If theories are underdetermined by observational data, then one is
often advised to choose the simplest theory compatible with the
evidence (Foster and Martin 1966). Simplicity may be an
aesthetic criterion of theory choice (Kuipers 2019), but it may also
have a cognitive function in helping us in our attempt to understand
the world in an “economical” way. Ernst Mach’s
notion of the economy of thought is related to the demand of
manageability, which is important especially in the
engineering sciences and other applied sciences: for example, a
mathematical equation can be made “simpler” by suitable
approximations, so that it can be solved by a computer. Simplicity has
also been related to the notion of systematic or unifying power. This
is clear in Eino Kaila’s concept of relative
simplicity, which he defined in 1939 as the ratio between the
explanatory power and the structural complexity of a theory (for a
translation, see Kaila 2014). According to this conception, progress
can be achieved by finding structurally simpler explanations of the
same data, or by increasing the scope of explanations without making
them more complex. Laudan’s formula of solved empirical problems
minus generated conceptual problems is a variation of the same
idea.
After Hempel’s pioneering work in 1948, various probabilistic
measures of explanatory power have been proposed (Hempel 1965;
Hintikka 1968). Most of them demand that the explanatory theory \(h\)
should be positively relevant to the empirical data \(e\). This is the
case also with the particular proposal 

\[
\frac{P(h\mid e) - P(h\mid\neg e)}{P(h\mid e) + P(h\mid\neg e)}
\]

 defended by
Schupbach and Sprenger (2011) as the unique measure which satisfies
seven intuitively plausible adequacy conditions.
Realist theories of scientific progress take truth to be an important
goal of inquiry. This view is built into the classical definition of
knowledge as justified true belief: if science is a knowledge-seeking
activity, then it is also a truth-seeking activity. However, truth
cannot be the only relevant epistemic utility of inquiry. This is
shown in a clear way by cognitive decision theory (Levi 1967;
Niiniluoto 1987).
Let us denote by \(B = \{h_{1}, \ldots ,h_{n}\}\) a set of mutually
exclusive and jointly exhaustive hypotheses. Here the hypotheses in
\(B\) may be the most informative descriptions of alternative states
of affairs or possible worlds within a conceptual framework \(L\). For
example, they may be complete theories expressible in a finite
first-order language. If \(L\) is interpreted on a domain \(U\), so
that each sentence of \(L\) has a truth value (true or false), it
follows that there is one and only one true hypothesis (say \(h^*\))
in \(B\). Our cognitive problem is to identify the target
\(h^*\) in \(B\). The elements \(h_{i}\) of \(B\) are the (potential)
complete answers to the problem. The set \(D(B)\) of
partial answers consists of all non-empty disjunctions of
complete answers. The trivial partial answer in \(D(B)\),
corresponding to ‘I don’t know’, is represented by a
tautology, i.e., the disjunction of all complete answers. 
For any \(g\) in \(D(B)\), we let \(u(g, h_{j})\) be the epistemic
utility of accepting \(g\) if \(h_{j}\) is true. We also assume that a
rational probability measure \(P\) is associated with language \(L\),
so that each \(h_{j}\) can be assigned with its epistemic probability
\(P(h_{j}\mid e)\) given evidence \(e\). Then the best hypothesis in
\(D(B)\) is the one \(g\) which maximizes the expected epistemic
utility
For comparative purposes, we may say that one hypothesis is better
than another if it has a higher expected utility than the other by
formula (1).
If truth is the only relevant epistemic utility, all true answers are
equally good and all false answers are equally bad. Then we may take
\(u(g, h_{j})\) simply to be the truth value of \(g\) relative to
\(h_{j}\):
Hence, \(u(g, h^*)\) is the real truth value \(tv(g)\) of \(g\)
relative to the domain \(U\). It follows from (1) that the expected
utility \(U(g\mid e)\) equals the posterior probability \(P(g\mid e)\)
of \(g\) on \(e\). In this sense, we may say that posterior
probability equals expected truth value. The rule of maximizing
expected utility leads now to an extremely conservative policy: the
best hypotheses \(g\) on \(e\) are those that satisfy \(P(g\mid e) =
1\), i.e., are completely certain on \(e\) (e.g. \(e\) itself, logical
consequences of \(e\), and tautologies). On this account, if we are
not certain of the truth, then it is always progressive to change an
uncertain answer to a logically weaker one.
The argument against using high probability as a criterion of theory
choice was made already by Popper in 1934 (see Popper 1959). He
proposed that good theories should be bold or improbable. This idea
has been made precise in the theory of semantic information. 
Levi (1967) measures the information content \(I(g)\) of a partial
answer \(g\) in \(D(B)\) by the number of complete answers it
excludes. With a suitable normalization, \(I(g) = 1\) if and only if
\(g\) is one of the complete answers \(h_{j}\) in \(B\), and \(I(g) =
0\) for a tautology. If we now choose \(u(g, h_{j}) = I(g)\), then
\(U(g\mid e) = I(g)\), so that all the complete answers in B have the
same maximal expected utility 1. This measure favors strong
hypotheses, but it is unable to discriminate between the strongest
ones. For example, the step from a false complete answer to the true
one does not count as progress. Therefore, information cannot be the
only relevant epistemic utility.
Another measure of information content is \(cont(g) = 1 - P(g)\)
(Hintikka 1968). If we choose \(u(g, h_{j}) = cont(g)\), then the
expected utility \(U(g\mid e) = 1 - P(g)\) is maximized by a
contradiction, as the probability of a contradictory sentence is zero.
Any false theory can be improved by adding new falsities to it. Again
we see that information content alone does not give a good definition
of scientific progress. The same remark can be made about explanatory
and systematic power.
Levi’s (1967) proposal for epistemic utility is the weighted
combination of the truth value \(tv(g)\) of \(g\) and the information
content \(I(g)\) of \(g\):
where \(0 \lt a \lt \bfrac{1}{2}\) is an “index of
boldness,” indicating how much the scientist is willing to risk
error, or to “gamble with truth,” in her attempt to be
relieved from agnosticism. The expected epistemic utility of \(g\) is
then
A comparative notion of progress ‘\(g_{1}\) is better than
\(g_{2}\)’ could be defined by requiring that both \(I(g_{1})
\gt I(g_{2})\) and \(P(g_{1}\mid e) \gt P(g_{2}\mid e)\), but most
hypotheses would be incomparable by this requirement. By using the
weight \(a\), formula (3) expresses a balance between two mutually
conflicting goals of inquiry. It has the virtue that all partial
answers \(g\) in \(D(B)\) are comparable with each other: \(g\) is
better than \(g'\) if and only if the value of (3) is larger for \(g\)
than for \(g'\). 
If epistemic utility is defined by information content cont(g) in a
truth-dependent way, so that 
(i,e., in accepting hypothesis \(g\), we gain the content of \(g\) if
\(g\) is true, but we lose the content of the true hypothesis \(\neg
g\) if \(g\) is false), then the expected utility \(U(g\mid e)\) is
equal to 
This measure combines the criteria of boldness (small prior
probability \(P(g))\) and high posterior probability \(P(g\mid e)\).
Similar results can be obtained if \(cont(g)\) is replaced by
Hempel’s (1965) measure of systematic power \(syst(g, e) =
P(\neg g\mid \neg e)\).
For Levi, the best hypothesis in \(D(B)\) is the complete true answer.
But his utility assignment also makes assumptions that may seem
problematic: all false hypotheses (even those that make a very small
error) are worse than all truths (even the uninformative tautology);
all false complete answers have the same utility (see, however, the
modified definition in Levi, 1980); among false hypotheses utility
covaries with logical strength (i.e. if \(h\) and \(h'\) are false and
\(h\) entails \(h'\), then \(h\) has greater utility than \(h')\).
These features are motivated by Levi’s project of using
epistemic utility as a basis of acceptance rules. But if such
utilities are used for ordering rival theories, then the theory of
truthlikeness suggests other kinds of principles.
Popper’s notion of truthlikeness is also a combination of truth
and information (Popper 1963, 1972). For him, verisimilitude
represents the idea of “approaching comprehensive truth.”
Popper’s explication used the cumulative idea that the more
truthlike theory should have (in the sense of set-theoretical
inclusion) more true consequences and less false consequences, but it
turned out that this comparison is not applicable to pairs of false
theories. An alternative method of defining verisimilitude, initiated
in 1974 by Pavel Tichy and Risto Hilpinen, relies essentially on the
concept of similarity. 
In the similarity approach, as developed in Niiniluoto (1987),
closeness to the truth is explicated “locally” by means of
the distances of partial answers \(g\) in \(D(B)\) to the target
\(h^*\) in a cognitive problem \(B\). For this purpose, we need a
function \(d\) which expresses the distance \(d(h_{i}, h_{j}) =:
d_{ij}\) between two arbitrary elements of \(B\). By normalization, we
may choose \(0 \le d_{ij} \le 1\). The choice of \(d\) depends on the
cognitive problem \(B\), and makes use of the metric structure of
\(B\) (e.g., if \(B\) is a subspace of the real numbers \(\Re)\) or
the syntactic similarity between the statements in \(B\). Then, for a
partial answer \(g\), we let \(D_{\min}(h_{i}, g)\) be the minimum
distance of the disjuncts in \(g\) from \(h_{i}\), and
\(D_{\rmsum}(h_{i}, g)\) the normalized sum of the distances of the
disjuncts of \(g\) from \(h_{i}\). Then \(D_{\min}(h_{i}, g)\) tells
how close to \(h_{i}\) hypothesis \(g\) is, so that the degree of
approximate truth of \(g\) (relative to the target \(h^*\))
is \(1 - D_{\min}(h^*, g)\). On the other hand, \(D_{\rmsum}(h_{i},
g)\) includes a penalty for all the mistakes that \(g\) allows
relative to \(h_{i}\). The min-sum measure 
where \(a \gt 0\) and \(b \gt 0\), combines these two aspects. Then
the degree of truthlikeness of \(g\) is 
Thus, parameter \(a\) indicates our cognitive interest in hitting
close to the truth, and parameter \(b\) indicates our interest in
excluding falsities that are distant from the truth. In many
applications, choosing \(a\) to be equal to \(2b\) gives intuitively
reasonable results.
If the distance function \(d\) on \(B\) is trivial, i.e., \(d_{ij} =
1\) if and only if \(i = j\), and otherwise 0, then \(Tr(g, h^*)\)
reduces to the variant (2) of Levi’s definition of epistemic
utility.
Obviously \(Tr(g, h^*)\) takes its maximum value 1 if and only if
\(g\) is equivalent to \(h^*\). If \(g\) is a tautology, i.e., the
disjunction of all elements \(h_{i}\) of \(B\), then \(Tr(g,h^*) = 1 -
b\). If \(Tr(g, h^*) \lt 1 - b\), \(g\) is misleading in the strong
sense that its cognitive value is smaller than that of complete
ignorance.
Oddie (1986) has continued to favor the average function instead of
the min-sum measure. An alternative account of truth approximation is
given by Kuipers (2019).
When \(h^*\) is unknown, the degree of truthlikeness (6) cannot be
calculated. But the expected degree of verisimilitude of a
partial answer \(g\) given evidence \(e\) is given by
If evidence \(e\) entails some \(h_{j}\) in \(B\), or makes \(h_{j}\)
completely certain (i.e., \(P(h_{j}\mid e) = 1)\), then \(ver(g\mid
e)\) reduces to \(Tr(g,h_{j})\). If all the complete answers \(h_{i}\)
in \(B\) are equally probable on \(e\), then \(ver(h_{i}\mid e)\) is
also constant for all \(h_{i}\). 
The truthlikeness function \(Tr\) allows us to define an absolute
concept of real progress:
and the expected truthlikeness function \(ver\) gives the relative
concept of estimated progress:
(Cf. Niiniluoto 1980.) According to definition RP, it is meaningful to
say that one theory \(g'\) satisfies better the cognitive goal of
answering problem \(B\) than another theory \(g\). This is an absolute
standard of scientific progress in the sense of Section 2.5.
Definition EP shows how claims of progress can be fallibly evaluated
on the basis of evidence: if \(ver(g\mid e) \lt ver(g'\mid e)\), it is
rational to claim on evidence \(e\) that the step from \(g\) to \(g'\)
in fact is progressive. This claim may of course be mistaken, since
estimation of progress is relative to two factors: the available
evidence \(e\) and the probability measure \(P\) employed in the
definition of \(ver\). Both evidence \(e\) and the epistemic
probabilities \(P(h_{i}\mid e)\) may mislead us. In this sense, the
problem of estimating verisimilitude is as difficult as the problem of
induction. 
Rowbottom (2015) argues against RP and EP that scientific progress is
possible in the absence of increasing verisimilitude. He asks us to
imagine that the scientists in a specific area of physics have found
the maximally truthlike theory C*. Yet this general true theory could
be used for further predictions and applications. This is indeed the
case if we do not make the idealized assumption that the scientists
know all the logical consequences of their theories. Then the
explanations and predictions from C* constitute new cognitive
problems. Moreover, in Rowbottom’s thought experiment further
progress is possible by expanding the conceptual framework in order to
consider as a target a deeper truth than C* (Niiniluoto 2017). 
The measure of expected truthlikeness can be used for retrospective
comparisons of past theories \(g\), if evidence \(e\) is taken to
include our currently accepted theory \(T\), i.e., the truthlikeness
of \(g\) is estimated by \(ver(g\mid e \amp T)\) (Niiniluoto, 1984,
171). In the same spirit, Barrett (2008) has proposed
that—assuming that science makes progress toward the truth
through the elimination of descriptive error—the “probable
approximate truth” of Newtonian gravitation can be warranted by
its “nesting relations” to the General Theory of
Relativity.
The definition of progress by RP can be contrasted with the model of
belief revision (Gärdenfors, 1988). The simplest case of revision
is expansion: a theory \(T\) is conjoined by an input statement \(A\),
so that the new theory is \(T \amp A\). According to the min-sum
measure, if \(T\) and \(A\) are true, then the expansion \(T \amp A\)
is at least as truthlike as \(T\). But if \(T\) is false and \(A\) is
true, then \(T \amp A\) may be less truthlike than \(T\). For example,
let the false theory \(T\) state that the number of planets is 9 or
20, and let \(A\) be the true sentence that this number is 8 or 20.
Then \(T \amp A\) states that the number of planets is 20, but this is
clearly less truthlike than \(T\) itself. Similar examples show that
the AGM revision of a false theory by true input need not increase
truthlikeness (Niiniluoto 2011).
Bird (2007) has defended the epistemic definition of progress
(accumulation of knowledge) against the semantic conception
(accumulation of true beliefs or succession of theories with
increasing verisimilitude). Here knowledge is not defined as justified
true belief, but still it is taken to entail truth and justification,
so that Bird’s epistemic view in fact returns to the old
cumulative model of progress. According to Bird, an accidentally true
or truthlike belief reached by irrational methods without any
justification does not constitute progress. This kind of thought
experiment may seem artificial, since there is always some sort of
justification for any hypothetical theory which is accepted or at
least seriously considered by the scientific community. But
Bird’s argument raises the important question whether
justification is merely instrumental for progress (Rowbottom, 2008) or
necessary for progress (Bird, 2008). Another interesting question is
whether the rejection of unfounded but accidentally true beliefs is
regressive. The truthlikeness approach replies to these problems by
distinguishing real progress RP and estimated progress EP:
justification is not constitutive of progress in the sense of RP, but
claims of real progress can be justified by appealing to expected
verisimilitude (Cevolani and Tambolo, 2013). On the other hand, the
notion of progress explicated by EP (or by the combination of RP and
EP) is relative to evidence and justification but at the same time
non-cumulative.
Bird (2015) can reformulate his initial example by assuming that an
accidentally true or truthlike theory \(H\) has been obtained by
scientific but yet unreliable means, perhaps by derivation from an
accepted theory which turns out to be false. Does such application of
mistaken reasoning constitute progress? The interplay of RP and EP
allows several possibilities here. Later evidence might show that the
initial estimate \(ver(H\mid e)\) was too high. Or the Tr-value was in
fact high but initially the ver-value was low (e.g. Aristarchus on
heliocentric system, Wegener on continental drift) and only later it
was increased by new evidence.
Most accounts of truthlikeness satisfy the principle that among true
theories truthlikeness covaries with logical strength (for an
exception, see Oddie, 1986). So accumulation of knowledge is a special
case of increasing verisimilitude, but it does not cover the case of
progress by successive false theories. In his attempt to rehabilitate
the cumulative knowledge model of scientific progress, Bird admits
that there are historical sequences of theories none of which are
“fully true” (e.g. Ptolemy—Copernicus—Kepler
or Galileo—Newton—Einstein). As knowledge entails truth,
Bird tries to save his epistemic account by reformulating past false
theories as true ones. He proposes that if \(g\) is approximately
true, then the proposition “approximately \(g\)” is true,
so that “the improving precision of approximations can be an
object of knowledge”. One problem with this treatment is that
scientists typically formulate their theories as exact statements, and
at the time of their proposal it is not known how large margins of
errors would be needed to transform them into true theories. With
reference to Barrett (2008), Saatsi (2019) argues that the approximate
truth of Newtonian mechanics can be assessed only from the vantage
point of General Theory of Relativity, so that this knowledge was not
epistemically accessible to Newton at his time. Further, many past
theories were radically false rather than approximately true or
truthlike, but still they could be improved by more truthlike
successors. Ptolemy’s geocentric theory was rejected in the
Copernican revolution, not retained in the form “approximately
Ptolemy”. Indeed, the progressive steps from Ptolemy to
Copernicus or from Newton to Einstein are not only matters of improved
precision but involve changes in theoretical postulates and laws. A
further problem for Bird’s proposal is the question whether his
approximation propositions are able to distinguish between progress
and regress in science (Niiniluoto, 2014).
Dellsén (2016, 2018b) has formulated the noetic
account of scientific progress as increasing understanding. Using
objectual understanding instead of understanding-why, he characterizes
understanding in terms of “grasping how to correctly explain and
predict aspects of a given target”. Against Bird (2007), who
takes understanding to be a species of knowledge of causes,
Dellsén argues that understanding does not require the
scientists to have justification for, or even belief in, the
explanations or predictions they propose. Still, understanding is a
matter of degree. Thus, there are increases in scientific
understanding without accumulation of scientific knowledge (e.g.
Einstein’s explanation of Brownian motion in terms of the
kinetic theory of heat) and accumulation of scientific knowledge
without increases in understanding (e.g. knowledge about random
experimental outcomes or spurious statistical correlations). The
latter thesis is easy to accept, especially if explanation needs laws,
but on the other hand the epistemic and truthlikeness approaches could
agree that the collection of new important data may constitute
scientific progress. The possibility of “quasi-factive”
understanding by means of idealized theories (a common feature with
the verisimilitudinarian approach) is taken to be an advantage of the
noetic account. Park (2017) has challenged Dellsén’s
conclusions against the epistemic definition. He argues that
scientific understanding involves beliefs that the explained phenomena
are real and the confirmed predictions are true. He also argues that
Wegener’s continental drift theory, which was not supported by
available evidence, was progressive, since it paved the way for the
later theory of plate tectonics in the 1960s. Dellsén (2018a)
questions Park’s arguments by rejecting the “means-end
thesis”, i.e., one should make the crucial distinction between
cognitive and non-cognitive scientific progress and likewise
distinguish episodes that constitute and promote
scientific progress.
In Section 3.5., we made a distinction between real and estimated
progress in terms of the truthlikeness measures. A similar distinction
can be made in connection with measures of empirical success. For
example, one may distinguish two notions of the problem-solving
ability of a theory: the number of problems solved so far,
and the number of solvable problems. Real progress could be
defined by the latter, while the former gives us an estimate of
progress.
The scientific realist may continue this line of thought by arguing
that all measures of empirical success in fact are at best indicators
of real cognitive progress, measured in terms of truth or
truthlikeness. For example, if \(T\) explains \(e\), then it can be
shown that \(e\) also confirms \(T\), or increases the
probability of \(T\) (Niiniluoto 1999b). A similar reasoning can be
employed to give the so-called “ultimate argument” or
“no miracle argument”for scientific realism: theoretical
realism is the only assumption that does not make the empirical
success of science a miracle (Putnam, 1978; Psillos 1999; Niiniluoto
2017; Kuipers 2019; cf. criticism in Laudan 1984b). This means that
the best explanation of the empirical progress of science is the
hypothesis that science is also progressive on the level of
theories.
The thesis that science is progressive is an overall claim about
scientific activities. It does not imply that each particular step in
science has in fact been progressive: individual scientists make
mistakes, and even the scientific community is fallible in its
collective judgments. For this reason, we should not propose such a
definition that the thesis about the progressive nature of science
becomes a tautology or an analytic truth. This undesirable consequence
follows if we define truth as the limit of scientific inquiry
(this is sometimes called the consensus theory of truth), as then it
is a mere tautology that the limit of scientific research is the truth
(Laudan 1984a). But this “trivialization of the self-corrective
thesis” cannot be attributed to Peirce who realized that truth
and the limit of inquiry coincide at best with probability one
(Niiniluoto 1980). The notion of truthlikeness allows us to make sense
of the claim that science converges towards the truth. But the
characterization of progress as increasing truthlikeness, given in
Section 3.5, does not presuppose “teleological
metaphysics” (Stegmüller 1976), “convergent
realism” (Laudan 1984), or “scientific eschatology”
(Moulines 2000), as it does not rely on any assumption about the
future behavior of science.
The claim about scientific progress can still be questioned by the
theses that observations and ontologies are relative to theories. If
this is true, the comparison of rival theories appears to be
impossible on cognitive or rational grounds. Kuhn (1962) compared
paradigm-changes to Gestalt switches (Dilworth 1981). Feyerabend
(1984) concluded from his methodological anarchism that the
development of science and art resemble each other.
Hanson, Popper, Kuhn, and Feyerabend agreed that all observation
is theory-laden, so that there is no theory-neutral observational
language. Accounts of reduction and progress, which take for granted
the preservation of some observational statements within
theory-change, thus run into troubles. Even though Laudan’s
account of progress allows Kuhn-losses, it can be argued that the
comparison of the problem-solving capacity of two rival theories
presupposes some kind of correlation or translation between the
statements of these theories (Pearce 1987). Various replies have been
proposed to this issue. One is the movement from language to
structures (Stegmüller 1976; Moulines 2000), but it turns out
that a reduction on the level structures already guarantees
commensurability, since it induces a translation between conceptual
frameworks (Pearce 1987). Another has been the point that an evidence
statement \(e\) may happen to be neutral with respect to rival
theories \(T_{1}\) and \(T_{2}\), even though it is laden with some
other theories. The realist may also point that the theory-ladenness
of observations concerns at most the estimation of progress (EP), but
the definition of real progress (RP) as increasing truthlikeness does
not mention the notion of observation at all.
Even though Popper accepted the theory-ladenness of observations, he
rejected the more general thesis about incommensurability as
“the myth of the framework” (Lakatos and Musgrave 1970).
Popper insisted that the growth of knowledge is always revolutionary
in the sense that the new theory contradicts the old one by correcting
it, but there is still continuity in theory-change, as the new theory
should explain why the old theory was successful to some extent.
Feyerabend tried to claim that successive theories are both
inconsistent and incommensurable with each other, but this combination
makes little sense. Kuhn argued against the possibility of finding
complete translations between the languages of rival theories, but in
his later work he admitted the possibility that a scientist may learn
different theoretical languages (Hoyningen-Huene 1993). Kuhn kept
insisting that there is “no theory-independent way to
reconstruct phrases like ‘really there’,” i.e., each
theory has its own ontology. Convergence to the truth seems to be
impossible, if ontologies change with theories. The same idea has been
formulated by Putnam (1978) and Laudan (1984a) in the so-called
“pessimistic meta-induction”: as many past theories in
science have turned out to be non-referring, there is all reason to
expect that even the future theories fail to refer—and thus also
fail to be approximately true or truthlike. But the optimistic reply
by comparative realists points out that for all rejected theories in
Laudan’s list the scientists have been able to find a better,
more truthlike alternative (Niiniluoto 2017; Kuipers 2019).
The difficulties for realism seem to be reinforced by the observation
that measures of truthlikeness are relative to languages. The choice
of conceptual frameworks cannot be decided by means of the notion of
truthlikeness, but needs additional criteria. In defense of the
truthlikeness approach, one may point to the fact that the comparison
of two theories is relevant only in those cases where they are
considered (perhaps via a suitable translation) as rival answers to
the same cognitive problem. It is interesting to compare
Newton’s and Einstein’s theories for their truthlikeness,
but not Newton’s and Darwin’s theories. When definitions
RP and EP are applied to rival theories in different languages, they
have to be translated into a common conceptual framework. 
Another line is to appeal to theories of reference in order to show
that rival theories can after all be regarded as speaking about the
same entities (Psillos 1999). For example, Thompson, Bohr, and later
physicists are talking about the same electrons, even though their
theories of the electron differ from each other. This is not possible
on the standard descriptive theory of reference: a theory \(T\) can
only refer to entities about which it gives a true description.
Kuhn’s and Feyerabend’s meaning holism, with devastating
consequences for realism, presupposes this account of reference. A
similar argument is used by Moulines (2000), who denies that progress
could be understood as “knowing more about the same,” but
his own structuralist reconstruction of progress with “partial
incommensurability” assumes that rival theories share some
intended applications. Causal theories of reference allow that
reference is preserved even within changes of theories (Kitcher 1993).
The same result is obtained if the descriptive account is modified by
introducing a Principle of Charity (Putnam 1975; Smith 1981;
Niiniluoto 1999a): a theory refers to those entities about which it
gives the most truthlike description. An alternative account,
illustrated by the relation of phlogiston theory and oxygen theory, is
given by Schurz (2011) by his notion of structural correspondence.
This makes it possible that even false theories are referring.
Moreover, there can be reference invariance between two successive
theories, even though both of them are false; progress means then that
the latter theory gives a more truthlike description about their
common domain than the old theory. 