The term ‘structuralism’ is used with different meanings
and therefore it seems appropriate to mention other
‘structuralisms’ and to explain how ‘structuralism
in physics’ is related to them. If you check the entry
 ‘structuralism (disambiguation)’
 in Wikipedia, you will be informed that there is a spectrum of
‘structuralisms’ in 11 different areas, including: 
Here we have mentioned some prominent representatives in brackets. All
types of structuralism share a common conviction about the rôle
of structures in their respective disciplines, but at first glance
they show little similarity. Nevertheless, there are connections and
mutual influences between the different structuralisms. It goes beyond
the scope of this entry to examine these influences in more detail.
For the relations between anthropologic and mathematical structuralism
see Aubin (1997). As mentioned, we will understand
‘structuralism in physics’ as a special case of
‘structuralism in philosophy of science’. There are close
connections with mathematical structuralism, which we will discuss in
more detail in the main part of this entry. To illustrate these
connections here we only mention the full title of Stegmüller
(1979a): The structuralist view of theories, A possible analogue of
the Bourbaki programme in physical science. 
Right now, we are taking the interim balance that ‘Structuralism
in Physics’ is part of an intellectual movement mainly in the
20th century and, compared to other structuralisms, represents a
rather late contribution. 
The three programs mentioned in the preamble share the following
characteristics and convictions:
A physical theory \(T\) consists, among other things, of a group of
laws which are formulated in terms of certain concepts. But an
apparent circularity arises when one considers how the laws of \(T\)
and the concepts acquire their content, because each seems to acquire
content from the other — the laws of \(T\) acquire their content
from the concepts used in the formulation of the laws, while the
concepts are often “introduced” or “defined”
by the group of laws as a whole. To be sure, if the concepts can be
introduced independently of the theory \(T\), the circularity does not
appear. But typically every physical theory \(T\) requires some new
concepts which cannot be defined without using \(T\) (we call the
latter “\(T\)-theoretical concepts”). Is the apparent
circularity concerning the laws and the T-theoretical concepts a
problem? Some examples will help us assess the threat. 
As an example, consider the theory \(T\) of classical particle
mechanics. For simplicity we will assume that kinematical concepts,
such as the positions of particles, their velocities and accelerations
are given independently of the theory as functions of time. A central
statement of \(T\) is Newton’s second law, \(\bF= m\ba\), which
asserts that the sum \(\bF\) of the forces exerted upon a particle
equals its mass \(m\) multiplied by its acceleration \(\ba\). 
While we customarily think of \(\bF=m\ba\) as an empirical assertion,
there is a real risk that it turns out merely to be a definition or
largely conventional in character. If we think of a force merely as
“that which generates acceleration” then the force \(\bF\)
is actually defined by the equation \(\bF=m\ba\). We have a particle
undergoing some given acceleration \(\ba\), then \(\bF=m\ba\) just
defines what \(\bF\) is. The law is not an empirically testable
assertation at all, since a force so defined cannot fail to satisfy
\(\bF=m\ba\). The problem gets worse if we define the (inertial) mass
\(m\) in the usual manner as the ratio \(|\bF|/|\ba\)|. For now we are
using the one equation \(\bF=m\ba\) to define two quantities \(\bF\)
and \(m\). A given acceleration \(\ba\) at best specifies the ratio
\(\bF/m\) but does not specify unique values for \(\bF\) and \(m\)
individually.
In more formal terms, the problem arises because we introduced force
\(\bF\) and mass \(m\) as \(T\)-theoretical terms that are not given
by other theories. That fact also supplies an escape from the problem.
We can add extra laws to the simple dynamics. For example, we might
require that all forces are gravitational and that the net force on
the mass \(m\) be given by the sum \(\bF=\Sigma_i \bF_i\) of all
gravitational forces \(\bF_i\) acting on the mass due to the other
masses of the universe, in accord with Newton’s inverse square
law of gravity. (The law asserts that the force \(\bF_i\) due to
attracting mass \(i\) with gravitational mass \(m_{gi}\) is \(Gm_g
m_{gi} \boldsymbol{r}_i / r_{i}^3\), where \(m_g\) is the
gravitational mass of the original body, \(\boldsymbol{r}_i\) the
position vector of mass \(i\) originating from the original body, and
\(G\) the universal constant of gravitation.) That gives us an
independent definition for \(\bF\). Similarly we can require that the
inertial mass \(m\) be equal to the gravitational mass \(m_g\). Since
we now have independent access to each of the terms \(\bF\), \(m\) and
\(\ba\) appearing in \(\bF=m\ba\), whether the law obtains is
contingent and no longer a matter of definition.
Further problems can arise, however, because of another
\(T\)-theoretical term that is invoked implicitly when \(\bF=m\ba\) is
asserted. The accelerations \(\ba\) are tacitly assumed to be measured
in relation to an inertial system. If the acceleration is measured in
relation to a different reference system, a different result is
obtained. For example, if it is measured in relation to a system
moving with uniform acceleration \(\ba\), then the measured
acceleration will be \(\ba' = (\ba - \ba)\). A body not acted on by
gravitational forces in an inertial frame will obey \(0=m\ba\) so that
\(\ba=0\). The same body in the accelerated frame will have
acceleration \(\ba' = -\ba\) and be governed by \(-m\ba = m\ba'\). The
problem is that the term \(-m\ba\) behaves just like a gravitational
force; its magnitude is directly proportional to the mass \(m\) of the
body. So the case of a gravitation free body in a uniformly
accelerated reference system is indistinguishable from a body in free
fall in a homogeneous gravitational field. A theoretical
underdetermination threatens once again. Given just the motions how
are we to know which case is presented to
 us?[1]
 Resolving these problems requires a systematic study of the relations
between the various \(T\)-theoretical concepts, inertial mass,
gravitational mass, inertial force, gravitational force, inertial
systems and accelerated systems and how they figure in the relevant
laws of the theory \(T\).
Similar problems arise in the formulation of almost all fundamental
physical theories.
There are various ways to cope with this problem. One could try to
unmask it as a pseudo-problem. Or one could try to accept the problem
as part of the usual way science works, albeit not in the clean manner
philosophers would like it. The structuralistic programs, however,
agree that this is a non-trivial problem to be solved and devise
meta-theoretical machinery to enable its solution. They further agree
on dividing the vocabulary of the theory \(T\) into \(T\)-theoretical
and \(T\)-non-theoretical terms, the latter being provided from
outside the theory. 
In the Sneedean approach the “empirical claim” of the
theory is formulated by using an existential quantifier for the
\(T\)-theoretical terms (i.e., in terms of the “Ramsey
sentence” for \(T)\). In our above example, Newton’s law
for gravitational forces would be reformulated as: “There exist
an inertial system and constants \(G, m_i, m_{gi}\) such that for each
particle the product of its mass times its acceleration equals the sum
of the gravitational forces as given above.” This removes the
circularity but leaves open the question of content. Here the
structuralists à la Sneed would argue that the empirical claim
of the theory \(T'\) has to contain all the laws of the theory as well
as higher-order laws, called “constraints”. In our
example, the constraints would be statements such as “all
particles have the same inertial and gravitational masses and the
gravitational constant assumes the same value in all models of the
theory.” The theory would thereby acquire more content and
become non-vacuous. 
Although Ludwig’s meta-theoretical framework is slightly
different, the first part of his solution is essentially equivalent to
the above one. On the other hand, he proposes a stronger program
(“axiomatic basis of a physical theory”) which proceeds by
considering an equivalent form \(T\)* of a theory \(T\) in which all
\(T\)-theoretical concepts are eliminated by explicit definitions.
This seems to be at variance with older results about the
non-definability of theoretical terms, but a closer inspection removes
the apparent contradiction. For example, the concept of
“mass” may be non-definable in a theory dealing only with
single orbits of a mechanical system, but definable in a theory
containing all possible orbits of that system. 
However, to formulate the axiomatic basis of a real theory, not just a
toy model, is a non-trivial task and typically requires one or two
books; see the examples Ludwig (1985, 1987) and Schmidt (1979).
Both programs address the further problem of how to determine the
extension, e.g., the numerical values, of a theoretical term from a
given set of observational data. We will call this the
“measurement problem”, not to be confounded with the
well-known measurement problem in quantum theory. Typically the
measurement problem has no unique solution. Rather the values of the
theoretical quantities can only be measured within a certain degree of
imprecision and using auxiliary assumptions which, although plausible,
are not confirmed with certainty. In the above Newton example one
would have to use the auxiliary assumption that the trajectories of
the particles are twice differentiable and that other forces except
the gravitational forces can be neglected. For a recent critical
examination of the solution to the measurement problem within
Sneed’s approach with detailed examples from astronomy see
Gähde (2014). 
The feature of imprecision and approximation plays a prominent
rôle in the structuralistic programs. In the context of the
measurement problem, imprecision seems to be a defect of the theory
which impedes the exact determination of the theoretical quantities.
However, imprecision and non-uniqueness is crucial in the context of
evolution of theories and the transition to new and
“better” theories. Otherwise the new theory could in
general not encompass the successful applications of the old theory.
Consider for example the transition of Kepler’s theory of
planetary motion to Newton’s and Einstein’s theories:
Newtonian gravitation theory and general relativity replace the Kepler
ellipses with more complicated curves. But these should still be
consistent with the old astronomical observations, which is only
possible if they don’t fit exactly into Kepler’s theory .
Part of the structuralistic program is the definition of various
intertheoretic relations. Here we will concentrate on the relation(s)
of “reduction”, which play an important rôle in the
philosophical discourse as well as in the work of the physicists,
albeit not under this name. Consider a theory \(T\) which is
superseded by a better theory \(T'\). One could use \(T'\) in order to
understand some of the successes and failures of \(T\). If there is
some systematic way of deriving \(T\) as an approximation within
\(T'\), then \(T\) is “reduced” to or by \(T'\). In this
case, \(T\) is successful where it is a good approximation to \(T'\)
and \(T'\) is successful. On the other hand, in situations where
\(T'\) is still successful but \(T\) is a poor approximation to
\(T'\), \(T\) will fail. For example, classical mechanics should be
obtained as the limiting case of relativistic mechanics for velocities
small compared with the velocity of light. This would explain why
classical mechanics was, and is still, successfully applied in the
case of small velocities but fails for large (relative) velocities.
As mentioned, the investigation of such reduction relations between
different theories is part of the every-day work of theoretical
physicists, but usually they do not adopt a general concept of
reduction. Rather they intuitively decide what has to be shown or to
be calculated, depending on the case under consideration. Here the
work of the structuralists could lead to a more systematic approach
within physics, although there does not yet exist a generally
accepted, unique concept of reduction.
Another aspect is the rôle of reduction within the global
picture of the development of physics. Most physicists, but not all,
tend to view their science as an enterprise which accumulates
knowledge in a continuous manner. For example, they would not say that
classical mechanics has been disproved by relativistic mechanics, but
that relativistic mechanics has partly clarified where classical
mechanics could be safely applied and where not. This view of the
development of physics has been challenged by some philosophers and
historians of science, especially by the writings of T. Kuhn and P.
Feyerabend. These scholars emphasize the conceptual discontinuity or
“incommensurability” between reduced theory \(T\) and
reducing theory \(T'\). The structuralistic accounts of reduction now
opens the possibility of discussing these matters on a less informal
level. The preliminary results of this discussion are different
depending on the particular program. 
In the writings of Ludwig there is no direct reference to the
incommensurability thesis and the corresponding discussion. But
obviously his approach implies the most radical denial of this thesis.
His reduction relation is composed of two simpler intertheoretic
relations called “restriction” and
“embedding”. They come in two versions, exact and
approximate. Part of their definitions are detailed rules of
translation of the non-theoretic vocabulary of \(T'\) into that of
\(T\). Hence commensurability, at least on the non-theoretical level,
is insured by definition. The problem is then shifted to the task of
showing that some of the interesting cases of reduction, which are
discussed in the context of incommensurability, fit into
Ludwig’s definition. Unfortunately, he gives only one
extensively worked-out example of reduction, namely thermodynamics vs.
quantum statistical mechanics, in Ludwig (1987). Incommensurability of
theoretical terms could probably be more easily incorporated in
Ludwig’s approach since it could be traced back to the
difference between the laws of \(T\) and \(T'\). 
The relation between incommensurability and the Sneedean reduction
relation is to some extent discussed in Balzer et al. (1987,
chapter VI.7). The authors consider an exact reduction relation as a
certain relation between potential models of the respective theories.
More interesting for physical real-life examples is the approximate
version which is obtained as a “blurred exact reduction”
by means of a subclass of an empirical uniformity on the classes of
potential models. The Kepler-Newton case is discussed as an example of
approximate reduction. The discussion of incommensurability suffers
from the notorious difficulties of explicating such notions as
“meaning preserving translation”. There is an interesting
application of the interpolation theorem of meta-mathematics which
yields the result that, roughly speaking, (exact) reduction implies
translation. However, the relevance of this result is questioned in
Balzer et al. (1987, 312 ff). Thus the discussion eventually
ends up as inconclusive, but the authors admit the possibility of a
spectrum of incommensurabilities of different degrees in cases of
pairs of reduced/reducing theories. 
Scheibe in his (1999) also explicitly refers to the theses of Kuhn and
Feyerabend and gives a detailed discussion. Unlike the other two
structuralistic programs, he does not propose a fixed concept of
reduction. Rather he suggests a lot of special reduction relations
which can be combined appropriately to connect two theories \(T\) and
\(T'\). Moreover, he proceeds by means of extensive real-life case
studies and considers new types of reduction relations if the case
under consideration cannot be described by the relations considered so
far. Scheibe concedes that there are instances of incommensurability
which make it difficult to find a reduction relation in certain cases.
As a significant example he mentions the notions of an
“observable” in quantum mechanics on the one hand, and in
classical statistical mechanics on the other hand. Although there are
maps between the respective sets of observables, Scheibe considers
this as a case of incommensurability, since these maps are not Lie
algebra homomorphisms, see Scheibe (1999, 174). 
Summarizing, the structuralistic approaches are capable of discussing
the issues of reduction and incommensurability and the underlying
problems on an advanced level. Thereby these approaches have a chance
of mediating between disparate camps of physicists and
philosophers.
In this section we will describe more closely the particular programs,
their roots and some of the differences between them. 
This program has been the most successful with respect to the
formation of a “school” attracting scholars and students
who adopt the approach and work on its specific problems. Hence most
of the structuralistic literature concerns the Sneedean variant.
Perhaps this is partly also due to the circumstance that only
Sneed’s approach is intended to apply (and has been applied) to
other sciences and not only physics. 
A more comprehensive account of the historical roots of structuralism
in philosophy of science can be found in Bolinger (2016), although
this book is not yet translated into English. The seminal book was
Sneed (1971) which presented a meta-theory of physics in the
model-theoretical tradition connected with P. Suppes, B. C. van
Fraassen, and F. Suppe. This approach was adopted and popularized by
the German philosopher W. Stegmüller (1923–1991), see e.g.,
Stegmüller (1979b) and further developed mainly by his disciples.
In its early days the approach was called the “non-statement
view” of theories, emphasizing the rôle of set-theoretical
tools as opposed to linguistic analyses. Later this aspect was
considered to be more of practical importance than a matter of
principle, see Balzer et al. (1987, 306 ff). Recently, H.
Andreas (2014) and G. Schurz (2014) have proposed two slightly
different frameworks that reconcile semantical and syntactical
formulations of Sneed’s program. Nevertheless, the almost
exclusive use of set-theoretic tools remains one of the characteristic
stylistic features of this program and one that distinguishes it
conspicuously from the other programs.
According to Moulines, in Balzer and Moulines (1996, 12–13), the
specific notions of the Sneedean program are the following. We
illustrate these notions by simplified examples, inspired by Balzer
et al. (1987), which are based on a system of \(N\) classical
point particles coupled by springs satisfying Hooke’s law. For a
recent introduction into the basic concepts see also H. Andreas and F.
Zenker (2014). 
Günther Ludwig (1918–2007) was a German physicist mainly
known for his work on the foundations of quantum theory. In Ludwig
(1970, 1985, 1987), he published an axiomatic account of quantum
mechanics, which was based on the statistical interpretation of
quantum theory. As a prerequisite for this work he found it necessary
to ask “What is a physical theory?” and developed a
general concept of a theory on the first 80 pages of his (1970). Later
this general theory was expanded into the book Ludwig (1978). A recent
elaboration of Ludwig’s program can be found in Schröter
(1996).
His underlying “philosophy” is the view that there are
real structures in the world which are “pictured” or
represented, in an approximate fashion, by mathematical structures,
symbolically \(\boldsymbol{PT} = \boldsymbol{W} (-) \boldsymbol{MT}\).
The mathematical theory \(\boldsymbol{MT}\) used in a physical theory
\(\boldsymbol{PT}\) contains as its core a “species of
structure” \(\Sigma\). This is a meta-mathematical concept of
Bourbaki which Ludwig introduced into the structuralistic approach.
The contact between \(\boldsymbol{MT}\) to some “domain of
reality” \(\boldsymbol{W}\) is achieved by a set of
correspondence principles \((-)\), which give rules for translating
physical facts into certain mathematical statements called
“observational reports”. These facts are either directly
observable or given by means of other physical theories, called
“pre-theories” of \(\boldsymbol{PT}\). In this way a part
\(\boldsymbol{G}\) of \(\boldsymbol{W}\), called “basic
domain” is constructed. But it remains a task of the theory to
construct the full domain of reality \(\boldsymbol{W}\), that is, the
more complete description of the basic domain that also uses
\(\boldsymbol{PT}\)-theoretical terms.
Superficially considered, this concept of theory shows some similarity
to neo-positivistic ideas and would be subject to similar criticism.
For example, the discussion of the so-called
‘theory-laden’ character of observation sentences casts
doubts on such notions as “directly observable facts”.
Nevertheless, the adherents of the Ludwig approach would probably
argue for a moderate form of observationalism and would point out
that, within Ludwig’s approach, the theory-laden character of
observation sentences could be analyzed in detail. 
Another central idea of Ludwig’s program is the description of
intra- and inter-theoretical approximations by means of “uniform
structures”, a mathematical concept lying between topological
and metrical structures. Although this idea was later adopted by the
other structuralistic programs, it plays a unique rôle within
Ludwig’s meta-theory in connection with his finitism. He
believes that the mathematical structures of the infinitely large or
small, a priori, have no physical meaning at all; they are
preliminary tools to approximate finite physical reality. Uniform
structures are vehicles for expressing this particular kind of
approximation.
We have already explained that for Ludwig the framework for the
reconstruction of physical theories was actually only a tool to
develop his interpretation of quantum mechanics.
It is no surprise that there are close relationships between the two
enterprises. We only mention the fact that the reconstruction of
theoretical terms by other terms that are more easily accessible is
particularly urgent when the theoretical terms refer to the
microscopic domain. This explains in particular why Ludwig is a
supporter of a statistical interpretation of quantum mechanics,
because more advanced interpretations such as the
single-particle-state interpretation of the wave function, in his
opinion, have no axiomatic basis. In the current debate on the
interpretation of quantum mechanics, the statistical interpretation
(or ensemble interpretation) plays only a marginal role and is,
moreover, usually attributed to L. E. Ballentine (1970). The Wikipedia
entry on the
 ‘ensemble interpretation’
 does not mention Ludwig at all. 
It would be premature, however, to deny Ludwig any influence on the
development of quantum theory. There are some achievements, like the
generalization of observables to POV measures, see Busch et al (2016),
which are well known, e.g., in the community practicing quantum
information theory, and which finally go back to Ludwig. Usually, the
standard reference for these generalizations is not Ludwig but his
pupil K. Kraus, see Kraus (1983). Finally it should be mentioned that
Ludwig’s axiomatics of quantum mechanics has been revived by new
mathematical results, see Casinelli and Lahti (2016). 
One year before his death Ludwig, together with Gérald Thurler,
published a revised and simplified edition of Ludwig (1990) with the
title “A new foundation of physical theories”. This work
cannot be used as a textbook but it is a remarkable document of the
central themes of his approach and his general views on physics. The
book clearly shows that Ludwig’s main concern is about
scientific realism, i.e., about the question of how hypothetical
objects and relations occurring within a successful theory acquire the
status of physical reality. Entities which cannot claim this status
are dubbed as “fairy tales” throughout the book. Examples
of fairy tales in quantum theory are hidden variables and, perhaps
surprising for some readers, also the single-particle-state
interpretation (in contrast to the ensemble interpretation fostered by
Ludwig). 
Among the new concepts and tools developed in Ludwig/Thurler (2006)
are the following:
Generally speaking, Ludwig’s program is, in comparison to those
of Sneed and Scheibe, less descriptive and more normative with respect
to physics. He developed an ideal of how physical theories should be
formulated rather than reconstructing the actual practice. The
principal worked-out example that comes close to this ideal is still
the axiomatic account of quantum mechanics, as described in Ludwig
(1985, 1987).
The German philosopher Erhard Scheibe (1927–2010) has published
several books and numerous essays on various topics of philosophy of
science; see, for example, Scheibe (2001). He has often commented on
the programs of Sneed and Ludwig, such as in his “Comparison of
two recent views on theories”, reprinted in Scheibe (2001,
175–194). Moreover, he published one of the earliest case
studies of approximate theory reduction; see Scheibe 2001
(306–323) for the 1973 case study. 
In his books on “reduction of physical theories,” Scheibe
(1997, 1999) developed his own concept of theory, which to some extent
can be considered an intermediate position between those of Ludwig and
Sneed. For example, he conveniently combines the model-theoretical and
syntactical styles of Sneed and Ludwig, respectively. Since his main
concern is reduction, he does not need to cover all the aspects of
physical theories that are treated in the other approaches. As already
mentioned, he proposes a more flexible concept of reduction that is
open to extensions arising from new case studies.
A unique feature of Scheibe’s approach is the thorough
discussion of almost all the important cases of reduction considered
in the physical literature. These include classical vs.
special-relativistic spacetime, Newtonian gravitation vs. general
relativity, thermodynamics vs. kinetic theory, and classical vs.
quantum mechanics. He essentially arrives at the conclusion of a
double incompleteness: the attempts of the physicists to prove
reduction relations in the above cases are largely incomplete
according to their own standards, as well as according to the
requirements of a structuralistic concept of reduction. But this
concept is also not complete, Scheibe argues, since, for example, a
satisfactory understanding of “counter-factual” limiting
processes such as \(\hslash \rightarrow 0\) or \(c\rightarrow \infty\)
has not yet been developed. Bolinger in his (2016) gives a fairly
general account of the structuralistic programme with special emphasis
on Scheibe’s work. 
As already noted, the programs of Ludwig and Sneed have been
independently developed in the 1970s, whereas Scheibe’s program,
at least partially, originated from a critical review of these two
programs. But this is only a coarse description. Additionally, there
have been numerous mutual interactions between the three programs that
influenced their later elaborations. Evidence for this interaction is
provided, besides various pertinent acknowledgements in books and
articles, by the following observations. 
We have sketched three structuralistic programs which have been
developed since the 1970s in order to tackle problems in philosophy of
physics, some of which are relevant also for physics itself. Any
program which employs a weighty formal apparatus in order to describe
a domain and to solve specific problems has to be scrutinized with
respect to the economy of its tools: to what extent is this apparatus
really necessary to achieve its goals? Or is it concerned mainly with
self-generated problems? We have tried to provide some arguments and
material for the reader who ultimately has to answer these questions
for him- or herself. 