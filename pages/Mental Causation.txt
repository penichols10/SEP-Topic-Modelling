Mental causation—the mind’s causal interaction with the
world, and in particular, its influence on behavior—is central
to our conception of ourselves as agents. Mind–world interaction
is taken for granted in everyday experience and in scientific
practice. The pain you feel when you sprain your ankle causes you to open the freezer in search of an ice pack. An intention
to go to the cinema leads you to get into your car. Psychologists
tell us that mental images enable us to navigate our surroundings
intelligently. Economists explain fluctuations in financial markets by
citing traders’ beliefs about the price of oil next month. In
each case, a mental occurrence appears to produce a series of complex
and coordinated bodily motions that subsequently have additional downstream
effects in the physical world. Instances of apparent mental causation
are so common that they often go unremarked, but they are central to the
commonsense picture we have of ourselves. It’s not surprising,
then, that questions about the nature and possibility of mental
causation arise in variety of philosophical contexts.
Ontology: Suppose you accept the “Eleatic
Principle” that power is the mark of being: to exist is to have
causal powers (Armstrong 1978, pp. 45-6; Oddie 1982). It’s plausible to think that if the
mental has any causal powers at all, it can affect the physical
world. Without such powers, the mental faces ontological
embarrassment, even elimination.
Metaphysics: Mental causation is “at the heart of
the mind-body problem” (Shoemaker 2001, p. 74), often figuring explicitly in how the problem is formulated (Mackie 1979; Campbell 1984; Crane 1999). To ask how mind and body are related just is, in
part, to ask how they could possibly affect one another.
Moral psychology: Agency of the sort required for free will
and moral responsibility
appears to require mental causation. If your behavior is not caused by
your mind’s activities—its deliberations, decisions, and the
like—what sense would it make to hold you responsible for what
your body does? You would appear to be scarcely more than a passive
observer of your body’s activities. We would then need to abandon
what Strawson (1962) calls our
“reactive attitudes”, the moral attitudes and feelings (e.g., gratitude, resentment) so central to our interpersonal
lives.
Action theory: It is widely believed that psychological explanation hinges on the possibility of mental causation. If your mind and its states, such as your beliefs and
desires, were causally isolated from your bodily behavior, then what
goes on in your mind could not explain what you do (Davidson 1963;
Mele 1992; for dissent, see “noncausalists” such as Ginet 1990; Sehon 2005; Tanney 2013; and see the essays
in D’Oro 2013). These observations about agency suggest a more basic conceptual point:
if minds did not influence behavior, in what sense would anyone
truly act? Sounds would be made, but no one
would mean anything by them. Bodies would move, but no one
would thereby do anything (Malcolm 1968; Horgan
2007).
Although each of the above points could be contested, collectively
they create pressure to address the problem of mental
causation—problem or problems: as will become clear,
there is more than one way in which puzzles about the mind’s
causal efficacy can arise.
At least since Hume, philosophers have assumed
that causal questions are largely empirical. We look to science to
tell us, for example, the moon’s role in causing the tides, or
smoking’s contribution to lung cancer: these are not considered
philosophical questions. It might seem equally obvious that the
mind’s causal role in producing behavior is also a matter for
science to settle. So is it in fact the case that working
scientists, and in particular, psychologists, find it necessary to
appeal to distinctively mental phenomena to account for behavior? Is
there evidence in neuroscience that mental states and processes figure
in the production of actions?
Although most psychologists would without hesitation accept the causal
interaction of minds and bodies, a small but growing number of
empirical researchers have insisted that the evidence supports some
version of epiphenomenalism, the
thesis that mental states, while caused by physical happenings, exert
no efficacy in return. Wegner, a psychologist, contends that
accumulated empirical evidence overwhelmingly supports
epiphenomenalism, at least with respect to conscious willing (Wegner
2002, 2004). He draws on influential work by Libet (1985, 2001, 2004) and others to argue that conscious intending is itself a product of nonconscious
processes that do the real causal work, so that free will
is “an illusion”. If Wegner and his colleagues are right, these results could have ancillary implications for the physical
efficacy of mental states generally.
Because this research has received extensive treatment in recent work
on free will, we will not consider it further, but instead refer
interested readers to the sources cited above and to Mele 2014 for
critical discussion and references. Here we simply note that traditional
and contemporary attempts to assess the efficacy of mental states have
run up against philosophical difficulties as well, difficulties that
tend to overshadow the experimental evidence accumulated thus far. In
this sense, the efficacy of mind is quite unlike that of, say, the
moon or smoking. This will, we hope, become clear in the discussion to
follow.
Some historians (e.g., Matson 1966; King 2007) say the mind-body
problem is relatively recent, the most important source
being Descartes’s “real
distinction” between mind and body. That said, you can find
topics closely related to mental causation in, for example,
Plato’s Phaedo and Aristotle’s De Anima,
and it might turn out that many features of the contemporary debate
are present in some form or other in pre-modern texts (Caston 1997). Skirting such historical questions, we begin with Descartes, who, for better or worse, set the agenda for modern
discussions of mental causation. The cluster of causal problems
arising from the Cartesian conception of mind is The Problem of
Interaction.
According to Descartes, minds and bodies are distinct kinds of thing,
or, in the technical terminology of the day, distinct kinds
of substance. Bodies, he held, are spatially extended
substances, incapable of feeling or thought; minds, in contrast, are
unextended, thinking, feeling substances:
souls. (We use “soul” with no theological
implications to designate minds considered in the Cartesian way as
immaterial substances.) Despite recognizing these deep differences,
Descartes accepted the common belief that mind and body causally
interact: “Everyone feels that he is a single person with both
body and thought so related by nature that the thought can move the
body and feel the things which happen to it” (in Cottingham et
al. 1991, p. 228). But if minds and bodies are so radically different, it is not easy to see how they could interact.
Descartes was well aware of the difficulty. Princess Elisabeth of
Bohemia puts it forcefully to him in a 1643 letter, pressing Descartes
to tell her
Elisabeth is expressing the prevailing mechanistic view as to how
causation of bodies works: it must involve the cause’s
impelling the body, where this requires contact between
cause and effect. Since a soul could never come into contact with a
body—souls have no spatial location—an immaterial soul
could never impel, and so could never causally interact with, a
body.
Elisabeth’s worries might seem quaint and outdated. Causal
relations countenanced by contemporary physics can take several forms,
not all of which are of the push-pull variety. Why shouldn’t
soul–body interaction simply be included as another sort of
“non-mechanistic” causation (Richardson 1982)? But
Elisabeth’s objection is in fact just one version of a more
general worry about soul–body interaction, a worry that rests on
the following thesis about causation:
Elisabeth presumes that when an effect is bodily motion, the required
nexus is spatial contact. But even if she is wrong about this (Garber 1983), (CN)
nevertheless poses problems for the dualist: if contact is not the
mind–body nexus, what is?
One line of thought appeals to the transference theory of causality.
Here the idea is that identity—the persistence of 
something from cause to effect—provides the needed link. If 
something in a soul could become present in a body, this could 
bridge the immaterial and material. Descartes himself appears 
to accept such a theory, declaring in the Third Meditation that there
could be nothing in an effect not present in its total efficient 
cause (Descartes 1642/1996, p. 28). But now the problem reasserts itself: 
if, as the substance dualist insists, bodies and minds are radically different, 
they have no properties in common. According to Descartes, a
body’s properties are modes of extension, ways of being extended, 
while a soul’s properties are modes of something quite different, 
thought or consciousness. If causation involved transference, a 
Cartesian soul could not interact with a body 
(but see Hart 1988; Hoffman and Rosenkrantz 1991).
Does a dualist need to accept (CN), however? The notion of a causal nexus
has come under criticism, often from philosophers working in the
Humean tradition (Blackburn 1990). More generally, (CN) and kindred
principles might be thought to rest on a conception of causality that
is now obsolete, finding no place in modern physics (for further 
discussion, see
 the metaphysics of causation,
 §2). But the next three versions of
the problem can arise even for those who reject the need for a causal
nexus.
A second version of the Problem of Interaction is the “Pairing
Problem” (Kim 1973, 2005; Sosa 1984; Foster 1991, ch. 6).
Imagine two exactly similar minds M1
and M2 and the bodies B1
and B2 to which they are “attached”,
that is, the bodies with which they directly interact. In virtue of
what is M1 causally paired
with B1, and M2
with B2?
This is not the epistemological question of how we could 
know that these are the pairings (although this is 
troublesome, too). The question, rather, is metaphysical: in virtue 
of what are these the pairings? If minds were, like bodies, 
located in space, causal pairing could be achieved by the relative 
spatial locations of the substances (Bailey et al. 2011). Particular minds might be inside
or “inhabit” particular bodies. But if minds are non-spatial souls, 
relative spatial location is unavailable to fill the pairing role. 
And since M1 and M2 are, by hypothesis, 
exactly similar, we cannot appeal to the different intrinsic 
properties that they might possess.
In reply, a dualist could appeal to “individualistic”
powers (Unger 2006, pp. 242–59; Foster 1991,
pp. 167–8). Powers are standardly thought of as powers to
interact with some type of object. A key has the
power to open this lock, but only by virtue of having the power to
open any lock of this kind, the power to open any intrinsically
comparable lock. Individualistic powers, in contrast, are powers
possessed by an object to affect or be affected by
a particular object. Think of a key with the power to
open this lock, but without the power to open any
intrinsically indiscernible lock. Likewise, a soul could have the
power to interact with a particular body and no other. As the key
example suggests, however, it is by no means obvious that
powers could be individualistic in this sense.
A third version of the Problem of Interaction appeals to conservation
laws. The leading idea is simple: Soul–body
interaction would have to change the amount of energy in the physical
universe. When souls act, new energy would appear in, say, the
brain. When souls are acted upon, some quantity of energy in the brain
would vanish. But either scenario would contravene established
conservation laws, which permit only the conversion and redistribution
of energy (or mass–energy) within the physical universe, not its addition or
subtraction.
This version of the problem has dogged dualism since the scientific
revolution (Lowe 1992; Papineau 2000), and a number of contemporary
philosophers present conservation as a major obstacle for dualists
(Fodor 1981; Dennett 1991, p. 35; Heil 2012, p. 26). That said, turning the leading idea into a compelling argument has proven difficult. First,
what is needed is a conservation law weak enough to have been
confirmed by physical science, but strong enough to preclude
soul–body interaction. Averill and Keating (1981) consider a
number of candidate “laws” and argue that none meets both
criteria. Second, it’s not clear in any case that a soul would
have to add energy to (or receive it from) the brain in order to
interact with it. The transference theory (§2.1) again seems to
be in the background here, but why accept it? Broad (1925,
pp. 103–9) suggests a soul could act merely by
redistributing the brain’s energy without changing its
quantity. (For more recent discussion of these and other complexities,
see Montero 2006; Koksvik 2007; Gibb 2010.)
A fourth version of the Problem of Interaction is related to the
third, but, because it is more prominent in the contemporary literature, especially
in some of the “property-based” problems we examine below, we will develop this last version at greater length. The first premise is:
The Completeness of the Physical: Every physical
effect has a sufficient physical cause.
When you trace the causal history of any physical effect—that
is, of anything physical that has a cause—you will 
never need to appeal to anything non-physical. The physical 
universe contains within itself the resources for a full causal explanation of 
any of its (caused) elements, and in this sense is “complete”. The 
point applies, then, to whatever might occur to or within our bodies.
Any instance of bodily behavior has a sufficient physical 
cause, which itself has a sufficient physical cause, and so on. In 
tracing the causal history of what we do, we need never appeal to 
anything non-physical.
This principle appears frequently in the mental causation literature
under a number of labels: most common are variations
of Completeness of the Physical (Crane 1995, 2001; Papineau
1993, 2000; O’Connor and Churchill 2010) or Physical
Closure (Crane 1992; Baker 1993; Melnyk 2003; Kim
2005). We’ll call it Completeness for short.
Labels aside, several versions of the premise appear in the
literature, and they can differ in strength. Note that the principle
as formulated says nothing about whether the non-physical can affect
the physical; a strengthened version prohibits this. (Closure
is sometimes reserved for this stronger principle: LePore and Loewer
1987; Kim 1998, p. 40; Marcus 2005; compare Strong Causal
Closure in Montero 2003.) An even more ambitious version blocks
the non-physical from being cause or effect; such is
suggested in Davidson’s work (see §5.1 and McLaughlin 1989,
who uses Physical Comprehensiveness for this thesis.) As for
weaker versions, Completeness could be limited to physical
effects within the human body without affecting its relevance to the
current topic. Note also that the principle is apparently committed to
deterministic physical causation; a weakened version permits
probabilistic causes. (For complications with such a weakening, see
Montero 2003, and for other challenges with
formulating Completeness, Lowe 2000; Gibb 2015.)
For simplicity, we stay with the principle as formulated at the
outset. Why think that it’s true? Perhaps it is a conceptual
truth: for an effect to be physical is, at least in part, for it to
have a physical cause. This defense turns on the proper analysis of
the concept physical, itself the subject of a contentious
literature (see physicalism). Here we
simply note that the principle does not seem analytic; it appears to be
a substantive, empirical claim about the causal structure of the
universe. (For more on the conceptual defense, see Crane 1991;
Papineau 1991, 1993, §1.9; Lowe 1996, p. 56.)
It’s natural, then, to look to science for a defense, and
especially physics (or physiology). Appeals to “current physical
theory” (Antony and Levine 1997, p. 100), “the development
of the sciences” (LePore and Loewer 1987, p. 630), and
“physics textbooks” (Melnyk 2003, p. 289) are common, but
what exactly in physical science supports the premise?
Papineau’s (2000) historical survey outlines two arguments. The
first is inductive: when physics has investigated the nature of
“special”, macroscopic forces, it has discovered that they
all reduce to a small number of basic, conservative physical
forces. Generalizing from this evidence, the idea is that all such
forces will reduce to the same small set of physical forces. The
second argument aims at establishing a weaker version
of Completeness, one restricted to the human
body. Were Completeness false owing to the routine
intervention of souls, physiology would have discovered anomalies
within the human body, events that have no physical explanation. But a
century of increasingly detailed investigation has revealed no such
anomalies. It appears as if the causes operating within our bodies are
entirely physical (compare Armstrong 1968/1993, pp. 32–3; Melnyk
2003, p. 289; for a response, see Montero 2003).
We will look at challenges to Completeness in a moment, but
note for now that the premise by itself does not preclude the efficacy
of souls. Even if every physical effect has a sufficient physical
cause, some physical effects might have non-physical causes
as well. This latest version of the Problem of Interaction thus
requires a second premise:
No Overdetermination: There is no systematic
overdetermination of physical effects.
This principle enjoys wide support in the literature. It is said that
postulating systematic overdetermination in this context is
“absurd” (Kim 1993a, p. 281), one of the
“nonstarters” in the mental causation debate (Kim 1998,
p. 65). But why? Perhaps it just looks like bad engineering (Schiffer
1987, p. 148). Or maybe the problem is that it would involve an
“intolerable coincidence” (Melnyk 2003, p. 291): every
time you act, there are two independent causal processes—one from
your brain, another from your soul—converging on the same
effect.
With the two premises now in place, the Problem of Interaction in
our final version is straightforward. Assume for reductio
that our souls routinely cause behavior. By Completeness,
such effects also have sufficient physical causes, so behavior is
systematically overdetermined. But this contradicts No
Overdetermination. The dualist’s options would then seem to
be severely limited. One is to embrace epiphenomenalism, a doctrine on
which the mental, while caused by the physical, exerts no
“downward” causal influence in return. A more radical
option, parallelism, depicts bodies and souls as running in tandem,
with no causal influence in either direction.
The two premises can, however, be challenged. Start
with Completeness. Baker (1993), not herself a Cartesian
dualist, argues that if the principle threatens to undermine our
ordinary (and scientific) explanatory practices—many of which
cite the mental—it’s Completeness that has to
go. Entrenched explanatory practices trump any abstract metaphysical
principles with which they might conflict (see also §§6.3,
7.5). Others argue that physical science, far from supporting the
principle, may in fact undermine it. Hendry (2006) finds indications
of “downward causation” in chemistry, while Stapp (2005)
culls evidence from contemporary physics suggesting that there are,
contrary to Completeness, causal gaps in the physical world,
gaps filled in by the mental (see also Sturgeon 1998; Davies
2006). Emergentists in general deny the principle, either on
scientific grounds or by appeal to our conscious experiences of agency
(see emergent properties,
esp. §4). And although the death of emergentism has been declared
more than once on empirical grounds (McLaughlin 1992; Papineau 2000),
the view continues to attract philosophers and scientists. (See the contributions to Clayton and Davies 2006; Bedau and Humphreys 2008; Macdonald and Macdonald 2010; Paoletti and Orilia 2017.)
No Overdetermination has been targeted as well. Mills (1996),
for example, defends mental–physical overdetermination as the most 
plausible route for the dualist to take. Overdetermination is 
plausible, the reasoning goes, if for any behavioral effect 
B, both a non-physical (mental) cause M and 
physical cause P satisfy the following counterfactual 
conditionals (among others):
If the dualist can reasonably claim that (1) and (2) are true, this
will make a strong prima facie case for
overdetermination. Along different lines, Lowe (2003) presents a model
of dualist interaction on which, owing to systematic mind–body
dependencies, overdetermination is not the intolerable coincidence
worrying opponents of dualism. And more generally, the ban on
systematic overdetermination has come under increased scrutiny in the
context of the Exclusion Problem, to be discussed in §6.
Cartesian dualism has fallen out of favor among philosophers and
cognitive scientists. There are, to be sure, non-Cartesian forms of
substance dualism that might have the resources to confront the
Problem of Interaction in its various guises (Hasker 1999; Lowe
2006). But the dominant view today would appear to be that if the mind
is a substance at all, it is a physical substance—the brain, for
instance. This sort of “substance monism” is in fact a
consequence of the more general token identity theory: every
concrete mental particular (token) is physical. We will assume token
identity in what follows: minds, mental events, and any other mental
“objects” are physical
(see the mind/brain identity theory).
 
What becomes of the Problem of Interaction on such a view? It would 
seem to dissolve. While causation between brain and body is complex, 
even to the point of being empirically inscrutable, it does not pose 
the same problems as soul–body interaction. There are no special 
philosophical problems with brain–body interaction, nor is there 
anything especially odd or worrisome about an event in your brain 
causing, say, your arm to go up. Any philosophical questions here 
belong to 
 the metaphysics of causation
 generally and have no special application to mental causation.
Nevertheless, philosophical worries about mental causation persist.
Theoretical and commonsensical considerations leading us to think the
mind or mental events cause behavior should also make us think that
they do so as mental, i.e., in virtue of their mental
 properties.
Properties figure in causal relations (Kim 1973; Mackie 1974, ch. 10;
Armstrong 1989, pp. 28–9; Ehring 1997). Drop a square
paperweight into soft clay and it will produce an impression. The
shape of the impression can be traced to the shape of the paperweight,
the depth of the impression to the mass of the paperweight. Here shape
and mass are “causally relevant” or “causally
efficacious” properties. In particular, they are relevant to
certain properties of the impression. By contrast, other properties of
the paperweight, such as its color or value, appear to be irrelevant
to producing this kind of impression. Or consider a soprano who sings
a high note, thereby shattering a glass. The sound, we can suppose,
has a meaning—a semantic property—but it is the
sound’s acoustic properties that are operative in producing the
shattering; the semantic properties play no causal role, at least not
with respect to this effect (Dretske 1989).
By themselves, these observations pose no special problem for the 
philosopher of mind. While the notion of a causally relevant property
calls for analysis (Horgan 1989; Dardis 1993; Braun 1995), there
is no reason at the outset for a token-identity theorist to be 
especially concerned about the efficacy of mental properties.
Gus smiles because of the way his food tastes, that phenomenal 
property; Lilian walks to school along a particular route because of 
what she believes, that representational property. Assuming the 
mind is something physical, why should a mind’s causing behavior in
virtue of its mental properties be any more puzzling than a 
paperweight’s causing a square impression in virtue of its shape?
Recent philosophical work on mental properties has revealed that
matters are not so simple, however. Mental properties are alleged to
have, not just one, but up to four features that make their
efficacy philosophically puzzling, no less problematic than
mind–body interaction is for the Cartesian dualist. These
features will be discussed in the following sections. Each feature
makes it appear as though mental properties, or some important family
of them, are irrelevant to the production of behavior. The threat is a
form of epiphenomenalism: even if minds and mental events are causes,
they are not causes as (or qua) mental.
This “new epiphenomenalism” (Campbell 1984, ch. 7)
immediately confronts a particularly strong version of
property dualism, 
one insisting that mental properties are sui generis, perhaps dependent on, but in no
way reducible to the dispositional and structural properties
recognized by the physical sciences. Some property dualists accord
this status only to a certain class of mental property, namely
 qualia,
the “what it’s like” features of conscious
experience. Other property dualists, including
some emergentists, are willing
to extend the thesis to all mental properties.
Suppose that this robust form of property dualism is true. Can mental
substances or events cause what they do qua mental, in virtue
of their mental properties? The arguments against soul–body
interaction, now couched in terms of properties, could enter again
here. For example, if you were worried about the mind–body nexus
for souls (§2.1), it seems you should also wonder how
non-physical properties can find any traction in the physical
world. Similarly, Completeness (§2.4) seems to lose none
of its attractiveness when formulated explicitly in terms of properties. You could add to the principle
a clause stipulating that a “sufficient physical cause” is
one that’s sufficient in virtue of its physical properties (see
also §5.4). Bring in No Overdetermination, and the
efficacy of mental properties is again threatened. The arguments here
and the responses to it are structurally similar to those in §2,
so we will not pursue further this version of the property-based
problem.  (Property dualism also faces the Exclusion Problem, to be
discussed in §6.)
Another version of the property-based problem of mental causation can
be traced to
 Davidson’s
 influential paper, “Mental Events” (Davidson 1970). 
There Davidson defends an account of the mind–body 
relation he calls 
 “anomalous monism”,
a view that at first appears to save mental causation, but in the 
end might deny efficacy to mental properties.
At the core of anomalous monism are three principles:
Principle of Causal Interaction: Some mental
events interact causally with physical events. 
Principle of the Nomological Character of Causality: Events 
related as cause and effect fall under strict laws.
Anomalism of the Mental: There are no strict laws on the 
basis of which mental events can be predicted and explained.
According to Davidson, the apparent tension among these principles
gives rise to the mind–body problem. Most of us unquestioningly
assent to the first principle. The second is more controversial,
although Davidson provides little argument for it. Here we just note
that it’s not as strong as it seems, for
“strict” is not synonymous with
“deterministic”. A strict law is exceptionless,
but could be either deterministic or probabilistic.
The third principle is the most contested of the three. It rules out
strict laws in psychology; in particular—and most importantly for
present concerns—it rules out strict psychophysical
laws, that is, laws connecting the mental and physical. According to
Davidson, application conditions for mental predicates feature a
rationality constraint absent from the application conditions for
physical predicates. In ascribing beliefs to others, for instance, we
employ a principle of charity that counsels us to make these
believers as rational as possible. But this normative constraint has,
as Davidson puts it, “no echo” in the physical realm. In
this regard, mental and physical predicates are misaligned in a way
that precludes strict psychophysical laws.
Now the second two principles seem to rule out the first. If causation
requires strict laws, and there are no strict psychophysical laws, how
can the mental be causally efficacious? But Davidson notes there is a
way to save the first principle: as long as every mental event is
physical, the first principle is compatible with the other two. In
this way, the three principles entail event monism. At the
same time, Davidson’s view entails type dualism, for
the anomalism of the mental (the third principle) precludes identities
between mental and physical types. Most philosophers find it natural
to say that types are properties, so Davidson is sometimes described
as a property dualist, a convenient label for the time being (but see §5.5).
Davidson’s property dualism, and the principle that lies behind
it, have led to a serious charge: anomalous monism robs mental
properties of any causal significance.
Suppose Gus decides to illuminate the room and subsequently flips a
switch, thereby turning on the light. In this case we have a cause
that, if Davidson is right, could be given both a mental and a
physical description, and an effect that has a physical
description. If this means that the cause has a mental
property (in virtue of which it satisfies a mental description)
and a physical property (in virtue of which it satisfies a
physical description), we are faced with a further question. Granting that
the event with the mental property is the event with a
physical property, why should we think that the mental
property had anything at all to do with the event’s physical
effect?  Davidson’s second two principles appear to block such
relevance. If all causal relations are subsumed under strict laws, and
if there are no strict psychophysical laws, then any instance of
mind–body causation is subsumed only by physical laws. But
then it looks as though only a mental event’s physical
properties are relevant to what it causes. The mental properties (or
mental types) are causally irrelevant (see, e.g., Stoutland 1980; Honderich
1982; Sosa 1984; a review of this literature is in
McLaughlin 1989).
LePore and Loewer (1987) look to counterfactuals to answer this charge
(see also Horgan 1989; LePore and Loewer 1989; Block 1990; Loewer
2007). The central idea is that anomalous monism permits physical
effects to depend counterfactually on mental properties. And such
dependence secures an important kind of causal relevance for the
mental, the sort that LePore and Loewer call “bringing
about”. On their view, a’s being F
brings about b’s being G when the following
conditions are met:
Now suppose a mental event, such as a decision to turn on the light,
causes Gus to move his finger, thereby flipping the light switch. Here
the crucial counterfactual is: If the cause had not been a decision to
turn on the light, the effect would not have been a
switch-flipping. This is plausible, as are similar counterfactuals in
a wide range of cases. But are such counterfactuals compatible with
anomalous monism? LePore and Loewer say Yes: while Davidson
prohibits strict laws connecting mental and physical
properties, he apparently leaves room for non-strict laws. Such laws
are enough to ground or “support”
counterfactuals. Consider, by analogy, the properties of being a
match-striking and being a match-lighting. If there is a
law connecting such properties, it is evidently non-strict: striking
causes lighting only ceteris paribus.  Nevertheless, we can
assert with confidence, after a given lighting, that if the match had
not been struck, it wouldn’t have lit.  Non-strict
psychophysical laws would similarly appear to ground counterfactuals
connecting mental and behavioral properties.
This counterfactual defense is attractive for a number of reasons. It
captures a sense in which mental properties make a difference to
behavior, but in a way that’s apparently compatible with
anomalous monism. It respects our causal intuitions about a wide range of cases. And it fits well with the more
general counterfactual theory of causation,
 which many philosophers have found independently
plausible. Moreover, Davidson himself seems sympathetic to the defense
(Davidson 1993; but see §5.5).
In spite of these advantages, a worry is that the pertinent counterfactuals don’t after all ensure causal relevance, and in
this sense don’t vindicate anomalous monism. This objection can
take the form of direct counterexamples (Braun 1995; Garrett 1999),
but here we look at a broader concern.
When a counterfactual is true, there should be something in the world
that makes it true. Even granting that, if the cause had not had its
mental property, the effect would not have had its behavioral
property, in virtue of what is this true? This truthmaker, not the
counterfactual itself, is what matters in determining whether a
property is causally relevant. And the worry is that once we look at
the truthmakers in the mental case, the threat of epiphenomenalism
crops up again. Although the effect counterfactually depends on the
mental property, this is only because the mental property depends on a
physical property doing the real work. The mental property looks like
a freeloader (Kim 1998, pp. 70–3, 2007; compare Crane 2008 on a
similar issue).
LePore and Loewer discuss a version of this worry. Condition (3), an
objector might say, is too crude to test for causal relevance, for the
counterfactual holds only because removing F
from a also removes some other property F*
of a, and it’s the absence of F* that’s
responsible for b’s not being G. A better
counterfactual test evaluates the effect’s status given
that a is not F and all
of a’s other properties—or at least all that are
potential causal rivals to F—are held
fixed. If b is not G in that case, only then can we
credit F with causal relevance. But mental properties fail
this more refined test. Consider again Gus’s decision to turn on
the light, and remove its mental property, this time holding fixed its
physical properties. It seems clear that he would still flip the
switch. After all, the physical properties of the cause figure in an
exceptionless law according to Davidson. It looks as if the physical properties of your decision “screen
off” the mental property, making the latter irrelevant.
LePore and Loewer concede that mental properties are screened off by
physical properties. But they argue that this more refined test is too
demanding, for it would also mean that the physical properties of a
mental cause are irrelevant. Note in particular that the
decision’s mental properties screen off its physical properties:
if the cause had lacked its physical properties yet had still been a
decision to turn on the light, it would have caused Gus to flip the
switch (ceteris paribus: here a hedged law, which anomalous
monism permits, is in play). Screening off thus goes both ways, and
since few would want to deny causal relevance to the physical
properties, we should not let screening off impugn the significance of
mental properties either.
Antony (1991) replies that there is no
symmetry here, at least not given anomalous monism. While the
decision’s physical properties screen off its mental
properties, the reverse doesn’t hold. Suppose again that the
cause had lacked its physical properties but had still been a decision
to turn on the light. On anomalous monism, Antony argues,
there’s no saying what Gus’s decision would have caused,
for mental properties, being anomalous, place no constraints on the
causal structure of the world. (See also Leiter and Miller 1994.)
The freeloader problem arises in a variety of contexts in the mental
causation literature, not just in discussions of anomalous monism. It
will return under a number of guises in what follows.
Fodor (1989) apparently agrees that counterfactuals capture a kind of
causal relevance, but he argues that LePore and Loewer have settled
for too little. On Fodor’s view, mental properties can be
relevant to behavior in a stronger sense in which they
are sufficient for their effects and in this way “make
a difference”. Fodor spells out sufficiency in terms of laws: a
property makes a difference if “it’s a property in virtue
of the instantiation of which the occurrence of one event is
nomologically sufficient for the occurrence of another” (Fodor
1989, p. 65, note omitted).
Might such an account save anomalous monism from the charge of
epiphenomenalism? On the face of it, it cannot, for as we’ve
noted, mental properties on Davidson’s view appear only in
hedged laws, laws that include an implicit ceteris paribus
rider. Consider a candidate psychological law:
The ceteris paribus clause here would seem to block the
mental properties in question from being causally sufficient for the
behavioral effect. But perhaps not: according to (L), the mental
properties are sufficient for the behavioral effect when the
ceteris paribus conditions are satisfied. And this sort of 
causal sufficiency, Fodor argues, is all anyone could reasonably want for
mental properties.
But can Davidson help himself to such an account? Davidson appears to
think so (1993, p. 10), as does McLaughlin (1989), who also appeals to
hedged laws. Fodor, however, doubts his account is compatible with
anomalous monism; such doubts are developed by Antony (1991) and Kim
(1993b). The question turns largely on Davidson’s reasons for
thinking the mental is anomalous, and on whether these reasons permit
him to appeal to hedged laws in the way the laws account requires.
Supposing anomalous monism is compatible with Fodor’s account,
you might still wonder whether nomological sufficiency is enough for
causal relevance. An account of causal relevance in terms of laws is
natural given the tight connections between laws and properties
(see laws of nature, §3). But
those sympathetic to Fodor’s position might still ask (as Fodor
himself does) what the causal mechanism is in mental–physical
interactions. For example, it could turn out that the reason
psychophysical laws such as (L) hold is that mental properties are
themselves grounded in more basic, physical properties, and that only
the latter do genuine causal work: mental properties again look like
freeloaders (§5.3), merely piggybacking on the real bearers of
causal powers (LePore and Loewer 1989; Block 1990; Leiter and Miller 1994; Marras 2003).
Davidson replies to his critics in “Thinking Causes”
(Davidson 1993). In that paper he sometimes speaks favorably of
“causally efficacious” properties, and he helps himself to
both hedged laws and counterfactuals to secure the efficacy of mental
properties. But his considered position appears less conciliatory. He
clearly denies a crucial assumption of his critics, namely, that
causes do their causing in virtue of their properties. When an event
causes something, it doesn’t do so qua this or that: it
just causes what it does, full stop. Were this so, none of the
property-based problems discussed here could get off the ground (Crane
1995; Campbell 1997; Gibb 2006).
Such a response seems to miss the point (Kim 1993b; McLaughlin 1993;
Sosa 1993). All parties in this dispute agree that mental events can
cause physical events. The difficulty is to understand how they could
do so in virtue of their mental
(rather than their physical) properties, how they could have physical
effects qua mental. The principle of the Nomological
Character of Causation (§5.1) apparently requires that, when one
event causes another, it does so in solely virtue of its physical
properties.
But Davidson is part of
a nominalist tradition that
rejects properties, at least as his critics conceive of them. Davidson
instead formulates anomalous monism in terms of predicates
and descriptions. An event is mental if it answers to a
mental predicate (that is, it can be picked out using a mental description), physical if it answers to a physical
predicate (it can be referred to using a physical description). Davidson’s critics assume that if an event answers to both sorts of predicate, it
includes a mental property and a physical property. But Davidson
thinks about the mental–physical distinction as merely a
difference in description, not as the expression of an ontological
divide between kinds of property. For Davidson, then, it makes no more
sense to ask whether an event had a particular effect in virtue of
being mental or in virtue of being physical than it would to ask
whether its effect stemmed from its being described in English or in
German. (For further discussion, see Heil 2009.)
While reflection on property dualism or anomalous monism can lead to
our next property-based problem, another route is by way of the
doctrine of
 non-reductive physicalism. 
Like the property dualist, the non-reductive physicalist holds that
mental properties are not physical.  But unlike the property dualist,
the non-reductive physicalist insists on a strong dependence of the
mental on the physical: mental properties are “realized” or “constituted” by physical
properties. This strong tie between the mental and physical is the
subject of a large contemporary literature, some of which we touch on
below.
Non-reductive physicalism in its current form grew out
of functionalism, according to which
mental properties are functional properties. To be in pain, for
example, is a matter of being in a state with a certain causal
profile, a state that’s caused by tissue damage, and causes
certain overt responses (moans, attempts to repair the damage, beliefs
that one is in pain). But, argue functionalists, it is most unlikely
that we could identify a single kind of physical state playing this role in every actual and possible case of pain. Human
beings differ in endless tiny physiological ways: your neurological
states, including states you go into when you are in pain, probably
differ subtly from another person’s. Human beings’
neurological states, in turn, differ from those of a cat or a dog, and
perhaps dramatically from states of an octopus. You might even imagine
encountering aliens with vastly different biologies, but to which you
would unhesitatingly ascribe pains.
Here we arrive at a core thesis of functionalism: states of mind are 
 “multiply realizable”.
The property of being in pain can be realized in a wide variety of
physical (and perhaps non-physical) systems. A creature is in pain in
virtue of being in a state with the right sort of causal profile, some
sort of neurological state, say. But the property of being in pain cannot
be identified with this neurological state, because
creatures of other kinds can be in pain in virtue of being in vastly
different physical conditions. Functionalists often put this point by
saying that mental properties are “higher-level”
properties, properties possessed by objects by virtue of their
possession of appropriate “lower-level” properties, their
realizers.
Now, however, we are again confronted with the threat of
epiphenomenalism. If mental properties are not physical,
how could they make a causal difference? Whenever any mental
(functional) property M is instantiated, it will be realized
by some particular physical property P. This physical
property is unproblematically relevant to producing various behavioral
effects. But then what causal work is left for M to do? It
seems to be causally idle, “excluded” by the work
of P.
This version of the problem of mental causation has appeared in
various guises. Much of the contemporary literature is inspired by Malcolm 1968, especially as refined in Kim 1989, 1993c, 1998, 2005. Whatever its precise formulation (cp. Shapiro and Sober 2007; O’Connor and Churchill 2010; historical perspective is in Patterson 2005), the Exclusion Problem has clear affinities with the other problems we’ve looked at so far. Consider our claim that the realizing property P must play a role in producing a particular behavioral effect. This would seem to be justified either
by an appeal to Completeness (§2.4) or to
Davidson’s doctrine (§5.1) that causal relations must fall
under strict (and so physical) laws. Moreover, the argument’s
depiction of P and M as competing for causal
relevance—one must exclude the other—would seem to require
a principle such as No Overdetermination (§2.4). And the
fundamental worry that P might exclude M looks
exactly like the freeloader problem that badgers mainstream attempts
to save anomalous monism (§§5.3–4).
In spite of these similarities, the Exclusion Problem is in one
important respect unique: unlike the problems we’ve looked at so
far, exclusion worries generalize to a wide range of phenomena outside
of the mental. Any properties, mental or otherwise, that are
multiply realizable in physical systems are threatened with causal
irrelevance. (For discussion of this and related issues, see Kim 1998,
pp. 77–87; Noordhof 1999; Bontly 2001; Gillett and Rives 2001;
Block 2003; Walter 2008.)
Some philosophers (e.g., Fodor 1989; Baker 1993; Shapiro 2010) take this general
nature of the problem to be an encouraging sign. We happily
accept biological, or meteorological, or geological properties as
causally significant despite their being distinct from their physical
realizers. Why then imagine that exclusion threatens the efficacy of
mental properties? Others turn this argument around, insisting that
the alleged efficacy of biological and other “special
science” properties is by no means sacrosanct (Antony
1995). Causal powers we attribute to them must respect what our best
metaphysics tells us. And in any case, the central issue is not so
much whether mental properties (and the rest) are causally
relevant to the production of physical effects, but how
they could be (Kim 1998, pp. 61–2, 78–9; Antony
and Levine 1997, p. 96; McLaughlin 2006). Even if the Exclusion
Problem, because it generalizes, does not tempt us to embrace
epiphenomenalism, it presses on us a responsibility to explain how
mental properties could play a causal role given that they appear to
be screened off by their physical realizers.
The Exclusion Problem is the subject of a large and still-growing 
literature. In the next few sub-sections, we look at some of the main
lines of response, dividing them into three broad categories.
The Exclusion Problem presents us with a picture on which 
higher-level mental properties compete with their 
lower-level physical realizers. Physical properties are 
unproblematically relevant in the production of behavior, and so 
mental properties must either find a way to do the work that their 
realizers are already doing or face exclusion. But some philosophers 
would insist that this picture is deeply misleading: mental 
properties enjoy causal relevance in their own right and are not 
threatened by exclusion from physical properties.
This “autonomy solution” (Jackson 1996, §2) can take
a variety of forms. One version starts by observing that psychological
explanations—and more generally, explanations in the special
sciences—are in an important sense independent of physical
explanations. Psychological explanations typically abstract away from
details of lower-level implementation, appealing instead to their own
distinctive kinds and laws. Explanations in the special sciences can
thus proceed independently of those in the lower-level physical
sciences. If the structure of the causal order reflects these
explanatory practices, mental properties need not be threatened by
exclusion. Mental and physical causes can peacefully
coexist. (Variations on this theme appear in Dennett 1973; Baker 1993;
Van Gulick 1993; Garrett 1998; Hardcastle 1998; Marcus 2001; Menzies 2003; Raymont
2003; Ross and Spurrett 2004; Woodward 2008; Zhong 2014; see also §7.5.)
This appeal to explanation can naturally lead to (though it does not
entail) another autonomy solution, the dual explanandum
strategy. The Exclusion Problem presents a mental (functional)
property M and its physical realizer P as competing
to be causally relevant to the same effect, namely a bit of
behavior. But M might not be threatened with exclusion
if M and P are causally relevant to different
properties of the effect. Return for a moment to the paperweight
example from §3. The shape of the paperweight is relevant, not to
the impression simpliciter, but to the
impression’s shape. In general, a causally relevant
property is relevant to some particular property of the effect (Horgan
1989). Perhaps, then, M and P do not causally
compete because they are parts of separate, autonomous causal lines to
different properties of the effect.
Consider one way this might work. Behavioral properties, just like
mental properties, appear to be multiply realizable. For example,
there is more than one way to hail a cab, many different physical
realizations of this kind of behavior. Now suppose a belief causes you
to hail a cab. In accordance with Completeness, some physical
property P of the belief is sufficient for your behavior. But
strictly speaking, P is relevant only to the
particular way in which you hailed the cab, the particular
physical realization of your hailing. What, then, is responsible for
your behavior’s higher-level property of simply
being a cab-hailing? It’s natural to suppose that it’s a 
higher-level property of your belief, namely, some mental property, 
such as the belief’s representational content. (For proposals along 
these lines, see Yablo 1992; Thomasson 1998; Marras 1998; Crisp and 
Warfield 2001; Gibbons 2006; Schlosser 2009; see also §§7.3–4.)
A strength of autonomy solutions is that they secure a causal role for
mental properties without running afoul of Completeness, as
the physical realization of behavior is always matched with some
physical properties of its cause. But do autonomy solutions
respect No Overdetermination? Here matters are not as
straightforward. Autonomy solutions present us with two
properties, P and M, each sufficient for the
behavioral effect. It might seem as if the dual explanandum strategy
avoids this awkwardness, since P and M are relevant
to different properties of the effect. But even here,
overdetermination threatens, as the effect’s behavioral property
is produced twice: directly by M, and indirectly
by P, which produces the behavioral property’s physical
realizer, which itself necessitates the behavioral property.
Proponents of autonomy solutions might grant these points but claim
that such “overdetermination” is innocuous, far from the
“intolerable coincidence” threatening Cartesian dualist
accounts of mental causation (§2.4), for the two causal lines
present are not independent. (The nature of overdetermination has
itself become the subject of a literature inspired, in part, by the
Exclusion Problem. See, e.g., Funkhouser 2002; Bennett 2003;
Sider 2003; Walter 2008; Carey 2011; Bernstein 2016.)
Autonomy solutions can make it appear that the causal powers of mental
properties “float free” of their physical realizers,
bringing to mind the doctrine of parallelism (for replies, see
Thomasson 1998; Marcus 2001, §3.3). Some non-reductive
physicalists have accordingly looked to tie the causal powers of
mental properties more closely to those of their physical
realizers. The idea is that mental properties are so intimately
related to their realizers that the former “inherit” the
causal powers of the latter. The relation between levels is not one of
rivalry, such that the physical might exclude the mental, but one of
cooperation. Nor, moreover, does there seem to be any threat of
overdetermination, since the mental works through the
physical. (Compare the metaphor of “transparency” in
Jackson 1996.)
On some versions of the inheritance solution, what the higher-level
mental property derives from its physical realizer is some weaker or
“lower-grade” form of causal relevance. For example,
Jackson and Pettit (1988, 1990) distinguish the robust “causal
efficacy” of physical properties from the weaker “causal
relevance” of higher-level properties. Causal relevance in this
sense is an explanatory notion: as one might put it, behavior is
produced at the physical level, but by being realized in the physical,
mental properties inherit an explanatory relevance they wouldn’t
have otherwise. An advantage of such a view is that it accords a
derived form of relevance to mental properties, but in a way that
respects both the priority of physical causation embodied
in Completeness as well as the principle of No
Overdetermination. (For similar views, see Kim 1984; Levine 2001,
§1.5; Segal 2009. Those who appeal to the counterfactual
dependence of behavior on the mental [§5.3] might also fall into
this category. For an answer to the charge that counterfactual
dependence is “causation lite”, see Loewer 2007; Menzies
2007.)
If such a weakening seems to amount to epiphenomenalism, you might
look for an inheritance solution on which mental properties are
efficacious in the same sense that their physical realizers are
(compare the “homogeneity assumption” in Crane 1995). How
can this be done without violating No Overdetermination?
Well, suppose that a mental property is, in spite of being distinct
from its physical realizer, immanent in this
realizer; M, that is, is somehow nothing over and
above P. In that case, any causal work done by P is,
in a straightforward way, inherited by M. Overdetermination
is avoided because M’s work is included
in P’s.
The metaphysical details of such a picture matter. Otherwise,
“immanence”, “nothing over and above”, and the
like will turn into mere labels for that psychophysical relation, we
know not what, that solves the Exclusion Problem. Accordingly, several
promising lines of inquiry have been pursued. Mental and physical
properties are said to be related by, for example, the
determinable–determinate relation (Yablo 1992; critics include
Ehring 1996; Worley 1997; Funkhouser 2006), constitution (Pereboom
2002; critics include Ney 2007; Heil 2011), metaphysical necessitation
(Bennett 2003, 2008), physical explicability (Antony 1991), physical
implementation (Marras 2003), and grounding (Kroedel and Schulz 2016).
You might ask why any of these relations should secure the desired
solution. One thought is that if mental properties are immanent in
their physical realizers, the causal powers of a mental property
are included among those of its realizer. Consider again
mental property M and one of its realizers in a given
instance, P. Plausibly, M’s powers are
included in P’s. Both properties, for example, have the
power to cause a certain kind of behavior, but because of its greater
“specificity”, P has in addition to this powers
that M lacks. Now in general we don’t think that wholes
causally compete with, or are excluded by, their parts. When Gus steps
on Lilian’s toe, his foot’s causing Lilian discomfort
doesn’t exclude Gus’s causing her discomfort. Both Gus and
his foot coexist as causes, without competition and, we might add,
without overdetermination. A similar point could be made about
properties: if the causal powers of M are included in those
bestowed by P, then P’s causal relevance to
behavior, far from excluding M’s, includes
it. (Approaches along these lines have been developed in Antony 1999; Shoemaker 2001; Wilson 1999, 2011; Clapp 2001; critical discussions include Heil 1999, 2011; McLaughlin 2007; Kim 2010; Ney 2010; Audi 2012.)
Autonomy and inheritance solutions grant at least this much to the
Exclusion Problem: mental and physical properties are numerically
distinct, however intimately they are otherwise related. But a third
sort of strategy tries to undermine the argument at exactly this
point: any mental property just is its physical realizer. If
M=P, there’s no question of one’s excluding the 
other, nor is there any mystery of how M can work through 
P, for M and P are one and the same.
This sort of psychophysical property identity would seem to be blocked
by the multiple realizability argument sketched earlier. But that
argument, in spite of its wide appeal, has come under attack from
several directions (see
 multiple realizability,
 §2). For example, some (Kim 1992; Lewis 1994; Jackson 1995; Heil 2003) take the argument to show, not that
mental properties are distinct from their physical realizers, but that
what we thought was one kind of mental property is actually
many. Pains realized by different physical properties, in spite of
having the same name (“pain”), are different,
though similar, mental properties. There is no such property as pain
simpliciter, only pain-for-this-physical-structure and
pain-for-that-physical structure. Once such
“structure-specific” identities are allowed, we can say
that M (now just, say, pain-for-human beings) is identical
with P, M’s “realizer” in human
beings (replies include Fodor 1997; Block 1997; Marras 2003; Moore and Campbell 2010).
This solution comes at a price: it forces us to abandon the belief
that pain is a single, natural kind. There is, however, a way to
preserve this doctrine while pursuing a strategy that’s
otherwise similar to the one just sketched. The essential idea is that
“property” as we’ve used the term so far is
ambiguous. A property could be what characterizes an object (event),
or what unifies several objects as a “one across
many”. Now suppose the characterizing properties are
 tropes:
 particularized properties, unique to each object. And suppose the 
unifying properties are something else—call these 
“types”. If the mental “properties” that 
are causally relevant to behavior are tropes, and the mental 
“properties” mentioned in the multiple realizability
argument are types, there’s no reason to think that this
argument rules out psychophysical property-identities in any way that
leads to exclusion worries. The M-trope and
the P-trope are one and the same trope falling under two
types, mental and physical.  This proposal allows for a
single type pain shared by diverse creatures; it’s just
that this type is not the same sort of entity (a trope) that’s
efficacious in the production of behavior (Heil 1992; Robb 1997; Heil and Robb 2003; what appears to be a similar view is defended by Macdonald and Macdonald 1986, 1995a; see also Whittle 2007.)
One worry about this proposal is that it appears to raise the
Exclusion Problem all over again, this time at the level of properties
(tropes). If a single property is both mental and
physical, Completeness and No Overdetermination
force us to say that it’s efficacious only qua
physical, not qua mental. (For this and other criticisms, see
Noordhof 1998; Raymont 2001; Gibb 2004; Macdonald and Macdonald 2006;
Alward 2008; Maurin 2008; see Robb 2013 for some replies.)
Functionalism, along with any non-reductive theory of mind, faces the
problem just discussed. But even if exclusionary worries are finessed,
functionalism faces an additional and possibly more fundamental
problem.
As we noted earlier, functionalism characterizes states of mind
causally. To be in a given mental state is to be in a state with the
right sort of causal profile, a state bearing the right sorts of
relation to other states. Think of functional states as nodes in a
network of states, the identity of which depends on the relations they
bear to other nodes, and think of the realizers as occupants of these
nodes. All there is to a node is the potential causal
relations it bears to other nodes (not so for the occupants, which
have intrinsic properties). Suppose, then, that F
and G are functional properties—nodes in this
network—and that all there is to something’s
being F is its being a G-causer. The resulting
generalization, “Fs cause Gs”, is no
doubt true, but it is vacuous, equivalent to the generalization
that G-causers cause Gs.
This appears to strip functional properties of their causal
efficacy. Why? One line of thought appeals to Hume’s celebrated
doctrine that there can be no necessary connections between distinct
existences. A mental property and its would-be effect are distinct,
yet functionalism entails that they enjoy a necessary connection. On
the Humean doctrine, such a connection could not be causal. Another,
closely related, version of the problem requires that causal relations
be subsumed by empirical laws. But there are no such laws available
for functional properties if all of the relevant generalizations are
analytic and vacuous. (The foregoing argument in either version
threatens to generalize to all dispositional properties:
see  dispositions, §6. For the
problem aimed at functionalism in particular, see Block 1990; Rupert
2006; functionalism, §5.2.)
This argument echoes the logical connection argument advanced in the 1950’s and 60’s against causal accounts of action (e.g., Melden 1961, pp. 52–3). Given that reasons (desires, intentions) are not logically distinct from the actions they rationalize, reasons could not cause actions. In
response, Davidson (1963) noted that logical connections hold among
predicates or descriptions of events, not among events themselves. A
cause could be described in various ways, some of which will involve
the effect: consider “the cause of the fire caused the
fire”. This is hardly informative, but it’s not thereby false. And of course the statement, far from precluding a causal relation,
explicitly asserts it. That said, if the claim is true, it should be possible
to identify the cause of the fire independently of reference to the
effect—as “the match’s igniting”, for
instance. In defense of his own causal theory of action, Davidson
argued that such a re-description of mental causes is always
available, at least in principle (see §5.1).
But Davidson’s saving move appears not to be available for the
functionalist, for in the case of functional states and properties, no
such independent descriptions are available, as the nature of a
functional property is exhausted by its place in the causal
network.
The functionalist has a number of options available, some of them
mirroring solutions to the Exclusion Problem (Rupert 2006 provides a
critical survey). For example, a functionalist could settle for a
weaker, explanatory role for functional properties, leaving causal
efficacy to the realizers of functional states (§6.4; see, e.g.,
Segal 2009; compare Roth and Cummins 2014). Or a functionalist might identify
states of mind with their realizers (§6.5); indeed, some of the
early functionalists were identity theorists (Lewis 1966, 1994; Armstrong
1968/1993). This would permit the sort of re-description that the more
mainstream version of functionalism apparently blocks. A third option
is to look for non-vacuous, empirical generalizations subsuming
functional properties (Antony and Levine 1997). Yet a fourth option
rejects the Humean doctrine, permitting necessary connections between
a causally efficacious property and its effect. Such a proposal would
find a home in the more general “causal theory of
properties” defended by Shoemaker (1980, 1998) and others.
Our final version of the property-based problem is restricted to
intentional mental properties, that is, properties in virtue of which
some mental states—propositional attitudes, perceptual
experiences, mental images, and so on—are about
something, properties in virtue of which mental states have
representational content. We assume here
that externalism is true, so
that the contents of representational states of mind depend, not
merely on intrinsic features of those states, but on relations, in
particular, on the causal, social, and historical relations agents
bear to their surroundings. In the simplest case, Lilian is thinking
about water (H2O) because she stands in the right
sorts of causal relation to water. The key move here is to reject the
idea that meaningful objects or states owe their meaning to their
intrinsic make-up alone.
The causally problematic feature for externalism is this contextual or
relational component of representational mental states. Suppose that
our mental representations are physical structures in the brain. Now
suppose with the externalist that the content of these representations
is determined, not just by our intrinsic features, but by context as
well. Lilian (or Lilian’s brain) represents a tree in the quad
by going into state T. But T represents a tree in the quad, not by virtue
of T’s (or, for that matter, Lilian’s) intrinsic
makeup, but by virtue of
T’s (and by extension Lilian’s) standing in the right kind 
of relation to the tree. The very same kind of state in a different 
context (in the brain of someone in different circumstances) might 
represent something very different—or nothing at all.
Now if the content of Lilian’s thought that there is a tree in
the quad is “broad”, if the significance of her thought
depends on factors outside Lilian’s body, then it is indeed hard
to see how this content could figure in a causal account of her
actions, including Lilian’s expressing her belief that there is
a tree in the quad by uttering the sentence, “There is a tree in
the quad”. This is bad news for any attempt to explain why we do
what we do by reference to the contents of our thoughts.
Consider an analogy (Dretske 1998). Gus inserts a quarter into a vending machine. The
coin has a range of intrinsic qualities common to quarters, but its
being a quarter does not depend solely on these intrinsic qualities: a
quarter’s intrinsic qualities would be shared by a decent
counterfeit. The coin’s being a quarter depends on its having
the right sort of history: it was produced in a United States
mint. This is something the vending machine cares nothing about. The
machine reacts only to the coin’s intrinsic features. You might
put this by saying that the coin affects the machine, not qua
quarter, but only qua possessor of a particular kind of
intrinsic makeup. (Vending machines are built to take advantage of the
contingent fact that objects with this intrinsic makeup are almost
always quarters.)
The worry is that we apparently operate, in important respects, as
vending machines do. We respond to incoming stimuli solely in virtue
of our intrinsic makeup and the intrinsic character of the
stimuli. But if our thoughts possess their content in virtue of our
standing in complicated environmental–social–historical
relations to our surroundings, it is hard to see how such contents
could make a causal difference in our psychological economy, how they
could figure in the production of behavior. Thoughts have
contents, but these contents could have no direct influence on the
operation of mental mechanisms (Stich 1978; Kim 1982; Fodor 1980,
1987, ch. 2, 1991; Jackson and Pettit 1988).
One general line of response notes that whenever we explain a bit of
behavior by appeal to extrinsic content, there is a local, intrinsic
property available as a “causal surrogate” to produce the
behavior (Crane and Mellor 1990). Such a surrogate may be
neurophysiological or, as
on computationalist views, a
complex of “formal” or “syntactic” properties
of internal representations. Now by itself, this point seems just to
highlight the problem: if intrinsic surrogates are always needed, all
the more reason to reject the efficacy of content. Some have indeed
drawn such a lesson, concluding either that content has no role to
play in an explanatory psychology (Stich 1978, 1983), or perhaps that
psychological explanations appealing to content were never causal to
begin with (Owens 1993; see also the noncausalists cited in
§1.1).
But this might be too hasty. Far from precluding the causal efficacy
of content, the surrogates might in fact play a role in ensuring
it. Note that while Lilian’s intrinsic properties don’t
guarantee the contents of her beliefs, her intrinsic properties are,
in her environment, reliably correlated with these contents—so
reliably, in fact, that content, in spite of being extrinsic, enters
into the counterfactuals or laws often thought to
ground causal efficacy. It seems clear, after all, that if Lilian had
not believed there was water in front of her, she would not have
extended her hand. This counterfactual could be secured by the fact
that Lilian’s believing “There’s water in front of
me” covaries with some internal state of her brain, but the
counterfactual, for all that, is still true. A similar point could be
made using (hedged) laws connecting content with behavior. The terrain
here in any case is similar to that explored earlier in
§§5.3–4, though the extrinsic nature of content
introduces its own complexities. (On the counterfactuals, see Mele 1992, ch. 2; Yablo 1997; on the laws, see Braun 1991; Fodor 1995.)
There’s a more direct way that the intrinsic surrogates might secure
the efficacy of content: perhaps the surrogate properties are
content, or rather a kind of
content. Distinguish narrow from broad
content. Think of narrow content as the content of a representational
state of mind minus its “broad” components. Consider
Lilian (or Lilian’s brain) and an intrinsically indiscernible brain in
a vat wired to a supercomputer. Grant that Lilian and the envatted
brain entertain intrinsically indiscernible thoughts with utterly
different representational contents. Now imagine that we could
abstract a common element from the contents of Lilian’s and the
brain’s intrinsically indiscernible thoughts. This element is their
narrow content. Because narrow content is something all intrinsic
duplicates must have in common, the hope is that such content could be
the very intrinsic properties that produce behavior.
The notion of narrow content might raise suspicion, however. Return to
the vending machine. The quarter Gus inserts in the machine has a
particular value owing to relations it bears to outside goings-on: it
was minted in the Denver mint. A counterfeit placed in the machine
could have the very same intrinsic makeup as the quarter, but it would
lack the quarter’s value. It looks as though it is the
quarter’s intrinsic makeup, not its value, that matters to the
operation of the machine. Now imagine someone arguing that a quarter
and an intrinsically indiscernible slug do in fact share a kind of
value: narrow value. Because narrow value accompanies an
object’s intrinsic qualities, we need not regard narrow value as
epiphenomenal. But what could narrow value be?  Whatever it is, could
it in any way resemble value ordinarily conceived—broad
value? Narrow value looks like a phony category posited ad
hoc to accommodate an otherwise embarrassing
difficulty. Nevertheless, some philosophers remain optimistic about
the prospects of a viable internalist account of content, one
that would allow fully fledged thoughts to have a role in the
production of behavior. (For references and further discussion,
see narrow mental content.)
Another, much different, attempt to preserve a causal role for content
can be found in Dretske 1988, 1989, 1993. So far we’ve assumed
that a behavioral event is distinct from the mental event that causes
it. On Dretske’s view, however, behavior is a process
that includes, as a component, its mental cause. When mental
event a causes bodily movement
b, the behavior in this case is not b itself, but 
the process of a’s causing b. When Lilian raises her hand 
because she wants to get the teacher’s attention and she believes 
that raising her hand will accomplish this end, her behavior is not 
her hand’s going up, but the process of this belief-desire pair’s 
causing her hand to go up.
Dretske grants that when mental event a initiates
(“triggers”) a process ending in bodily
movement b,
a does so solely in virtue of its intrinsic makeup. 
Nevertheless, a’s relational, intentional properties have a 
causal role, for they can be relevant to the fact that a causes 
b. Reasons are “structuring causes” of behavior: it’s because of
what a indicates that it was “recruited” during the learning
process as a cause of b. (Indication here is a matter of 
reliable co-variation.) It’s because, for example, Lilian’s belief 
indicates what it does—raising one’s hand (in these 
circumstances) is a way to get the teacher’s attention—that it 
was (together with the relevant desire) recruited as a cause of her 
hand-raising. Relational, intentional mental properties thus become 
causally relevant to behavior, because they are relevant to 
structuring the very causal processes that, on Dretske’s view, 
constitute instances of behavior.
Dretske’s proposed solution quickly produced a number of
responses (e.g., Smith 1990; Block 1990; Baker 1991; Horgan 1991; Kim 1991; Mele
1991). One question is whether relational, intentional properties
in fact play a causal role in the structuring (or
“wiring”) of causal processes in the brain. Even during the learning process, the states of Lilian’s brain would seem to
be sensitive only to local, intrinsic features of one another,
features that screen off external goings-on.  Dretske might be
able to avoid such screening-off by appealing to the counterfactual
dependence of behavior-structuring on these goings-on.  His view would
then stand or fall with the success of counterfactual theories of
causal relevance (§5.3). A second question is whether intentional
states, even if they were relevant in the way Dretske says they are,
deliver the kind of causal relevance we want. When Lilian
raises her hand, the structuring of the relevant processes in her
brain has already occurred. If intentional properties are relevant at
all, then, they are apparently relevant only to what happened in the
past during the learning process. But we normally regard mental
properties as causally relevant to what’s going on here and now,
the very time when Lilian (or anyone) acts (but cf. Allen 1995; Dretske replies to critics in his 1991, esp. pp. 210-7).
Dretske’s proposal is a version of the dual explanandum
strategy (§6.3). The idea is that physical and mental properties
are causally responsible for different effects.  For Dretske, the
(triggering) physical properties are responsible for bodily motions,
while the (structuring) mental properties are responsible for
behavior.
Another version of this strategy begins with a point also made in
§6.3, namely that to question a property’s causal relevance
is really to question its relevance to some property of the
effect. The form of our central causal question, that is, is whether a
mental cause qua F causes a behavioral effect
qua G. Now when F is an intentional mental
property, what G is the object of our question? One 
possibility is that it is a behavioral property that, like the mental
property, is itself “broad” (see, e.g., Enc 1995).
Consider a simple example: Suppose Lilian believes that a glass in
front of her contains water, and this belief (together with her
desires) causes her to reach for the glass. Her behavior is an
instance of trying to get water, and it’s the
instantiation of this property (and not, say, the property of
being a certain kind of bodily motion) that we’re wondering
about when we ask whether the intentional property of her belief is
causally relevant.  (If our interest lay solely in explaining a
particular bodily motion, we would rest content with a
non-psychological, purely physiological explanation.) But now the
answer seems straightforward. For what makes Lilian’s
behavior a trying for water is that it’s caused by a
belief whose content concerns water. Once we realize that the
behavioral property of the effect is itself broad, its connection to
the intentional mental property seems clear.
This is not to say that the physical properties of Lilian’s
belief do no work: it’s just that they are responsible for a different
property of the effect, for instance, the property of being a forward
arm-movement. The intentional properties of her belief are relevant to
the effect qua (broad) behavior; the physical properties are
relevant to the effect qua (narrow) bodily motion. And as we
noted earlier (§6.3), such a solution can be employed in response
to the Exclusion Problem as well. If a mental property and its
physical realizer are relevant to different properties of the effect,
they need not compete causally.
Because it promises to solve two outstanding problems of mental
causation, this approach is potentially quite powerful. (For
discussion, see Fodor 1991; Burge 1995.) One question to raise here,
however, is whether the fact that some behavior can be described
broadly makes the intentional mental property of its cause relevant.
The undeniable conceptual connections between mental and behavioral
descriptions might point to a kind of explanatory relevance,
but it’s a further question whether causal connections grounding
these explanations involve broad properties. Those motivated by the
original epiphenomenalist arguments will worry that narrow, physical
properties are really doing all the work here: the apparent relevance
of the broad properties is an illusion created by the way we, in
describing and explaining behavior, conceptualize both cause and
effect (see Owens 1993). This point leads to a fourth, related
response to the problem.
Some theorists would challenge the distinction—implicit in the
foregoing discussion—between explanation and causation. Our
concept of causality, they would insist, is bound up with the
concept of explanation: causally relevant properties are those that
figure in our best causal explanations (Segal and Sober 1991; Wilson
1992; Burge 1993; Raymont 2001; §6.3). We find out what causal
relations amount to by starting with clear cases of causal
explanation. Given that we (and the cognitive scientists) routinely
explain physical events by citing mental causes (and mental events by
invoking physical causes), questioning whether real causal
relations answer to these explanations is to succumb to the kind of
metaphysical hubris that gives metaphysics a bad name.
This appeal to explanatory practice has the potential to answer in one
fell swoop all four of the property-based problems we’ve
considered.
Doubtless our understanding of the notions of causality and causal
relevance depends importantly on our grasp of causal explanations.
But there are at least two areas of concern about the explanatory
strategy (compare Kim 1998, pp. 60–7). First, you might wonder
whether the strategy addresses the right question. Earlier,
we pointed out that the central question of mental causation is not so
much whether mental properties are causally relevant but
how they could be, given some alleged feature of mental 
properties (in the case at issue here, the feature is their being 
relational properties). The explanatory strategy would at best seem 
to be addressing only the “whether” question, not the “how” question.
Second, even when restricted to the “whether” question, the strategy 
rests on a conflation of what appears to be an epistemological notion
(explanation) with metaphysical notions (causation and causal 
relevance). A full evaluation of the view would thus require a deeper
look into how the two are related.
We have been treating the problem of mental causation as though it
were a problem in applied metaphysics. Perhaps this approach is
wrong-headed. Perhaps the problem really falls under the purview of
the philosophy of science. What if we began with a look at actual
scientific practice (as suggested in §§6.3, 7.5) and
determined what exactly science requires for acceptable causal
explanation? An examination of established special sciences reveals
that the very features (multiple realizability, higher-level and
“broad” properties, for instance) metaphysically inclined
philosophers regard as posing apparently insuperable difficulties for
mental causation, are routinely invoked in causal explanations in
those sciences. This suggests that, rather than let a priori
conceptions of causation (or properties, or causal powers) lead us to
regard mental causation with suspicion, we should reason in the other
direction: revise our conception of causation to fit our actual
scientific beliefs and practices. If the metaphysicians were right
about causation, no science would be possible beyond basic physics
(biological properties, for instance, would lack causal efficacy).
This is one way to go. Another way is to take a step backward and ask
which features of our conception of the mental, features we commonly
take for granted, might be the source of our difficulties.
Eliminativists aside, all parties evidently agree that “realism
about the mental” requires that mental predicates figuring in
causal accounts of behavior designate distinctively mental
properties. If we aim to honor psychology (and the other special
sciences), our job is to show how these properties could be causally
relevant to physical goings-on. Suppose, in contrast, that you took
the goal to be, not the preservation of mental properties,
but the preservation of mental truths. In that case we would
seek an account of the mind that provides plausible truthmakers for
psychological and psycho-physical claims, including claims concerning
mental causation.
One possibility is that truthmakers for psychological truths include
irreducibly mental properties. This is not the only possibility,
however. Another is that psychological assertions are made true by
physical states and properties, states and properties answering to
predicates belonging to physics and chemistry. A view of this kind
(which is close to Davidson’s as spelled out in §5 and to
the identity solutions discussed in §6.5) would endeavor to
resolve the problem of mental causation, not by tinkering with the
causal concept, but by rejecting the idea that mental and physical
properties are distinct kinds of property. All parties agree that
mental predicates and descriptions differ from physical predicates and
descriptions. Application conditions for mental terms and physical
terms diverge in ways that preclude definitional reduction of the one
to the other. Perhaps it is a mistake, however, to move from this
linguistic fact to a substantive ontological thesis: mental and
physical predicates designate properties belonging to distinct
families of properties.
Whether anything like this could be made to work is an open question.
To the extent that you regard the current state of play as 
unsatisfying, however, it is perhaps a question worth pursuing.