Twentieth century philosophy of science was largely dominated by
logical empiricism. More a framework for doing philosophy of science
than any coherent set of doctrines, logical empiricism addressed a
range of issues in philosophy of science through the lens of the
logical and mathematical structures constitutive of scientific thought
and practice (see the entry on 
 logical empiricism). Logical
 empiricism tended, by and large, to
focus on abstract, epistemic features of science, with little
attention to scientific practice. Physics was the dominant
exemplar.
The new mechanical philosophy emerged around the turn of the
twenty-first century as a new framework for thinking about the
philosophy of science. The philosophers who developed this framework
were, by comparison with the logical empiricists, practitioners as
well of the history of science and tended, by and large, to focus on
the biological, rather than physical, sciences. Many new mechanists
developed their framework explicitly as a successor to logical
empiricist treatments of causation, levels, explanation, laws of
nature, reduction, and discovery. 
As with logical empiricism, the new mechanical philosophy is less a
systematic and coherent set of doctrines than it is an orientation to
the subject matter of the philosophy of science. The approach emerged
as philosophers and historians of science began to break from the
once-standard practice of reconstructing scientific inference with the
tools of logic and, instead, to embrace detailed investigation of
actual episodes from the history of science. The main tenets of
logical empiricism had been under intense criticism for decades, and a
new era of historically informed philosophy of science had taken hold
through the works of, e.g., Kuhn (1962), Laudan (1977), and Lakatos
(1977). To many such scholars raised in this post-logical empiricist
milieu, it appeared that much of the practice of contemporary science
(both in the laboratory and in print) was driven by the search for
mechanisms, that many of the grand achievements in the history of
science were discoveries of mechanisms, and that more traditional
philosophy of science, for whatever reason, had failed to appreciate
this central feature of the scientific worldview.
Aspects of the new mechanical philosophy began to emerge in the
late 1960s. Fodor (1968), for example, contrasted mechanistic
explanations (dealing with parts and their law-like interactions) with
functional explanations in psychology. Wimsatt (1972a, 1976), building
on the work of Simon (1962) and Kaufman (1971), argued repeatedly that
the abstract and idealized structures of logical empiricism were
ill-suited to understanding how scientists discover and explain
complex systems at multiple levels of organization. Cummins (1975)
provided an account of functional analyses, characterizing a function
as a contribution a component part makes to the overall capacity
of some system that includes that component. Salmon (1984, 1989)
argued that empiricist views of scientific explanation are
fundamentally flawed because they neglect causal
mechanisms. Cartwright (1989) argued that the logical empiricist
conception of a law of nature is, in fact, a philosophical fiction
used to describe the search for capacities and nomological
machines.
These strands began to coalesce into an over-arching perspective in
the 1990s. The earliest clear statement of the new mechanism was
Bechtel and Richardson’s (2010 [1993]) Discovering
Complexity. They self-consciously put aside logical empiricist
concerns with theory reduction and focused instead on the process by
which scientists discover mechanisms
(see Section 6 below). Soon after,
Glennan argued that mechanisms are the secret connexion Hume sought
between cause and effect (1996), a thesis related to and partly
inspired by Cartwright’s focus on capacities and nomological machines
(Glennan 1997). Likewise, Thagard’s How Scientists Explain
Disease centered the search for causes and mechanisms in medicine
(Thagard 2000; see also Section 6
below). Machamer, Darden and Craver’s “Thinking about
Mechanisms” (Machamer, Darden, and Craver 2000; familiarly known
as “MDC”) drew these strands together and became for many
the lightening rod of the new mechanist perspective. MDC suggested
that the philosophy of biology, and perhaps the philosophy of science
more generally, should be restructured around the fundamental idea
that many scientists organize their work around the search for
mechanisms.
The term “mechanism” emerged in the seventeenth century
and derived from Greek and Latin terms for “machine”
(Dijksterhuis 1961). Descartes understood mechanics as the basic
building block of the physical world; in Le Monde, he
proposed to explain diverse phenomena in the natural world (such as
planetary motion, the tides, the motion of the blood, and the
properties of light) in terms of the conservation of inertial motion
through contact action (see the entry on
 René Descartes). Subsequently, the
 idea of mechanism has been
transformed many times to reflect an evolving understanding of the
basic causal forces in the world (besides conserved motion): e.g.,
attraction and repulsion (du Bois Reymond), conservation of energy
(Helmholtz), gravitational attraction (Newton) (Boas 1952; Westfall
1971; see also entries on
 Hermann von Helmholtz and
 Isaac Newton). The concept
of mechanism has had an almost separate evolution in the history of
the life sciences (Allen 2005; Des Chene 2001, 2005; Nicholson 2012),
at times eschewing the metaphysical austerity embraced by Descartes
and many early mechanists.
The new mechanists inherit the word “mechanism” from
these antecedents, but, in their effort to capture how the term is
used in contemporary science, have distanced themselves both from the
idea that mechanisms are machines and especially from the austere
metaphysical world picture in which all real change involves only one
or a limited set of fundamental activities or forces (cf. Andersen
2014a,b). 
Mechanists have generally eschewed the effort to spell out
necessary and sufficient conditions for something to be a
mechanism. Instead, they offer qualitative descriptions designed to
capture the way scientists use the term and deploy the concept in
their experimental and inferential practices.
Three characterizations are most commonly cited:
Each of these characterizations contains four basic features: (1) a
phenomenon, (2) parts, (3) causings, and (4) organization. We consider
each of these in detail below.
A useful canonical visual representation of a mechanism underlying
a phenomenon is shown in Figure 1 (from Craver 2007). At the top is
the phenomenon, some system S engaged in
behavior ψ. This is the behavior of the mechanism as a
whole. Beneath it are the parts (the Xs) and their activities
(the φs) organized together. The dotted roughly-vertical lines
reflect the fact that the parts and activities are contained within,
are components of, the mechanism engaged in this behavior. Thus represented,
mechanisms are decompositional in the sense that the behavior of the
system as a whole can be broken down into organized interactions among
the activities of the parts.
Figure 1. A visual representation of a
mechanism (adapted from Craver 2007).
In the early literature, these different characterizations were
often treated as competitors. Tabery (2004) argued instead that they
reflect different, and complementary, emphases and intellectual
orientations. Many mechanists have adopted this ecumenical stance. For
example, Illari and Williamson offer a “consensus concept”
of mechanism:
A mechanism for a phenomenon consists of entities
and activities organized in such a way that they are responsible for
the phenomenon. (2012: 120)
Likewise, Glennan refers to “minimal
 mechanism”:
A mechanism for a phenomenon consists of entities
(or parts) whose activities and interactions are organized in such a
way that they produce the phenomenon. (Glennan forthcoming: Ch.
2) 
These ecumenical characterizations each include the four basic
elements and are designed to make the characterization more inclusive.
MDC’s insistence on the regularity of mechanisms is abandoned, for
example, to accommodate mechanisms that work only once or that work
irregularly (Skipper and Milstein 2005; Bogen 2005; see
also Section 2.1.2 below). Bechtel and Abrahamsen’s
emphasis on the “functions” is abandoned to accommodate
mechanisms that serve no end and to distance mechanism from this
loaded term so often opposed to mechanism (although see Craver 2001a;
Garson 2013; Maley and Piccinini forthcoming; see
also Section 4.5 below).
These ecumenical characterizations intentionally downplay the fact
that the term “mechanism” is used differently in different
scientific and philosophical contexts (see Levy 2013 and Andersen
2014a,b for alternative overviews of the differences). Indeed, much of
the progress in the early years involved learning to recognize the
many ways that the term “mechanism” can be used and the
many commitments that can be undertaken in its name. (For still other
characterizations of mechanism, see Woodward (2002), Fagan (2012),
Nicholson (2012), and Garson (2013)). Taking these ecumenical views as
a starting point, we now consider the four basic components: 1) the
phenomenon, 2) parts, 3) causings, and 4) organization.
The phenomenon is the behavior of the mechanism as a whole. All
mechanisms are mechanisms of some phenomenon (Kauffman 1971;
Glennan 1996, 2002). The mechanism of protein synthesis synthesizes
proteins. The mechanism of the action potential generates action
potentials. The boundaries of a mechanism—what is in the
mechanism and what is not—are fixed by reference to the
phenomenon that the mechanism explains. The components in a mechanism
are components in virtue of being relevant to the phenomenon.
MDC (2000) describe mechanisms as working from start- or set-up
conditions to termination conditions. They insist that it is
impoverished to describe the phenomenon as an input-output relation
because there are often many such inputs and outputs from a mechanism
and because central features of a phenomenon might be neither inputs
nor outputs (but rather details about how the phenomenon unfolds over
time). Darden, appealing to the example of protein synthesis, often
associates the phenomenon with the end-state: the protein (Darden
2006). Craver (2007), following Cummins (1975) and Cartwright (1989),
often speaks of the phenomenon roughly as a capacity or behavior of
the mechanism as a whole.
New mechanists speak variously of the mechanism as producing,
underlying, or maintaining the phenomenon (Craver and Darden
2013). The language of production is best applied to
mechanisms conceived as a causal sequence terminating in some
end-product: as when a virus produces symptoms via a disease mechanism
or an enzyme phosphorylates a substrate. In such cases, the phenomenon
might be an object (the production of a protein), a state of affairs
(being phosphorylated), or an activity or event (such as
digestion). For many physiological mechanisms, in contrast, it is more
appropriate to say that the mechanism underlies the
phenomenon. The mechanism of the action potential or of working
memory, for example, underlies the phenomenon, here characteristically
understood as a capacity or behavior of the mechanism as a
whole. Finally, a mechanism might maintain a phenomenon, as
when homeostatic mechanisms hold body temperature within tightly
circumscribed boundaries. In such cases, the phenomenon is a state of
affairs, or perhaps a range of states of affairs, that is held in
place by the mechanism. These ways of talking can in many cases be
inter-translated (e.g., the product is produced, the production has an
underlying mechanism, and the state of affairs is maintained by an
underlying mechanism). Yet clearly confusion can arise from mixing
these ways of talking. 
Must the relationship between the mechanism and the phenomenon be
regular? This is an area of active discussion (DesAutels 2011;
Andersen 2011, 2014a,b; Krickel 2014). MDC stipulate that mechanisms
are regular in that they work “always or for the most part in
the same ways under the same conditions” (2000: 3). Some have
understood this (incorrectly in our view) as asserting that there are
no mechanisms that work only once, or that a mechanism must work
significantly more than once in order to count as a mechanism.
Some argue that mechanisms have to be regular in this factual sense
(Andersen 2014a,b); i.e., repeated on many occasions (see Leuridan
2010). This view would seem to require a somewhat arbitrary cut-off
point in degree of regularity between things that truly count as
mechanisms and those that do not. Some mechanists (Bogen 2005; Glennan
2009) argue that there is no difficulty applying the term
“mechanism” to one-off causal sequences, as when an
historian speaks of the mechanism that gave rise to World War I. Other
mechanists argue that the type-token distinction is too crude a
dichotomy to capture the many levels of abstraction at which mechanism
types and tokens might be characterized (Darden 1991).
It is possible, however, to read the MDC statement as asserting,
not a factual kind of regularity, but as a counterfactual kind of
near-determinism: were all the conditions the same, then the mechanism
would likely produce the same phenomenon, where “likely”
accommodates mechanisms with stochastic elements.
While the MDC account leaves open the possibility that some
mechanisms are stochastic, it clearly rules out mechanisms that
usually fail to produce their phenomena. Skipper and Millstein (2005)
press this point to argue that the MDC account cannot accommodate the
idea that natural selection is a mechanism. If, as Gould (1990)
argued, one could not reproduce the history of life by rewinding the
tapes and letting things play forward again, then natural selection
would not be an MDC mechanism (see also
 Section 2.6 below). It is unclear why
 MDC would allow for the possibility
of stochastic mechanisms and rule out, by definition, the possibility
that they might fail more often than they work. Whether any biological
mechanisms are truly irregular in this sense (i.e., all the causally
relevant factors are the same but the product of the mechanism
differs) is a separate question from whether they are mechanisms
simpliciter (see Bogen 2005; Machamer 2004; Steel 2008 develops a
stochastic account of mechanisms).
Krickel (2014) reviews the many different ways of unpacking the
relevant notion of regularity (see also Andersen 2012). Her favored
solution, “reverse regularity,” holds that there must be a
generalization to the effect that, typically, when the phenomenon
occurs, the mechanism was acting.
Mechanists have struggled to find a concise way to express the idea
of parthood required of the components in a mechanism. The project is
to develop an account that is both sufficiently permissive to include
the paradigmatic mechanisms from diverse areas of science and yet not
vacuous.
Formal mereologies are difficult to apply to the material parts of
biological mechanisms. Axioms of mereology, such as reflexivity
(everything is a part of itself) and unrestricted composition (any two
things form a whole) do not apply in standard biological uses of the
“part” concept.
Glennan (1996) recognized the difficulty of defining parthood very
early on. His proposal:
The parts of mechanisms must have a kind of
robustness and reality apart from their place within that
mechanism. It should in principle be possible to take the part out of
the mechanism and consider its properties in another context. (1996:
53)
 Yet even this is perhaps too strong, given that some parts of a
mechanism might become unstable when removed from their mechanistic
context. Later, Glennan (2002: S345) says that the properties of a
part must be stable in the absence of interventions, or that parts
must be stable enough to be called objects. This notion is perhaps too
strong to accommodate the more ephemeral parts of some biochemical
mechanisms or of the mechanisms of natural selection (Skipper and
Millstein 2005; but see Illari and Williamson 2010).
Mechanists have disagreed with one another about how to understand
the cause in causal mechanism. New mechanists have in general been at
pains both (1) to liberate the relevant causal notion from any overly
austere view that restricts causation to only a small class of
phenomena (such as collisions, attraction/repulsion, or energy
conservation), and (2) to distance themselves from the Humean,
regularist conception of causation common among logical empiricists
(see also the entry on the
  the metaphysics of causation).
 Four ways of unpacking the cause in
causal mechanism have been discussed: conserved quantity accounts,
mechanistic accounts, activities accounts, and counterfactual
accounts. (It should be noted that some mechanists have evolved in
their thinking about causation.)
According to transmission accounts, causation involves the
transmission and propagation of marks or conserved quantities (Salmon
1984, 1994; Dowe 1992). The most influential form of this view holds
that two causal processes causally interact when they intersect in
space-time and exchange some amount of a conserved quantity, such as
mass. On this view, causation is local (the processes must intersect)
and singular (it is fully instantiated in particular causal
processes), though the account relies upon laws of conservation
(Hitchcock 1995).  Although this view inspired many of the new
mechanists, and although it shares their commitment to looking toward
science for an account of causation, it has generally been rejected by
new mechanists (though see Millstein 2006; Roe 2014).
This view has been unpopular in part because it has little direct
application in nonfundamental sciences, such as biology. The causal
claims biologists make usually don’t involve explicit reference to
conserved quantities (even if they presuppose such notions
fundamentally) (Glennan 2002; Craver 2007). Furthermore,
biological mechanisms often involve causation by omission, prevention,
and double prevention (that is, when a mechanism works by removing a
cause, preventing a cause, or inhibiting an inhibitor) (Schaffer 2000,
2004). Such forms of causal disconnection are ubiquitous in the
special sciences.
Glennan (1996, 2009) sees causation (at least non-fundamental
causation) as derivative from the concept of mechanism: causal claims
are claims about the existence of a mechanism. The truth-maker for a
causal claim at one level of organization is a mechanism at a lower
level. In short, mechanisms are the hidden connexion Hume sought
between cause and effect. Like the Salmon-Dowe account, Glennan’s view
is singular: particular mechanisms link particular causes and
particular effects (Glennan forthcoming)
This view has been charged with circularity: the concept of
mechanism ineliminably contains a causal element. However, Glennan
replies that many accounts of causation (such as Woodward’s 2003
account, see Section 2.3.4 below) share this
flaw. Furthermore, he argues that for at least all non-fundamental
causes, a mechanisms clearly explains how a given cause produces its
effect.
Whether the analysis succeeds depends on how one deals with the
resulting regress (Craver 2007). As Glennan (2009) notes, the
decomposition of causes into mechanisms might continue infinitely, in
which case there is no point arguing about which notion is more
fundamental, or the decomposition might ground out in some basic,
lowest-level causal notion that is primitive and so not analyzable
into other causal mechanisms. The latter option must confront the
widely touted absence of causation in the theories of fundamental
physics (Russell 1913); at very small size scales, classical
conceptions of objects and properties no longer seem to apply, making
it difficult to see what content is left to the idea that there are
mechanisms at work (see also Teller 2010; Kuhlman and Glennan
2014).
Still other mechanists, such as Bogen (2005, 2008a) and Machamer
(Machamer 2004), embrace an Anscombian, non-reductive view
that causation should be understood in terms of productive activities
(see also the entry on 
 G.E.M. Anscombe). Activities are
 kinds of causing, such as
magnetic attraction and repulsion or hydrogen bonding.  Defenders of
activity-based accounts eschew the need to define the concept, relying
on science to say what activities are and what features they might
have. This view is a kind of causal minimalism (Godfrey-Smith
2010). Whether an activity occurs is not a matter of how frequently it
occurs or whether it would occur always or for the most part in the
same conditions (Bogen 2005).
This account has been criticized as vacuous because it fails to say
what activities are (Psillos 2004), to account for the relationship of
causal and explanatory relevance (Woodward 2002), and to mark an
adequate distinction between activities and correlations (Psillos
2004), though see Bogen (2005, 2008a) for a response. Glennan
(forthcoming) argues that these problems can be addressed by
recognizing that activities in a mechanism at one level depend on
lower-level mechanisms. (See also Persson 2010 for a criticism of
activities based on their inability to handle cases of polygenic
effects.)
Lastly, some new mechanists, particularly those interested in
providing an account of scientific explanation, have gravitated toward
a counterfactual view of causal relevance, and in particular, to the
manipulationist view expressed in Woodward (2001, 2003) (see, e.g.,
Glennan 2002; Craver 2007). The central commitment of this view is
that models of mechanisms describe variables that make a difference to
the values of other variables in the model and to the phenomenon.
Difference-making in this manipulationist sense is understood as a
relationship between variables in which interventions on cause
variables can be used to change the value of effect variables
(see the entry on 
 causation and manipulability).
Unlike the views discussed above, this way of thinking about
causation provides a ready analysis of explanatory relevance that
comports well with the methods for testing causal claims. Roughly, one
variable is causally relevant to a second when there exists an ideal
intervention on the first that changes the value of the second via the
change induced on the first. The view readily accommodates omissions,
preventions, and double preventions—situations that have
traditionally proven troublesome for production-type accounts of
causation. In short, the claim that C causes E requires
only that ideal interventions on C can be used to change the
value of E, not that C and E are physically
connected to one another. Finally, this view provides some tools for
accommodating higher-level causal relations and the non-accidental
laws of biology. On the other hand, the counterfactual account is
non-reductive (like the mechanistic view), and it inherits challenges
faced by other counterfactual views, such as pre-emption and
over-determination which are common in biological mechanisms
(see the entry on 
 counterfactual theories of causation).
The characteristic organization of mechanisms is itself the subject
of considerable discussion.
Wimsatt (1997) contrasts mechanistic organization with aggregation,
a distinction that mechanists have used to articulate how the parts of
a mechanism are organized together to form a whole (see Craver 2001b).
Aggregate properties are properties of wholes that are simple sums of
the properties of their parts. In aggregates, the parts can be
rearranged and intersubstituted for one another without changing the
property or behavior of the whole, the whole can be taken apart and
put back together without disrupting the property or behavior of the
whole, and the property of the whole changes only linearly with the
addition and removal of parts. These features of aggregates hold
because organization is irrelevant to the property of the
whole. Wimsatt thus conceives organization as non-aggregativity. He
also describes it as a mechanistic form of emergence
(see Section 4.2 below).
Mechanistic emergence is ubiquitous—truly aggregative
properties are rare. Thus mechanists have tended to recognize a
spectrum of organization, with aggregates at one end and highly
organized mechanisms on the other. Indeed, many mechanisms studied by
biologists involve parts and causings all across this spectrum. (For
further discussion of mechanistic emergence in relationship to other
varieties, see Richardson and Stephan 2007.)
Following Wimsatt, mechanists have detailed several kinds of
organization characteristic of mechanisms. A canonical list includes
both spatial and temporal organization. Spatial organization includes
location, size, shape, position, and orientation; temporal
organization includes the order, rate, and duration of the component
activities. More recently, mechanists have emphasized
organizational patterns in mechanisms as a whole. Bechtel, for
example, discusses how mathematical models, and dynamical models in
particular, are used to reveal complex temporal organization in
interactive mechanisms (Bechtel 2006, 2011, 2013b). Some argue that
dynamical models push beyond the limits of the mechanistic framework
(e.g., Chemero and Silbestein 2008 and, at times, Bechtel himself; see
Kaplan and Bechtel 2011). Others argue that dynamical models are, in
fact, often merely descriptive (i.e., non-explanatory models) or,
alternatively, that they are used to describe the temporal
organization of mechanisms (Kaplan and Bechtel 2011; Kaplan 2012).
Mechanists have also recently borrowed from Alon’s (2006; Milo et
al. 2002) work on network motifs, repeated patterns in causal
networks, to expand the vocabulary for thinking about abstract
patterns of organization (Levy 2014; Levy and Bechtel
2012). Understanding how parts compose wholes is likely to be a growth
area in the future of the mechanistic framework. (For some other
recent additions, see Kuorikoski and Ylikoski 2013; Kuhlmann 2011;
Glennan forthcoming.)
Woodward’s (2001, 2002, 2011, 2014) counterfactual definition of a
mechanism (which is indirectly specified via an account of mechanistic
models), as well as a descendant elaborated by Menzies (2012), require
that models of mechanisms be modular. This means, roughly, that it
should be physically possible to intervene on a putative cause
variable in a mechanism without disrupting the functional
relationships among the other variables in the mechanism. In terms of
structural equation models in particular, this means that one should
be able to replace the right-hand side of an equation in the model
with a particular value (i.e., set the left-hand variable to a value)
without needing to change any of the other equations in the
model. This is intended to formally capture the sense in which
mechanism is composed of separable, interacting parts. For arguments
in favor of a modularity condition on mechanistic models see Menzies
(2012).
Steel (2008) appeals to a somewhat weaker form of modularity in his
probabilistic analysis of mechanisms—one that follows directly
from Simon’s (1996 [1962]) idea of nearly decomposable systems.  On
Simon’s view, the parts of a mechanism have more and stronger causal
relations with other components in the mechanism than they do with
items outside the mechanism. This gives mechanisms (and parts of
mechanisms) a kind of “independence” or
“objecthood” defined ultimately in terms of the intensity
of interaction among components. Grush (2003), following Haugeland
(1998), develops an idea of modularity in terms of the bandwidth of
interaction, where modules are high-bandwidth in their internal
interactions and low-bandwidth in their external interactions. On this
view, modularity is not an all-or-none proposition but a matter of
degree; mechanisms are only nearly decomposable. Craver (2007) argues
that such a generic notion fails to account for the relevance of
different causal interactions for different mechanistic
decompositions; what counts as a part of a mechanism can only be
defined relative to some prior decision about what one takes the
mechanism to be doing. For criticisms of modularity, see Mitchell
(2005) and Cartwright (2001, 2002).
Fagan (2012, 2013) emphasizes the interdependent relationship
between parts of a mechanism. Components in a mechanism, she points
out, often form a more complex unit by virtue of the individual
properties that unite them—their “meshing
properties”; the complex unit then figures into the mechanism’s
behavior. This interdependent relationship—jointness—is
exemplified by the lock-and-key model of enzyme action. Fagan applies
this notion to research on stem cells (Fagan 2013) but argues that it
is a general feature of experimental biology (Fagan 2012).
Many mechanists emphasize the hierarchical organization of
mechanisms and the multilevel structure of theories in the special
sciences (see especially Craver 2007, Ch. 5). Antecedents of the new mechanism focused almost exclusively on
etiological, causal relations. However, the new emphasis on mechanisms
in biology and the special sciences demanded an analysis of
mechanistic relations across levels of organization.
From a mechanistic perspective, levels are not monolithic divides
in the furniture of the universe (as represented by Oppenheim and
Putnam 1958), nor are they fundamentally a matter of size or the
exclusivity of causal interactions within a level (Wimsatt
1976). Rather, levels of mechanisms are defined locally within a
multilevel mechanism: one item is at a lower level of mechanisms than
another when the first item is a part of the second and when the first
item is organized (spatially, temporally, and actively) with the other
components such that together they realize the second item. Thus, the mechanism of spatial memory has multiple levels,
some of which include organs such as the hippocampus generating a
spatial map, some of which involve the cellular interactions that
underlie map generation, and some of which involve the molecular
mechanisms that underlie those cellular interactions (Craver
2007). For more on levels, see Section 4.2 below.
Finally, mechanists have found it necessary to distinguish between
stable mechanisms, which rely fundamentally upon the more or less
fixed arrangement of parts and activities, and ephemeral mechanisms,
which involve a process evolving through time without fixed spatial
and temporal arrangement (Glennan 2009). The time-keeping mechanism in
a clock, for example, is a relatively stable assemblage of components
in relatively fixed locations that work the same way, with the same
organizational features, each time it works. Ephemeral mechanisms, in
contrast, involve a much looser kind of organization: items still
interact in space and time, but they do not do so in virtue of robust,
stable structures. Many chemical mechanisms in a cell are like that
(Richardson and Stephan 2007). Ephemeral mechanisms are surely a
primary focus of historical sciences, such as archaeology, history,
and evolutionary biology (Glennan 2009).
The term “mechanism” has been used in many different
ways to express many different ideas. The new mechanists’
appropriation of the term is thus likely to cause unhelpful
associations, and their liberalization of the term is likely to raise
worries that the notion of mechanism has thereby been trivialized
(see, e.g., Moss 2012 and
Nicholson 2012). Here, we first distinguish the new mechanism from
other doctrines with which it shares both name and family
resemblance. We then discuss some things to which the new use of the
term “mechanism” does not apply.
New mechanists have explicitly eschewed the following associations
with the term “mechanism”:
One might object that there’s nothing left of mechanism once it
sheds these historical associations. One might suspect that it has
been trivialized (Dupré 2013).
The idea of mechanism is a central part of the explanatory ideal of
understanding the world by learning its causal structure. The history
of science contains many other conceptions of scientific explanation
and understanding that are at odds with this commitment. Some have
held that the world should be understood in terms of divine
motives. Some have held that natural phenomena should be understood
teleologically.  Others have been convinced that understanding the
natural world is nothing more than being able to predict its
behavior. Commitment to mechanism as a framework concept is commitment
to something distinct from and, for many, exclusive of, these
alternative conceptions. If this appears trivial, rather than a
central achievement in the history of science, it is because the
mechanistic perspective now so thoroughly dominates our scientific
worldview.
Yet there are many ways of organizing phenomena besides revealing
mechanisms. Some scientists are concerned with physical structures and
their spatial relations without regard to how they work: an anatomist
might be interested in the spatial organization of parts within the
body with minimal interest in how those parts articulate together to
do something. Many scientists build predictive models of systems
without any pretense that these models in fact reveal the causal
structures by which the systems work. Some scientists are concerned
with taxonomy, sorting like with like without regard to how the sorted
items came about or how they work. Finally, in many areas of science,
there is a widely recognized and practically significant distinction
between knowing that C (e.g., smoking) is a cause of E
(lung cancer) and knowing how C causes E. This is not so
much an ontological difference as it is a difference in the grain with
which one seeks to understand a system’s causal structure. In short,
there are many framework concepts in science, and not all of them can
be assimilated to mechanisms.
But what, the critic might push further, does not count as a
mechanism? Here are some contrast classes:
This is not an exhaustive list of non-mechanisms or non-mechanistic
framework concepts. Yet it demonstrates that even the liberalized
concept of mechanism is neither vacuous nor trivial.
Much of the early new mechanical philosophy has focused on the
special sciences, such as neuroscience and molecular biology. In the
years since, philosophers have extended the mechanistic framework to
other scientific disciplines, such as cell biology (Bechtel 2006),
cognitive science (Bechtel 2008; Thagard 2006), neuroeconomics (Craver
and Alexandrova 2008), organic chemistry (Ramsey 2008), physics
(Teller 2010), astrophysics (Illari and Williamson 2012), behavior
genetics (Tabery 2014a), and phylogenetics (Matthews
forthcoming). Philosophers continue to test the limits of this
framework, with the expectation that alternative organizing frameworks
might play central roles in other sciences. For example, a debate has
emerged in the philosophy of biology over whether or not natural
selection is a mechanism (see, for example, Skipper and Millstein
2005; Baker 2005; Barros 2008; Illari and Williamson 2012; Havstad
2011; and Matthewson and Calcott 2011).  Similar debates have emerged
concerning mechanistic explanation in cognitive science (Bechtel 2008; Piccinini and Craver 2011; Weiskopf 2011;
Povich forthcoming).
One area that has received particular attention is the effort to
understand computational mechanisms. On some accounts, computational
mechanisms form a proper subclass of mechanisms that can be defined
explicitly in terms of the kinds of entities, properties, and
activities involved in mechanisms in that class (Piccinini 2007;
Milkowski 2013). According to this view, computational mechanisms are
mechanisms that have the function to manipulate medium independent
vehicles in accordance with a general rule that applies to all
vehicles and depends on the inputs for its application (Piccinini and
Scarantino 2011). Digital computers are distinctive in that their
vehicles are digits (Piccinini 2007). Proponents of this account hope
to demarcate computing mechanisms from non-computing mechanisms by
appeal to the distinctive components proprietary to computing
mechanisms. This view contrasts both with a semantic view, according
to which computation is essentially a matter of manipulating symbols
or representations, and with perspectivalist views, according to which
whether a mechanism counts as computing is a matter of whether it is
so described (Churchland 1986; Churchland and Sejnowski 1992; Shagrir
2010).
Philosophers of the social sciences have also emphasized and
debated the importance of mechanistic knowledge (e.g., Elster 1989;
for a useful review of these connections, see Hedström and Ylikoski
2010). In that context, appeals to mechanisms are intended to remedy
the relative uninformativeness of social (or macro-level) explanations
of social phenomena (such as widespread norms, persistent
inequalities, network and institutional structures) by insisting that
these explanations ultimately be grounded in mechanistic details about
individual agents and actors, their desires and motivations, and,
importantly, their relations to one another. The emphasis on relations
among actors distances this mechanistic view from methodological
individualism (see the entry on 
 methodological individualism).
 Mechanists in the social sciences
have also tended to shy away from grand, overarching theories and
toward more local explanations: scientific knowledge grows by adding
items to a toolbox of mechanisms and showing how items from that
toolbox can be combined to provide an explanation for a particular
phenomenon. Frederica Russo (2009) discusses a number of strategies
for modeling social mechanisms (see also Little 1991, 1998; Hedström
2005; Hedström and Swedberg 1998).
The covering-law model of explanation was a centerpiece of the
logical empiricist conception of science. According to that model,
explanations are arguments showing that the event to be explained
(the explanandum event) was to have been expected on the
basis of laws of nature and the antecedent and boundary conditions
(the explanans). For advocates of the covering-law model, the
philosophical problem of explanation is thus largely a matter of
analyzing the formal structure of explanatory arguments (Hempel and
Oppenheim 1948; Hempel 1965). A rainbow, for example, is explained
under the covering-law model by reference to laws of reflection and
refraction alongside conditions concerning the position of the sun and
the nature of light, the position of the raindrops, and the position
of the person seeing the rainbow. The description of the rainbow is
the conclusion of a deductive argument with law statements and
descriptions of conditions as premises, and so the rainbow was to be
expected in light of knowledge of the laws and conditions.
Mechanists, in contrast, insist explanation is a matter of
elucidating the causal structures that produce, underlie, or maintain
the phenomenon of interest. For mechanists, the philosophical problem
is largely about characterizing or describing the worldly or ontic
structures to which explanatory models (including arguments) must
refer if they are to count as genuinely explanatory. A rainbow, for
the mechanist, is explained by situating that phenomenon in the causal
structure of the world; the explanation is an account of how the
phenomenon was produced by entities (like rain drops and eyeballs)
with particular properties (like shapes and refractive indices) that
causally interact with light propagating from the sun. Mechanists
typically distinguish several ways of situating a phenomenon within
the causal structure of the world.
Most mechanists recognize two main aspects of mechanistic
explanation: etiological and constitutive. Salmon (1984) describes
them as two different ways of situating an explanandum phenomenon in
the causal nexus (see also Craver 2001b; Glennan 2009). Etiological
explanations reveal the causal history of the explanandum phenomenon,
as when one says a virus explains a disease. Constitutive
explanations, in contrast, explain a phenomenon by describing the
mechanism that underlies it, as when one says brain regions, muscles,
and joints explain reaching.
Philosophical arguments against the covering law model often
focused on its inability to deal with causal, etiological
explanations. The model failed to deliver the right verdict on a
variety of problem cases precisely because it attempted to provide an
account of explanation without any explicit mention of causation
(Bromberger 1966; Salmon 1984; Scriven 1959)
New mechanists extend these kinds of criticism to the covering law
model of intertheoretic, micro-reduction. According to the covering
law model of reductive explanation, a theory about parts reduces, and
so explains, a theory about wholes when it is possible to derive the
second from the first given bridge laws to connect the two (see Nagel
1961; Schaffner 1993).
Some mechanists argue that the covering law model of constitutive
explanation has problems analogous to those that beset the
covering-law model of etiological explanations. Action potentials
cannot be explained by mere temporal sequences of events utterly
irrelevant to the phenomenon, but one can derive a description of the
action potential from descriptions of such irrelevant
phenomena. Action potentials cannot be explained by mere patterns of
correlation that are not indicative of an underlying causal
relation. Irrelevant byproducts of a mechanism might be correlated
with the behavior of the mechanism, even perfectly correlated such
that one could form bridge laws between levels, but would not thereby
explain the relationship. Merely finding a neural correlate of
consciousness, for example, would not, and is not taken by anyone to,
constitute an explanation of consciousness. So mechanists argue that
micro-reductive explanations must satisfy causal constraints just as
surely as etiological explanations must (Craver 2007).
The covering law model also fails to distinguish models that merely
re-describe the phenomenon in general terms from explanations that, in
addition to predicting aspects of the phenomenon, reveal the
mechanisms that produce it (Craver 2006; Kaplan and Craver 2011; but
see Weiskopf 2011). For example, Snell’s law allows one to predict how
light bends when passing from one medium to another, but it does not
explain why the light bends. New mechanists also argue that the
covering law model fails to distinguish predictively adequate but
fictional models from explanatory models. Finally, mechanists argue
that the intertheoretic model of reduction fails to capture an
important dimension of explanatory quality: depth. An implication of
the covering law model is that any true law statements that allow one
to derive the explanandum law (with suitable corrections and
assumptions) will count as a complete explanation. Yet it seems one
can deepen an explanation by opening black boxes and revealing how
things work down to whatever level one takes as relatively fundamental
for the purposes at hand. Such criticisms suggest that the
covering-law model of constitutive explanation is too weak to capture
the norms of explanation in the special sciences.
Other mechanists have argued that the covering law model is too
strong. Philosophers of biology have long argued that there are no
laws of the sort the logical empiricist described in biology and other
special sciences (Beatty 1995; Mitchell 1997, 2000; Woodward
2001). One might conclude from this that there are no explanations in
biology (Rosenberg 1985), but such a radical conclusion is difficult to square
with obvious advances in understanding, e.g., protein synthesis,
action potentials, cell signaling, and a host of other biological
phenomena.  In such cases, one finds that scientists appeal to
mechanisms to do the explanatory work, even in cases where nothing
resembling a law appears to be available.
With increased attention to constitutive explanation, mechanists
realized the need for an account of constitutive relevance, a
principal for sorting relevant from irrelevant factors in a mechanism
(Craver 2007; Ylikoski 2013). A system (S) exhibiting
phenomenon (ψ) is composed of many different entities
(x), with various properties, engaging in myriad activities
(φ) organized together (see Figure 1 above in
Section 2). One central research problem is to say which of these
entities, activities, and organizational features contribute to the
phenomenon and which do not. In a sense, this is a challenge of
defining the boundaries of a mechanism: of saying what is and is not
in the mechanism.
Three proposals have been considered. The first, the mutual
manipulability account, understands constitutive relevance in
terms of the experimental manipulations used to test interlevel
relations. According to this account, if it can be shown (i) that the
putative components are contained within S, (ii) that some
ideal interventions on the putative component
(x’s φ-ing) change the phenomenon
(S’s ψ-ing), and (iii) that some ideal interventions
on S’s ψ-ing change x’s φ-ing, that is
sufficient to establish that x is a component in the
mechanism. The notion of an ideal intervention in this account is
explicitly indebted to and a proposed extension of Woodward’s theory
of causal relevance to the constitutive domain (see Craver 2007; see
also Kaplan 2012). A concern with the mutual manipulability account,
though, is that it is best an epistemic guide to constitutive
relevance, not an account of what constitutive relevance is (Couch
2011). The account offers, at best, a sufficient condition of
relevance. Also, the notion of an “ideal” intervention,
borrowed from Woodward’s account of causal relevance, cannot be
applied straightforwardly to constitutive
explanations. An ideal intervention on a system cannot
intervene on both the independent and the dependent variable at the
same time. However, when one intervenes to make S ψ (or
prevent S from ψ-ing), one invariably also intervenes on
the components of S’s ψ-ing. And when one intervenes on
the components of S’s ψ-ing, one often intervenes
on S’s ψ-ing. Because x’s φ-ing
and S’s ψ-ing are related as part to whole, they are not
independent, and so require another way to think about ideal
interventions (see Baumgartner 2010; 2013; Leuridan 2011; yet see
Menzies 2012; Woodward 2014.
A second proposal offers a regularity account of constitutive
relevance modeled on Mackie’s notion of understanding a cause as an
INUS condition: an Insufficient but Non-redundant part of an
Unnecessary but Sufficient condition for the effect in question
(Mackie 1974; see also Cummins 1983). On this account, a
constitutively relevant component is an insufficient but non-redundant
part of an unnecessary but sufficient mechanism for a given phenomenon
(Couch 2011; see also Harbecke 2010, 2014). Allow that any number of
mechanisms might suffice to bring about S’s ψ-ing; each
possible sufficient mechanism is then unnecessary
for ψ-ing. Each of these mechanisms is made of components, none
of which is alone sufficient to produce the behavior of the mechanism
as a whole, but each of which is necessary in the context of the
mechanism for S to ψ.  This account presupposes the idea
of being necessary in context, and one might reasonably worry about
sorting accidentally correlated Xs from Xs that in fact
make a difference to S’s ψ-ing.
A third approach to constitutive relevance dispenses with the
interlevel framing enforced by the mutual manipulability account and
attempts to analyze relevance using causal notions only. According to
accounts of this sort, constitutive relevance is a kind of causal
between-ness. If S’s ψ-ing is understood as an
input-output relationship of some sort, then mechanistic relevance
could be understood as being a necessary link in the causal chain
between the input and the output (see Harinen forthcoming; Menzies
2012). The putatively interlevel experiments in the mutual
manipulability account can then be recast as different kinds of
unilevel causal experiments. Romero (forthcoming) provides a helpful framing of these issues and offers the novel suggestion that putatively high-level interventions are in fact fat-handed interventions relative to their lower-level counterparts.
The philosophical literature on mechanisms also overlaps with the
philosophical literature on scientific models (see
the entry on models in science). Here
we distinguish mechanical models from models of mechanisms and we
discuss varieties of non-mechanical models.
Glennan (2005) proposed a definition of a mechanical model
as follows:
 (MM) A mechanical model consists of (i) a description
of the mechanism’s behavior (the behavioral description); and (ii) a
description of the mechanism that accounts for that behavior (the
mechanical description). (446)
Such models can be represented in many different ways (see also
Giere 2004). They are evaluated in terms of their ability to predict
the features of the phenomenon and in terms of the mapping between
items in the model and the entities, activities, and organizational
features in the mechanism (Glennan 2005: 17; Kaplan and Craver 2011).
Glennan emphasizes that there is no hard line between complete and
incomplete models; rather models are continually in the process of
articulation and refinement. Whether a model is complete enough is
determined by pragmatic considerations.
This last point is related to Darden’s distinction
between mechanism schemas and mechanism sketches
(Darden and Cain 1989; Darden 2002). In discovering a
mechanism, it is often crucial to identify gaps that have to be filled
in one’s model. While no model is ever complete in the absolute sense,
some models have lacunae that must be filled before the model is
complete enough
Mechanism schemas are abstract descriptions of mechanisms
that can be filled in with details to yield a specific type or token
mechanism. Thus, the schema:
DNA → RNA → Protein
can be filled in with a specific sequence of bases in DNA, its
complement in RNA, and a corresponding amino acid sequence in the
protein. The arrows can be filled in, showing how transcription and
translation work. A mechanism sketch is an incomplete
representation of a mechanism that specifies some of the relevant
entities, activities, and organizational features but leaves gaps that
cannot yet be filled. Black boxes, question marks, and filler-terms
(such as “activate”, “cause”, or
“inhibitor”) hold the place for some entity, activity or
process yet to be discovered. The distinction between sketches and
schemas is a matter of completeness: schemas are more complete than
sketches in the sense that a sketch omits one or more stages of the
mechanism that have to be understood if one really wants to solve
one’s discovery problem.
Mechanists also emphasize the distinction between
a how-possibly schema and a how-actually-enough
schema (Craver and Darden 2013). A how-possibly schema describes how
entities and activities might be organized to produce a
phenomenon. A how possibly model is n hypothesis about how the
mechanism works. Such models might be true (enough) or false. A true
(enough) how-possibly model is (though we may not know it) also a
how-actually (enough) model. A how-actually-enough schema describes
how entities and activities are in fact organized to produce the
phenomenon. The term “how-actually-enough” captures the
idea that the requisite “accuracy” of a mechanistic model
can vary considerably from one pragmatic context to another (Weisberg
2013).A false how possibly model is merely a how possibly model;
just-so-stories are merely how possibly models (Dray 1957; Brandon
1985). Used in this way, the term “how possibly model” is
similar to the term “hypothesis”: it is entertained as a
possibility but not necessarily endorsed.
In contrast to mechanism schemas and sketches, some models of
mechanisms work not by describing all of the parts, causal
interactions, and organizational features, but rather by abstracting
away from such potentially obfuscating details (Craver and Darden
2013; Strevens 2008; Levy and Bechtel 2012). In such cases, idealizing
assumptions can be introduced to bring the relevant feature of the
mechanism most clearly into view: infinite populations, frictionless
planes, perfect geometrical shapes are presumed in order to strip the
model of detail that does not matter for, or would only obstruct, the
intended purposes of model.
Critics of the new mechanical philosophy have pushed on the
importance of abstraction in science, drawing attention to the above
discussions of completeness. The goals of completeness and accuracy
are taken to conflict with the common practice of being satisfied with
models that sacrifice detail and truth for clarity and generality
(Strevens 2008; Woodward 2014). The normative distinction between a
schema and a sketch, for example, seems to suggest that science
progresses by moving from incomplete to complete models. And the
distinction between how-possibly and how-actually-enough likewise
seems to privilege accuracy over other goals of modeling, which often
require distortion and falsity (see Wimsatt 2007; Weisberg 2007; Levy
and Bechtel 2012; Batterman and Rice 2014; Chirimuuta 2014; Levy
2014).
Yet mechanists can surely allow that not all models of mechanisms
are mechanical models or mechanism schemas. Often other sorts of model
are useful for isolating central aspects of a mechanism’s
functioning. Dynamical models, for example, can be used to
characterize the temporal dynamics of a mechanism (Bechtel 2013a,b;
Kaplan and Bechtel 2011). Network models can be used to characterize
patterns of connectivity regardless of what units are connected and
regardless of what kinds of connections one is particularly interested
in characterizing (Hunneman 2010). Minimal models can be used to
capture something fundamental about the dynamics of a broad class of
mechanisms that share no entities and activities in common (Batterman
2002). A model of a mechanism is a model that describes a
mechanism. It need not be a mechanical model or a mechanism schema, in
the above sense, to play that role.
Some mechanists reserve the term “mechanical models”
for models that describe the entities, activities, and organizational
features of a system. According to Glennan’s (2005) account, a
mechanical model that leaves out some relevant features is, ipso
facto, incomplete and sketchy. One specific instantiation of this
debate concerns the explanatory force of functional models in
psychology. Piccinini and Craver (2011)
argue that such models should be understood as mechanistic sketches,
black-box models to be evaluated and filled in as details about the
underlying mechanism are discovered. Black box models are incomplete
in virtue of leaving out details about underling mechanisms and that
those models ultimately depend for their explanatory force on the
promise that the functional models do, in fact, correspond to how the
mechanism works. (See Weiskopf 2011 for a criticism of this account
and Povich forthcoming for a response) 
One might talk about mechanistic explanation in a way that
abstracts from the kind of model used to describe the mechanism: the
commitment to mechanistic explanation is not a commitment about the
form of the model but rather a commitment about what such models must
represent: namely, causal and mechanistic structures. Models are
explanatory in virtue of the fact that they represent the
causal/mechanistic structures that produce, underlie, or maintain the
phenomenon. They are non-mechanistic if they refer to some non-causal,
non-mechanistic kind of relation (Salmon 1984; Craver 2014).
To date, much of the work on mechanistic explanation has been
driven by the goal of providing a descriptively and normatively
adequate theory of mechanistic explanation. Some claim there are kinds
of explanation that rely very little on a precise understanding of the
mechanistic details of a system (Woodward 2014; Weiskopf 2011) or that
work fundamentally by removing all such details from one’s model
(Batterman and Rice 2014). Resolving such debates will require being
very clear about precisely what one expects out of a philosophical
theory of scientific explanation and what one takes a scientific
explanation to be (Strevens 2008; Craver 2014). Research is required
to understand the diverse representational forms that scientists use
to represent mechanisms (Burnston et al. forthcoming), and to
understand the role of idealization in mechanistic explanation (Levy
and Bechtel 2012; Huneman 2010). Further work is also required to limn
the boundaries between mechanistic explanation and other putative
varieties of explanation and to say, as perspicuously as Hempel or the
causal-mechanical theory, what a model must do to count as explanatory
and precisely how good explanations are to be distinguished from
bad.
In this section, we review some of the ways that the concept of
mechanism has been used in diverse areas of metaphysics. Of all the
areas we have discussed, this is likely the most in need of future
development. Here we discuss the relationship between mechanisms and
laws, emergence, realization, natural kinds, and functions.
In much of the early literature on mechanisms, mechanisms are
contrasted explicitly with laws of nature (Bechtel 1988; Bechtel and
Abrahamsen 2005; MDC 2000). This contrast clearly grew out of an
emerging consensus in philosophy that there are few, or perhaps no,
laws of biology (see Section 3.1 above). The
empirical generalizations one finds in biology tend to be hedged
by ceteris paribus clauses; whether they hold or not depends
on background conditions that might not hold and on conditions
internal to the mechanism that might fail.  These generalizations, in
short, are mechanistically explicable; what necessity they have
derives from a mechanism (Cummins 2000; Glennan 1996). Mechanisms thus
seem to play the role of laws in the biological sciences: we seek
mechanisms to explain, predict, and control phenomena in nature even
if mechanisms lack many of the characteristics definitive of laws in
the logical empiricist framework (such as universality, inviolable
necessity, or unrestricted scope).
One specific strand of this discussion emerged from consideration
of Weber’s (2005) argument that biology is heteronymous,
i.e., that it ultimately borrows its explanatory power from the laws
of physics and chemistry. Weber uses Hodgkin and Huxley’s model of the
action potential as an exemplar of the reducing biological phenomena
to physical laws (such as Ohm’s law and the Nernst equation). Craver
(2006) responds that the explanatory force of Hodgkin and
Huxley’s model, in fact, requires a grasp of the distinctly biological
properties of ion channels, which properties were black-boxed in
Hodgkin and Huxley’s total current equation (see also Craver 2007;
Bogen 2008b; Weber 2008).
Yet the contrast between laws and mechanisms has not always been
entirely clear. Some, such as Bogen (2005), Machamer (2004), and
Glennan (forthcoming) emphasize that causes and mechanisms are, at
base, singular, not general or universal. Leuridan (2010), building on
the work of Mitchell (2000), objects that mechanisms cannot replace
laws of nature in our conceptual understanding of explanation and the
metaphysics of science. Scientists rarely investigate token
mechanisms, one might think, but are much more interested in
types. And once one starts talking about types of mechanisms, one is
back in the business of formulating general regularities about how
mechanisms work. So it would appear that the concept of mechanism
cannot supplant the work that generalization was supposed to do, but
requires the idea of regularity, and so something akin to laws, if it
is to do that explanatory work (see Andersen 2011, 2012, 2014a,b;
Krickel 2014). For a reply to Leuridan, see Kaiser and Craver (2013).
 
Work on mechanisms has also helped to clarify the idea of levels of
organization and its relation to other forms of organization and
non-mechanistic forms of emergence.
Many mechanists, following Simon (1996 [1962]), emphasize that
biological systems are hierarchically organized into near-decomposable
structures: mechanisms within mechanisms, within mechanism. Using the
parable of Tempus and Hora, Simon (1962) argued that a watchmaker who
builds hierarchically decomposable watches (Tempus) will make more
watches than one who builds holistic watches (Hora). This parable led
Simon to the conclusion that evolved structures are more likely to be
nearly decomposable into hierarchically organized, more or less stable
structures and sub-structures. Some have objected that the story is
misleading because evolution does not construct organisms from
scratch, piece by piece (Bechtel 2009b). Steel (2008), building on the
work of others (Schlosser and Wagner 2004), therefore attempts to
reconstruct this argument as a way of showing that evolved systems are
more likely to be modular: systems made of independently manipulable
parts can quarantine the effects of changes to specific parts, giving
them added flexibility to make local changes without causing
catastrophic side-effects.
The near decomposability of mechanisms is directly related to the
idea that mechanisms span multiple levels of organization. The
behavior of the whole is explained in terms of the activities and
interactions among the component parts. These activities and
interactions are themselves sustained by underlying activities and
interactions among component parts, and so on (see Bechtel and
Richardson 2010 [1993]).  Craver (2007) defines levels of mechanisms
in terms of a relationship between the behavior (ψ) exhibited
by a system (S) and the activity (φ) of some component
part (X) of that system. On this
account, X’s φ-ing is at a lower level of mechanistic
organization than S’s ψ-ing if and only if (i) X
is a part of S, and (ii) X’s φ-ing is a component
in S’s ψ-ing. In short, to say that something is at a
lower mechanistic level than the mechanism as a whole is to say that
it is a working part of the mechanism. Though the term
“level” is used in many legitimate ways,
levels of mechanisms seem to play a central role in structuring the
relations among many different models in contemporary biology (e.g.,
between Mendelian and molecular genetics (Darden 2006), between
learning and memory and channel physiology (Craver 2007), and between
population-level variation and developmental mechanisms (Tabery 2009,
2014a)).
One implication of this view of levels, combined with certain
familiar assumptions about causal relations, is that there can be no
causal relationships between items at different levels of mechanisms.
There can be causal relationships between things of different sizes,
and there can be causal relationships between things described in very
different vocabularies; but (again, conjoined with certain assumptions
about the temporal asymmetry of cause and effect and the independence
of cause and effect) there cannot be causal relationships between the
behavior of a mechanism and the activities of the parts that jointly
constitute that behavior. Claims about interlevel causation, which are
ubiquitous in the scientific literature, are best understood either as
targeting a different sense of levels or, concerning levels of
mechanisms, as expressing hybrid claims combining constitutive claims
about the relationship between the behavior of the mechanism as a
whole and the activities of its parts, and causal claims concerning
relationships between things not related as part and whole (Craver and
Bechtel 2007). For alternative interpretations of levels, see Fehr
2004; Leuridan 2011; Thalos 2013; Eronen
2013; 2015; Baumgartner
and Gebhardter forthcoming; Romero
forthcoming. For
reflections on the metaphysical status of higher-level phenomena and
higher-level causes, see Baumgartner 2010; Glennan
2010 a, b; Hoffman-Kolss 2014, as
well as the entries on 
 causation and manipulability,
 physicalism, and
 scientific reduction.
As noted above, the fact that phenomena at higher levels of
mechanisms depend upon the organization of component parts entails
that the properties/activities of wholes are not simple sums of the
properties/activities of the parts. Levels of mechanisms can thus be
contrasted with levels of mere aggregation. Because the whole is
greater (in this sense) than the sum of the parts, some (such as
Wimsatt) have found it appropriate to describe this as a kind of
emergence. Mechanistic (or organizational) emergence thus
understood is ubiquitous and banal but extremely important for
understanding how scientists explain things.
Also familiar is epistemic emergence, the inability to
predict the properties or behaviors of wholes from properties and
behaviors of the parts. Epistemic emergence can arise as a result of
ignorance, such as failing to recognize a relevant variable, or from
failing to know how different variables interact in complex networks.
It might also result from limitations on human cognitive abilities or
in current-generation representational tools (Bedau 1997; Boogerd
2005; Richardson and Stephan 2007). The practical necessity of
studying mechanisms by decomposing them into component parts raises
the epistemic challenge of putting the parts back together again in a
way that actually works (Bechtel 2013a).
The mechanists’ emphasis on mechanistic/organizational and
epistemic emergence contrasts with their desire to distance themselves
from spooky emergence (Richardson and Stephan 2007). Spooky emergence
would involve the appearance of new properties with no sufficient
basis in mechanisms. It is not clear that emergent properties are
properly said to be properties of the necessary mechanisms; and it is
not clear in what since the emergent property is
“emergent” rather than a fundamental feature of the causal
structure of the world.
In short, such forms of emergence are altogether distinct from, and
so gain no plausibility from, verbal association with
organizational/mechanistic and epistemic emergence.
Because the framework concept of a mechanism is so useful for
thinking about levels and explanation in the sciences, some scholars
have sought in the notion of mechanism a way of fleshing out the
ontological relationship of realization.
According to the “flat view” (Gillett 2002) realization
is a relationship between different properties of one and the same
thing (Kim 1998; Shapiro 2000; Shoemaker 2003, 2007; Polger 2007). The
subset view, which holds that a property P1 (e.g., mean kinetic energy
of the gas) realizes property P2 (e.g., temperature of the gas) when
the causal powers distinctive of P2 (temperature) are a subset of the
causal powers distinctive of P2 (mean kinetic energy), is an example
of the flat view. P1 and P2 are both attributed to the same thing, the
gas (Gillett 2002, 2003). The dimensioned view describes realization
as a relationship holding between the properties of wholes and the
properties of the parts and their organization. This view of
realization comports with the explanatory aims of the special sciences
and fits nicely with the evidential base on which interlevel claims
are grounded (see Aizawa and Gillett 2011). Gillett has since expanded
this notion to handle the realization of objects, properties, and
processes (Gillett 2013); for criticism and alternatives, see Polger
2010; Melnyk 2003; Melnyk 2010)
Mechanistic theories of natural kinds develop out of
Boyd’s homeostatic property cluster (HPC) view. The HPC view
is a theory of natural kinds designed to work in domains with high
individual variability. The HPC view is offered as a third way between
essentialism and nominalism about kinds in the special sciences (Boyd
1991, 1997, 1999; Kornblith 1993; Wilson 1999, 2005; see also
the entry on natural kinds).
According to this view, a natural kind is characterized by i) a
cluster of properties that regularly co-occur, and ii) a similarity
generating mechanism that explains why the properties in (i) tend to
co-occur. In short, kinds are property clusters explained by
mechanisms.
This view of natural kinds has been deployed to argue for taxonomic
revision in, for example, the biology of human emotion (Griffiths
1997), the structure of concepts (Machery 2009), and the taxonomy of
psychiatry (Kendler, Zachar, and Craver
2010; see Craver 2009): a
putatively single kind is split into multiple kinds because it is
discovered that distinct properties in a property cluster are
explained by distinct mechanisms. This view of kinds can also be used
to make sense of kinds that are historically transient and, in some
ways, the product of human attitudes and so socially constructed in
this straightforward sense; perhaps race is like this (see Kuorikoski
and Pöyhönin 2012; Khalidi 2013).
Emphasis on the importance of mechanisms is historically associated
with the rejection of teleology and formal causes (e.g., Westfall
1971). Yet contemporary biology and many other special sciences,
despite the widespread acceptance of the mechanism framework concept,
continue to make use of the concept of function, a teleological notion
(see the entry on 
 teleological notions in biology).
 How is the notion of function at play in contemporary
science related to the concept of mechanism? Craver (2001a), following
Cummins (1975), argues that functional description is a perspectival
means of situating some part within a higher-level
mechanism. According to this view, teleology is not a feature of the
world so much as it is imposed upon it by an intentional describer
(see also Machamer 1977). Garson (2011, 2012), following Wimsatt
(1972b), Wright (1973) and Neander (1991a,b), argues that functions
are effects of an item that are part of the etiological explanation
(through selection, learning, or reinforcement) for why the item is
present; as such, functions are reduced to causal histories. In a
third view, Maley and Piccinini (forthcoming) argue that the
(teleological) function of an item is its contribution to the goals of
organisms, which may be objective or subjective goals. Like Garson,
Maley and Piccinini hold that functions are objective (i.e., not
observer relative). Unlike Garson, however, they are not grounded in
the etiology of the item but in their current contribution to survival
or reproduction (the objective goals of organisms) or to what the
organism itself desires (the subjective goals of organisms).
What must the world be like for this mechanistic perspective to be
accurate? Clearly, there are many ways of answering this question from
different metaphysical starting assumptions. And clearly, many
metaphysical starting assumptions rule this world picture out as
illegitimate. The clearest path forward, it would seem, is to work out
precisely what one must be committed to in holding that the world is
composed of a hierarchy of mechanisms and precisely what of that can
be recovered on the basis of different starting assumptions.
That said, not all applications of the mechanism framework require
a fully articulated metaphysics. Work on discovery and explanation
might proceed perfectly well without embracing any particular
metaphysical world picture. Philosophers with different interests
(discovery, explanation, testing, reduction, emergence, and so) are
likely to elaborate the concept in different ways. There is every
reason to doubt, that the idea of mechanism can be given a one-size
fits all metaphysical analysis that will adequately address the
diverse philosophical ends to which the concept is being deployed.
According to Nagel (1961), reduction is a species of covering-law
explanation: one theory is reduced to another when it is possible to
identify the theoretical terms of the first with those of the second
and to literally derive the first from the second. On the assumption
that scientific disciplines and theories correspond to one another,
reduction serves as a model of interdisciplinary integration as well.
Mechanist’s objections to the covering-law model of constitutive
explanation (i.e., micro-reduction) are discussed above
(see Section 3.1); here the focus is rather
on how distinct disciplines of science are integrated.
On the Nagel view, reduction is an interlevel relationship. It is
also a relationship between theories. Theories about phenomena at a
higher level (e.g., gases, lightning, and life) are reduced to (i.e.,
derived from) theories about phenomena at lower levels (e.g.,
molecules, electrons, and physiological systems). Finally, the
relationship is formally specified and has little to do with either
the content of the theories or the material structures those theories
describe. From the mechanistic perspective, each of these features of
the Nagel model is problematic.
First, mechanists criticize the idea that reduction should be
understood primarily as a relationship between theories. In
integrating their results, scientists are not simply building theories
simpliciter; they are building theories about mechanisms. Mechanisms
can perhaps be described using formal accounts of
theories—perhaps they can be axiomatized in predicate logic or
reconstructed as set theoretic predicates. But such formal accounts of
the structures of scientific theories gloss over the mechanistic
structures crucial for understanding how these theories are
constructed and evaluated (Craver 2001b).
Mechanists also challenge the idea that disciplines are related by
way of the relationship between their theories. Darden and
Maull (1977) argued that disciplinary fields often integrate their
findings through the construction of interfield theories, appealing to
diverse material relationships between items in the different
fields’ domains: relations such as cause and effect, part and
whole, or structure and function. Darden and Maull did not offer a
general account of interfield theories, but Bechtel presciently
suggested that such theories often take the form of descriptions of
mechanisms (Bechtel 1988: 101–102).
The mechanistic approach also has been claimed to have many
advantages over reduction for thinking about interlevel forms of
interdisciplinary integration. First, it provides a straightforward
way to interpret the talk of levels (see
Sections 2.4.5  and 4.2). Second, it offers
significantly more insight into what interlevel integration is, into
the evidential constraints by which interlevel bridges are evaluated,
and into the forces driving the co-evolution of work at different
levels. Constraints on the parts, their causal interactions, and their
spatial, temporal, and hierarchical organization all help to flesh out
an interlevel integration. Finally, mechanists repeatedly recognize
the need to not only look down to the constitutive mechanisms
responsible for a given phenomenon (emphasized by classical reduction
models), but also to look up and around to the context within which
the phenomenon is embedded: interlevel integration is an effort to see
how phenomena at many different levels are related to one another
(Bechtel 2009a; Craver 2007).
Mechanists have developed several extended examples of the many
forms of mechanism integration pursued in mechanistic research
programs. Darden (2005), for example, suggests that philosophers in
the grip of classical reduction fundamentally misunderstood the
relationship between Mendelian and molecular genetics. While
reductionists see it as an instance of interlevel explanation, she
argues, it is in fact a case in which different scientists worked on
different parts of a mechanism that are etiologically (not
constitutively) related to one another. Mendelian genetics did not
reduce to molecular biology; rather, classical geneticists and
molecular biologists integrated their work by focusing on different
working entities in the sequentially operating chromosomal and
molecular hereditary mechanisms. Examples have also been drawn from
the discovery of the mechanisms of protein synthesis (Darden 2006) and
cell biology (Bechtel 2006). Craver (2007) uses examples from
the neuroscience of memory to explore how multilevel integration does
and ought to proceed. In each case, the search for mechanisms serves
as an abstract scaffold onto and around which the findings of diverse
scientists converge.
The mechanistic perspective tends to emphasize integrative
pluralism in scientific research (Mitchell 2003, 2009). The goal is
not to explain the less fundamental in terms of the more fundamental
in a step-wise relating of monolithic theories at one level to
monolithic theories at another. Rather, such scientific achievements
are collaborative and piecemeal, adding incremental constraints to an
emerging picture of how a mechanism works both at a level and across
levels. The many scientific disciplines that investigate a phenomenon
pluralistically co-exist and co-inform one another by integratively
contributing to the etiological, constitutive, and contextual
mechanistic explanations of that phenomenon (Bechtel
2009a; Tabery 2014a).
The Nagel model of theory reduction offers a clear vision of the
“unity of science”
(see the entry on unity of science).
According to the model, the unity among scientific disciplines is
achieved by reducing theories of higher-level disciplines to the
theories of lower-level disciplines. Integration, on that vision, is
understood as progress toward a grand, unified body of scientific
knowledge. For mechanists, in contrast, integration is piecemeal,
local, and pluralistic. What sort of unity could such an
“integration” sustain? This question plays out in a
back-and-forth between Longino and Tabery concerning disciplinary
relationships in the behavioral sciences. Tabery argues that
disciplines as disparate as neurobiology and quantitative genetics
could pluralistically co-exist and co-inform one another’s causal
explanations of complex behaviors by way of mechanism integration.
Longino counters that Tabery’s pluralism is only a
“moderate” sort because the push for integration
ultimately is a push for unification (Longino 2013, 2014; Tabery
2014a,b).  Sullivan (2009) also challenges the push for mechanism
integration; she argues that there are significant barriers to the
kind of integration mechanists envision. Different laboratories use
different experimental protocols to study what they assume to be the
same phenomenon; however, these different protocols often in fact
target different phenomena, so the integration achieved by combining
results is only illusory. These discussions are symptomatic of more
general philosophical questions faced by mechanists: How are mechanism
integrations actually achieved (as opposed to just asserted)? And what
is the relationship between mechanism integration and unification? The
new mechanical philosophy stands to benefit from future efforts to
situate mechanistic integration into more general philosophical views
of integration and pluralism.
What can philosophers say about scientific discovery? Many logical
empiricists had a simple answer: Nothing. According to Popper, for
example, philosophers can illuminate the epistemology of testing, but
they can say nothing of substance about how scientists generate the
ideas to be tested (Popper 1959). Such “A-ha!” moments of
creativity are in the province of psychology, not philosophy.
Reichenbach distinguished the context of discovery from the context of
justification (the “context distinction”) (Reichenbach
1938; but see the entry on 
 Hans Reichenbach for an alternate
 interpretation of this
distinction). The process of scientific discovery was thus largely off
limits to philosophers.
Not all philosophers of science agreed. Hanson, for example,
articulated a logic of discovery involving abductive inferences from
anomalous data to new hypotheses designed to account for them (Hanson
1958). Others focused on methodologies of discovery that could either
allow one to rationally reconstruct why something was discoverable at
a given time (Nickels 1985) or to explain why a new hypothesis is
considered promising and worthy of further investigation (Schaffner
1993). Early contributions to the new mechanical philosophy followed
this path and characterized investigative strategies scientists use to
discover mechanisms (see the entry on 
 scientific discovery).
Bechtel and Richardson’s Discovering Complexity (2010
[1993]) is organized around a flowchart representing choice-points in
the discovery of a mechanism. The process of searching for mechanisms
begins with a provisional characterization of the phenomenon. Then
follow strategies of localizing the mechanism within the
system, and decomposing the phenomenon into distinct
sub-functions. Localization of function involves determining which of
these sub-functions of the system is performed by which parts. Bechtel
and Richardson further characterize the use of excitatory and
inhibitory experiments to obtain these kinds of information. Bechtel
and Abrahamsen (2013) add a subsequent stage, in which
scientists recompose what they have learned about the
functional parts by putting them back together to produce the
phenomenon in question (perhaps using simulations). 
Darden also emphasized mechanisms as an important framework concept
in scientific discovery (Darden 1980, 1982, 1986, 1991). In the
discovery of protein synthesis (jointly investigated by molecular
biologists and biochemists in the 1950s and 1960s), scientists didn’t
simply have an “A-ha” moment. Rather, they deployed
strategies for revealing how a mechanism works (Darden 2006; Craver
and Darden 2013). Darden characterizes the process of mechanism
discovery as an “extended, piecemeal process with hypotheses
undergoing iterative refinement”; that process occurs via the
construction, evaluation, and revision of mechanism schemas in light
of observational and experimental constraints (Darden 2006: 272).
Darden’s construction strategies are strategies for generating new
hypotheses about a mechanism. In addition to decomposition and
localization, Darden shows that scientists often borrow a schema
type from another area of science, as when selection-type
mechanisms were borrowed to understand how the immune system works, or
assemble a mechanism from known modules of functional activity
(modular sub-assembly), as is common in biochemistry and
molecular biology. Sometimes, scientists know one part of the
mechanism and attempt to work forward or backward through to the other
parts and activities. In the discovery of the mechanism of protein
synthesis, for example, molecular biologists worked forward from the
structure of DNA to figure out what molecules could interact with it
(forward chaining), and biochemists worked backward from
proteins to figure out what chemical reactions would be necessary to
create them (backward chaining). They met in the middle at
RNA. Protein synthesis is now understood to involve transcribing DNA
into RNA and then translating RNA into proteins. Far from being
philosophically inscrutable, Darden points out that scientists used
what they knew about the working entities and activities in the
mechanism to infer what could come next or before in the mechanism of
protein synthesis (Darden 2006; see
also the entry on 
molecular biology).
Evaluation strategies, for Darden, involve constraint-based
reasoning to limn the contours of the space of possible
mechanisms for a given phenomenon. Often scientists reason about how a
mechanism works by building off basic findings concerning the spatial
and temporal organization of its parts. Harvey, for example, reasoned
his way to the circulation of the blood by considering the locations
of the valves of the veins and their orientation with respect to the
heart. These organizational constraints, and many others, combined to
narrow the space of possible mechanisms to a small region containing a
model in which the blood completes a circuit of the body (Craver and
Darden 2013).
Darden and Craver also discuss experimental strategies for learning
how a mechanism works. These strategies reveal how different entities
and activities in a mechanism act, interact, and are organized
together. For example, one might intervene to remove a putative
component to see if and how the mechanism functions in its absence
(inhibitory experiments). Or one might stimulate
that component to see if it can drive the mechanism or modulate its
behavior. Or one might activate a mechanism by placing it in
the precipitating conditions for the phenomenon and observe how the
entity or activity changes as the mechanism works. Craver (2002)
discusses these under the heading of “interlevel
experiments” (see also Harinen forthcoming). 
Craver and Darden (2013) also discuss more complex
kinds of experiments for learning what sort of entity or activity
contributes to a process and for learning more complex features of a
mechanism’s organization.
Datteri (2009; Datteri and Tamburrini 2007), explores the use of
robotic simulations for the purposes of testing mechanisms. They
discuss both how assumptions are built into robotic models and how
experiments can be designed to reveal how mechanisms work. This work
extends the mechanistic framework into the area of bio-robotics and
reveals a set of strategies distinct from those explored in Darden’s
work.
Rather than focusing on the process by which mechanism schemas are
constructed, evaluated, and revised, Steele focuses on the question of
how one extrapolates from a sample population or a model organism to
the structure of a mechanism in the target. Will a treatment proven to
suppress tumors in mice (a model organism) also suppress tumors in
humans (the target population)? After developing a probabilistic
account of mechanisms, Steele considers how researchers get around
what he calls the extrapolator’s circle: determining
how we could know that the model and the target are
similar in causally relevant respects without already knowing the
causal relationship in the target. (Steel 2008: 78)
 Steel breaks the extrapolator’s circle by
developing a mechanisms-based extrapolation strategy—the
strategy of comparative process tracing. Once a mechanism for
some phenomenon has been elucidated in a model (such as a particular
process of carcinogenesis in rats), scientists (toxicologists in this
case) then compare key stages (particularly downstream stages) of the
model with the stages in the target, paying particular attention to
points in the process where differences are most likely to arise. The
greater the similarities of the entities, activities, and organization
of the mechanisms in both populations, the stronger is the basis for
extrapolation; the greater the differences, the weaker the basis (but
see Howick et al. 2013; see also the sections on extrapolation in the
entries on
 molecular biology
and
 experiment in biology).
Discovery in medicine is another domain where the mechanical
philosophy has been applied. Thagard draws on the case of H.
pylori as a cause of ulcers to provide an account of how
investigating mechanisms contributes to scientific discovery.
Thagard draws attention to both statistical evidence that suggests
ulcers are somehow associated with H. pylori, as well as
mechanistic evidence that can explain how the agent of infection could
persist in a hostile environment long enough to cause an ulcer. More
recently, philosophers interested in evidence-based medicine have
probed the relationship between these two types of evidence in the
health sciences. Russo and Williamson argue that both types of
evidence are necessary to justify causal inference; the correlational
evidence establishes that there is a difference-making relation
between some cause and some effect, while the mechanistic evidence
establishes how exactly the cause produces its effect—the
“Russo-Williamson Thesis” (Russo and Williamson
2007). Philosophers have since refined the Russo-Williamson Thesis,
pointing out, for instance, that “type of evidence” could
refer to different methodologies for gathering evidence or to
different objects of evidence.  Difference-making methodologies
include observational studies and randomized controlled trials, while
mechanistic methodologies include interventionist experiments such as
those described above; likewise, the object of evidence could be the
evidence of an associated difference or it could be the evidence
concerning the mechanism linking the cause and effect (Illari 2011;
see also Campaner 2011).  Evidence-based medicine hierarchies, which
rank different kinds of evidence in terms of its epistemic strength,
tend to prioritize evidence from difference-making methodologies (such
as randomized controlled trials and meta-analyses) over mechanistic
evidence; in reply, these philosophers argue that the different types
of evidence are on a par (each with its own strengths and weaknesses)
and advocate for integrating difference-making and mechanistic
evidence, a sentiment which aligns with the emphasis on mechanism
integration discussed in Section 5.2 above
(Clarke et al. 2013, 2014). 
Many mechanists have explored the strategies that scientists use in
discovery. Bechtel and Richardson attended to decomposition and
localization; Darden and Craver highlighted forward and backward
chaining; Russo and Williamson emphasized drawing on both
difference-making and mechanistic evidence. These strategies were
found in specific, experimental sciences, such as neuroscience and
molecular biology. So one task for philosophers moving forward is to
assess whether or not similar strategies exist in other sciences,
especially those that operate outside the traditional laboratory, both
in the human sciences (such as sociology and economics) and in the
physical sciences (such as cosmology).
We also expect tremendous development to come from bridging the gap
between the qualitative accounts of mechanisms and mechanistic
explanation developed in the new mechanism and quantitative theories
of discovery from the discipline of machine learning and causal
modeling (Spirtes et al. 2000; Pearl 2009). The latter offer tools to
mine correlational data for causal dependencies. Such tools might
escape more qualitative, historical approaches and might, in fact, go
beyond the common strategies that scientists traditionally use. Such
tools also offer a means to assess discovery strategies by exploring
the conditions under which they succeed and fail and the efficiency
with which they deliver verdicts on causal hypotheses.
The new mechanical philosophy and, more generally, attention to the
framework concept of “mechanism” has expanded rapidly over
the last two decades bringing with it new orientations toward a wide
range of issues in the philosophy of science. Yet it is clear that
many of the major topics are only beginning to develop, leaving a lot
of work for scholars to elaborate the basic commitments of this
framework and to consider what it means to do science outside of that
framework.  The near future is likely to see continued discussion of
the implications and limits of this framework for thinking about
science and scientific practice.