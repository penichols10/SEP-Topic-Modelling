Resemblance theories of depiction are commonly traced to
Republic, book X, where Plato suggests that a painting of an
object is a mimesis (imitation or representation) of its
shape and colour. The idea is intuitively plausible, and it provides
the basis for a variety of attempts by philosophers to define or
analyse the concept of a picture, or to explain how pictures
represent. It is true that pictures represent things that do not have
shapes or colours, such as God and Justice, but they do so by
depicting things that do have shapes and colours, such as bearded men
and blindfolded women carrying scales. Accordingly, the basic thought
that underlies resemblance theories of depiction is that pictures are
composed of shapes and colours that resemble the shapes and colours of
the visible objects they depict. But even if this provides an adequate
starting-point, a convincing theory of depiction needs to be
elaborated with care, as Nelson Goodman (1968) showed. The simplistic
claim that A depicts B if and only if A
appreciably resembles B is demonstrably false. According to
Goodman “more error could hardly be compressed into so short a
formula” (1968: 3–4).
As a matter of fact, the simplistic formula Goodman attacks was never
proposed by Charles Sanders Peirce or his followers, such as Suzanne
Langer (1942) and John Hospers (1947), whose semiotic theories were
Goodman’s immediate target, or by any other philosopher or
theorist of art. Peirce described pictures as iconic signs,
i.e., signs that signify objects by resembling them, and he contrasted
iconic signs with indices, which signify objects by standing in
spatial, temporal or causal relations to them, and with
symbols, which signify objects by means of conventions
(Peirce 1982, Vol. 2: 53–56). But this classification depends on
the basic idea of signification, which Peirce holds is a three-termed
relation between a sign, its object, and an
“interpretant”, i.e., a thought of the object or a
translation of the sign. Moreover, Peirce acknowledges that these
three categories of sign are not mutually exclusive, and that the
signification of a picture can also depend on iconographic
conventions, and on its context of use.
Hence, Peirce’s conception of depiction is not captured by the
formula Goodman criticizes. But arguably the formula has some
heuristic value, because it draws attention to some of the challenges
a theory that explains depiction in terms of resemblance will need to
address. Thus, according to Goodman, resemblance is a reflexive and
symmetric relation, whereas representation is neither: an object
resembles itself to the maximum degree but does not normally represent
itself, and the object that a picture represents does not represent
the picture, although it resembles the picture to exactly the same
degree and in exactly the same respects as the picture resembles it.
Furthermore, many pictures resemble other pictures, such as copies of
them, more closely than they resemble their objects, but they do not
represent those pictures. “Plainly” Goodman concludes
“resemblance in any degree is no sufficient condition for
representation”(1968: 4).
As we have indicated, Goodman’s initial challenge to resemblance
theories of depiction does not show that the approach is wrong. For
according to philosophers who favour the approach, the idea of
resemblance is used to explain what makes a pictorial representation
specifically pictorial, rather than what makes it generically
representational. The depictive relation between a portrait and its
subject is indeed neither reflexive nor symmetric. But resemblance
remains a candidate for explaining what makes a representation
pictorial or figurative, and therefore how a portrait of an individual
differs from a text describing her appearance. For comparison, the
referential relation between the indexical “now” and the
time it refers to is neither reflexive nor symmetric, but this does
not prevent us from explaining how “now” refers to a
specific time in terms of simultaneity (between the use of the word
and the time referred to), which is both.
However, the example of a portrait brings us to another objection to
resemblance theories of depiction, which Goodman mentions in passing
(1968: 25), and others have accorded greater weight (Hopkins 1998b;
Abell 2009). For if resemblance is a relation, and if the relata of a
relation must be existing particulars, then it appears that pictures
that represent fictional individuals (Zeus, Pegasus), and genre
pictures, which represent kinds of objects without representing any
particular instances of them, cannot resemble what they represent.
Hence, even if it is plausible that a resemblance theory can explain
how a portrait represents a sitter, it cannot provide a general
explanation of depiction.
One response to this argument is to claim that fictional characters
are abstract entities that actually exist (Kripke 2013: 73). Another
is to claim that a fictional character can be a genuine relatum of a
relation without existing: it is sufficient that it is capable of
being identified, referred to, and described, and meeting these
conditions does not require existence (Rundle 1979: 249; Sainsbury
2005: ch. 6). But even if one of these responses is correct, and the
objection therefore fails to show that the concept of resemblance is
unsuited to explaining how pictures represent fictional characters,
the problem of genre pictures remains. However, John Hyman (2012:
129–132) has argued that the verb “resemble”
sometimes expresses a relation and sometimes does not. For instance,
in the sentence “Darwin resembles Socrates”,
“resembles” expresses a relation, whereas in the sentence
“Socrates resembles a satyr”, it is a copular (linking)
verb. Thus, according to Hyman, “resembles”, “looks
like”, “is like”, etc. have the same kind of dual
use as “is”, which can either express identity or have a
copular function (Russell 1914: 48). If this is right, the objection
also fails to show that the concept of resemblance is unsuited to
explaining generic depiction (cf. Blumson 2014).
Goodman places more weight on a third objection to resemblance
theories of depiction. A theory of this kind, he maintains, would need
to specify the visible aspect or aspects of its object that a picture
imitates or copies. But every object can be seen in many ways,
depending on the experience, interests, and attitudes of the viewer:
“the object before me is a man, a swarm of atoms, a complex of
cells, a fiddler, a friend, a fool and much more” (1968: 8).
Since the artist cannot copy all of these aspects at once, all of the
ways the object is or looks, one might assume that her aim is to strip
away the varnish of perceptual habit, prejudice or interpretation, and
capture the object as seen “under aseptic conditions by the free
and innocent eye”. But, Goodman claims, following Ernst Gombrich
(1960), “there is no innocent eye”: the idea that we can
access some raw visual data by means of “purification rites or
by methodical disinterpretation” is a myth. Both “the way
we see and the way we depict depends upon and varies with experience,
practice, interests, and attitudes” (Goodman 1968: 10).
According to Goodman and Gombrich, resemblance theories of depiction
depend on the mistaken assumption that visual perceptions result from
a process of interpreting two-dimensional patterns of raw colour,
without any intrinsic meaning, which artists are trained to observe
and record. Psychologists such as Hermann von Helmholtz, artists such
as Claude Monet, and art theorists such as John Ruskin embraced a
theory of painting of this kind. For instance, the passage by Ruskin
from which Gombrich took the phrase “innocent eye” reads
as follows:
The whole technical power of painting depends on our recovery of what
may be called the innocence of the eye; that is to say, of a
sort of childish perception of these flat stains of colour, merely, as
such, without consciousness of what they signify. (Gombrich 1960: 296;
quoting Ruskin 1857: 6, note 1)
Goodman and Gombrich associate this conception of painting with
resemblance theories of depiction. But it is not an essential part of
such a theory. If the depiction of an object depends on the imitation
of its form and colour, it follows that an artist must be able to
perceive these properties and reproduce them, but it does not follow
that we need to conceive of painting in the way Ruskin recommends.
The principal objections to resemblance theories of depiction may be
unconvincing, but the challenge for such a theory is to specify the
respect or respects in which pictures resemble their objects, and this
is not a simple task. Merely referring to ‘form and
colour’ is unsatisfactory. For as Descartes pointed out, it is
unclear how the 2-D shape of a mark on the surface of a painting or
drawing can resemble the 3-D shape of an object it depicts; and the
use of foreshortening shows that rhombuses can represent squares
better than squares, ovals can represent circles better than circles,
and so on ([1637] 1985: I 165). Furthermore, some pictures (for
instance, cubist paintings) do not bear much obvious resemblance to
the objects they depict in either form or colour. Hence, the basic
idea that depiction depends on resemblances in form and colour will
need to be specified in such a way as to meet what Dominic Lopes calls
the diversity constraint (Lopes 1996: 32), in other words, it
will need to accommodate the wide variety of styles of picture-making.
Different resemblance theorists have responded to these challenges in
different ways.
John Hyman and Catherine Abell have proposed different theories of
depiction in which the idea of resemblance plays a significant role.
Hyman rejects the theory that pictures are iconic signs (2012: 127),
but he claims that there is a strict and invariable relationship
between the shapes and colours on a picture’s surface and the
shapes and colours of the objects it represents. Hyman’s theory
depends on Gottlob Frege’s distinction between sense and
reference (see §3.2 of the  entry on
 Frege).
 Taking one of Frege’s own examples, the phrases “the
morning star” and “the evening star” have the same
reference, but different senses, or modes of presentation. Both
phrases refer to one and the same object, the planet Venus, but they
describe or present it as a star that is visible at different times of
day. Similarly, two portraits of the same individual may present him
as dark-haired and seated, wearing a black smock
 (Kramskoy’s 1873 portrait of Tolstoy),
 or as grey-haired and standing, wearing a white smock
 (Repin’s 1901 portrait).
 They portray (refer to) the same individual, but they present him
differently (they differ in sense). The distinction matters, Hyman
argues, because resemblances do not explain a picture’s
reference, they explain its sense. (The claim that A depicts
B if and only if A appreciably resembles B, which
Goodman criticizes, is about depiction qua portrayal, i.e.,
pictorial reference, not sense.)
According to Hyman, the sense or mode of presentation of a picture,
expressed in the most general terms, is an aspect or view of an object
or arrangement of objects, relative to an implicit point (or a variety
of points) of view. (An “object” in this sense is not
necessarily a “material object”, it might be a shadow, a
rainbow, or part of the sky.) Different parts of a picture can present
different aspects of an object or its parts, corresponding to
different points of view, but nothing can be depicted independently of
a point of view. Otherwise, Hyman points out,
[we could] discover different aspects of an object represented in a
picture by moving around it and studying it from different angles, as
we can in the case of a free-standing sculpture. (2012: 142)
Hyman’s principal claim is that the sense or mode of
presentation of a picture is defined by the colours and shapes of the
marks on its surface in accordance with definite optical principles
concerning colour and shape (2006: ch. 5; see also Hopkins 1998a: 27).
We shall concentrate on shape.
Hyman’s shape-principle employs the concept of an object’s
occlusion shape, i.e., the 2-D cross-section of the cone of
light it subtends to a viewer’s eye. (The concept is similar to
Hopkins’s outline shape; see below,
 §3.2.)
 For example, the occlusion shape of a circular coin viewed obliquely
is an ellipse. This shape, Hyman argues, is a visible property of the
coin. It is especially salient when an object is backlit, and appears
in silhouette. It is relative to a point of view, and changes as the
point of view changes. But Hyman insists that relative does not mean
subjective. An object’s occlusion shape “is not merely a
feature of the viewer’s experience. It belongs to optics, not
psychology” (2012: 143; cf. Peacocke 1987). Hyman’s
shape-principle is that the shape of a region on a picture’s
surface (or, in the case of anamorphic pictures, its occlusion shape
relative to the intended point of view of a spectator) is identical to
the occlusion shape of the object it represents, relative to the
implicit point of view. In other words, there is an exact resemblance
between these shapes (2006: 81).
According to Hyman, this principle captures an exact relationship
between the marks on a picture’s surface and the picture’s
sense, which does not depend on the artist’s intention, or on
the picture’s psychological effect on a spectator, and which
applies to pictures regardless of their style or the artistic
tradition to which they belong. Together with a principle concerning
colour, it is supposed to explain how the colours and shapes on the
surface of a picture fix the colours and shapes of the objects it
depicts. But Hyman’s optical principles do not imply that a
portrait of Tolstoy resembles Tolstoy, since they are only concerned
with a picture’s sense, as opposed to its reference. Nor do they
imply that a painting of a bearded man resembles a bearded man, since
they are only concerned with the shapes and colours of the objects in
a picture. Hyman therefore claims that his theory dovetails neatly
with the idea that a picture’s reference is normally determined
by the artist’s intention, and with the idea that the depiction
of objects of specific kinds, such as men and horses, depends on a
picture’s propensity to trigger a spectator’s ability to
recognize these kinds of objects by their shapes and colours, and the
shapes and colours of their parts (see below,
 §3.2).
 He explains how these two elements of a theory of depiction can be
combined with the example of a silhouette:
the black shapes the silhouettist has cut out fix the occlusion shapes
of the objects represented and their parts, relative to an implicit
line of sight. And the spectator’s ability to recognize, say, a
girl or a cat, enables him to see a girl or a cat depicted in a
silhouette by seeing its occlusion shape and the occlusion shapes of
its parts. (2012: 113)
Hyman’s theory has been criticised on various grounds. First,
and most generally, Michael Podro argues that it expresses a bias in
favour of realistic or literal representation (Podro 2010: 457).
However, Hyman replies that the optical principles he defines
“do not dictate or limit the forms artists create, the models
they follow, or the values they embody in their work”, any more
than English grammar limits the imagination of English poets (Hyman
2012: 145). Second, it has been alleged that Hyman’s theory
cannot explain “the depiction of nonexistent objects”
(Abell 2009: 195). However, this objection depends on the questionable
assumption that resemblance is invariably a relation between existing
particulars (see above
 §1.1).
 Third, it has been argued that indeterminacies in the occlusion
shapes of objects represented in a picture may not match the
indeterminacies in the shapes of the parts of the picture that depict
them (Kulvicki 2014: 61–62). Finally, it has been argued more
generally that the exact correspondences in shape and colour between
the surface of a picture and its content, which Hyman’s theory
predicts, sometimes break down; and that the correspondences which do
exist depend on contingent features of the human visual system (Newall
2006; Hyman 2007; Newall 2011).
The last objection reflects the most widely accepted reason for
rejecting resemblance theories such as Hyman’s, in which the
basic mechanism of depiction is defined without reference either to
the visual experience of a spectator, or to the changing cultural
context in which pictures are made. Catharine Abell has defended a
resemblance theory of depiction which differs from Hyman’s in
both of these respects, and is designed to avoid the objections
mentioned above. It is also a more ambitious theory, both because
Abell does not distinguish between the sense and reference of a
picture, but aims to explain both at once, and because she explains
the depiction of specific kinds of objects, such as men and horses, in
terms of resemblance, instead of confining the scope of the theory to
the shapes and colours of the objects in a picture. Unlike Hyman,
Abell does not specify which particular respects of resemblance are
necessary for depiction, beyond the requirement that they should be
visible (2009: 199), arguing instead that “different respects of
resemblance govern different instances of depiction” (2009:
196), including resemblance in respect of optical properties, such as
occlusion shape, and response-dependent properties, such as when
painters mimic the effect of simultaneous contrast.
Drawing on Paul Grice’s seminal article “Meaning”
(Grice 1957), Abell argues that the respects of resemblance governing
a particular picture depend on the artist’s communicative
intentions:
A picture’s resemblance to some object O in a given
respect(s) is relevant to determining what the picture depicts if its
maker intended the picture to resemble O in the relevant
respect(s) and thus to bring O to viewers’ minds; and
intended that these resemblances have this effect in part because
viewers recognize that intention. (2009: 201; cf. Blumson 2009 and
2014)
According to Abell, a picture depicts some object O only if it
resembles O in a range of relevant respects, and if it thereby
captures O’s “overall appearance”, enabling a
spectator to distinguish it from objects for which it would not
ordinarily be mistaken (2009: 210). As noted above, Abell regards
pictures of objects that do not actually exist as problematic for
resemblance theories of depiction. Her solution to the problem
combines two ideas: first, a picture of an object that does not
actually exist, but could exist, such as a gold mountain,
would resemble the object, if it did exist; second, we can
make-believe that a fictional character such as Sherlock Holmes
exists, and make-believe that a picture resembles him (2009:216).
Abell argues that because she does not specify which particular
respects of resemblance are necessary for depiction, her theory is
consistent with the diversity constraint, in other words, it
accommodates the wide variety of stylistic conventions that have
developed in different artistic traditions. However, it can be
objected that it fails to accommodate another alleged constraint on an
adequate resemblance theory of depiction identified by Lopes, which he
calls the independence constraint. According to Lopes, a
spectator must be able to perceive the resemblances postulated by a
resemblance theory of depiction “without first knowing”
what a picture represents (Lopes 2005a: 16–17). In fact, this
objection only applies to a theory which implies that a spectator
perceives a certain kind of object in a picture by perceiving a
resemblance between the marks on its surface and an object of
this kind, and a resemblance theory need not have this implication.
However, Abell accepts that the objection applies to her own theory,
especially since she holds that the “respects of
resemblance” that “govern” a picture depend on the
artist’s communicative intentions, and that a spectator’s
knowledge of these intentions is gained, at least in part, from the
picture itself. However, she addresses the objection by highlighting
alternative, context-specific sources of information about them (Abell
2005, 2009; cf. Blumson 2014).
Resemblance theories of depiction differ from one another in
significant ways. But they agree on the following crucial point: the
fundamental difference between pictorial and linguistic representation
consists in the fact that the former depends on resemblances between
representations and the objects they represent, whereas the latter
does not. It is widely agreed that linguistic representation depends
on conventions that create the vocabulary of a language and the
semantically significant structures in which the elements of its
vocabulary are combined. But the contribution words and structures
make to the meaning of a sentence are hardly ever explained by
resemblance. If there are exceptions, such as onomatopoeia, they
confirm the rule.
Art theorists such as Roman Jakobson challenged this division between
pictorial art and language early in the twentieth century (Jakobson
[1921/1971] 1987), reacting against what were thought of as
illusionistic styles of painting. Once it was understood that artistic
styles are comparable to languages or codes, it was thought, artists
would feel freer to abandon academic conventions, to follow
“primitive” models, and to participate in the fauvist and
cubist experiments of Matisse, Picasso, and Braque (Bois 1987).
Conventionalism was well established by the 1950s. For example, the
following remark appears in an article by the American art historian
Leo Steinberg entitled “The Eye Is a Part of the Mind”,
which anticipates Gombrich’s and Goodman’s stance on the
“innocent eye” (see above
 §1.1):
“Technical capacity in the imitation of nature” simply
does not exist. What does exist is the skill of reproducing handy
graphic symbols for natural appearances, of rendering familiar facts
by set professional conventions. (Steinberg [1953] 1972: 198
However, the first attempt to defend a conventionalist theory of art
systematically and in detail was made in Goodman’s book
Languages of Art.
Goodman accepts that pictures may resemble the objects they depict,
but he denies that this explains why they depict them:
A picture that represents—like a passage that describes—an
object refers to and, more particularly, denotes it. Denotation is the
core of representation and is independent of resemblance. (1968:
5)
Goodman does not define denotation, beyond describing it as a variety
of reference, but two features of his conception of denotation should
be noted. First, it is supposed to be the relation in which a name
stands to its bearer, or a predicate stands to the members of its
extension, or a portrait stands to its subject. Hence the
controversial doctrine that predicates and names have the same
semantic function is implicit in Goodman’s theory of depiction
(Geach 1972; Strawson 1976; Hyman 2006: 185–190). Second,
Goodman’s nominalist theory of properties excludes the
possibility that a symbol denotes an object because it resembles it
(Arrell 1987: 42). For he does not merely make the uncontroversial
observation that an object is gray if and only if “gray”
applies to it, he claims that the properties an object has depends
on what predicates apply to it (Goodman 1968: 51, 54–55).
In other words, “gray” does not denote an object because
it has the property of being gray; on the contrary, it has the
property because “gray” denotes it. Equally, the same
predicates do not denote different individuals because they resemble
each other, or have properties in common. On the contrary, they
resemble each other, or have properties in common, because the same
predicates denote them. Hence, resemblance is explained by, and
therefore cannot itself explain, denotation.
According to Goodman, pictorial symbol systems differ from linguistic
ones in being analog and relatively replete, an
analog system being one that is syntactically and
semantically dense. (For reasons of space we shall not
discuss the relationship between analog and dense;
see Lewis 1971 and Haugeland 1981.) A pictorial system is
syntactically dense because it provides for a dense set of
pictorial characters, in other words, a set containing infinitely many
pictures “so ordered that between each two there is a
third” (Goodman 1968: 136), and it is semantically
dense because it provides for a dense set of classes of denotata.
(By contrast, the Arabic numeral system for denoting the natural
numbers provides for infinitely many characters—“1”,
“2”, “3” …, “11”,
“12”, “13” …, etc.—but there is a
“gap” between each numeral and its successor, and between
each of the corresponding natural numbers and its successor:
the system is articulate, not dense.) Finally, a
pictorial system is relatively replete because relatively
many properties of a picture are relevant to its interpretation:
Any thickening or thinning of the line, its colour, its contrast with
the background, its size, even the qualities of the paper-none of
these is ruled out, none can be ignored. (Goodman 1968: 229)
Thus, whereas different instances of the same written letter, word or
sentence can differ widely in appearance, pictures that differ in
appearance, in any one of many different ways, and however small the
difference is, will also differ in what they represent.
Thus, Goodman’s principal claims are these:
All three claims have been contested.
The first difficulty with (1) is that a set is dense only relative to
an ordering. For example, the set of natural numbers can be given a
dense ordering, but it is not dense in the familiar 1, 2, 3, …
ordering. In the first edition of Languages of Art, Goodman
does not explain what ordering of pictures he has in mind, but in the
revised edition he states that
the ordering in question is understood to be such that any element
lying between two others is less discriminable from each of them than
they are from each other. (1976: 136)
This raises two questions. First, is an ordering of pictures of this
kind possible? Second, Goodman’s ordering appears to depend on
degrees of resemblance, albeit between signs as opposed to between
signs and denotata. But is this reintroduction of the concept of
resemblance compatible with his nominalist theory of properties and
his attack on the doctrine of the “innocent eye”?
The second difficulty with (1) is that digital photographs would
normally be classified as pictures along with analog ones (Bach 1970;
Kulvicki 2006); and some diagrams, which would not normally
be classified as pictures, are analog and relatively replete (Peacocke
1987). Furthermore, outline drawings are less replete than diagrams in
which not only shape but also colour affects what they represent, but
the former would normally be classified as pictures, whereas the
latter would not (Schier 1986; Kulvicki 2006). Goodman acknowledges
that “some old and vague boundaries are transgressed, some
significant new alliances and alienations effected” by the
classification of symbol systems he defends (1968: 232), but it is
debatable how revisionist his theory can be, without ceasing to be a
theory of depiction. For we want to know how pictures,
including digital photographs, represent. It is possible to
claim, in reply, that depiction is not the unitary phenomenon we
naïvely imagine it to be. But this cannot be established merely
by showing that Goodman’s theory of symbols precludes a unitary
explanation of depiction.
The principal ground on which philosophers have contested (2) is that
it is inconsistent with the so-called natural generativity of
pictures. The argument is originally due to Flint Schier (1986:
43–55), but it is also advanced by Richard Wollheim:
if I can recognize a picture of a cat, and I know what a dog looks
like, then I can be expected to recognize a picture of a dog. But on
[Goodman’s] view this ought to be baffling. It should be as
baffling as if, knowing that the French word “chat” means
a cat, and knowing what dogs look like, I should, on hearing it, be
able to understand what the word “chien” means. (1987:
77)
However, there appear to be conventional symbol systems, such as
guitar tablature, in which natural generativity occurs. Hence, it is
arguable that Schier and Wollheim mistook a disanalogy between
pictures and words for a disanalogy between pictures and conventional
signs in general.
(3) invites two questions. First, what explains the fact that a
picture has a particular denotation, e.g., that Goya’s portrait
denotes the Duke of Wellington? Second, denotation is a
relation—the relation between a name and its bearer, or between
a predicate and the members of its extension. So Goodman’s
theory also faces the question raised earlier about resemblance
theories of depiction, regarding pictures of fictional individuals
(Zeus, Pegasus), and genre pictures. If the relata of a relation must
be existing particulars, then it appears that pictures of these kinds
cannot denote what they depict. So how do they depict them?
Regarding the first question, Wittgenstein claims that “An
obvious, and correct, answer to the question ‘What makes a
portrait the portrait of so-and-so?’ is that it is the
intention” (1958: 32). But Goodman disagrees. He acknowledges
that intentions are “usually involved” in setting up
symbol systems, as they are in building bridges, “but in both
cases, we can study the results independently of the thoughts of the
makers” (1972: 125). He claims that what a painting or drawing
denotes pictorially depends solely on the arrangement of colours on
its surface, and the semantic and syntactic conventions that define
the symbol system to which it belongs (1968: 42). But it seems to
follow that few portraits, if any, portray a single individual, as
opposed to every member of a class of similar individuals. For if
pictures are effectively predicate-like symbols in a pictorial system,
then unless X is the sole individual satisfying a portrait,
i.e., unless the portrait is a uniquely identifying pictorial
“description” of X, X is not the only
subject of the portrait, the sole individual it portrays. Furthermore,
it is hard to see how one can paint an inaccurate portrait of someone,
just as it is hard to see how one can use an inaccurate description to
refer to someone (e.g., “The man drinking a martini is
my brother”, when he is actually drinking a daiquiri), if whom
one refers to depends purely on the syntax and semantics of the phrase
(Kripke 1977).
Regarding the second question, concerning pictures of fictional
individuals and genre pictures, Goodman argues that the verbs
“depict” and “represent” are “highly
ambiguous” (1968: 22). In the sentence “Goya’s
portrait represents the Duke of Wellington”,
“represents” is a two-place predicate, expressing a
relation, and the sentence as a whole identifies the denotation of
Goya’s portrait; whereas in the sentence “Rubens’
painting represents Pegasus”, “represents” is part
of a one-place predicate, and the sentence as a whole classifies or
characterizes Rubens’ painting without implying that it denotes
anything at all. Thus, pictures with null denotation are comparable to
predicates or descriptions with null denotation, such as “flying
horse” or “largest prime number”. We can distinguish
between a picture of a centaur and a picture of a unicorn, even though
they denote exactly the same objects (i.e., none), because they are
instances of different characters in a symbol system that we
understand. The symbol system consists of rules “correlating
symbols with denotata” (1968: 228), but it provides for pictures
with null denotation.
Finally, according to Goodman, a pictorial symbol system consists of
rules correlating symbols with denotata, but he does not propose a
single example of such a rule. He refers to “the traditional
Western system of representation” (1968: 226), but he does not
begin to formulate its rules. It is uncontroversial that various kinds
of customs, rules and conventions are involved in making pictures,
including technical procedures, iconographic conventions, rules of
composition, and so on. But none of these have the function of
correlating symbols with denotata, and it is doubtful whether
pictorial rules of this specific kind exist (Hyman 2006:
174–175).
Despite these objections to Goodman’s theory of depiction, it
continues to exert an influence on philosophers of art. For example,
John Kulvicki has recently defended a theory that is designed to
address some of the arguments above, and to incorporate some of the
ideas advanced by Goodman’s opponents, while retaining
Goodman’s principal ideas. In particular, Kulvicki agrees with
Goodman that a picture is a symbol in a denotative system, and that a
denotative system is pictorial in virtue of its structure, rather than
any resemblance between its symbols and the objects they denote
(Kulvicki 2006: 13). But it is difficult to be certain how far he
shares Goodman’s approach to the semantics of pictures, and of
symbols generally. In particular, Kulvicki relies on the idea that
pictures have different kinds of content (see below), but it
is unclear whether he agrees with Goodman’s reduction of content
to denotation (1968: 27–29), and whether he shares
Goodman’s general commitment to extensionalism (see 
§3.1 of the entry on
 Nelson Goodman),
 or whether he agrees with Frege that as well as having a reference or
denotation, names and descriptions also express a sense.
According to Kulvicki, the semantic features of a picture are the
“features the picture depicts its scene as having”, while
its syntactic features are the colour and shape properties that are
“relevant to the semantics of the picture” (2014:
92–93). Not all of a picture’s colour and shape properties
qualify as syntactic features. For example, the brownish colour of a
sepia photograph is merely an “incidental” feature.
Kulvicki argues that a pictorial symbol system has four
characteristics: (a) repleteness, i.e., a relatively wide
range of properties of a picture qualify as syntactic features, e.g.,
colour, thickness of lines, etc.; (b) sensitivity, i.e.,
small changes to a picture in respect of any of these properties are
syntactically significant (cf. Bach 1970: 128–132); (c)
richness, i.e., “there are at least as many possible
denotations in the system as there are syntactic types”
(Kulvicki 2006: 38); (d) transparency, i.e., if part of a
picture X depicts a picture Y, then that part of
X has the syntactic features that Y is depicted as
having.
Repleteness, sensitivity and richness are
explained, and compared with Goodman’s relative repleteness,
syntactic density and semantic density, in Kulvicki 2006
(29–46). But Kulvicki explores transparency in most detail,
deducing in particular the following consequence: that a picture
resembles the scene it represents in respect of a limited
range of colour and shape properties, such as “the abstract
pattern of light and dark” recorded by a black-and-white
photograph (2014: 101). Kulvicki calls this range of properties the
picture’s “bare bones content”, following Haugeland
1991. He does not attempt to define the colour- and shape-properties
it consists in, but like Hyman, he suggests that the resemblance he
postulates between a picture and the scene it represents partially
explains how the normal experience of perceiving what a picture
represents occurs. A picture’s “fleshed out content”
(i.e., the content identified in a normal description of a picture: a
horse, a man, etc.) depends on its propensity to trigger a
spectator’s ability to recognize kinds of objects by the shape-
and colour-properties included in its bare bones content:
Seeing a fleshed out content results from deploying concepts as a
result of seeing the picture surface—and thus registering its
bare bones content—that do not apply to the picture surface.
Which concepts we deploy depends on what recognitionally keyed
concepts we have, which determines the perceptual salience of a given
fleshed out content. (2006: 173–174)
The main questions critics have raised about Kulvicki’s theory
are as follows. First, it is designed to avoid some of the objections
to Goodman’s theory, notably the fact that there are digital
pictures as well as analog ones, but other objections remain,
especially those concerning Goodman’s doctrine that denotation
is “the core of representation”. Second, it is unclear
what role Kulvicki accords to the artist’s intention in the
theory of depiction. The question is ignored in Kulvicki 2006, as it
is in Goodman 1968. In Kulvicki 2014, by contrast, he suggests that
pictures “represent in virtue of the intentions of their
makers” (2014: 156), but he does not discuss the scope of this
principle (e.g., whether it applies to the sense or reference of a
picture, or to both) or how precisely the role of intention should be
defined. Finally, Kulvicki’s explicit disagreement with Goodman
focuses on how the relationships between the symbols in a pictorial
system should be defined. But it is debatable whether the four
conditions he stipulates are in fact necessary and sufficient for
depiction. Some alleged counter-examples are discussed in Blumson
2011, Newall 2011, and Kulvicki 2012.
Experiential theories seek to explain depiction in terms of the kind
of experience a picture causes in a spectator, rather than the kind of
representational system to which a picture allegedly belongs, or the
spectator-independent resemblance or isomorphism between a picture and
the objects it depicts, or the subpersonal cognitive mechanisms a
picture may be thought to engage. It remains an open question whether
theories of this kind can avoid the charge of circularity, in other
words, whether it is possible to define the experience of seeing what
a picture represents without employing the concept of depiction. But
even among philosophers who believe that this is possible,
the exact nature of the experience has been a matter of debate.
The simplest experiential theory is that a picture depicts an object
of a certain kind by causing a spectator to have the visual experience
she would normally have if she saw the kind of object it depicts.
Descartes’ remarks about depiction in his Optics
suggest a theory of this kind:
The problem is to know simply how [pictures] can enable the soul to
have sensory perceptions of all the various qualities of the objects
to which they correspond—not to know how they can resemble these
objects. ([1637] 1985: I, 166)
Michael Newall has recently defended the theory that “pictures
occasion non-veridical seeing of their subject-matter” (Newall
2011: 42), which can be interpreted as an endorsement of
Descartes’s position. But it is generally thought that Descartes
assimilates pictures in general to trompes l’oeil,
whose purpose is (or is commonly thought to be) to cause spectators to
experience a kind of illusion. The experiential theories philosophers
advocate today tend to define the experience caused by pictures
differently, for this reason. (Newall distinguishes between his own
theory and the theory that pictorial experience is a kind of illusion
in Newall 2011: 23–30.)
The most important twentieth-century source of experiential theories
is Ernst Gombrich’s book Art and Illusion (1960), based
on the Mellon Lectures he delivered in 1956. In this pathbreaking
book, Gombrich argues that realistic or naturalistic pictures
do approximate to trompes l’oeil. Indeed, as
Wollheim points out,
the two sets of terms, “naturalism”,
“naturalistic” on the one hand, “illusion”,
“illusionistic” on the other, are used interchangeably
in Art and Illusion (Wollheim 1963: 25). However, no general
theory of depiction is presented in Art and Illusion,
although Gombrich compares the perception of pictorial content with
the phenomenon of aspect-switching or “seeing as”. He
introduces “seeing as” with the ambiguous drawing of a
duck or a rabbit that Wittgenstein’s Philosophical
Investigations had made famous (Wittgenstein 1953: 194):
We can see the picture as either a rabbit or a duck. It is easy to
discover both readings. It is less easy to describe what happens when
we switch from one interpretation to the other. Clearly we do not have
the illusion that we are confronted with a “real” duck or
rabbit. The shape on the paper resembles neither animal very closely.
And yet there is no doubt that the shape transforms itself in some
subtle way. (Gombrich 1960: 5)
The significance of the ambiguous image is meant to be that it makes
us aware of a process that the perception of pictorial content
always involves: the process of making a “tentative
projection, a trial shot which transforms the image if it turns out to
be a hit.” “Ambiguity—rabbit or duck?—is
clearly the key to the whole problem of image reading” (1960:
198). Gombrich is commonly described as proposing an “illusion
theory” of depiction (e.g., Lopes 1996: 37; Newall 2011: 2), but
he emphatically disavowed any such intention, pointing out that the
title of the lectures on which Art and Illusion was based was
The Visible World and the Language of Art:
[I] never dreamed that this title [Art and Illusion] would
convey to some that I considered illusion, or even deception, the main
aim of art. (Gombrich 1973: 195)
Gombrich explores a variety of fertile ideas in Art and
Illusion, about the history of style, about realism in the visual
arts, and about the relationship between the content of a
representation and its use in imaginative play, some of which we shall
return to below. But the comparison between seeing pictures and seeing
aspects provides the focus of Richard Wollheim’s criticism of
Gombrich’s ideas, out of which he develops his own theory of
depiction.
Wollheim interprets Gombrich as claiming that a spectator cannot be
simultaneously conscious of the marks on a picture’s surface and
the scene it represents, and that these can only be objects of
alternating perceptions, although Gombrich does not say this
explicitly (Wollheim 1963; cf. Bantinaki 2007). But according to
Wollheim himself, simultaneous awareness of surface and content is
precisely what is distinctive about the experience of seeing a
picture. Furthermore, these are two distinguishable but
“inseparable” aspects of a single visual experience, and
not two experiences somehow combined (Wollheim 1987, 1998, 2003a,b;
Wollheim does not attempt to define a criterion of identity for
experiences, so this claim is difficult to assess). Thus, the
experience of seeing a picture has a sui generis
phenomenology, which Wollheim calls “twofoldness”. The two
aspects of this experience—its configurational aspect
and its recognitional aspect—are held to be
psychologically real and to be integrated in a way that also affects
the phenomenal character of the experience as a whole.
Wollheim names this twofold visual experience “seeing-in”,
but he explains that it is not confined to pictures. For example, it
can also occur if we follow Leonardo’s famous advice to discover
landscapes, battles and grotesque faces in the stains on an old
wall.
Seeing-in is a distinct kind of perception, and it is triggered by the
presence within the field of vision of a differentiated surface.
[…] When the surface is right, then an experience with a
certain phenomenology will occur, and it is this phenomenology that is
distinctive about seeing-in. […] The distinctive
phenomenological feature I call ‘twofoldness’, because,
when seeing-in occurs, two things happen: I am visually aware of the
surface I look at, and I discern something standing out in front of,
or (in certain cases) receding behind, something else. (Wollheim 1987:
46)
According to Wollheim, a genealogical parable reveals how
“representation can be explained in terms of
seeing-in”:
In a community where seeing-in is firmly established, some member of
the community—let us call him (prematurely) an artist—sets
about marking a surface with the intention of getting others around
him to see some definite thing in it: say, a bison. If the
artist’s intention is successful to the extent that a bison can
be seen in the surface as he has marked it, then the community closes
ranks in that someone who does indeed see a bison in it is now held to
see the surface correctly, and anyone is held to see it incorrectly if
he sees, as he might, something else in it, or nothing at all. Now the
marked surface represents a bison. (Wollheim 1987: 46)
This is not meant to be piece of speculative history. The purpose of
the story is to show that depiction occurs when the marks on a surface
are successfully designed to make the seeing-in experience occur. It
is not enough that this experience should occur. It must, when it
occurs, fulfil the intention of the “artist”. Notice that
for Wollheim, neither trompe l’oeils nor purely
abstract paintings (i.e., abstract paintings that do not solicit the
perception of figure-ground relations), are depictions, although they
may resemble depictions in certain ways and embody some of the same
aesthetic values. Purely abstract paintings do not produce an
experience with the “recognitional” aspect of seeing in,
whereas trompes l’oeil do not produce an experience
with its “configurational” aspect.
Wollheim’s theory has been widely discussed and criticised (see
especially van Gerwen 2001; Kemp & Mras 2016; Jagnow 2019).
The principal objections to it are the following. First, the
implication that trompe l’oeils are not
representational has been contested (Lopes 1996: 49–50; Levinson
[1998] 2001; Newall 2009: 25–26; for a critical assessment of
Wollheim’s conception of abstract painting see Caldarola 2012).
Second, the suggestion that the figure-ground relationship is a
universal feature of depiction has been challenged (Hyman 2006).
Third, Wollheim proposes that the standard of correctness, which
determines whether the spectator has correctly perceived the content
of a picture, “is set … for each painting by the
intentions of the artist in so far as they are fulfilled”
(Wollheim 1987: 46). But this appears to oversimplify the relationship
between the representational content of a picture and the content
intended by the artist. It is well known that the meaning of an
uttered sentence can diverge from the intended meaning of the speaker,
and hard to see why the same should not apply to a picture (see 
§4 of the entry on
 Paul Grice;
 cf. Terrone forthcoming). Fourth, Wollheim declines to offer a detailed
characterisation of seeing in, which explains (a) how the experience
of seeing a certain kind of object in a surface is related to the
experience of seeing the same kind of object face to face (he
describes these experiences as “incommensurable” (1987:
47)); or (b) how the experience of seeing one certain kind of
object in a surface differs from the experience of seeing
another kind of object in a surface (Budd 2008a; Hopkins
1998a). Fifth, Wollheim’s theory is unable to explain the fact
that objects are necessarily depicted from an implicit point of view
(Hopkins 1998a). Finally—a development rather than an
objection—it has been argued that, at least in the case of
pictures that have a reference as well as a sense, the experience of
seeing a picture has a third aspect, i.e. it is
“threefold” rather than merely “twofold”, as
Wollheim suggests (see Brough 2012; Nanay 2018; Mion 2019; cf.
Voltolini 2018).
Despite these objections, and the elusive character of his writing,
Wollheim’s theory became the key point of reference for
subsequent experiential theories of depiction.
Experienced resemblance: As noted above, experiential
theories explain depiction in terms of the kind of experience a
picture causes in a spectator. The two most influential theories that
have sought to define this experience more precisely than Wollheim
does are due to Christopher Peacocke and Robert Hopkins, and the
principal concept both employ is that of experienced
resemblance.
Consider the experience of being struck by someone’s resemblance
to another person one already knows well, e.g., when one sees the
grown-up child of an old friend for the first time in several years.
(We might speak here of seeing the parent ‘in’ the child.)
No doubt there is a resemblance—in bone-structure,
pigmentation, etc.—with a genetic explanation. But we can
describe the experience as an experience of a resemblance,
independently of whether the resemblance actually exists, in what
respects, or why. According to theories that employ the concept of
experienced resemblance, this is comparable to (though not exactly
like) the experience a spectator has when she sees what a picture
represents. Hence, the assumption (made by or attributed to Wollheim
inter alia) that the object or scene represented by a picture
is itself somehow perceived by the spectator, or present in
her experience, is rejected by those who explain depiction in terms of
experienced resemblance.
According to Peacocke (1987: 386–388), a design or configuration
of marks on a surface depicts a certain kind of object φ if, and
only if, it is successfully designed to occupy a region of the
spectator’s two-dimensional visual field that she experiences as
similar in shape to a region in which a φ could be presented, but
without being experienced (as a sculpture representing a φ might
be) as occupying a three-dimensional region of physical space similar
to one which could be occupied by a φ. The details of
Peacocke’s account have been criticized (see Hopkins 1998a; Budd
2008b; Voltolini 2015), but his appeal to experienced resemblance in
the explanation of depiction proved influential.
The most widely discussed development of Wollheim’s approach is
by Robert Hopkins. Hopkins adopts Wollheim’s term “seeing-in” to
refer to the kind of visual experience a picture is allegedly designed
to produce. He agrees with Peacocke that seeing-in can be defined in
terms of experienced resemblance, but he argues that seeing-in is an
experience of resemblance in outline shape between the marks
on the surface of a picture and the object or arrangement of objects
they represent, rather than shape in the two-dimensional visual field
(Hopkins 1998a). Outline shape, Hopkins explains, is “a property of
things that we regularly perceive, but rarely articulate” (1998b:
§6), a visible property, but one which is relative to a point of
view (unlike colour, for example). In fact it appears to be the same
property as Hyman’s occlusion shape, i.e., the 2-D
cross-section of the cone of light an object subtends to a point of
view (see above
 §1).
 Unlike Peacocke’s concept of the shape of a region in a
spectator’s visual field, it is not defined subjectively, in
terms of the experience of a spectator, but objectively, purely in
terms of projective geometry. And since seeing-in can be defined in
terms of outline shape, so can depiction:
Seeing-in […] is essentially the experience of likeness in
respect of outline shape. Depiction may then be understood as that
representation which works through the deliberate generation of this
experience. (Hopkins 1998b: §6)
Hopkins’ definition of seeing-in addresses several influential
objections to Wollheim’s own approach. In particular, it avoids
the implication that the figure-ground relationship is a universal
feature of depiction; it explains precisely how the experience of
seeing a certain kind of object in a surface is related to the
experience of seeing the same kind of object face to face, and how the
experience of seeing one kind of object in a surface differs from the
experience of seeing another kind of object in a surface; and it
explains the fact that objects are necessarily depicted from an
implicit point of view. But Hopkins does not claim that there is
invariably an exact match between the content of a picture and what
can be seen in it (Hopkins 1998a: 128; see also Brown 2010; Dilworth
2005, 2010). Drawing on his or her knowledge of pictorial culture and
convention, an educated spectator will discount some features of the
object seen in a picture—such as deviations from normal human
anatomy—attributing them to the prevalent pictorial style,
rather than including them in the picture’s intended content. In
this way, Hopkins draws a distinction between the content of
seeing-in, which is determined by experienced resemblance in
outline shape alone, and pictorial content, which also
depends on the artist’s intentions (Hopkins 1998a).
However, several difficulties remain. First, it is unclear how
Hopkins’s theory can accommodate Lopes’s independence
constraint. As we have seen (see above,
 §1.2),
 according to Lopes, if a theory implies that a spectator perceives a
picture’s content by perceiving a resemblance between the marks
on its surface and the kind of object which it represents, then she
must be able to perceive this resemblance “without first
knowing” what the picture represents. But a spectator’s
“experience of likeness in respect of outline shape” may
depend on what she sees in a picture, Lopes claims, and
“experienced resemblance cannot explain depiction if it is
beholden to [i.e., explained by] depiction” (2005a:
16–17). Second, Hopkins agrees with Wollheim that the standard
of correctness for a spectator’s perception of the content of a
picture, “is set … for each painting by the intentions of
the artist in so far as they are fulfilled”, and therefore faces
the same Gricean objection (see above,
 §3.1).
 Finally, every experiential theory of depiction faces a difficulty in
explaining how the shapes (or outline shapes) of the marks on the
surface of a picture constrain the shapes (or outline shapes) of the
objects they represent. On the one hand, if the only constraint is
that they must be such as to generate an experience of the kind the
theory postulates, then it is difficult to explain how this experience
differs from a hallucination caused by an optical stimulus, such as
the mysterious blank canvas described by Flint Schier, which causes
the illusory experience of seeing a portrait of Marilyn Monroe, but
presumably does not depict anything at all (Schier 1986:
197). On the other hand, if there must be a direct optical or
geometrical correspondence between the shapes (or outline shapes) of
the marks and the shapes (or outline shapes) of the objects they
represent, so that we can perceive the latter by perceiving
the former, then the theory is no longer purely experiential, and
depends ultimately on the kind of relationship between surface and
content postulated (for different reasons) by Hyman, Kulvicki, and
Voltolini. (See Hyman 2006, Kulvicki 2014, Voltolini 2015. For
Hopkins’ replies to these objections, see Hopkins 2003 and
2005.)
Make-believe: An alternative characterisation of the
experience generated by pictures, which refers to the imagination, is
proposed by Kendall Walton (1990, 2008a,b, 2011) in the context of a
wider theory of artistic representation. Following Gombrich (1963),
and drawing on Ryle’s seminal writings on imagination and
pretence (Ryle 1949: ch. 8; cf. White 1990), Walton claims that
pictures are props in visual games of make-believe, which prescribe
visual imaginings with a particular content. When one engages in the
right way with a picture of a certain kind of object or scene, one
imagines that one is seeing an object or scene of that kind:
Participation in visual games of make-believe using pictures as props
is a complex perceptual and imaginative activity. […] At a
minimum, one imagines seeing the depicted objects or objects of the
kinds that are depicted, as one scans the picture surface. One also
imagines one’s actual visual experience of the picture to be a
visual experience of these objects or objects of these kinds.
[…] I claim that this complex experience constitutes,
approximately, what Wollheim and others call seeing trees, fields,
etc. in the picture. (Walton 2011: 396–397)
Walton’s general theory of make-believe is widely regarded as an
important contribution to the philosophy of art. But his theory of
depiction faces the same difficulty as other experiential theories in
explaining how the shapes (or outline shapes) of the marks on the
surface of a picture constrain the shapes (or outline shapes) of the
objects they represent, or the imaginative games they invite
spectators to engage in. Furthermore, some of Walton’s critics
have denied that visual imagination is an essential feature of picture
perception (Savile 1986); and others have denied that the concept of a
visual game of make-believe can capture the experience of seeing in,
on the grounds that Walton fails to integrate the
“recognitional” and “configurational” aspects
of the experience, or at least fails to integrate them in the right
way. However, the force of this objection is blunted to some degree by
the disagreement among Wollheim’s followers about the right way
of explaining how the experience of seeing in is integrated. (For
objections to Walton, see Wollheim 1998, 2003b; Budd 2008a; Nanay
2004. For Walton’s replies to objections, see Walton 2008b,c.
For an alternative analysis of seeing in in terms of imagining, see
Stock 2008. For different views about the “integration” of
seeing in, see Abell & Bantinaki 2010; Newall 2015; Voltolini
2015.)
Inflection: As noted above, the alleged
“integration” of seeing in has been a matter of debate.
This is especially true with respect to cases where the marks on the
surface of a picture are not merely a means by which the spectator
perceives its content, but are designed by the artist to contribute to
the content of the picture in virtue of their character as marks. For
example, in several pastel drawings made in the 1880s, in which
 Degas depicts a woman drying herself,
 he trace of the pastel rubbing against the paper’s surface
subliminally registers the motion of the towel against the
woman’s skin. In this kind of case, as Michael Podro
explains,
the recognition of the subject is extended and elaborated by the way
its conditions of representation, the medium and the psychological
adjustments the painting invites become absorbed into its content.
(Podro 1998: 2)
The spectator’s experience of this phenomenon has been called
“inflected seeing in”, and both the phenomenon and the experience have
received considerable attention, both from philosophers who maintain
that depiction can be defined in experiential terms, and from those
who doubt or deny this. Lopes (2005a) makes the interesting claim that
inflection solves the puzzle of mimesis: in other words, it
explains why we value or enjoy seeing pictures of kinds of objects
that we do not value or enjoy seeing face-to-face (The seminal
treatment of this problem is in Aristotle’s Poetics (Book
IV). Noteworthy discussions of inflection include Hopkins 2010, Nanay
2010, and Voltolini 2013. Broader discussions of the kinds of
pictorial experience that pictures in different styles can elicit
include Lopes 2005a, Cavedon-Taylor 2011, Newall 2011, and Bradley
2014.)
We noted in
 §3.1
 that experiential theories seek to explain depiction in terms of the
kind of experience a picture causes in a spectator, rather than the
subpersonal cognitive mechanisms a picture is thought to engage. Some
philosophers therefore maintain that theories which explain depiction
in terms of the propensity of a picture to activate a
spectator’s recognitional skills are not experiential theories,
on the grounds that recognition can occur without experience (Matthen
2005: 25–26; Newall 2011: 21–23). Others either claim or
assume, on the contrary, that recognition is a kind of
experience, at least the kind of recognition that is stimulated by a
picture (Squires 1969; Schier 1986).
The basic thought that underlies recognition-based theories of
depiction is that a picture must be recognisable:
It must be the kind of thing that can be connected up with what the
artist had in mind, if looked at in the right way by people with
aptitude and experience. […] Ultimately, we establish what is
recognisable by reference to what is recognised. (Squires 1969:
203)
The same thought is developed by Schier. As noted above (see
 §2),
 Schier claims that our interpretation of pictures, unlike our
interpretation of words, is generated naturally:
Once you have succeeded in an initial pictorial interpretation
[…] you should then be able to interpret novel icons without
being privy to additional stipulations given only that you can
recognise the object or state of affairs depicted. (Schier 1986:
43)
Accordingly, Schier argues that depiction can be defined in terms of
natural generativity and recognition: a picture is the kind of
representation that causes naturally generated interpretations in
competent spectators by activating their recognitional skills. Thus,
“pictures are symbols whose interpretation can be causally
explained by relevant recognitional abilities” (Schier 1986:
49). Specifically, “a picture of O is precisely something
which can trigger the interpreter’s O-recognising
abilities” (Schier 1986: 195).
Schier’s basic thought was subsequently incorporated into an
eclectic theory of depiction by Dominic Lopes (1996). Drawing on
Gareth Evans’s information-theoretic account of reference (Evans
1982; see §2.3 of the entry on
 reference)
 and Kendall Walton’s controversial claim that photographs are
“transparent” (Walton 1984), as well as Schier’s
recognition-based theory of depiction, Lopes defends the following
ideas.
First, pictures belong to “information systems”, and
transmit perceptual information from their subjects (Lopes 1996: 107),
thereby engaging (and also extending) the recognitional skills
spectators exercise in ordinary visual perception. “The ability
to work out what pictures depict covaries with the ability to
recognize their depicta in the flesh” (2005a: 170). Second,
Lopes adopts Walton’s claim that photographs are
“transparent”, i.e., spectators literally see the
objects that appear in photographs, as if through a pane of glass, and
not merely visual records or sources of information about them.
However, Lopes extends this claim to encompass every kind of picture:
“there is as much reason to believe that we see through
paintings and drawings as through photographs” (1996: 181).
Third, pictures present aspects of their subjects, by making both
“commitments” and “non-commitments” regarding
their properties: “Every picture represents its subject as
having some property that precludes it from making commitments about
some other property” (Lopes 1996: 125). For example, a picture
that depicts a man sporting a beard makes a commitment regarding the
property of being hirsute, but by the same token is non-commital
regarding the property of having a dimpled chin. Explicit
“non-commitment” distinguishes depiction from other kinds
of representation. (For criticism see Herwitz 2000, Savile 2000,
Kulvicki 2006.) Fourth, pictorial styles, or systems of pictorial
representation, differ from each other in the kinds of aspects they
typically present. Pictorial competence is relative to specific styles
or systems: to be able to interpret a picture, one needs to have the
recognitional skills corresponding to the system to which it belongs
(Lopes 1996: 152–3).
These ideas face various difficulties, some of which we have already
considered in connection with other experiential theories. First,
Lopes’s ideas about the transmission of perceptual information
and the transparency of pictures are difficult to apply to pictures of
fictional individuals and genre pictures (Hopkins 1997). Second, the
transparency claim has been criticised even in the case of
photographs, where the problem of fictional subjects and genre
pictures does not normally arise (Currie 1995). Third, the claim that
pictures differ from other kinds of representations in that only
pictures explicitly “non-commit” to properties has been
challenged (Kulvicki 2006). Finally, as we have seen, Walton’s
theory that picture are props in games of visual make-believe does not
seem capable of explaining how the shapes of the marks on the surface
of a picture constrain the shapes of the objects they represent, or
the imaginative games they invite spectators to engage in.
Recognition-based theories are open to a similar objection. Various
theories of depiction are compatible with the claim that pictures
activate the same recognitional skills as the kinds of objects they
depict. The question on which they differ is why they do so. For
example, is it because the shape of a region on a picture’s
surface is identical to the occlusion shape of the object it depicts?
Or is it because part of a picture’s surface occupies a region
of the spectator’s two-dimensional visual field that she
experiences as similar in shape to a region in which the kind of
object that it depicts could be presented? Or is it for some other
reason? Without an answer to this question, the problem of explaining
how pictures represent is elaborated by introducing ideas about
recognition, natural generativity and transparency, but it is not
solved (Newman 1998; cf. Neander 1987, Sartwell 1991).
As we have seen, any plausible theory of depiction will need to
accommodate the wide variety of styles of picture-making. Art history
contains more sophisticated and fertile treatments of the concept of
style than philosophy does, notably by Heinrich Wolfflin (1950), Alois
Riegl ([1893] 1992), Erwin Panofsky (1997), Ernst Gombrich (1968), and
Meyer Schapiro (1994). However, one topic in the theory of style on
which there is a substantial philosophical literature is
realism.
The term “realism” and equivalent terms in other European
languages were introduced into literary and art criticism during the
nineteenth century, and paintings and sculptures are still commonly
described as realistic (faithful, true to nature, etc.) by critics and
historians of art. However, many philosophers and historians of art
since the 1920s have expressed scepticism about the idea that some
styles of art represent reality more truthfully or faithfully than
others (Jakobson [1921/1971] 1987; Steinberg [1953] 1972; Nochlin
1971; Stewart 1997). The most influential exponent of this view is
Goodman, who argues that realism cannot be a matter of fidelity to
nature, and cannot be measured by resemblance to reality, because our
judgements about fidelity to nature depend on our visual habits, which
are shaped in turn by the visual culture we inhabit, and the images we
are used to seeing and interpreting. Resemblance cannot be a
“constant and independent” standard against which works of
art can be measured, because “the criteria of resemblance vary
with changes in representational practice” (Goodman 1968: 39).
“The literal or realistic or naturalistic system of
representation”, Goodman claims, “is simply the customary
one”.
Realism is relative, determined by the system of representation
standard for a given culture or person at a given time. Newer or older
or alien systems are accounted artificial or unskilled. (1968: 37)
Goodman’s argument has been challenged on several grounds.
First, the realistic system of representation cannot simply be the
standard or customary one, because as an artistic style evolves,
spectators are inevitably less accustomed to innovative subjects and
techniques than they are to the ones these modify or replace. So if
Goodman’s claim were true, an artistic style could never become
more realistic, in the eyes of spectators living at the time. But the
historical record proves, on the contrary, that it does (Newall 2011:
119–121). Second, Goodman exaggerates the extent to which visual
experience is modified by art. Oscar Wilde famously claimed that there
had been no fog in London before it appeared in Turner’s
paintings. But in fact, writers generally described optical effects
long before painters learned to represent them. For example, the
spinning highlights on a chariot-wheel were described by the Latin
poet Prudentius many centuries before Velazquez captured this effect
in paint. Third, even if the art we see does modify our visual habits
and influence the resemblances we perceive to some extent, it does not
follow that realism cannot consist in resemblance or fidelity to
nature. Compare the relationship between theory and observation in
science. The growth of scientific knowledge has enabled us to refine
our observations of natural phenomena, and these observations have in
turn enabled us to test scientific theories. There is nothing
suspicious about this interaction between theory and observation, and
nothing that should make us wonder whether we possess a
“constant and independent” standard, with which scientific
theories can be assessed (see §4; of the entry on
 theory and observation in science
 and  §3 of the entry on 
 Popper).
It is now generally agreed that the concepts of resemblance and
fidelity to nature are too vague and metaphorical to explain what
realism is, and that “realist” or “realistic”
art proceeds from specific values, methods and viewpoints, no less
than other kinds of art (Schapiro 1978). Furthermore, confusion about
realism is compounded by the fact that the term is used to describe a
variety of period styles, including late medieval and early
Renaissance art, Dutch painting in the seventeenth century, and French
painting in the nineteenth century. But it does not follow that
“realism” is merely an honorific term, which we apply to
art in a familiar style, or that fidelity to nature is a vacuous
idea.
The fundamental distinction we need to draw, in order to clarify the
concept of realism, is between realism in subject-matter and realism
in technique (Hyman 2005). Realism in subject-matter is about the
choice of subject-matter and the manner in which it is treated.
Realistic art, in this sense, represents the lower social classes,
comic as opposed to tragic material, daily life as opposed to myth.
For example, in the paintings of Courbet, Manet and Degas the
traditional hierarchy of genres, which promoted the representation of
history, myth or allegory, is definitively set aside, and the everyday
lives of people belonging to the lower social classes are taken
seriously, and placed in a contemporary social setting, as they are in
the novels of Balzac and Flaubert.
Realism in technique is a different phenomenon, which can be traced
back to the revolutionary developments in Greek art between the sixth
and fourth centuries BC, specifically, developments in anatomy and in
the representation of space and light. Since philosophers and art
theorists abandoned the idea that realism can be defined in terms of
fidelity to nature or resemblance, most of those who do not regard
realism as a purely ideological concept or a sham (e.g., Stewart 1997;
Neer 2002) have defined realism in technique in terms of information:
either the quantity of information recorded in a picture (Gombrich
1960; Schier 1986), or the quantity of relevant or visually salient
information (Lopes 1996; Sartwell 1994; Abell 2006, 2007; Kulvicki
2006), or the ease with which information issues (Goodman 1968), or
the range of information (Hyman 2005), is said to be the, or the
principal, measure of realistic art. (See also Walton 1990; Chasid
2007; and Newall 2011 for comparable views.)
According to Hyman, realism in technique can be defined in terms of
three characteristics: accuracy, animation, and
modality (Hyman 2005: 40–46). Accuracy means the
accurate depiction of a kind of material or object or activity, such
as water or satin, a palm tree or a dove, sleeping, galloping or
making love. Animation combines mobility with the expression of
emotion, character or thought (see also Penrose 1973: 268). The term
“modality” refers to the expressive potential available to
artists during a particular phase in the development of an artistic
tradition, in other words, the range of kinds of information that the
technical resources available to artists allow them to record:
The technical resources of pictorial art are always limited in their
expressive range, as languages are also bound to be; and these
technical resources, like languages, can expand in different
directions to express new ideas and new observations. The development
of realistic techniques is the expansion of the modality of art, in
other words, the expansion of what it is possible for art to
represent. (Hyman 2009: 497)
The commonest argument debunking the idea of a realistic artistic
style depends on the thought that artistic styles are analogous to
languages (see above,
 §2
 for references). The comparison is intended to underline the extent
to which artists rely on systems of conventions, and to discourage the
idea that some styles are more truthful, or closer to reality, than
others. For the things we say are not truer or closer to reality if we
say them in French, or English, or Chinese. However, the analogy
actually supports the claim that expressive potential is the measure
of realistic art. For languages are not like codes or scripts. For
example, the Hieratic and Hieroglyphic Egyptian scripts do not differ
in the range of information they can be used to record, and neither do
Semaphore and Morse code. But languages obviously differ widely in
their expressive powers, and have expanded rapidly in some periods of
history. Thus, the difference between trecento and seicento Italian
art is comparable to the difference between the English of
Chaucer’s Canterbury Tales and the English of
Milton’s Paradise Lost, not to that between Morse Code
and Semaphore or between English and French (see Ackerman 1978:
157–160; Hyman 2005: 47).