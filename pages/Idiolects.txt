Key to the distinction between an idiolect and a social language is
the fact that the same natural language, L, can be picked out
in either of two ways: L as the language with specified
linguistic (semantic, syntactic, phonological, etc.)
properties, or L as the language possessed (spoken,
etc.) by a specific individual or population. French, for
example, is the language containing an adjective, rouge, that
refers to the color red and in its spoken form begins with a voiced
uvular fricative, etc. But French is also the first language of most
residents of France, the lingua franca of Côte
d’Ivoire, the medium in which Simone de Beauvoir wrote, spoke,
and thought, etc.
There is no limit to the number of languages we could conjure up in
the abstract using the first mode of individuation. But only a small
number of these abstract objects will be realized in the
sense of being describable in the second mode—as possessed,
known, spoken, understood, or in some other respect used by some
individual or population. If we pick out a language as the language of
some individual, and believe we can specify its properties by
reference to the intrinsic properties of that individual, then we are
picking out an idiolect. If on the contrary we either specify it by
reference to a community, or specify it by reference to an individual
but can only determine its properties by looking to their wider social
environment (identifying salient linguistic authorities, for example),
then we are picking out a social language.
Language theorists have varying conceptions of what it is for a
language to be realized. For David Lewis, a language in the abstract
(which for him amounts to a pairing of sentences and meanings) is
realized in a population when it describes a convention governing
their behaviour, in the specific sense summarized in
 Section 2.
 Lewis, then, takes a non-idiolectal perspective. For Noam Chomsky, in
contrast, a language is realized in an individual if it is
“represented” in that individual’s “language
faculty”, a component of their brain. The goal of linguists
working in the Chomskian tradition is to make what is represented
explicit in the form of a theory, a grammar, for that individual.
This, then, is an idiolectal perspective. There is a twist, however.
The brain properties that most interest Chomsky are species-wide
rather than unique to any individual, so the “individual”
is essentially the product of an idealization, useful for helping us
to understand linguistic competence, a human biological trait. Still,
we can persist in calling this an idiolectal perspective in that it
eschews any essential role for languages of discrete linguistic
communities.
The folk, and plenty of self-proclaimed experts, tend to operate with
an ontology of social languages that most linguists reject. This folk
ontology includes English, Hungarian, Tagalog, Old Norse, etc., and
commitment to this ontology has real-world effects, which politicians
are sensitive to and which sociolinguists can study. But the objects
themselves, as opposed to the folk’s beliefs in and about them,
are generally regarded, by linguists anyway, as fictional or
ideological. Although linguists will inevitably talk of
“Hungarian” and the like, they tend to take themselves as
using a convenient shorthand for “the idiolect of some typical
inhabitant of Hungary”.
Grounds for rejecting folk ontologies of language vary. Some argue
that specifying a folk language’s properties is, unavoidably, a
prescriptive (and so unscientific) exercise. An example sometimes used
to illustrate this charge is the meaning of English word
“livid”. Most dictionaries give its meanings as
“bluish” or “pale”, in deference to its
complex etymology. Most English speakers lean towards thinking it
means red, after the idiomatic expression “livid with
rage” and the belief that rage makes a person red. Similarly,
and to the consternation of many who claim to know what English really
is, English speakers regularly split infinitives, and see the use of
“hopefully” in (1) as no less acceptable than its use in
(2), despite being a “Germanism”.
The problem with these and similar judgements (Crystal 2007 recounts
their history in the case of English) is not that they are obnoxiously
conservative, a tool for social exclusion. Often they don’t play
this role. Some dictionaries now include red as a possible meaning of
“livid”, for example, but this, too, is a normative stance
and it is normativity, not conservativism in particular, that is
incompatible with a scientific stance. Even liberal views on
linguistic acceptability (e.g., that it is okay to end sentences with
a preposition) are prescriptions. In so far as such normativity is
unavoidable in the determination of the properties of English and
other languages in the folk ontology, these languages have no place in
science (save as a fictional object for sociological
investigation—because belief in the fiction has social
effects—or as a useful shorthand).
A distinct but related case against the folk ontology is that the
delineation of a population as speakers of a single language is
invariably driven by geo-political considerations. Serbo-Croatian and
the Czechoslovak languages endured only as long as nationalist
politics required them to, and ceased to be almost overnight, without
any major change in how people spoke. Some dialects of the Netherlands
are closer in their characteristics to dialects in neighboring Germany
than they are to dialects spoken on the Netherlands coast, despite
being grouped with the latter but not the former as variants of the
same language, Dutch. The concern here is not well captured in the
observation that languages in the folk sense are fuzzy. The special
sciences are replete with fuzziness. Rather, the individuation
conditions seem arbitrary from a linguistic perspective. The same
arguments against languages in the folk sense apply at the level of
dialects in the folk sense. Cockneys, and hence speakers of the
cockney dialect, are traditionally required to have been born within
earshot of the bells of Bow Church in east London, but noise pollution
and demographic change have rendered that definition absurd. No matter
how fine-grained a version of the folk ontology one seeks out, similar
problems will recur.
Ruling out folk-ontological languages does not necessarily push us
into an idiolectal direction. Nothing said so far speaks against the
possibility of technical notions of a social language that side-step
the normativity or arbitrariness built into their folksy cousins
(assuming such side-stepping is indeed needed). Lewis’s account
of language as a convention is, arguably, in this category.
Lewis’s (1975) take on human languages results from his attempt
to solve an apparent paradox. On the one hand, languages are functions
from sentences to meanings, and a theory of meaning for any language
will describe such functions. On the other hand, a natural
language is a social practice followed by a given population. It seems
that languages (simpliciter) and natural languages belong to deeply
different categories, raising the puzzle of how the two might be
related. One difference is that there are indefinitely many languages,
but the great majority are not even potentially natural languages.
They could not be learned, acquired, or deployed by humans because
they have an infinite lexicon, for example, or infinitely many rules
of composition, or allow for an unlimited embedding of subordinate
sentences. Another difference is that languages are abstract objects
while a natural language appears to be a concrete thing that, by
definition, is learned, acquired, and developed by members of a
specific human population.
Lewis claims that we can incorporate both perspectives within a single
view. Natural languages, he says, are a proper subset of the set of
languages. More specifically, a natural language is a function
L from sentences to meanings that a particular population uses,
where this use of L is governed by a convention of
“truthfulness and trust in L”. To understand this
proposal, we need to understand (a) Lewis’s conception of the
motive a population might have to use L, (b) what he means by
“convention”, and (c) how he thinks a language—a
function from sentences to meanings—could figure within a
convention thus understood.
(a) At the most general level, members of any population often want
the others to think and act in a particular way. This requires them to
recognize each other’s intentions, share thoughts, and to act
accordingly. Members of the population must therefore find a way to
display their intentions, etc., and, in equal measure, to recognize
the intentions, etc., of others. Using the same language (i.e., the
same function from sentences to meanings) to convey their mental
states offers an excellent way of meeting this need. It gives members
of the population a way to “control others’ beliefs and
actions to some extent by means of sounds and marks” (Lewis
1975: 166). Lewis explains how they do this—and in particular
how they settle on the same language—by invoking his general
notion of a convention.
(b) A convention is a practice that solves a coordination problem
within a community. The solution will bring mutual benefits but it
will also be arbitrary. For example, the practice in North America of
driving on the right is a convention in this sense: it is a mutually
beneficial practice, but at least one other solution to the problem of
avoiding head-on collisions is available: driving on the left. Natural
languages (i.e., the use of languages by populations along the lines
described in (a)) seem to be conventions in this simple sense. The
existence of shared meanings within a community is clearly of mutual
benefit, as evidenced, for example, by the use of English among
English-speaking populations. It allows members of a population to
learn one another’s thoughts about the world, for example. But
there are many other solutions to the problem of finding out one
another’s thoughts about the world, such as using Spanish or
Japanese, so the choice is arbitrary.
Moving beyond this simple account of conventionality, Lewis tells us
that a convention in his sense is a regularity R in action
(driving on the left, for example) or in belief within a population
P for which the following six conditions nearly always
hold:
(2) and (3) jointly predict that R perpetuates itself within
the community (as in (1)), despite being (according to (5))
arbitrarily chosen. A convention is stable within a community because
it is rational for each member of the community to abide by it. (The
 convention
 entry goes into more detail.)
(c) How could the use of a language in Lewis’s sense (a function
pairing sentences with meanings) be a convention in his sense, i.e., a
regularity satisfying conditions (1) to (6)? Lewis’s answer is
that the regularity, the R, is the practice of being truthful
and trusting in a language, L. When this practice is a
convention in a community, L is the community’s language.
To be truthful in L is to utter a sentence only if one believes
that what it means in L holds. To be trusting in L is to
believe whatever is meant in L by the sentences one hears
uttered. Together, these conventions give rise to a basic two-way
cooperation, with speakers being truthful and hearers being trusting.
Without this two-way coordination the coordination problem would be
difficult (if not impossible) to solve. If speakers are not truthful,
what they say is not trustworthy evidence of what they think. If
hearers are not trusting, what speakers say is not useful to get
hearers to believe and act in the intended manner.
Putting this together with the six conditions that define what it is
to be a convention, a language L is the natural language of a
given community when the following six conditions hold, at least to a
significant degree:
Section
 2.1
 gives the basic vision of natural languages as the embodiment in a
population of a convention defined in terms of a language in the
abstract sense. There are three further features of Lewis’s view
that merit emphasis: his explanation of why natural languages must be
compositional, his disclaimer that his account is but an idealization,
and the fact that his is a theory of expression meaning rather than of
speaker meaning.
For the coordination problem within P to be solved by using
L, all members of P must be in a position to determine
the meaning of all the sentences of L. In other words, it must
be that members of P have a way to identify the function that,
for any given sentence, will deliver the corresponding meaning. Given
the limitations of speakers, both physical and cognitive, there must
be a finite and simple way to do this. The compositionality of
L can help explain how this is possible (see entry on
 compositionality).
Roughly put, for L to be compositional is for the meaning of
all complex expressions
e1…en of L to be
fully determined by the meaning of their parts and by the way such
parts are composed. Thus, the functions that map sentences into their
meanings will take into account the meaning of their parts and the way
they are combined.
But language use exhibits several problematic features that must be
accommodated: indexicality, context sensitivity, ambiguity, etc. To
properly account for these features, the relevant meaning functions
must take several variables as arguments. It will not be a simple
one-to-one mapping from sentence to meaning, but a more complex
mapping of a sentence together with a speaker, a time, a world, and
what have you, onto a corresponding meaning. Lewis is aware of this,
and includes it as part of what L should be like if it is to be
used by P. So long as members of P know this about
L, and use it while abiding by the conventions of truthfulness
and trust, there should be no serious trouble. (To say that speakers
know this is not to say that they can, upon request, explicitly
describe how it is that L works, but to say that they have
implicit knowledge of L, such that they can successfully use
L to communicate with and understand other members of
P.) Lewis calls the situation of a language’s being
realized in this way a “perfect case of normal language
use”. That is, it is at best an idealization in need of
refinement. Chomsky and Davidson (below) can be thought of as in
different ways suggesting that the conceptualization offered here of
language and its realization is fundamentally mistaken and not merely
a rough draft.
Lewis’s is an account of expression meaning and as such
it is sometimes seen as a useful complement to an intention-based
account of speaker’s meaning, such as Paul
Grice’s. Speaker’s meaning in the Gricean tradition is
identified with the effect that, in performing a given utterance, the
speaker intends, by means of the audience’s recognition of this
very intention, to produce in that audience. The exact form
meaning-bestowing intentions take is a matter of debate and not
especially relevant here (see entry on
 Paul Grice).
 But a theory of individual speaker’s meaning requires, in
addition to an accurate statement of the meaning-bestowing intentions,
a complementary theory of expression meaning. Only with the latter can
we account, first, for the expectation on the part of the speaker that
she or he will be interpreted as intended (and some expectation of
success is a precondition for the formation of any intention); and
second, for the rate of success in audience uptake. Grice originally
related expression meaning to speaker’s meaning by suggesting
that:
[expression] x means (timeless[ly]) that
“so-and-so” might as a first shot be equated with some
statement or disjunction of statements about what “people”
(vague) intend…to effect by x. (Grice 1957: 385).
Lewis’s convention-based account of expression meaning is
generally thought to be a vast improvement on this crude early effort.
But equally, Grice’s account of speaker’s meaning gives us
something missing from Lewis’s. For there to be a convention of
being truthful and trusting in L, there has to be something it
is to speak with a particular meaning on an occasion, and
Grice’s theory gives us this.
In “A Nice Derangement of Epitaphs”, Donald Davidson
argues that languages, if they are “anything like what many
philosophers and linguists have supposed”, do not exist (1986:
446). He does not list the philosophers and linguists he has in mind,
but somewhere near the centre of the cloud of positions he is
criticizing is Lewis’s conventionalist
 theory.[1]
 More broadly, he rejects the notion of socially established links
between expressions and meanings, shared participation in which
enables a community to communicate. Davidson’s article is
jargon-rich and so his argument is tricky to unpack. In this statement
of it, we begin by explaining his formulation of the view he rejects,
then outline his case against the view so
 formulated.[2]
The view is expressed as the claim that first meaning is shared,
systematic, and prepared. To see what he means by “first
meaning”, consider Grice’s famous example of a testimonial
for an academic job candidate:
Dear Sir, Mr X’s command of English is excellent, and his
attendance at tutorials has been regular. Yours, etc. (Grice 1975:
33)
The author’s insinuation—that Mr X is a weak
candidate—is arrived at only via a prior interpretation of the
expressions as they are used in the utterance. This prior
interpretation is the first meaning. The contrast implicit in
“first” is with the insinuations or implicatures one
subsequently goes on to read into the utterance. Davidson uses
“first” meaning in an effort to avoid the terms
“literal” or “conventional” meaning because
the thought that there is a level of meaning that is somehow
determined independently of the communicative act, by linguistic
convention, is exactly what he plans to challenge. “First
meaning” is to be understood more neutrally as the initial
meaning the utterer intends you to ascribe to the uttered expressions
in the context of a particular utterance.
On the view Davidson rejects, successful communication happens because
this first meaning is shared (i.e., utterer and audience
assign the same first meaning), prepared (i.e., it was
available to both utterer and audience prior to the utterance) and
systematic (i.e., capturable in a compositional theory). All
three properties are implicit in the conventionalist supposition that
expressions have their meaning specified within the social language
from which they are drawn. We might conceptualize this social language
as English, or instead as a convention in Lewis’s technical
sense. If the latter, the claim Davidson has in his sights is that
communication within a given linguistic community is made possible by
a (shared, prepared, systematic) convention to be truthful and
trusting in some L. Davidson denies that there is any such
L.
His argument against first meaning’s being systematic, shared,
and prepared emerges from reflection on various linguistic phenomena,
all of which have in common that “the speaker expects to be, and
is, interpreted as the speaker intended, although the interpreter did
not have a correct theory in advance” (1986: 440). Grice’s
example does not fit this description. It does not,
therefore, threaten the thought that the first meaning (about regular
attendance) is the simple product of an antecedently shared
compositional theory. Malapropisms, on the other hand do fit the
description. Here is the original Mrs Malaprop addressing Captain
Absolute in the exchange that gives Davidson’s paper its
title:
[I]f I reprehend anything in this world, it is the use of my oracular
tongue, and a nice derangement of epitaphs! (Richard Sheridan, The
Rivals, Act III, Scene 3)
Captain Absolute manages to figure out the first meaning of Mrs
Malaprop’s utterance, which is that if she understands
(comprehends) anything it is the use of her own vernacular tongue and
a nice arrangement of epithets. Davidson offers an intuitive
description of what is going on in this case, a description that
applies equally to regular communicative exchange. He then argues that
this description of communicative exchange is incompatible with the
claim that first meaning is systematic, shared, and prepared—and
so conventional.
The intuitive description is couched in terms of prior theories and
passing theories of first meaning, defined for an arbitrary utterer
S and intended audience H as follows:
H’s prior theory: How H is prepared in
advance of S’s utterance to interpret the expressions in
it
S’s prior theory: What S believes
H’s prior theory to be
S’s passing theory: The theory S intends
H to use to interpret the expressions in S’s
utterance
H’s passing theory: How H in fact
interprets the expressions in S’s utterance
Successful communication at the level of first meaning happens
whenever S’s and H’s passing theories
coincide, notwithstanding any disagreement in prior theories. Letting
S be Mrs. Malaprop and H be Captain Absolute, their
prior and passing theories assign meanings to “epitaph” as
in the table below:
Neither meaning-according-to-prior-theories nor
meaning-according-to-passing-theories have all three of the properties
required to make them conventional. Specifically:
Prior theories are systematic and prepared, but not shared.
Passing theories are systematic and shared, but not prepared
Davidson anticipates the simple response that two interlocutors
“share the same language” if their prior theories overlap
closely enough that they can exploit ad hoc strategies for
interpretation, such as that used by Captain Absolute and the theatre
audience, i.e., searching for a similar sounding word that makes sense
of the utterance in context. But these “principles of …
inventive accommodation are not themselves reducible to theory,
involving as they do nothing less than all our skills at theory
construction”. In other words:
Such a capacity, though shared and prepared, is not systematic.
To put the claim as a charge against Lewis in particular: there is no
L, no pairing of sentences and meanings, such that
communication as it actually occurs is made possible by virtue of a
(shared, prepared, systematic) convention to be truthful and trusting
in L.
Malapropisms may seem like a marginal phenomenon to be treated as a
special case. But Davidson thinks the point generalizes, and that
achieving passing-theory agreement involves far more work than
participating in a convention. For a start there are plenty of
relevantly similar phenomena (metaphor, polysemy, incomplete
sentences, unfamiliar names, and performance errors such as slips of
the tongue or temporary confusion over whether to use
“underestimated” or “overestimated” after
“cannot be”). Indeed, even where there is
prior-theory agreement, general intelligence and not simply
application of a known convention must be exercised by both speaker
and audience to appreciate this fact.
Davidson’s position, conceived as an objection to Lewis, comes
with three separate claims. First, as demonstrated in the case of
malapropisms, antecedent knowledge of L prior to a given use
may not be enough to reach successful communication, because
“prior meanings” may not coincide between speaker and
hearer and, thus, antecedent knowledge is not mutual. Second, once the
relevant use takes place, mutual knowledge of L is reached,
which is enough to achieve communication, but such knowledge is not
grasped antecedently. Third, the move from insufficient antecedent
knowledge of L to successful communication may happen in virtue
of non-linguistic knowledge (i.e., practical reasoning, explanatory
reasoning, general knowledge, etc.), but this knowledge is not
systematic.
Lewis, it seems, has a way to reply to Davidson’s objection.
We will only sketch such a reply here. Recall the central tenets of Lewis’s
account. First, languages (all of them, including natural ones) are
abstract objects, a function from sentences to meanings. These
functions may be as complex as required; they may take as arguments more
than just sentences (i.e., occasions of use, times, worlds, speakers,
etc.). As with any abstract object, these functions are what they are
independently of any convention that may hold among human populations.
Second, humans face a coordination problem. To solve it, they use some
language or other, some abstract set of functions or other. Third, for
the use of an abstract object L to successfully solve the
coordination problem among members of a population P, at least
two conventions must hold among members of P: the conventions
of truthfulness and of trust in L. Finally, it is assumed that
members of P know all relevant functions, or have a way to know
them, for any possible sentence of L. In short, members of
P antecedently know (in some sense) all the relevant
sentence-to-meaning functions of L.
Now, Davidson presents us with a case where antecedent knowledge of
L is not enough to guarantee communication and, hence, to solve
the coordination problem that Lewis has in mind. Yet, there clearly is
a way in which speakers manage to solve the coordination problem even
in cases of malapropisms. Davidson suggests that this is done in
virtue of using non-linguistic knowledge (e.g., using practical
reasoning, explanatory reasoning, etc.). To see if such uses of
L really constitute a counterexample to Lewis’s position
we must ask ourselves if, in solving this coordination problem,
speaker and hearer do observe the conventions of truthfulness and
trust in L, or if they simply reject them in order to
successfully communicate.
A quick glance at Davidson’s example suggests that, even in
cases of malapropisms, speaker and hearer do observe the said
conventions. Both speaker S and hearer H presuppose that
they are using the same language, even though they do not realize that
this is not exactly true (i.e., in virtue of having different
prior theories they do not share the same prior-L);
yet, despite her malapropism, S is still being truthful.
H assumes S to be truthful, and so finds a way to
reinterpret S by engaging in practical, explanatory, or another
form of general reasoning. Thus, we must take H as observing
the convention of trust, for otherwise H’s diagnosis of
S’s malapropism (together with H’s
reinterpretation of S’s original utterances) would be
absurd. Furthermore, it seems that something like an assumption of
compositionality is also in place, for otherwise it would be strange
for H to (so to speak) interpolate the expression “a nice
derangement of epitaphs”, which seems to compose its meaning in
just the same way as “a nice arrangement of epithets”.
From here a Lewisian reply could follow either one of two strategies.
One would be to allow that the account does not extend to malapropisms
but treat malapropisms as a special case, an example of a non-purely
linguistic phenomenon that, as such, necessarily involves general
intelligence. The success of this strategy depends on how
generalizable these cases are.
A second strategy would be to revise the theory in order to include
general intelligence as a central element. This should not have to be
problematic since Lewis’s theory is meant as an idealization. As
Lewis notes, general intelligence is already needed to deal with
vagueness, indexicality, and other phenomena. Nor would Lewis be alone
in claiming this. Some have claimed that “pragmatic determinants
of what is said” are at work in every single utterance. (For
more on this same theme, see the entries on
 pragmatics
 and
 defaults in semantics and pragmatics.)
This second strategy might itself be developed in two distinct ways,
in an effort to show its compatibility with the broad sweep of
Lewis’s theory. First, it could be admitted that there is no
prior L with respect to which the conventions of truthfulness
and trust both hold. The conventions hold, however, with respect to
their passing theories. Participants arrive at these passing
theories from their (potentially divergent) prior theories plus some
general intelligence. Compositionality, moreover, also plays an
essential role in the extraction of passing theories from prior
theories, with the conventions of truthfulness and trust being
observed in the resulting passing L. However, the principle of
compositionality would have to be weakened so as to not consider the
strictly linguistic process it describes as fully determining meaning,
thus leaving room for extra elements to take part. Alternatively,
there could be truthfulness and trust in prior L if
Lewis’s fine-grained individuation of languages is rejected. On
this second version of the theory, one and the same L may
sometimes have different sentence-to-meaning mappings; alternatively,
it could be claimed that the conventions hold with respect to
different common Ls or a set of sufficiently similar such
languages.
With appropriate extrapolation, then, Lewis’s main tenets may be
perfectly compatible with Davidson’s own description of these
supposedly troublesome cases. Even in cases of malapropism, speaker
and hearer are trying to solve a coordination problem by using a
common language L (i.e., a common passing L, a common
open or dynamic L, or a common set of sufficiently similar
Ls) in a way that observes the conventions of truthfulness and
trust. Of course, Lewis must include some form of general explanatory
reasoning, thereby contradicting his apparent assumption that
successful uses of L are fully systematic (or compositional).
Yet it is worth considering how damaging this would be for
Lewis’s account. It seems clear that something like
Lewis’s theory (including some appropriately weakened version of
his compositionality assumption, such as that developed in
García-Ramírez 2019), will be needed.
The “I-” in “I-language” is short, not for
“idiolectal”, but for a cluster words that connote an
idiolectal approach and coincidentally begin with the same letter,
especially “internal” and
 “individualistic”.[3]
 “E-language” is used critically by Chomsky to refer to
those things, whatever they are, that are the target of study for
those who take languages and their properties to be external to the
mind. This includes many philosophers of language. Chomsky’s
case for introducing and using the notion of an I-language is, in the
end, indistinguishable from his case for a cognitivist approach to the
study of language as a natural phenomenon. And his case against
E-languages is that there is no scientifically coherent project to
which they belong as posits.
Once one sees beyond the technicalities, Lewis’s notion of
natural languages approximates to the ordinary notion of languages as
things we use to communicate with others in a linguistic community.
Chomsky’s notion of a language as an object internal to the
human mind or brain can seem odd from this perspective. We can dispel
this sense of oddity by appreciating the scientific project from which
this usage of “a language” emerges. The fact that a usage
fails to mesh with ordinary thinking hardly constitutes an objection
to the usage if the project housing it is a good one. Ordinary
thinking would struggle to accept mass as one of energy’s
possible forms, but this gives physicists no cause to pause.
Chomsky’s project is to work towards a scientifically credible
understanding of a natural object, the human brain. More feasibly, his
ambition is to make progress on understanding those aspects of the
brain that are central to our nature as linguistic beings. A
reasonable starting hypothesis for such an inquiry is that a
functionally discrete part of the brain, the “language
faculty”, is responsible for core elements of our capacity to
use language. If this hypothesis is right, other parts of the brain,
and plenty that lies outside the brain in our external social and
physical environment, may well combine with this language faculty to
produce linguistic behaviour; but the inquiry itself is limited to
understanding the language faculty itself. This voluntary limitation
has a rationale. Our overt behaviour is extraordinarily complex, an
intractable interaction effect, so we need to be appropriately modest
in our explanatory ambitions. A scientific understanding of the
internal workings of the language faculty would in itself be a massive
achievement. Linguistic behaviour—the sounds language-users
produce, their description of certain constructions as ungrammatical,
etc.—can supply defeasible evidence for or against hypotheses we
make about the language faculty proper, but we should not treat the
description of overt behaviour as the goal of study. (In an earlier
incarnation of much the same point, Chomsky distinguished between core
competence and the use of that competence manifest in overt
performance, arguing that competence is far more promising an
object of linguistic inquiry than the latter. He moved away from this
terminology after it gave rise to persistent misinterpretations.
Competence, for example, has unintended normative
connotations—we speak of people as having “poor competence
in Spanish”.)
While this captures the sense in which Chomsky is taking an
internalist (and individualist) approach to the study of language, it
does not yet reveal where the notion of a language, internalized or
otherwise, sits within the approach, or why any appeal to
languages (with “language” used as a count noun
rather than a mass noun) is needed at all. Chomsky’s discussion
of language acquisition can provide us with a good illustration of
this further step. It will also bring out a revealing contrast with
Lewis’s approach (see
 2.1).[4]
Lewis, we saw, thinks a language is an arbitrary pairing of sentences
and meanings. This arbitrariness is overcome through the co-ordination
embodied in a conventional practice, an E-language in Chomsky’s
terminology. Chomsky does not deny the existence of some linguistic
arbitrariness, manifest in linguistic diversity but he holds that this
diversity is limited by human psychology (1995a: 15f). On a
“learning” model of language development, which Chomsky
rejects, infants are little scientists observing and inferring the
linguistic conventions prevailing among adult users (e.g., to be
truthful and trusting in some L). But these learners could not
possibly rule out all but one of the languages that are logically
compatible with the data. Even if the child was exceptionally smart,
the evidence available in the typical linguistic environment is
insufficiently rich—there is a “poverty of
stimulus”. If the information in a child’s environment is
too poor to account for developments in her competence, anterior
knowledge must be providing her with mental stirrups (see Laurence and
Margolis 2001 and the entry on
 innateness and language).
This is the context in which introducing talk of I-languages can be
useful, according to Chomsky (1986: 22–3; 2000: 4–5).
Language acquisition can be thought of as a development through states
of the brain from S0 through intermediate states
into a relatively stable mature state, SM.
S0 is the initial state common to all humans,
idealizing away from individual linguistic impairments and the like.
Subsequent states arise through exposure to a particular linguistic
environment. Nothing said so far requires that these states be thought
of as representational states we could call “knowing a
language”. But if we describe being-in-state
SL as knowing a language L, knowledge that
a linguist might in principle make explicit in a theory of L,
language acquisition can be described—usefully—as a matter
of children evolving through various stages of knowledge en
route to acquiring adult competence. This description is
useful because the empiricist/nativist debate can now be couched as a
debate over what linguistic information must already be known by
someone in S0 if information supplied by the
linguistic environment is to culminate in knowledge of the mature
language M. Empiricists claim that nothing much is needed, that
S0 is a “blank slate” to be filled in
using environmental data. Nativists claim that plenty of information
must already be provided, in the form of innate knowledge of a
language dubbed Universal Grammar (UG) by Chomsky. We each come
predisposed to acquire only certain languages, the humanly possible
ones that can grow out of UG.
An I-language, then, is something that is represented in the language
faculty of an (idealized) individual at a particular stage of
development. But it is not anything beyond the language faculty.
Statements about I-languages being represented in the brain are
“statements about the structures of the brain formulated at a
certain level of abstraction from mechanisms” (1986: 33). In
other words, to talk of the language faculty as representing some
piece of information is simply one way among others of giving an
abstract description of the language faculty, a human
“organ” (Chomsky 1975: 10; Anderson & Lightfoot 2000).
Another way might be to describe it in chemical terms, but the
representationalist description is—for reasons just
sketched—rather more helpful than a chemical one within the
context of explaining language acquisition. A grammar for an
individual, a linguistic theory in other words, is an abstract
statement of this I-language, but what it purports to describe is
their language faculty, not something external to it.
As theoretical posits, I-languages earn their keep through their role
in this kind of enquiry. By treating states on the path to normal
mature linguistic competence in humans as representational states,
states of knowledge (where what is represented or known is an
I-language), important empirical generalizations can be formulated and
assessed. One would not even have to sit at the nativist end of the
spectrum in the debate on language acquisition to accept this way of
framing the question. Moreover, this conception of the brain as a
representational, information processing system, or as an integrated
bundle of such systems, has application beyond the specific instance
of language, developmental or otherwise. Chomsky’s case against
behaviorism in the study of language (1959), and his alternative
vision of how it might be studied, was pivotal in the cognitive
revolution across psychology and affiliated disciplines (see e.g.,
Glass, Holyoak, & Santa 1979; Marr 1982; Pylyshyn 1984; Fodor
1987).
Chomsky does not deny that language (in the mass-noun sense) is at
least in part “a social product” (1986: 18). He cites
Putnam’s famous “division of linguistic labor”
hypothesis (Putnam 1975), for example, arguing that, suitably
described, the phenomenon of semantic deference is compatible with his
internalized perspective. The E-languages (“E-” for
“externalized”) of which he is skeptical are languages in
the count-noun sense. These objects have properties that are
independent of the mind/brain, or of the language faculty in
particular. He offers a number of examples (1986: 19):
Bloomfield’s view that a language is a totality of utterances
that can be made in a speech community; Saussure’s notion of a
langue (an arbitrary association of sounds with concepts);
and Lewis’s pairing of sentences and meanings, the actual
language of a population when the regularities described earlier hold.
Chomsky also includes any system of actions or behaviours, where this
system is individualist but is the product of a myriad of performance
systems interacting with the language faculty and each other. A
grammar, on the E-language approach, purports to describe these
mind-external (or at least language-faculty external) entities.
Because there is considerable variety here in the underlying
conceptions of languages, Chomsky’s criticisms can seem
sweeping, but the underlying thought is that, because E-languages are
less “real” than I-languages, “the concept [of an
E-language] appears to play no role in the theory of language”
(1986: 26). The argument for this negative conclusion is not so
different from the positive argument for an I-language perspective
outlined in
 3.1.1.
 Linguistic behaviour is the product of both the language faculty on
the one hand and external influences—performance systems in the
mind/brain of the individual and social factors—on the other. At
issue is not whether anything at all can ever be said, usefully, about
these “downstream” effects, but whether the notion of an
E-language has any pivotal explanatory role to play in saying it (save
as a useful shorthand). Nothing much is added to the account of
language learning in
 3.1.1,
 for example, by describing it as development towards the learning of
an externalistically specified social language, as opposed to some
specific mature state, SM, of an individual.
One apparent corollary of this is significant for those many
philosophers of language who have agonized over how to construct a
theory of meaning for English. A common thought is that such a theory
ought to take the form of a statement of the referential properties of
the expressions of English—a link between words and objects in
the world—from which the truth conditions of all English
sentences can be derived (e.g., Davidson 1970, Montague 1970; see the
entries for
 theories of meaning
 and
 reference).
 Echoing P.F. Strawson (1950), Chomsky suggests that referring is
something people do. They use words in doing so, it is true, but
referring is not something that words somehow do by themselves,
through some fantastical medium, English (2000: 40–1). If
referential properties of expressions amount to anything, rather than
being relational properties between expressions and external objects
(or “word-world” relations) they should be thought of as
embodying instructions to the individual’s conceptual system,
one of the performance systems with which the language faculty
interfaces (an idea explored in Jackendoff 2002). If Chomsky is right,
a great deal of the philosophy of language is either radically off
beam or needs considerable re-interpretation (see Hornstein 1989,
Ludlow 2003, Pietroski 2003, Stainton 2006).
Criticisms of Chomsky’s internalism, and so by implication his
notion of an I-language, stretch back over half a century, as do his
responses. Three collections (George 1989; McGilvray 1999; Antony and
Hornstein 2003) between them contain a full array of philosophical
commentary. In this and the next section we focus on concerns that
have particular currency.
Many critics have focused on an unacknowledged commitment to
externalism that they think is implicit in Chomsky’s
terminology. The charge can be made using any of the different
phrasings he has used to express his internalism, including
competence, knowledge, and representation.
For the first: competence implies competence in something.
For that something to be defined in terms of the language faculty
itself, there would be no such thing as incompetence, making a
nonsense of talk of competence. Error would be impossible (see Barber
2001). For the second: knowledge implies something known—an
external language or some subset of its properties. Chomsky has
described these criticisms as arising from a misinterpretation of his
view, and said that he was using competence and knowledge in a
technical sense rather than in full accordance with ordinary usage. He
has occasionally suggested “cognize” as an alternative
term of art to prevent confusion, where to cognize an I-language is
for it to be represented in one’s language
 faculty.[5]
 Recent iterations of the criticism have thus tended to focus on
representation. It seems that there can be no representing without
something’s being represented—something external to the
thing doing the representating, and so external to the language
faculty or even the individual. Chomsky’s response has been to
say that he is not using representation in a relation sense,
representation of (1995a: 53 and in Antony and
Hornstein 2003: 276–7).
The notion of representation is central to a good deal of cognitive
science and is a topic that has preoccupied many philosophers of mind
and language who share Chomsky’s naturalistic bent. Many of the
latter have been surprised and puzzled by his rejection of both the
relational notion of representation (where the relation is between
vehicles of representation in the mind/brain, and the things they
represent) and attempts to define this relation in naturalistic
language (see
 causal theories of mental content,
 intentionality, and
 mental representation).
 Georges Rey, for example, sees the intentionality, the
“aboutness”, implicit in the notion of representation as
essential to the computational-representational theory of
mind—precisely the theory that he and others think
Chomsky’s work has helped to inspire and shape (Rey 2003a,b
& 2005). Rey concludes that Chomsky is mistaken about the status
his own theory, and offers instead what he thinks is a more charitable
interpretation: that the representations are of something, but
typically inaccurate and harmlessly so.
In the earlier presentation
 (3.1.1)
 we tried to capture Chomsky’s arelational notion of
representation, where to describe something as representating an
I-language is simply a way of describing it abstractly. John Collins
has gone to greater lengths to make good this suggestion that there
could be representations without representata (2014). Adopting “dyadic
representational talk” helps us to “frame generalizations
about monadic representational states”, he says. Representata
are no more than the byproducts of a grammarians’ attempt to
type non-relational states the mind/brain can be in or pass through.
Invoking them does not generate any ontological commitment to
languages external to the mind/brain being described.
Frances Egan has taken a view that appears to capture the spirit of
Chomsky’s attitude to representation while also making room (and
seeing the need) for a relational notion of representational content
in cognitive explanation (generally, and in linguistics in
particular). According to Egan (2003, 2014), representational
content—the dyadic notion, that is—figures in cognitive
explanation, but not in the way orthodoxy would have it. The internal
computational mechanism alone, uninterpreted, does the explaining.
That this mechanism has the representational content it does figures
only within the explanans. It is used to specify the explanandum.
This explanandum, and hence any allocation to it of content, will
often be quite vaguely characterized, and may even fail to correspond
to anything real.
Because the mechanism, as computationally characterized, would not
track these [external] properties in every environment, the semantic
interpretation of the device is not an essential characterization, and
cannot serve to individuate it. However, the semantic interpretation
enables us to specify the cognitive function of the mechanism, to
characterize it as computing [visual] depth from disparity, for
example, or as computing the syntactic structure of a sentence. (Egan
2014: 98)
This is arguably in the same spirit as Chomsky’s description of
the language faculty as “providing instructions” to
performance systems (1995b: 15). Representations in the language
faculty corresponding to elements of a grammar such as [voiced coronal
sibilant], for example, do not stand for movements of the mouth (such
as the one produced at the beginning of an utterance of the English
word zebra), but they might nonetheless be part of the causal
story of why a human moves her or his mouth in a particular way in
particular circumstances.
Many of those engaged in this debate focus on cases such as the edges
in Kaniza’s triange illusion (figure 1) or PRO (a sytanctic
constituent to which nothing corresponds in the sound-stream). The nub
of the issue, here, seems to be what to make of the fact that there is
no edge, or no syntactic constituent, beyond the edge or syntactic
constituent represented in our mind-brain. The same might even hold of
the notion of a common language. What we make of this for the nature
of cognitive explanation, and of the notion of representation that so
typically figures within it, is yet to be settled, and goes to the
very heart of the philosophy of cognitive science.
Figure 1. Kanizsa’s Triange (from
 Wikimedia Commons, by User:Fibonacci)
More recently, a whole field of scientific research,
psycholinguistics, has been precisely dedicated to studying external,
anti-individualistic, mind-independent properties of language,
massively advancing our understanding of language development in the
process (see Hoff and Shatz 2007). The guiding assumption within this
field is that external factors, such as the child’s social and
physical environment, can play a substantial role in determining both
the child’s linguistic competence and the vocabulary and syntax
of the acquired language. On this view, such external factors supply
most, if not all, of the relevant stimuli for language acquisition,
contrary to Chomsky’s central poverty of stimulus argument for
I-languages.
Several different inquires have benefited from psycholinguistic
studies of overt linguistic behavior. These include questions about
the relative autonomy of distinct areas of linguistic knowledge, such
as the question: are syntax, semantics and pragmatics independent from
each other, or do they rather support each other? (see Gleitman,
Cassidy, et al. 2005; Gleitman 1990; Naigles and Swensen 2007; and
Diesendruck 2007); and about the role of the child in the process of
language acquisition: is the child a passive subject, or an active
participant within her linguistic community (see Shatz 1987, 1994;
Shafer and Garrido-Nag 2007; and Poulin-Dubois and Graham 2007)?
We saw (in section
 3.1.1
 and
 3.1.2)
 that Chomsky’s case for I-languages and against E-languages is
heavily entwined with the poverty of stimulus assumption. This is used
to defend the claim that human languages are little more than
modifications of UG, and that the process of language acquisition and
development is the process of such modifications. But studies have
shown that social input, which children may pick up from and rely on,
is rich both in content and structure (see Baldwin and Meyer 2007). In
child-directed speech, adults use words in a way that makes it easier
for children to identify the relevant information (see Brent and
Siskind 2001; Akhtar, Dunham, and Dunham 1991), suggesting that social
input is highly relevant to the development of semantic knowledge.
Even if we limit the UG hypothesis to a claim about syntax there are
empirical challenges. According to this more limited reading, the
acquisition of syntactic process is “seen to rely most heavily
on the operation of innate structural principles” (Baldwin and
Meyer 2007: 95). Social input, on this view, plays a mere triggering
role. Further studies have shown this hypothesis to be controversial.
Alternative, socio-pragmatic, accounts have shown that children can
learn syntax from adult language use (see Tomasello 2003, 2004).
Children’s domain general abilities of statistical analysis, and
pattern and intention recognition, are believed to assist the child in
identifying and acquiring syntactic structure from the social
linguistic input they receive (see Saffran, Aslin, and Newport 1996;
Gentner, Holyoak, and Kokinov 2001). In general, the empirical
evidence obtained by psycholinguistic studies strongly suggests that
language acquisition and development is much more than just a process
of UG modifications by means of mind/brain maturation.
However these debates evolve, two things seem clear. First, the
external, anti-individualistic, mind-independent properties of
language, including overt linguistic behavior, are apt for proper
scientific investigation. Exactly how much of a threat this is to
Chomsky’s view is a matter for debate, since as we saw (in
 3.1.2)
 he insists he is not denying that language is at least partly a
social product; but the claims made on the back of these results
certainly seem to run contrary to the thrust of his internalism. And,
second, against Chomsky’s skepticism, there are good reasons to
develop such research into external influences, as it may prove to be
central for a proper understanding of the semantics, and even the
grammar and syntax, of human language and its acquisition.
For thoughts on how best to characterize an idiolectal conception of
language, and views on how such a conception sits with respect to
Chomskian internalism and to conventionalist views, see George 1990
and Higginbotham 2006.
The theory of conventions used in Lewis 1975 is developed at length in
his earlier book (1969). The resulting theory of language is
elaborated by Bennett 1976 and criticized in Burge 1975 and Laurence
1996. Wiggins 1997 and Millikan 2005, like Lewis, see languages as
essentially social in nature (Chomsky replies to a version of the
latter in Antony and Hornstein 2003).
A special issue of the journal Inquiry (see Begby &
Ramberg 2016) contains a handful of useful discussions of
Davidson’s influential 1986 article. These include Stainton
2016, which rejects what the author describes as Davidson’s case
against public languages, adding to parallel criticisms of Chomskian
arguments to the same end in Stainton 2011. For work on the
pragmatics/semantics boundary, much of it raising similar issues, see
Stanley 2000, Carston 2002, Borg 2004, Recanati 2004, Cappelen and
Lepore 2005, and Szabó 2005. In earlier work on
Davidson’s paper, his anti-conventionalism is discussed by
Hacking 1986, Dummett 1986, Pietroski 1994, and Reimer 2004. Hacking
addresses the extent to which Davidson’s conclusion undermines
his earlier philosophy of language. Dummett attempts to show that the
notion of a prior theory presupposes the notion of a linguistic
community, and hence of a shared language.
McGilvray 1999 and Smith and Allott 2016 both offer clear introductions to
Chomsky’s philosophy of language and linguistics, including his
E-/I-language distinction. A shorter account of his views on this
topic in particular can be found in Bezuidenhout 2006. Critical
discussion can be found in five collections: George 1989, Otero 1994
(Volume II), Antony and Hornstein 2003, Barber 2003, and McGilvray
2005. Chomsky’s own non-technical writing is usually accessible.
Good starting places would be the second chapter of Chomsky 1986, the
essays in Chomsky 2000 (some of which also appeared within his 1995a),
or the early sections of Chapter 1 of his 1995b (co-written with
Howard Lasnik).
Hoff and Shatz 2007 offers an excellent overview of the field of
language development, including foundational issues, as well as
syntactic, semantic and pragmatic topics in infancy, early childhood
and atypical development.