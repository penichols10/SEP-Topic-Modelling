Analogies are widely recognized as playing an important
heuristic role, as aids to discovery. They have been
employed, in a wide variety of settings and with considerable success,
to generate insight and to formulate possible solutions to
problems. According to Joseph Priestley, a pioneer in chemistry
and electricity,
analogy is our best guide in all philosophical
investigations; and all discoveries, which were not made by mere
accident, have been made by the help of it. (1769/1966: 14)
 Priestley may be over-stating the case, but there is no
doubt that analogies have suggested fruitful lines of inquiry in many
fields. Because of their heuristic value, analogies and
analogical reasoning have been a particular focus of AI research. Hájek (2018) examines analogy as a heuristic tool in philosophy.
Analogies have a related (and not entirely separable)
justificatory role. This role is most obvious where an
analogical argument is explicitly offered in support of some
conclusion. The intended degree of support for the conclusion can
vary considerably. At one extreme, these arguments can be
strongly predictive. For example
(Example 1),
hydrodynamic analogies exploit mathematical similarities between the equations
governing ideal fluid flow and torsional problems. To predict stresses
in a planned structure, one can construct a fluid model, i.e., a
system of pipes through which water passes (Timoshenko and Goodier
1970). Within the limits of
idealization, such analogies allow us to make demonstrative inferences, for example,
from a measured quantity in the fluid model to the analogous value in
the torsional problem. In practice, there are numerous complications
(Sterrett 2006). 
At the other extreme, an analogical argument may provide very weak
support for its conclusion, establishing no more than minimal
plausibility. Consider
(Example 2)
Thomas Reid’s (1785) argument for the existence of life on other planets (Stebbing
1933; Mill 1843/1930; Robinson 1930; Copi 1961). Reid notes a
number of similarities between Earth and the other planets in our solar
system: all orbit and are illuminated by the sun; several have
moons; all revolve on an axis. In consequence, he concludes, it
is “not unreasonable to think, that those planets may, like our
earth, be the habitation of various orders of living creatures”
(1785: 24).
Such modesty is not uncommon. Often the point of an analogical
argument is just to persuade people to take an idea seriously. 
For instance
(Example 3),
Darwin takes himself to be using an analogy
between artificial and natural selection to argue for the plausibility
of the latter:
Why may I not invent the hypothesis of Natural Selection (which from
the analogy of domestic productions, and from what we know of the
struggle of existence and of the variability of organic beings, is, in
some very slight degree, in itself probable) and try whether this
hypothesis of Natural Selection does not explain (as I think it does) a
large number of facts…. (Letter to Henslow, May 1860 in Darwin 1903)
Here it appears, by Darwin’s own admission, that his analogy
is employed to show that the hypothesis is probable to some
“slight degree” and thus merits further investigation. Some, however, reject this characterization of Darwin’s reasoning (Richards 1997; Gildenhuys 2004). 
Sometimes analogical reasoning is the only available form of
justification for a hypothesis. The method of ethnographic
analogy is used to interpret
the nonobservable behaviour of
the ancient inhabitants of an archaeological site (or ancient culture)
based on the similarity of their artifacts to those used by living
peoples. (Hunter and Whitten 1976: 147)
For example (Example 4), Shelley (1999,
2003) describes how ethnographic analogy was used to determine the
probable significance of odd markings on the necks of Moche clay pots
found in the Peruvian Andes. Contemporary potters in Peru use these
marks (called sígnales) to indicate ownership; the
marks enable them to reclaim their work when several potters share a
kiln or storage facility. Analogical reasoning may be the only avenue
of inference to the past in such cases, though this point is subject
to dispute (Gould and Watson 1982; Wylie 1982, 1985). Analogical
reasoning may have similar significance for cosmological phenomena
that are inaccessible due to limits on observation (Dardashti et
al. 2017). See 
§5.1 for further discussion. 
As philosophers and historians such as Kuhn (1996) have repeatedly
pointed out, there is not always a clear separation between the two
roles that we have identified, discovery and justification. 
Indeed, the two functions are blended in what we might call the
programmatic (or paradigmatic) role of analogy: 
over a period of time, an analogy can shape the development of a
program of research. For example
(Example 5),
an
‘acoustical analogy’ was employed for many years by certain
nineteenth-century physicists investigating spectral lines. 
Discrete spectra were thought to be
completely analogous to the
acoustical situation, with atoms (and/or molecules) serving as
oscillators originating or absorbing the vibrations in the manner of
resonant tuning forks. (Maier 1981: 51) 
Guided by this
analogy, physicists looked for groups of spectral lines that exhibited
frequency patterns characteristic of a harmonic oscillator. This
analogy served not only to underwrite the plausibility of conjectures,
but also to guide and limit discovery by pointing scientists
in certain directions. 
More generally, analogies can play an important programmatic role by guiding conceptual development (see §5.2). In some cases, a programmatic analogy culminates in the theoretical
unification of two different areas of inquiry. Descartes’s
(1637/1954) correlation between geometry and algebra, for example
(Example 6), provided methods for
systematically handling geometrical problems that had long been
recognized as analogous. A very different relationship between
analogy and discovery exists when a programmatic analogy breaks down,
as was the ultimate fate of the acoustical analogy. That atomic
spectra have an entirely different explanation became clear with the
advent of quantum theory. In this case, novel discoveries emerged
against background expectations shaped by the guiding
analogy. There is a third possibility: an unproductive or
misleading programmatic analogy may simply become entrenched and
self-perpetuating as it leads us to “construct… data that
conform to it” (Stepan 1996: 133). Arguably, the danger of
this third possibility provides strong motivation for developing a
critical account of analogical reasoning and analogical arguments. 
Analogical cognition, which embraces all cognitive processes
involved in discovering, constructing and using analogies, is broader than analogical reasoning (Hofstadter 2001; Hofstadter and Sander 2013). 
Understanding these processes is an important objective of current
cognitive science research, and an objective that generates many
questions. How do humans identify analogies? Do
nonhuman animals use analogies in ways similar
to humans? How do analogies and metaphors influence concept
formation?
This entry, however, concentrates specifically on analogical
arguments. Specifically, it focuses on three central
epistemological questions:
Following a preliminary discussion of the basic structure of
analogical arguments, the entry reviews selected attempts to provide
answers to these three questions. To find such answers would
constitute an important first step towards understanding the nature of
analogical reasoning. To isolate these questions, however, is to
make the non-trivial assumption that there can be a theory of
analogical arguments—an assumption which, as
we shall see, is attacked in different ways by both philosophers and
cognitive scientists. 
Analogical arguments vary greatly in subject matter, strength and
logical structure. In order to appreciate this variety, it is
helpful to increase our stock of examples. First, a geometric
example:
Example 7
(Rectangles and boxes). Suppose that you have
established that of all rectangles with a fixed perimeter, the square
has maximum area. By analogy, you conjecture that of all boxes
with a fixed surface area, the cube has maximum volume.
Two examples from the history of science:
Example 8 (Morphine and
meperidine). In 1934, the pharmacologist Schaumann was
testing synthetic compounds for their anti-spasmodic effect. These
drugs had a chemical structure similar to morphine. He observed that
one of the compounds—meperidine, also known
as Demerol—had a physical effect on mice that was
previously observed only with morphine: it induced an S-shaped tail
curvature. By analogy, he conjectured that the drug might also share
morphine’s narcotic effects. Testing on rats, rabbits, dogs and
eventually humans showed that meperidine, like morphine, was an
effective pain-killer (Lembeck 1989: 11; Reynolds and Randall 1975:
273). 
Example 9
(Priestley on electrostatic force). In 1769, Priestley
suggested that the absence of electrical influence inside a hollow
charged spherical shell was evidence that charges attract and repel
with an inverse square force. He supported his hypothesis by
appealing to the analogous situation of zero gravitational force inside
a hollow shell of uniform density.
Finally, an example from legal reasoning: 
Example 10
(Duty of reasonable care).  In a much-cited case
(Donoghue v. Stevenson 1932 AC 562), the United Kingdom House of Lords
found the manufacturer of a bottle of ginger beer liable for damages
to a consumer who became ill as a result of a dead snail in the
bottle. The court argued that the manufacturer had a duty to take
“reasonable care” in creating a product that could
foreseeably result in harm to the consumer in the absence of such
care, and where the consumer had no possibility of intermediate
examination. The principle articulated in this famous case was
extended, by analogy, to allow recovery for harm against an
engineering firm whose negligent repair work caused the collapse of a
lift (Haseldine v. CA Daw & Son Ltd. 1941 2 KB 343). By
contrast, the principle was not applicable to a case where a workman
was injured by a defective crane, since the workman had opportunity to
examine the crane and was even aware of the defects (Farr
v. Butters Brothers & Co. 1932 2 KB 606).
What, if anything, do all of these examples have in common? We
begin with a simple, quasi-formal characterization. Similar formulations are found in elementary critical thinking texts (e.g., Copi and Cohen
2005) and in the literature on argumentation theory (e.g., Govier 1999, Guarini 2004, Walton and Hyra 2018). An analogical argument has the following form:
(1) and (2) are premises. (3) is the conclusion of the
argument. The argument form is ampliative; the conclusion
is not guaranteed to follow from the premises. 
S and T are referred to as the source
domain and target domain, respectively. A
domain is a set of objects, properties, relations and
functions, together with a set of accepted statements about those
objects, properties, relations and functions. More formally, a
domain consists of a set of objects and an interpreted set of
statements about them. The statements need not belong to a
first-order language, but to keep things simple, any formalizations
employed here will be first-order. We use unstarred symbols
(a, P, R, f) to refer to items in
the source domain and starred symbols
(a*, P*, R*, f*) to
refer to corresponding items in the target domain. In
 Example 9,
the source domain items
pertain to gravitation; the target items pertain to electrostatic
attraction.
Formally, an analogy between S and T is a
one-to-one mapping between objects, properties, relations and functions
in S and those in T. Not all of the items in
S and T need to be placed in correspondence. 
Commonly, the analogy only identifies correspondences between a select
set of items. In practice, we specify an analogy simply by
indicating the most significant similarities (and sometimes
differences). 
We can improve on this preliminary characterization of the argument
from analogy by introducing the tabular representation found
in Hesse (1966). We place corresponding objects, properties,
relations and propositions side-by-side in a table of two columns, one
for each domain. For instance, Reid’s argument
 (Example 2)
can be represented as
follows (using ⇒ for the analogical inference):
Figure 1.
Hesse introduced useful terminology based on this tabular
representation. The horizontal relations in an
analogy are the relations of similarity (and difference) in the mapping
between domains, while the vertical relations are those
between the objects, relations and properties within each domain. 
The correspondence (similarity) between earth’s having a moon and
Mars’ having moons is a horizontal relation; the causal relation
between having a moon and supporting life is a vertical relation within
the source domain (with the possibility of a distinct such relation
existing in the target as well). 
In an earlier discussion of analogy, Keynes (1921) introduced some
terminology that is also helpful. 
Positive analogy.
Let P stand for a list of accepted propositions
P1, …, Pn
about the source domain S.  Suppose that the corresponding propositions
P*1, …, P*n,
abbreviated as P*, are all accepted as holding for the target
domain T, so that P and P* represent accepted (or
known) similarities. Then we refer to P as the positive
analogy.
Negative analogy.
Let A stand for a list of
propositions A1, …,
Ar accepted as holding in S, and
B* for a list B1*,
…, Bs* of propositions
holding in T. Suppose that the analogous propositions
A* = A1*, …, Ar*
fail to hold in T, and similarly the propositions B =
B1, …, Bs fail to hold
in S, so that A, ~A* and ~B,
B* represent accepted (or known) differences. Then we refer
to A and B as the negative
analogy. 
Neutral analogy.
The neutral analogy consists of accepted propositions about
S for which it is not known whether an analogue holds in
T.
Finally we have:
Hypothetical analogy.
The hypothetical analogy is simply the proposition Q
in the neutral analogy that is the focus of our attention.
These concepts allow us to provide a characterization for an
individual analogical argument that is somewhat richer than the
original one.
An analogical argument may thus be summarized: 
It is plausible that Q* holds in the target,
because of certain known (or accepted) similarities with the
source domain, despite certain known (or accepted)
differences.
In order for this characterization to be meaningful, we need to say
something about the meaning of ‘plausibly.’ To ensure
broad applicability over analogical arguments that vary greatly in
strength, we interpret plausibility rather liberally as meaning
‘with some degree of support’. In general, judgments
of plausibility are made after a claim has been formulated, but prior
to rigorous testing or proof. The next sub-section provides
further discussion.
Note that this characterization is incomplete in a number of
ways. The manner in which we list similarities and differences,
the nature of the correspondences between domains: these things
are left unspecified. Nor does this characterization accommodate
reasoning with multiple analogies (i.e., multiple source domains),
which is ubiquitous in legal reasoning and common elsewhere. To
characterize the argument form more fully, however, is not possible
without either taking a step towards a substantive theory of analogical
reasoning or restricting attention to certain classes of analogical
arguments.
Arguments by analogy are extensively discussed within argumentation theory. There is considerable debate about whether they constitute a species of deductive inference (Govier 1999; Waller 2001; Guarini 2004; Kraus 2015). Argumentation theorists also make use of tools such as speech act theory (Bermejo-Luque 2012), argumentation schemes and dialogue types (Macagno et al. 2017; Walton and Hyra 2018) to distinguish different types of analogical argument.
Arguments by analogy are also discussed in the vast literature on scientific models and model-based reasoning, following the lead of Hesse (1966). Bailer-Jones (2002) draws a helpful distinction between analogies and models. While “many models have their roots in an analogy” (2002: 113) and analogy “can act as a catalyst to aid modeling,” Bailer-Jones observes that “the aim of modeling has nothing intrinsically to do with analogy.” In brief, models are tools for prediction and explanation, whereas analogical arguments aim at establishing plausibility. An analogy is evaluated in terms of source-target similarity, while a model is evaluated on how successfully it “provides access to a phenomenon in that it interprets the available empirical data about the phenomenon.” If we broaden our perspective beyond analogical arguments, however, the connection between models and analogies is restored. Nersessian (2009), for instance, stresses the role of analog models in concept-formation and other cognitive processes.
To say that a hypothesis is plausible is to convey that it has
epistemic support: we have some reason to believe it, even prior
to testing. An assertion of plausibility within the context of an
inquiry typically has pragmatic connotations as well: to say that
a hypothesis is plausible suggests that we have some reason to
investigate it further. For example, a mathematician working on a
proof regards a conjecture as plausible if it “has some chances
of success” (Polya 1954 (v. 2): 148). On both points, there
is ambiguity as to whether an assertion of plausibility is categorical
or a matter of degree. These observations point to the existence
of two distinct conceptions of plausibility, probabilistic and
modal, either of which may reflect the intended conclusion of
an analogical argument.
On the probabilistic conception, plausibility is naturally
identified with rational credence (rational subjective degree of
belief) and is typically represented as a probability. A classic
expression may be found in Mill’s analysis of the argument from
analogy in A System of Logic: 
There can be no doubt that every resemblance [not known to be
irrelevant] affords some degree of probability, beyond what would
otherwise exist, in favour of the conclusion. (Mill 1843/1930: 333)
In the terminology introduced in §2.2,
Mill’s idea is that each element of the positive analogy boosts
the probability of the conclusion. Contemporary
‘structure-mapping’ theories (§3.4)
employ a restricted version: each structural similarity
between two domains contributes to the overall measure of similarity,
and hence to the strength of the analogical argument. 
On the alternative modal conception, ‘it is plausible
that p’ is not a matter of degree. The meaning,
roughly speaking, is that there are sufficient initial grounds for
taking p seriously, i.e., for further investigation (subject
to feasibility and interest). Informally: p passes
an initial screening procedure. There is no assertion of
degree. Instead, ‘It is plausible that’ may be
regarded as an epistemic modal operator that aims to capture a notion,
prima facie plausibility, that is somewhat stronger than
ordinary epistemic possibility. The intent is to single out
p from an undifferentiated mass of ideas that remain bare
epistemic possibilities. To illustrate: in 1769, Priestley’s argument
(Example 9), if successful, would
establish the prima facie plausibility of an inverse square
law for electrostatic attraction. The set of epistemic
possibilities—hypotheses about electrostatic attraction
compatible with knowledge of the day—was much larger. Individual
analogical arguments in mathematics (such
as Example 7) are
almost invariably directed towards
prima facie plausibility. 
The modal conception figures importantly in some discussions of
analogical reasoning. The physicist N. R. Campbell (1957)
writes:
But in order that a theory may be valuable it must … display
an analogy. The propositions of the hypothesis must be analogous
to some known laws…. (1957: 129)
Commenting on the role of analogy in Fourier’s theory of heat
conduction, Campbell writes:
Some analogy is essential to it; for it is only this
analogy which distinguishes the theory from the multitude of
others… which might also be proposed to explain the same laws.
(1957: 142) 
The interesting notion here is that of a “valuable”
theory. We may not agree with Campbell that the existence of
analogy is “essential” for a novel theory to be
“valuable.” But consider the weaker thesis that an
acceptable analogy is sufficient to establish that a theory is
“valuable”, or (to qualify still further) that an
acceptable analogy provides defeasible grounds for taking the theory
seriously. (Possible defeaters might include internal
inconsistency, inconsistency with accepted theory, or the existence of
a (clearly superior) rival analogical argument.) The point is
that Campbell, following the lead of 19th century
philosopher-scientists such as Herschel and Whewell, thinks that
analogies can establish this sort of prima facie
plausibility. Snyder (2006) provides a detailed discussion of the
latter two thinkers and their ideas about the role of analogies
in science. 
In general, analogical arguments may be directed at establishing
either sort of plausibility for their conclusions; they can have a
probabilistic use or a modal use.
 Examples 7
through
 9
are best interpreted as
supporting modal conclusions. In those arguments, an analogy is
used to show that a conjecture is worth taking seriously. To
insist on putting the conclusion in probabilistic terms distracts
attention from the point of the argument. The conclusion might be
modeled (by a Bayesian) as having a certain probability value
because it is deemed prima facie plausible, but not
 vice versa. Example 2,
perhaps,
might be regarded as directed primarily towards a probabilistic
conclusion.
There should be connections between the two conceptions. 
Indeed, we might think that the same analogical argument can establish
both prima facie plausibility and a degree of probability for
a hypothesis. But it is difficult to translate between epistemic modal
concepts and probabilities (Cohen 1980; Douven and Williamson
2006; Huber 2009; Spohn 2009, 2012). We cannot simply take the
probabilistic notion as the primitive one. It seems wise to keep
the two conceptions of plausibility separate. 
Schema (4) is a template that represents all analogical
arguments, good and bad. It is not an inference rule. 
Despite the confidence with which particular analogical arguments are
advanced, nobody has ever formulated an acceptable rule, or set of
rules, for valid analogical inferences. There is not even a
plausible candidate. This situation is in marked contrast not
only with deductive reasoning, but also with elementary forms of
inductive reasoning, such as induction by enumeration.
Of course, it is difficult to show that no successful analogical
inference rule will ever be proposed. But consider the following
candidate, formulated using the concepts of schema (4) and taking us
only a short step beyond that basic characterization. 
Rule (5) is modeled on the
 straight rule for enumerative induction
and inspired by Mill’s view of
analogical inference, as described in §2.3. 
We use the generic phrase ‘degree of support’ in place of
probability, since other factors besides the analogical argument may
influence our probability assignment for Q*.
It is pretty clear that (5) is a non-starter. The main problem
is that the rule justifies too much. The only substantive
requirement introduced by (5) is that there be a nonempty positive
analogy. Plainly, there are analogical arguments that satisfy
this condition but establish no prima facie plausibility and
no measure of support for their conclusions. 
Here is a simple illustration. Achinstein (1964: 328) observes
that there is a formal analogy between swans and line segments if we
take the relation ‘has the same color as’ to correspond to
‘is congruent with’. Both relations are reflexive,
symmetric, and transitive. Yet it would be absurd to find
positive support from this analogy for the idea that we are likely to
find congruent lines clustered in groups of two or more, just because
swans of the same color are commonly found in groups. The
positive analogy is antecedently known to be irrelevant to the
hypothetical analogy. In such a case, the analogical inference
should be utterly rejected. Yet rule (5) would wrongly assign
non-zero degree of support.
To generalize the difficulty: not every similarity increases
the probability of the conclusion and not every difference decreases
it. Some similarities and differences are known to be (or
accepted as being) utterly irrelevant and should have no influence
whatsoever on our probability judgments. To be viable, rule (5)
would need to be supplemented with considerations of
relevance, which depend upon the subject matter, historical
context and logical details particular to each analogical
argument. To search for a simple rule of analogical inference
thus appears futile. 
Carnap and his followers (Carnap 1980; Kuipers 1988; Niiniluoto 1988; Maher 2000; Romeijn 2006) have formulated principles of analogy for inductive logic, using Carnapian λγ rules. Generally, this body of work relates to “analogy by similarity”, rather than the type of analogical
reasoning discussed here. Romeijn (2006) maintains that there is a relation between Carnap’s concept of analogy and analogical prediction. His approach is a hybrid of Carnap-style inductive rules and a Bayesian model. Such an approach would need to be generalized to handle the kinds of arguments described in §2.1. It remains unclear that the Carnapian approach can provide a general rule for analogical inference.
Norton (2010, and 2018—see Other Internet Resources) has argued
that the project of formalizing inductive reasoning in terms of one or
more simple formal schemata is doomed. His criticisms seem especially
apt when applied to analogical reasoning. He writes: 
If analogical reasoning is required to conform only to a simple
formal schema, the restriction is too permissive. Inferences are
authorized that clearly should not pass muster… The natural
response has been to develop more elaborate formal
templates… The familiar difficulty is that these
embellished schema never seem to be quite embellished enough; there
always seems to be some part of the analysis that must be handled
intuitively without guidance from strict formal rules. (2018: 1)
Norton takes the point one step further, in keeping with his
“material theory” of inductive inference. He argues that there is no universal logical principle that
“powers” analogical inference “by asserting that
things that share some properties must share others.” 
Rather, each analogical inference is warranted by some local
constellation of facts about the target system that he terms “the
fact of analogy”. These local facts are to be determined
and investigated on a case by case basis.
To embrace a purely formal approach to analogy and to abjure
formalization entirely are two extremes in a spectrum of
strategies. There are intermediate positions. Most recent
analyses (both philosophical and computational) have been directed
towards elucidating criteria and procedures, rather than formal
rules, for reasoning by analogy. So long as these are not
intended to provide a universal ‘logic’ of analogy, there
is room for such criteria even if one accepts Norton’s basic
point. The next section discusses some of these criteria and
procedures.
Logicians and philosophers of science have identified
‘textbook-style’ general guidelines for evaluating
analogical arguments (Mill 1843/1930; Keynes 1921; Robinson 1930;
Stebbing 1933; Copi and Cohen 2005; Moore and Parker 1998; Woods,
Irvine, and Walton 2004). Here are some of the most
important
ones:
These principles can be helpful, but are frequently too vague to
provide much insight. How do we count similarities and
differences in applying (G1) and (G2)? Why are the structural and
causal analogies mentioned in (G5) and (G6) especially important, and
which structural and causal features merit attention? More
generally, in connection with the all-important (G7): how do we
determine which similarities and differences are relevant to the
conclusion? Furthermore, what are we to say about similarities
and differences that have been omitted from an analogical argument but
might still be relevant?
An additional problem is that the criteria can pull in different
directions. To illustrate, consider Reid’s argument for
 life on other planets (Example 2).
Stebbing (1933) finds Reid’s argument
“suggestive” and “not unplausible” because the
conclusion is weak (G4), while Mill (1843/1930) appears to reject the
argument on account of our vast ignorance of properties that might be
relevant (G3). 
There is a further problem that relates to the distinction just made
(in §2.3) between two kinds of
plausibility. Each of the above criteria apart from (G7) is
expressed in terms of the strength of the argument, i.e., the degree of
support for the conclusion. The criteria thus appear to
presuppose the probabilistic interpretation of
plausibility. The problem is that a great many analogical
arguments aim to establish prima facie plausibility rather
than any degree of probability. Most of the guidelines are not
directly applicable to such arguments.
Aristotle sets the stage for all later theories of analogical
reasoning. In his theoretical reflections on analogy and in his
most judicious examples, we find a sober account that lays the
foundation both for the commonsense guidelines noted above and for more
sophisticated analyses. 
Although Aristotle employs the term analogy (analogia) and
discusses
 analogical predication,
he never talks about analogical reasoning or
analogical arguments per se. He does, however, identify
two argument forms, the argument from example
(paradeigma) and the argument from likeness
(homoiotes), both closely related to what would we now
recognize as an analogical argument.
The argument from example (paradeigma) is
described in the Rhetoric and the Prior
Analytics:
Enthymemes based upon example are those which proceed from one or
more similar cases, arrive at a general proposition, and then argue
deductively to a particular inference. (Rhetoric
1402b15)
Let A be evil, B making war against neighbours, C Athenians against
Thebans, D Thebans against Phocians. If then we wish to prove
that to fight with the Thebans is an evil, we must assume that to fight
against neighbours is an evil. Conviction of this is obtained
from similar cases, e.g., that the war against the Phocians was an evil
to the Thebans. Since then to fight against neighbours is an
evil, and to fight against the Thebans is to fight against neighbours,
it is clear that to fight against the Thebans is an evil. 
(Pr. An. 69a1)
Aristotle notes two differences between this argument form and
induction (69a15ff.): it “does not draw its proof from all
the particular cases” (i.e., it is not a “complete”
induction), and it requires an additional (deductively valid) syllogism
as the final step. The argument from example thus amounts to
single-case induction followed by deductive inference. It has the
following structure (using ⊃ for the conditional):
Figure 2.
In the terminology of §2.2, P is the
positive analogy and Q is the hypothetical analogy. In
Aristotle’s example, S (the source) is war between
Phocians and Thebans, T (the target) is war between Athenians
and Thebans, P is war between neighbours, and Q is
evil. The first inference (dashed arrow) is inductive; the second
and third (solid arrows) are deductively valid. 
The paradeigma has an interesting feature: it is
amenable to an alternative analysis as a purely deductive
argument form. Let us concentrate on Aristotle’s assertion,
“we must assume that to fight against neighbours is an
evil,” represented as ∀x(P(x)
⊃ Q(x)). Instead of regarding this
intermediate step as something reached by induction from a single case,
we might instead regard it as a hidden presupposition. This
transforms the paradeigma into a syllogistic argument with a
missing or enthymematic premise, and our attention shifts to
possible means for establishing that premise (with single-case
induction as one such means). Construed in this way,
Aristotle’s paradeigma argument foreshadows deductive
analyses of analogical reasoning (see
§4.1). 
The argument from likeness (homoiotes) seems to be
closer than the paradeigma to our contemporary understanding
of analogical arguments. This argument form receives considerable
attention in Topics I, 17 and 18 and again in VIII, 1. 
The most important passage is the following.
Try to secure admissions by means of likeness; for such admissions
are plausible, and the universal involved is less patent; e.g. that as
knowledge and ignorance of contraries is the same, so too perception of
contraries is the same; or vice versa, that since the perception is the
same, so is the knowledge also. This argument resembles
induction, but is not the same thing; for in induction it is the
universal whose admission is secured from the particulars, whereas in
arguments from likeness, what is secured is not the universal under
which all the like cases fall. (Topics 156b10–17)
This passage occurs in a work that offers advice for framing
dialectical arguments when confronting a somewhat skeptical
interlocutor. In such situations, it is best not to make
one’s argument depend upon securing agreement about any universal
proposition. The argument from likeness is thus clearly distinct
from the paradeigma, where the universal proposition plays an
essential role as an intermediate step in the argument. The
argument from likeness, though logically less straightforward than the
paradeigma, is exactly the sort of analogical reasoning we
want when we are unsure about underlying generalizations. 
In Topics I 17, Aristotle states that any shared attribute
contributes some degree of likeness. It is natural to ask when the degree of likeness between two things is sufficiently great to warrant inferring a further likeness. In
other words, when does the argument from likeness succeed? 
Aristotle does not answer explicitly, but a clue is provided by the way
he justifies particular arguments from likeness. As Lloyd (1966)
has observed, Aristotle typically justifies such arguments by
articulating a (sometimes vague) causal principle which governs the two phenomena being
compared. For example, Aristotle explains the saltiness of the
sea, by analogy with the saltiness of sweat, as a kind of residual
earthy stuff exuded in natural processes such as heating. The
common principle is this:
 Everything that grows and is
naturally generated always leaves a residue, like that of things burnt,
consisting in this sort of earth. (Mete 358a17) 
From this method of justification, we might conjecture that Aristotle
believes that the important similarities are those that
enter into such general causal principles. 
Summarizing, Aristotle’s theory provides us with four
important and influential criteria for the evaluation of analogical
arguments:
These four principles form the core of a common-sense model
for evaluating analogical arguments (which is not to say that they are
correct; indeed, the first three will shortly be called into
question). The first, as we have seen, appears regularly in
textbook discussions of analogy. The second is largely taken for
granted, with important exceptions in computational models of analogy
(§3.4). Versions of the third are found in
most sophisticated theories. The final point, which distinguishes
the argument from likeness and the argument from example, is endorsed
in many discussions of analogy (e.g., Quine and Ullian 1970).
A slight generalization of Aristotle’s first principle helps
to prepare the way for discussion of later developments. As that
principle suggests, Aristotle, in common with just about everyone else
who has written about analogical reasoning, organizes his analysis of
the argument form around overall similarity. In the terminology
of section 2.2, horizontal relationships drive the
reasoning: the greater the overall similarity of the two
domains, the stronger the analogical argument. Hume makes
the same point, though stated negatively, in his Dialogues
Concerning Natural Religion:
Wherever you depart, in the least, from the similarity of the cases,
you diminish proportionably the evidence; and may at last bring it to a
very weak analogy, which is confessedly liable to error and
uncertainty. (1779/1947: 144)
Most theories of analogy agree with Aristotle and Hume on this
general point. Disagreement relates to the appropriate way of
measuring overall similarity. Some theories assign greatest
weight to material analogy, which refers to shared, and
typically observable, features. Others give prominence to
formal analogy, emphasizing high-level structural
correspondence. The next two sub-sections discuss representative
accounts that illustrate these two approaches.
Hesse (1966) offers a sharpened version of Aristotle’s theory,
specifically focused on analogical arguments in the sciences. She
formulates three requirements that an analogical argument must satisfy
in order to be acceptable:
For Hesse, an acceptable analogical argument must include
“observable similarities” between domains, which she refers
to as material analogy. Material analogy is contrasted
with formal analogy. Two domains are formally analogous
if both are “interpretations of the same formal theory”
(1966: 68). Nomic isomorphism (Hempel 1965) is a special case in which the physical laws governing two systems have identical mathematical form. Heat
and fluid flow exhibit nomic isomorphism. A second example is the
analogy between the flow of electric current in a wire and fluid in a
pipe. Ohm’s law
states that voltage difference along a wire equals current times a
constant resistance. This has the same mathematical form as
Poiseuille’s law (for ideal fluids):
which states that the pressure difference along a pipe equals the
volumetric flow rate times a constant. Both of these systems can
be represented by a common equation. While formal analogy is linked to common mathematical structure, it should not be limited to nomic isomorphism (Bartha 2010: 209). The idea of formal analogy generalizes to cases where there is a common mathematical structure between models for two systems. Bartha offers an even more liberal definition (2010: 195): “Two features are formally similar if they occupy corresponding positions in formally analogous theories. For example, pitch in the theory of sound corresponds to color in the theory of light.” 
By contrast, material analogy consists of what Hesse calls
“observable” or “pre-theoretic”
similarities. These are horizontal relationships of similarity
between properties of objects in the source and the target. 
Similarities between echoes (sound) and reflection (light), for
instance, were recognized long before we had any detailed theories
about these phenomena. Hesse (1966, 1988) regards such
similarities as metaphorical relationships between the two domains and
labels them “pre-theoretic” because they draw on personal
and cultural experience. We have both material and formal analogies between sound and light, and it is significant for Hesse that the former are independent of the latter.
There are good reasons not to accept Hesse’s requirement of
material analogy, construed in this narrow way. First, it is
apparent that formal analogies are the starting point in many
important inferences. That is certainly the case in mathematics,
a field in which material analogy, in Hesse’s sense, plays no
role at all. Analogical arguments based on formal analogy have
also been extremely influential in physics (Steiner 1989,
1998). 
In Norton’s broad sense, however, ‘material
analogy’ simply refers to similarities rooted in factual
knowledge of the source and target domains. With reference to
this broader meaning, Hesse proposes two additional material
criteria.
Hesse requires that the hypothetical analogy, the feature
transferred to the target domain, be causally related to the
positive analogy. In her words, the essential requirement for a
good argument from analogy is “a tendency to
co-occurrence”, i.e., a causal relationship. She states the
requirement as follows:
The vertical relations in the model [source] are causal relations in
some acceptable scientific sense, where there are no compelling a
priori reasons for denying that causal relations of the same kind may
hold between terms of the explanandum [target]. (1966: 87)
The causal condition rules out analogical arguments where there is
no causal knowledge of the source domain. It derives support from
the observation that many analogies do appear to involve a transfer of
causal knowledge. 
The causal condition is on the right track, but is arguably too
restrictive. For example, it rules out analogical arguments in
mathematics. Even if we limit attention to the empirical
sciences, persuasive analogical arguments may be founded upon strong
statistical correlation in the absence of any known causal
connection. Consider
(Example 11)
Benjamin Franklin’s prediction, in 1749, that pointed metal rods would
attract lightning, by analogy with the way they attracted the
“electrical fluid” in the laboratory:
Electrical fluid agrees with lightning in these particulars: 
1. Giving light. 2. Colour of the light. 3. 
Crooked direction. 4. Swift motion. 5. Being
conducted by metals. 6. Crack or noise in exploding. 
7. Subsisting in water or ice. 8. Rending bodies it
passes through. 9. Destroying animals. 10. 
Melting metals. 11. Firing inflammable substances. 
12. Sulphureous smell.—The electrical fluid is attracted
by points.—We do not know whether this property is in
lightning.—But since they agree in all the particulars
wherein we can already compare them, is it not probable they agree
likewise in this? Let the experiment be made. (Benjamin
Franklin’s Experiments, 334)
Franklin’s hypothesis was based on a long list of properties
common to the target (lightning) and source (electrical fluid in the
laboratory). There was no known causal connection between the
twelve “particulars” and the thirteenth property, but there
was a strong correlation. Analogical arguments may be plausible
even where there are no known causal relations.
Hesse’s final requirement is that the “essential
properties and causal relations of the [source] have not been shown to
be part of the negative analogy” (1966: 91). Hesse does not
provide a definition of “essential,” but suggests that a
property or relation is essential if it is “causally closely
related to the known positive analogy.” For instance, an
analogy with fluid flow was extremely influential in developing the
theory of heat conduction. Once it was discovered that heat was
not conserved, however, the analogy became unacceptable (according to
Hesse) because conservation was so central to the theory of fluid
flow. 
This requirement, though once again on the right track, seems too
restrictive. It can lead to the rejection of a good analogical
argument. Consider the analogy between a two-dimensional rectangle and
a three-dimensional box
 (Example 7).
  Broadening Hesse’s notion, it seems that there
are many ‘essential’ differences between rectangles and
boxes. This does not mean that we should reject every analogy between
rectangles and boxes out of hand. The problem derives from the fact
that Hesse’s condition is applied to the analogy relation
independently of the use to which that relation is put. What counts as
essential should vary with the analogical argument. Absent an
inferential context, it is impossible to evaluate the importance or
‘essentiality’ of similarities and differences. 
Despite these weaknesses, Hesse’s ‘material’
criteria constitute a significant advance in our understanding of
analogical reasoning. The causal condition and the
no-essential-difference condition incorporate local factors, as urged
by Norton, into the assessment of analogical arguments. These
conditions, singly or taken together, imply that an analogical argument
can fail to generate any support for its conclusion, even when there is
a non-empty positive analogy. Hesse offers no theory about the
‘degree’ of analogical support. That makes her
account one of the few that is oriented towards the modal, rather than
probabilistic, use of analogical arguments
(§2.3).
Many people take the concept of
 model-theoretic isomorphism
to set the standard for thinking about similarity and
its role in analogical reasoning. They propose formal
criteria for evaluating analogies, based on overall structural or
syntactical similarity. Let us refer to theories oriented around
such criteria as structuralist.
A number of leading computational models of analogy are
structuralist. They are implemented in computer programs that
begin with (or sometimes build) representations of the source and
target domains, and then construct possible analogy mappings. 
Analogical inferences emerge as a consequence of identifying the
‘best mapping.’ In terms of criteria for analogical
reasoning, there are two main ideas. First, the goodness of an
analogical argument is based on the goodness of the associated
analogy mapping. Second, the goodness of the analogy
mapping is given by a metric that indicates how closely it approximates
isomorphism. 
The most influential structuralist theory has been Gentner’s
structure-mapping theory, implemented in a program called the
structure-mapping engine (SME). In its original form
(Gentner 1983), the theory assesses analogies on purely structural
grounds. Gentner asserts: 
Analogies are about relations, rather than simple features. No
matter what kind of knowledge (causal models, plans, stories, etc.), it
is the structural properties (i.e., the interrelationships between the
facts) that determine the content of an analogy. (Falkenhainer,
Forbus, and Gentner 1989/90: 3)
In order to clarify this thesis, Gentner introduces a distinction
between properties, or monadic predicates, and
relations, which have multiple arguments. She further
distinguishes among different orders of relations and
functions, defined inductively (in terms of the order of the relata or arguments). The best mapping is determined by
systematicity: the extent to which it places
higher-order relations, and items that are nested in higher-order
relations, in correspondence. Gentner’s Systematicity Principle states:
 A
predicate that belongs to a mappable system of mutually interconnecting
relationships is more likely to be imported into the target than is an
isolated predicate. (1983: 163)
A systematic analogy (one that places high-order relations and their
components in correspondence) is better than a less systematic
analogy. Hence, an analogical inference has a degree of
plausibility that increases monotonically with the degree of
systematicity of the associated analogy mapping. Gentner’s
fundamental criterion for evaluating candidate analogies (and
analogical inferences) thus depends solely upon the syntax of the given
representations and not at all upon their content.
Later versions of the structure-mapping theory incorporate
refinements (Forbus, Ferguson, and Gentner 1994;
Forbus 2001; Forbus et al. 2007; Forbus et al. 2008; Forbus et al 2017). For example, the earliest version of the theory is vulnerable to worries about hand-coded representations of source and target domains. Gentner and her colleagues have attempted to solve this problem in later work that generates LISP representations from natural language text (see (Tunney 2008) for a different approach).
 

The most important challenges for the structure-mapping approach relate to the Systematicity Principle itself. Does the value of an analogy derive
entirely, or even chiefly, from systematicity? There appear to be
two main difficulties with this view. First: it is not always appropriate to give priority to systematic, high-level relational matches. Material criteria, and
notably what Gentner refers to as “superficial feature
matches,” can be extremely important in some types of analogical
reasoning, such as ethnographic analogies which are based, to a considerable degree, on surface resemblances between artifacts. Second and more significantly: systematicity seems to be at best a fallible marker for good analogies rather than the
essence of good analogical reasoning.
 

Greater systematicity is neither necessary nor sufficient for a more plausible analogical
inference. It is obvious that increased systematicity is not sufficient for increased plausibility. An implausible analogy can be represented in a form that exhibits a high degree of structural parallelism. High-order relations can come cheap, as
we saw with Achinstein’s “swan” example
(§2.4). 
More pointedly, increased systematicity is not necessary
for greater plausibility. Indeed, in causal analogies, it may
even weaken the inference. That is because systematicity
takes no account of the type of causal relevance, positive or negative. (McKay 1993) notes that microbes have been found in frozen lakes in Antarctica; by analogy, simple life forms might exist on
Mars. Freezing temperatures are preventive or counteracting
causes; they are negatively relevant to the existence of
life. The climate of Mars was probably more favorable to
life 3.5 billion years ago than it is today, because temperatures were
warmer. Yet the analogy between Antarctica and present-day Mars
is more systematic than the analogy between Antarctica and
ancient Mars. According to the Systematicity Principle,
the analogy with Antarctica provides stronger support for life on
Mars today than it does for life on ancient Mars. 
The point of this example is that increased
systematicity does not always increase plausibility, and reduced
systematicity does not always decrease it (see Lee and Holyoak 2008). 
The more general point is that systematicity can be misleading, unless
we take into account the nature of the relationships between
various factors and the hypothetical analogy. Systematicity does not
magically produce or explain the plausibility of an analogical
argument. When we reason by analogy, we must determine which
features of both domains are relevant and how they relate to
the analogical conclusion. There is no short-cut via
syntax. 
Schlimm (2008) offers an entirely different critique of the
structure-mapping theory from the perspective of analogical reasoning
in mathematics—a domain where one might expect a formal
approach such as structure mapping to perform well. 
Schlimm introduces a simple distinction: a domain is
object-rich if the number of objects is greater than the
number of relations (and properties), and relation-rich
otherwise. Proponents of the structure-mapping theory typically
focus on relation-rich examples (such as the analogy between the solar
system and the atom). By contrast, analogies in mathematics
typically involve domains with an enormous number of objects (like the
real numbers), but relatively few relations and functions (addition, multiplication,
less-than). 
Schlimm provides an example of an analogical reasoning problem in
group theory that involves a single relation in each domain. In
this case, attaining maximal systematicity is trivial. The
difficulty is that, compatible with maximal systematicity, there are
different ways in which the objects might be placed in
correspondence. The structure-mapping theory appears to yield the
wrong inference. We might put the general point as follows: 
in object-rich domains, systematicity ceases to be a reliable
guide to plausible analogical inference.
During the past thirty-five years, cognitive scientists have conducted
extensive research on analogy. Gentner’s SME is just one of
many computational theories, implemented in programs that construct and
use analogies. Three helpful anthologies that span this period
are Helman 1988; Gentner, Holyoak, and Kokinov 2001; and Kokinov,
Holyoak, and Gentner 2009. 
One predominant objective of this research has been to model the
cognitive processes involved in using analogies. Early models
tended to be oriented towards “understanding the basic
constraints that govern human analogical thinking” (Hummel and
Holyoak 1997: 458). Recent connectionist models have been
directed towards uncovering the psychological mechanisms that come into
play when we use analogies: retrieval of a relevant
source domain, analogical mapping across
domains, and transfer of information and learning of
new categories or schemas. 
In some cases, such as the structure-mapping theory
(§3.4), this research overlaps directly with the
normative questions that are the focus of this entry; indeed, Gentner’s Systematicity Principle may be interpreted normatively. In other
cases, we might view the projects as displacing those
traditional normative questions with up-to-date, computational forms
of
naturalized epistemology.
Two approaches are singled out here because
both raise important challenges to the very idea of finding sharp
answers to those questions, and both suggest that connectionist models
offer a more fruitful approach to understanding analogical
reasoning.
The first is the constraint-satisfaction
model (also known as the multiconstraint
theory), developed by Holyoak and Thagard (1989,
1995). Like Gentner, Holyoak and Thagard regard the heart of
analogical reasoning as analogy mapping, and they stress the
importance of systematicity, which they refer to as a
structural constraint. Unlike Gentner, they acknowledge
two additional types of constraints. Pragmatic
constraints take into account the goals and purposes of the agent,
recognizing that “the purpose will guide selection” of
relevant similarities. Semantic constraints represent
estimates of the degree to which people regard source and target items
as being alike, rather like Hesse’s “pre-theoretic”
similarities. 
The novelty of the multiconstraint theory is that these
structural, semantic and pragmatic
constraints are implemented not as rigid rules, but rather as
‘pressures’ supporting or inhibiting potential pairwise
correspondences. The theory is implemented in a connectionist
program called ACME (Analogical Constraint
Mapping Engine), which assigns an initial activation value to each
possible pairing between elements in the source and target domains
(based on semantic and pragmatic constraints), and then runs through
cycles that update the activation values based on overall coherence
(structural constraints). The best global analogy mapping emerges
under the pressure of these constraints. Subsequent connectionist
models, such as Hummel and Holyoak’s LISA program (1997, 2003),
have made significant advances and hold promise for offering a more
complete theory of analogical reasoning.
The second example is Hofstadter and Mitchell’s Copycat program (Hofstadter 1995; Mitchell 1993). The program is “designed to discover
insightful analogies, and to do so in a psychologically realistic
way” (Hofstadter 1995: 205). Copycat operates in the domain
of letter-strings. The program handles the following type of
problem: 
Suppose the letter-string abc were changed to abd;
how would you change the letter-string ijk in “the same
way”?
Most people would answer ijl, since it is natural to think
that abc was changed to abd by the
“transformation rule”: replace the rightmost letter
with its successor. Alternative answers are possible, but do not agree with most
people’s sense of what counts as the natural analogy.
Hofstadter and Mitchell believe that analogy-making is in large part about the
perception of novel patterns, and that such perception
requires concepts with “fluid” boundaries. Genuine
analogy-making involves “slippage” of concepts. The
Copycat program combines a set of core concepts pertaining to
letter-sequences (successor, leftmost and so forth)
with probabilistic “halos” that link distinct concepts
dynamically. Orderly
structures emerge out of random low-level processes and the program produces plausible
solutions. Copycat thus shows
that analogy-making can be modeled as a process akin to perception,
even if the program employs mechanisms distinct from those in human
perception. 
The multiconstraint theory and Copycat share the idea that analogical
cognition involves cognitive processes that operate below the level of
abstract reasoning. Both computational models—to the extent that
they are capable of performing successful analogical
reasoning—challenge the idea that a successful model of
analogical reasoning must take the form of a set of quasi-logical
criteria. Efforts to develop a quasi-logical
theory of analogical reasoning, it might be argued, have
failed. In place of faulty inference schemes such as those
described earlier (§2.2, §2.4),
computational models substitute procedures that can be
judged on their performance rather than on traditional philosophical
standards.  
In response to this argument, we should recognize the value of the
connectionist models while acknowledging that we still need a
theory that offers normative principles for
evaluating analogical arguments. In the first place, even if the
construction and recognition of analogies are largely a matter of
perception, this does not eliminate the need for subsequent critical evaluation of
analogical inferences. Second and more importantly, we need to look not
just at the construction of analogy mappings but at the ways in which
individual analogical arguments are debated in fields such
as mathematics, physics, philosophy and the law. These high-level
debates require reasoning that bears little resemblance to the
computational processes of ACME or Copycat. (Ashley’s HYPO
(Ashley 1990) is one example of a non-connectionist program that
focuses on this aspect of analogical reasoning.) There is,
accordingly, room for both computational and traditional philosophical
models of analogical reasoning.
Most prominent theories of analogy, philosophical and computational,
are based on overall similarity between source and target
domains—defined in terms of some favoured subset of Hesse’s
horizontal relations (see §2.2). 
Aristotle and Mill, whose approach is echoed in textbook discussions,
suggest counting similarities. Hesse’s theory
(§3.3) favours “pre-theoretic”
correspondences. The structure-mapping theory and its successors
(§3.4) look to systematicity, i.e., to
correspondences involving complex, high-level networks of
relations. In each of these approaches, the problem is
twofold: overall similarity is not a reliable guide to
plausibility, and it fails to explain the plausibility of any
analogical argument.
Bartha’s articulation model (2010)
proposes a different approach, beginning not with horizontal relations,
but rather with a classification of analogical arguments on the basis
of the vertical relations within each domain. The
fundamental idea is that a good analogical argument must satisfy two
conditions:
Prior Association.
There must be a clear connection, in the source domain, between the
known similarities (the positive analogy) and the further similarity
that is projected to hold in the target domain (the hypothetical
analogy). This relationship determines which features of the source
are critical to the analogical inference.
Potential for Generalization.
There must be reason to think that the same kind of connection could
obtain in the target domain. More pointedly: there must be
no critical disanalogy between the domains.
The first order of business is to make the prior association
explicit. The standards of explicitness vary depending on the
nature of this association (causal relation, mathematical proof,
functional relationship, and so forth). The two general
principles are fleshed out via a set of subordinate models that allow
us to identify critical features and hence critical disanalogies.
 To see how this works, consider Example 7
(Rectangles and boxes). In this analogical argument,
the source domain is two-dimensional geometry: we know that of
all rectangles with a fixed perimeter, the square has maximum
area. The target domain is three-dimensional geometry: by
analogy, we conjecture that of all boxes with a fixed surface area, the
cube has maximum volume. This argument should be evaluated
not by counting similarities, looking to pre-theoretic
resemblances between rectangles and boxes, or constructing
connectionist representations of the domains and computing a
systematicity score for possible mappings. Instead, we should
begin with a precise articulation of the prior association in the
source domain, which amounts to a specific proof for the result about
rectangles. We should then identify, relative to that proof, the
critical features of the source domain: namely, the concepts and
assumptions used in the proof. Finally, we should assess the
potential for generalization: whether, in the three-dimensional
setting, those critical features are known to lack analogues in the
target domain. The articulation model is meant to reflect the
conversations that can and do take place between an advocate
and a critic of an analogical argument.
 

As noted in §2.4, Norton rejects analogical inference rules. But even if we agree with Norton on this point, we might still be interested in having an account that gives us guidelines for evaluating analogical arguments. How does Norton’s approach fare on this score?
According to Norton, each analogical argument is warranted by local facts that must be investigated and justified empirically. First, there is “the fact of the analogy”: in practice, a low-level uniformity that embraces both the source and target systems. Second, there are additional factual properties of the target system which, when taken together with the uniformity, warrant the analogical inference. Consider Galileo’s famous inference 
(Example 12) that there are mountains on the moon (Galileo 1610). Through his newly invented telescope, Galileo observed points of light on the moon ahead of the advancing edge of sunlight. Noting that the same thing happens on earth when sunlight strikes the mountains, he concluded that there must be mountains on the moon and even provided a reasonable estimate of their height. In this example, Norton tells us, the the fact of the analogy is that shadows and other optical phenomena are generated in the same way on the earth and on the moon; the additional fact about the target is the existence of points of light ahead of the advancing edge of sunlight on the moon.
What are the implications of Norton’s material theory when it comes to evaluating analogical arguments? The fact of the analogy is a local uniformity that powers the inference. Norton’s theory works well when such a uniformity is patent or naturally inferred. It doesn’t work well when the uniformity is itself the target (rather than the driver) of the inference. That happens with explanatory analogies such as Example 5 (the Acoustical Analogy), and mathematical analogies such as Example 7 (Rectangles and Boxes). Similarly, the theory doesn’t work well when the underlying uniformity is unclear, as in Example 2 (Life on other Planets), Example 4 (Clay Pots), and many other cases. In short, if Norton’s theory is accepted, then for most analogical arguments there are no useful evaluation criteria. 
For those who sympathize with Norton’s skepticism about universal inductive schemes and theories of analogical reasoning, yet recognize that his approach may be too local, an appealing strategy is to move up one level. We can aim for field-specific “working logics” (Toulmin 1958; Wylie and Chapman 2016; Reiss 2015). This approach has been adopted by philosophers of archaeology, evolutionary biology and other historical sciences (Wylie and Chapman 2016; Currie 2013; Currie 2016; Currie 2018). In place of schemas, we find ‘toolkits’, i.e., lists of criteria for evaluating analogical reasoning. 
For example, Currie (2016) explores in detail the use of ethnographic analogy 
(Example 13) between shamanastic motifs used by the contemporary San people and similar motifs in ancient rock art, found both among ancestors of the San (direct historical analogy) and in European rock art (indirect historical analogy). Analogical arguments support the hypothesis that in each of these cultures, rock art symbolizes hallucinogenic experiences. Currie examines criteria that focus on assumptions about stability of cultural traits and environment-culture relationships. Currie (2016, 2018) and Wylie (Wylie and Chapman 2016) also stress the importance of robustness reasoning that combines analogical arguments of moderate strength with other forms of evidence to yield strong conclusions.
Practice-based approaches can thus yield specific guidelines unlikely to be matched by any general theory of analogical reasoning. One caveat is worth mentioning. Field-specific criteria for ethnographic analogy are elicited against a background of decades of methodological controversy (Wylie and Chapman 2016). Critics and defenders of ethnographic analogy have appealed to general models of scientific method (e.g., hypothetico-deductive method or Bayesian confirmation). To advance the methodological debate, practice-based approaches must either make connections to these general models or explain why the lack of any such connection is unproblematic.
Close attention to analogical arguments in practice can also provide valuable challenges to general ideas about analogical inference. In an interesting discussion, Steiner (1989, 1998) suggests that
many of the analogies that played a major role in early
twentieth-century physics count as “Pythagorean.” The
term is meant to connote mathematical mysticism: a
“Pythagorean” analogy is a purely formal analogy, one founded on mathematical
similarities that have no known physical basis at the time it is
proposed. One example is Schrödinger’s use of analogy 
(Example 14) to “guess” the form of the relativistic wave
equation. In Steiner’s view, Schrödinger’s
reasoning relies upon manipulations and substitutions based on purely
mathematical analogies. Steiner argues that the success, and even
the plausibility, of such analogies “evokes, or should evoke,
puzzlement” (1989: 454). Both Hesse (1966) and Bartha (2010) reject the idea that a purely formal analogy, with no physical significance, can support a plausible analogical inference in physics. Thus, Steiner’s arguments provide a serious challenge. 
 

Bartha (2010) suggests a response: we can decompose Steiner’s examples into two or more steps, and then establish that at least one step does, in fact, have a physical basis. Fraser (forthcoming), however, offers a counterexample that supports Steiner’s position. Complex analogies between classical statistical mechanics (CSM) and quantum field theory (QFT) have played a crucial role in the development and application of renormalization group (RG) methods in both theories 
(Example 15). Fraser notes substantial physical disanalogies between CSM and QFT, and concludes that the reasoning is based entirely on formal analogies.
What philosophical basis can be provided for reasoning by
analogy? What justification can be given for the claim that
analogical arguments deliver plausible conclusions? There have been several ideas for answering this question. One natural strategy assimilates analogical reasoning
to some other well-understood argument pattern, a form of deductive or
inductive reasoning (§4.1,
§4.2). A few philosophers have explored the
possibility of a priori justification
(§4.3). A pragmatic justification may be
available for practical applications of analogy, notably in legal
reasoning (§4.4).
Any attempt to provide a general justification for analogical
reasoning faces a basic dilemma. The demands of generality
require a high-level formulation of the problem and hence an abstract
characterization of analogical arguments, such as schema (4). On
the other hand, as noted previously, many analogical arguments that
conform to schema (4) are bad arguments. So a general
justification of analogical reasoning cannot provide support for all
arguments that conform to (4), on pain of proving too much. 
Instead, it must first specify a subset of putatively
‘good’ analogical arguments, and link the general
justification to this specified subset. The problem of
justification is linked to the problem of characterizing good
analogical arguments. This difficulty afflicts some of the strategies described in this section.
Analogical reasoning may be cast in a deductive mold. 
If successful, this strategy neatly solves the problem of
justification. A valid deductive argument is as good as it
gets.
An early version of the deductivist approach is exemplified by
Aristotle’s treatment of the argument from example
(§3.2), the paradeigma. On this
analysis, an analogical argument between source domain S and
target T begins with the assumption of positive analogy
P(S) and P(T), as well as the
additional information Q(S). It proceeds via
the generalization ∀x(P(x) ⊃
Q(x)) to the conclusion: 
Q(T). Provided we can treat that intermediate
generalization as an independent premise, we have a deductively valid
argument. Notice, though, that the existence of the
generalization renders the analogy irrelevant. We can derive
Q(T) from the generalization and
P(T), without any knowledge of the source domain. The literature on analogy in argumentation theory (§2.2) offers further perspectives on this type of analysis, and on the question of whether analogical arguments are properly characterized as deductive.
Some recent analyses follow Aristotle in treating analogical
arguments as reliant upon extra (sometimes tacit) premises, typically
drawn from background knowledge, that convert the inference into a
deductively valid argument––but without making the source domain irrelevant. Davies and Russell introduce a
version that relies upon what they call determination rules
(Russell 1986; Davies and Russell 1987; Davies 1988). Suppose
that Q and
P1, …, Pm are
variables, and we have background knowledge that the value of
Q is determined by the values of
P1, …, Pm. In the
simplest case, where m = 1 and both P and
Q are binary Boolean variables, this reduces to
i.e., whether or not P holds determines whether or
not Q holds. More generally, the form of a
determination rule is
i.e., Q is a function of P1, …,
Pm. If we assume such a rule as part of our
background knowledge, then an analogical argument with conclusion
Q(T) is deductively valid. More precisely, and
allowing for the case where Q is not a binary variable: 
if we have such a rule, and also premises stating that the source
S agrees with the target T on all of the values
Pi, then we may validly infer that
Q(T) = Q(S). 
The “determination rule” analysis provides a clear and
simple justification for analogical reasoning. Note that, in
contrast to the Aristotelian analysis via the generalization
∀x(P(x) ⊃ Q(x)), a
determination rule does not trivialize the analogical argument. 
Only by combining the rule with information about the source domain can
we derive the value of Q(T). To illustrate by
adapting one of the examples given by Russell and Davies 
(Example 16), let’s
suppose that the value (Q) of a used car (relative to a
particular buyer) is determined by its year, make, mileage, condition,
color and accident history (the variables
Pi). It doesn’t matter if one or more
of these factors are redundant or irrelevant. Provided two cars
are indistinguishable on each of these points, they will have the same
value. Knowledge of the source domain is necessary; we
can’t derive the value of the second car from the determination
rule alone. Weitzenfeld (1984) proposes a variant of this approach, advancing
the slightly more general thesis that analogical arguments are
deductive arguments with a missing (enthymematic) premise that
amounts to a determination rule.
Do determination rules give us a solution to the problem of
providing a justification for analogical arguments? In general:
no. Analogies are commonly applied to problems such as 
 Example 8 (morphine and meperidine), where we are not even aware of all relevant factors, let alone in possession of a determination rule. Medical researchers conduct drug
tests on animals without knowing all attributes that might be relevant
to the effects of the drug. Indeed, one of the main objectives of such
testing is to guard against reactions unanticipated by theory. On the
“determination rule” analysis, we must either limit the
scope of such arguments to cases where we have a well-supported
determination rule, or focus attention on formulating and justifying
an appropriate determination rule. For cases such as animal testing,
neither option seems realistic. 
Recasting analogy as a deductive argument may help to
bring out background assumptions, but it makes little headway with the
problem of justification. That problem re-appears as the need to state and establish the plausibility of a determination rule, and that is at
least as difficult as justifying the original analogical argument.
Some philosophers have attempted to portray, and justify, analogical
reasoning in terms of some well-understood inductive argument pattern. There have been three moderately popular versions of this
strategy. The first treats analogical reasoning as generalization
from a single case. The second treats it as a kind of sampling
argument. The third recognizes the
argument from analogy as a distinctive form, but treats past
successes as evidence for future success.
Let’s reconsider Aristotle’s argument from example or
paradeigma (§3.2), but this time regard
the generalization as justified via induction from a single case (the
source domain). Can such a simple analysis of analogical
arguments succeed? In general: no.
A single instance can sometimes lead to a justified
generalization. Cartwright (1992) argues that we can sometimes
generalize from a single careful experiment, “where we have
sufficient control of the materials and our knowledge of the requisite
background assumptions is secure” (51). Cartwright thinks
that we can do this, for example, in experiments with compounds 
that have stable “Aristotelian natures.” In a similar
spirit, Quine (1969) maintains that we can have instantial confirmation
when dealing with natural kinds. 
Even if we accept that there are such cases, the objection to
understanding all analogical arguments as single-case induction is obvious: the view is simply too restrictive. Most
analogical arguments will not meet the requisite conditions. We
may not know that we are dealing with a natural kind or Aristotelian
nature when we make the analogical argument. We may not know which
properties are essential. An insistence on the ‘single-case induction’
analysis of analogical reasoning is likely to lead to skepticism
(Agassi 1964, 1988).
Interpreting the argument from analogy as single-case induction is
also counter-productive in another way. The simplistic
analysis does nothing to advance the search for criteria that help us
to distinguish between relevant and irrelevant similarities, and hence
between good and bad analogical arguments. 
On the sampling conception of analogical arguments, acknowledged
similarities between two domains are treated as statistically relevant
evidence for further similarities. The simplest version of the sampling argument is due to Mill (1843/1930). An argument from analogy, he writes, is “a
competition between the known points of agreement and the known points
of difference.” Agreement of A and B in 9
out of 10 properties implies a probability of 0.9 that B will
possess any other property of A: “we can
reasonably expect resemblance in the same proportion”
(367). His only restriction has to do with sample size: we
must be relatively knowledgeable about both A and
B. Mill saw no difficulty in using analogical reasoning
to infer characteristics of newly discovered species of plants or
animals, given our extensive knowledge of botany and zoology. But
if the extent of unascertained properties of A and B
is large, similarity in a small sample would not be a reliable guide;
hence, Mill’s dismissal of Reid’s argument about life on
 other planets (Example 2). 
The sampling argument is presented in more explicit mathematical
form by Harrod (1956). The key idea is that the known properties
of S (the source domain) may be considered a random sample of
all S’s properties—random, that is, with respect
to the attribute of also belonging to T (the target
domain). If the majority of known properties that belong to
S also belong to T, then we should expect most other
properties of S to belong to T, for it is unlikely
that we would have come to know just the common properties. In effect, Harrod proposes a binomial distribution, modeling ‘random selection’ of properties on random selection of balls from an urn.
There are grave difficulties with Harrod’s and Mill’s
analyses. One obvious difficulty is the counting
problem: the ‘population’ of
properties is poorly defined. How are we to count similarities
and differences? The ratio of shared to total known properties
varies dramatically according to how we do this. A second serious difficulty is the problem of bias: we cannot justify the assumption that the sample of known features is random. In the case of the urn, the selection
process is arranged so that the result of each choice is not influenced
by the agent’s intentions or purposes, or by prior choices. 
By contrast, the presentation of an analogical argument
is always partisan. Bias enters into the initial representation
of similarities and differences: an advocate of the argument will
highlight similarities, while a critic will play up differences. The paradigm of repeated selection from an urn seems totally inappropriate. Additional variations of the sampling approach have been developed (e.g., Russell 1988), but ultimately these versions also fail to solve either the counting problem or the problem of bias.
Section 3.6 discussed Steiner’s view that appeal to ‘Pythagorean’ analogies in physics “evokes, or should evoke,
puzzlement” (1989: 454). Liston (2000) offers a possible response:   physicists are entitled to use Pythagorean analogies on the basis of induction from their
past success:
[The scientist] can admit that no one
knows how [Pythagorean] reasoning works and argue that the very fact
that similar strategies have worked well in the past is already reason
enough to continue pursuing them hoping for success in the present
instance. (200) 
Setting aside familiar worries about arguments from success, the
real problem here is to determine what counts as a similar
strategy. In essence, that amounts to isolating the features of
successful Pythagorean analogies. As we have seen (§2.4),
nobody has yet provided a satisfactory scheme that characterizes
successful analogical arguments, let alone successful Pythagorean analogical arguments. 
An a priori approach traces the validity of a pattern of
analogical reasoning, or of a particular analogical argument, to some
broad and fundamental principle. Three such approaches will be
outlined here.
The first is due to Keynes (1921). Keynes appeals to his famous Principle of the Limitation of Independent
Variety, which he articulates as follows:
Armed with this Principle and some additional assumptions, Keynes is
able to show that in cases where there is no negative
analogy, knowledge of the positive analogy increases the
(logical) probability of the conclusion. If there is a non-trivial
negative analogy, however, then the probability of the conclusion
remains unchanged, as was pointed out by Hesse (1966). Those familiar
with Carnap’s theory of logical probability will recognize that
in setting up his framework, Keynes settled on a measure that permits
no learning from experience. 
Hesse offers a refinement of Keynes’s strategy, once again along Carnapian lines. In her (1974), she proposes what she calls the Clustering Postulate: the
assumption that our epistemic probability function has a
built-in bias towards generalization. The objections to such postulates of
uniformity are well-known (see Salmon 1967), but even if we waive
them, her argument fails. The main objection here—which also
applies to Keynes—is that a purely syntactic axiom such as the Clustering Postulate fails to discriminate between analogical arguments that are good and those that are clearly without value (according to Hesse’s own material criteria, for example). 
A different a priori strategy, proposed by Bartha
(2010), limits the scope of justification to analogical arguments that
satisfy tentative criteria for ‘good’ analogical
reasoning. The criteria are those specified by the articulation
model (§3.5). In simplified form, they
require the existence of non-trivial positive analogy and no known
critical disanalogy. The scope of Bartha’s
argument is also limited to analogical arguments directed at
establishing prima facie plausibility, rather than
degree of probability. 
Bartha’s argument rests on a principle of symmetry
reasoning articulated by van Fraassen (1989: 236): 
“problems which are essentially the same must receive essentially
the same solution.” A modal extension of this principle
runs roughly as follows: if problems might be
essentially the same, then they might have essentially the
same solution. There are two modalities here. Bartha argues
that satisfaction of the criteria of the articulation model is
sufficient to establish the modality in the antecedent, i.e., that the
source and target domains ‘might be essentially the same’
in relevant respects. He further suggests that prima
facie plausibility provides a reasonable reading of the modality
in the consequent, i.e., that the problems in the two domains
‘might have essentially the same solution.’ To call a
hypothesis prima facie plausible is to elevate it to the point
where it merits investigation, since it might be
correct.
The argument is vulnerable to two sorts of concerns. 
First, there are questions about the interpretation of the
symmetry principle. Second, there is a
residual worry that this justification, like all the others,
proves too much. The articulation model may be too
vague or too permissive.
Arguably, the most promising available defense of analogical
reasoning may be found in its application to case law (see
 Precedent and Analogy in Legal Reasoning).
Judicial decisions are based
on the verdicts and reasoning that have governed relevantly similar
cases, according to the doctrine of stare decisis (Levi 1949;
Llewellyn 1960; Cross and Harris 1991; Sunstein 1993). Individual
decisions by a court are binding on that court and lower
courts; judges are obligated to decide future cases ‘in the same
way.’ That is, the reasoning applied in an individual
decision, referred to as the ratio decidendi, must be applied
 to similar future cases (see Example 10).
In practice, of course, the situation is extremely
complex. No two cases are identical. The ratio
must be understood in the context of the facts of the original case,
and there is considerable room for debate about its generality and its
applicability to future cases. If a consensus emerges that a past
case was wrongly decided, later judgments will distinguish it
from new cases, effectively restricting the scope of the ratio
to the original case.
The practice of following precedent can be justified by two main
practical considerations. First, and above all, the practice is
conservative: it provides a relatively stable basis for
replicable decisions. People need to be able to predict the
actions of the courts and formulate plans accordingly. Stare
decisis serves as a check against arbitrary judicial
decisions. Second, the practice is still reasonably
progressive: it allows for the gradual evolution of the
law. Careful judges distinguish bad decisions; new values and a
new consensus can emerge in a series of decisions over time. 
In theory, then, stare decisis strikes a healthy balance
between conservative and progressive social values. This
justification is pragmatic. It pre-supposes a common set of
social values, and links the use of analogical reasoning to optimal
promotion of those values. Notice also that justification occurs
at the level of the practice in general; individual analogical
arguments sometimes go astray. A full examination of the nature
and foundations for stare decisis is beyond the scope of this
entry, but it is worth asking the question: might it be possible
to generalize the justification for stare decisis? Is a
parallel pragmatic justification available for analogical arguments in
general? 
Bartha (2010) offers a preliminary attempt to provide such a
justification by shifting from social values to epistemic values. 
The general idea is that reasoning by analogy is especially well suited
to the attainment of a common set of epistemic goals or values. 
In simple terms, analogical reasoning—when it conforms to
certain criteria—achieves an excellent (perhaps optimal)
balance between the competing demands of stability and
innovation. It supports both conservative epistemic values, such
as simplicity and coherence with existing belief, and progressive
epistemic values, such as fruitfulness and theoretical unification
(McMullin (1993) provides a classic list).
As emphasized earlier, analogical reasoning takes in a great deal more than analogical arguments. In this section, we examine two broad contexts in which analogical reasoning is important.
The first, still closely linked to analogical arguments, is the confirmation of scientific hypotheses. Confirmation is the process by which a
scientific hypothesis receives inductive support on the basis of
evidence (see
 evidence, 
 confirmation,
and
 Bayes’ Theorem).
Confirmation may also signify the logical
relationship of inductive support that obtains between a
hypothesis H and a proposition E that expresses the
relevant evidence. Can analogical arguments play a role, either
in the process or in the logical relationship? Arguably yes (to
both), but this role has to be delineated carefully, and several
obstacles remain in the way of a clear account.
The second context is conceptual and theoretical development in cutting-edge scientific research. Analogies are used to suggest possible extensions of theoretical concepts and ideas. The reasoning is linked to considerations of plausibility, but there is no straightforward analysis in terms of analogical arguments.
How is analogical reasoning
related to the confirmation of scientific hypotheses? The examples and philosophical discussion from earlier sections suggest that a good analogical argument can indeed provide support for a hypothesis. But there are good reasons
to doubt the claim that analogies provide actual
confirmation. 
In the first place, there is a logical difficulty. To appreciate this, let us concentrate on confirmation as a relationship between propositions. Christensen
(1999: 441) offers a helpful general characterization:
Some propositions seem to help make it rational to believe other
propositions. When our current confidence in E helps
make rational our current confidence in H, we say that
E confirms H. 
In the Bayesian model, ‘confidence’ is represented in
terms of subjective probability. A Bayesian agent starts with an
assignment of subjective probabilities to a class of
propositions. Confirmation is understood as a three-place
relation: 
E represents a proposition about accepted evidence,
H stands for a hypothesis, K for background knowledge
and Pr for the agent’s subjective probability
function. To confirm H is to raise its conditional
probability, relative to K. The shift from prior
probability Pr(H ∣ K) to posterior
probability Pr(H ∣ E ·
K) is referred to as conditionalization on
E. The relation between these two probabilities is
typically given by Bayes’ Theorem (setting aside more complex
forms of conditionalization):
For Bayesians, here is the logical difficulty: it seems that an analogical argument cannot provide confirmation. In the first place, it is not clear that we can
encapsulate the information contained in an analogical argument in a
single proposition, E. Second, even if we can formulate
a proposition E that expresses that information, it is
typically not appropriate to treat it as evidence because the information
contained in E is already part of the background,
K. This means that
E · K is equivalent to K,
and hence Pr(H ∣ E · K) =
Pr(H ∣ K). According to the Bayesian
definition, we don’t have confirmation. (This is a version of the problem of old evidence; see confirmation.)  Third, and perhaps
most important, analogical arguments are often applied to novel
hypotheses H for which the prior probability
Pr(H ∣ K) is not even defined. Again,
the definition of confirmation in terms of Bayesian conditionalization seems inapplicable.
If analogies don’t provide inductive support via ordinary
conditionalization, is there an alternative? Here we face a
second difficulty, once again most easily stated within a Bayesian
framework. Van Fraassen (1989) has a well-known objection to any
belief-updating rule other than conditionalization. This
objection applies to any rule that allows us to boost credences when
there is no new evidence. The criticism, made vivid by the tale
of Bayesian Peter, is that these ‘ampliative’ rules are
vulnerable to a
 Dutch Book. 
Adopting any such rule would lead us to acknowledge as fair a system of
bets that foreseeably leads to certain loss. Any rule of this type for analogical reasoning appears to be vulnerable to van Fraassen’s
objection. 
There appear to be at least three routes to avoiding these difficulties and finding a role for
analogical arguments within Bayesian epistemology. First, there is what we might call minimal Bayesianism. Within the
Bayesian framework, some writers (Jeffreys 1973; Salmon 1967,
1990; Shimony 1970) have argued that a ‘seriously proposed’
hypothesis must have a sufficiently high prior probability to allow it
to become preferred as the result of observation. Salmon has
suggested that analogical reasoning is one of the most important means
of showing that a hypothesis is ‘serious’ in this sense. If analogical reasoning is directed primarily towards prior
probability assignments, it can provide inductive support while
remaining formally distinct from confirmation, avoiding the logical difficulties noted above. This approach is minimally Bayesian because it provides nothing more than an entry point into the Bayesian apparatus, and it only applies to novel hypotheses. An orthodox Bayesian, such as de Finetti (de Finetti and Savage 1972,
de Finetti 1974), might have no problem in allowing that analogies
play this role.
The second approach is liberal Bayesianism: we can change our prior probabilities in a non-rule-based fashion. Something along these lines is needed if analogical arguments are supposed to shift opinion about an already existing hypothesis without any new evidence. This is common in fields such as archaeology, as part of a strategy that Wylie refers to as “mobilizing old data as new evidence” (Wylie and Chapman 2016: 95). As Hawthorne (2012) notes, some Bayesians simply accept that both initial
assignments and ongoing revision of prior probabilities (based
on plausibility arguments) can be rational, but
the logic of Bayesian induction (as described here) has
nothing to say about what values the prior plausibility assessments
for hypotheses should have; and it places no restrictions on how they
might change.
In other words, by not stating any rules for this type of probability revision, we avoid the difficulties noted by van Fraassen. This approach admits analogical reasoning into the Bayesian tent, but acknowledges a dark corner of the tent in which
rationality operates without any clear rules. 
Recently, a third approach has attracted interest: analogue
confirmation or confirmation via analogue simulation. As
described in (Dardashti et al. 2017), the idea is as follows: 
 Our key idea is that, in certain circumstances,
predictions concerning inaccessible phenomena can be confirmed via an
analogue simulation in a different system. (57)
Dardashti and his co-authors concentrate on a particular example
(Example 17):
‘dumb holes’ and other analogues to gravitational black
holes (Unruh 1981; Unruh 2008). Unlike real black holes, some of these
analogues can be (and indeed have been) implemented and studied in the
lab. Given the exact formal analogy between our models for these
systems and our models of black holes, and certain important
additional assumptions, Dardashti et al. make the controversial claim
that observations made about the analogues provide evidence about
actual black holes. For instance, the observation of phenomena
analogous to Hawking radiation in the analogue systems would provide
confirmation for the existence of Hawking radiation in black holes. In
a second paper (Dardashti et al. 2018, Other Internet Resources), the
case for confirmation is developed within a Bayesian framework. 
The appeal of a clearly articulated mechanism for analogue
confirmation is obvious. It would provide a tool for exploring
confirmation of inaccessible phenomena not just in cosmology, but also
in historical sciences such as archaeology and evolutionary biology,
and in areas of medical science where ethical constraints rule out
experiments on human subjects. Furthermore, as noted by Dardashti et
al., analogue confirmation relies on new evidence obtained
from the analogue system, and is therefore not vulnerable to the
logical difficulties noted above.
Although the concept of analogue confirmation is not entirely new
(think of animal testing, as in
 Example 8), the claims of (Dardashti et al. 2017, 2018 [Other
Internet Resources]) require evaluation. One immediate difficulty for
the black hole example: if we think in terms of ordinary analogical
arguments, there is no positive analogy because, to put it
simply, we have no basis of known similarities between a ‘dumb
hole’ and a black hole. As Crowther et al. (2018, Other Internet
Resources) argue, “it is not known if the particular modelling
framework used in the derivation of Hawking radiation actually
describes black holes in the first place.” This may not
concern Dardashti et al., since they claim that analogue confirmation
is distinct from ordinary analogical arguments. It may turn out that
analogue confirmation is different for cases such as animal testing,
where we have a basis of known similarities, and for cases where our
only access to the target domain is via a theoretical model. 
In §3.6, we saw that practice-based studies of analogy provide insight into the criteria for evaluating analogical arguments. Such studies also point to dynamical or programmatic roles for analogies, which appear to require evaluative frameworks that go beyond those developed for analogical arguments.
Knuttila and Loettgers (2014) examine the role of analogical reasoning in synthetic biology, an interdisciplinary field that draws on physics, chemistry, biology, engineering and computational science. The main role for analogies in this field is not the construction of individual analogical arguments but rather the development of concepts such as “noise” and “feedback loops”. Such concepts undergo constant refinement, guided by both positive and negative analogies to their analogues in engineered and physical systems. Analogical reasoning here is “transient, heterogeneous, and programmatic” (87). Negative analogies, seen as problematic obstacles for individual analogical arguments, take on a prominent and constructive role when the focus is theoretical construction and concept refinement.
Similar observations apply to analogical reasoning in its application to another cutting-edge field: emergent gravity. In this area of physics, distinct theoretical approaches portray gravity as emerging from different microstructures (Linneman and Visser 2018). “Novel and robust” features not present at the micro-level emerge in the gravitational theory. Analogies with other emergent phenomena, such as hydrodynamics and thermodynamics, are exploited to shape these proposals. As with synthetic biology, analogical reasoning is not directed primarily towards the formulation and assessment of individual arguments. Rather, its role is to develop different theoretical models of gravity.
These studies explore fluid and creative applications of analogy to shape concepts on the front lines of scientific research. An adequate analysis would certainly take us beyond the analysis of individual analogical arguments, which have been the focus of our attention. Knuttila and Loettgers (2014) are led to reject the idea that the individual analogical argument is the “primary unit” in analogical reasoning, but this is a debatable conclusion. Linneman and Visser (2018), for instance, explicitly affirm the importance of assessing the case for different gravitational models through “exemplary analogical arguments”:
 We have taken up the challenge of making explicit
arguments in favour of an emergent gravity paradigm… That arguments
can only be plausibility arguments at the heuristic level does not
mean that they are immune to scrutiny and critical assessment tout
court. The philosopher of physics’ job in the process of
discovery of quantum gravity… should amount to providing exactly this
kind of assessments. (Linneman and Visser 2018: 12)
Accordingly, Linneman and Visser formulate explicit analogical arguments for each model of emergent gravity, and assess them using familiar criteria for evaluating individual analogical arguments. Arguably, even the most ambitious heuristic objectives still depend upon considerations of plausibility that benefit by being expressed, and examined, in terms of analogical arguments.