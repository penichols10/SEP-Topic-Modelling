It is not uncommon for humans to find themselves with the intuition
that random, unplanned, unexplained accident just
couldn’t produce the order, beauty, elegance, and
seeming purpose that we experience in the natural world around us. As
Hume’s interlocutor Cleanthes put it, we seem to see “the
image of mind reflected on us from innumerable objects” in
nature. (Hume 1779 [1998], 35). And many people find themselves
convinced that no explanation for that mind-resonance which
fails to acknowledge a causal role for intelligence, intent and
purpose in nature can be seriously plausible.
Cosmological arguments often begin with the bare fact that there are
contingently existing things and end with conclusions concerning the
existence of a cause with the power to account for the
existence of those contingent things. Others reason from the
premise that the universe has not always existed to a cause that
brought it into being. Teleological arguments (or arguments from
design) by contrast begin with a much more specialized catalogue
of properties and end with a conclusion concerning the existence of a
designer with the intellectual properties (knowledge,
purpose, understanding, foresight, wisdom, intention) necessary to
design the things exhibiting the special properties in
question. In broad outline, then, teleological arguments focus upon
finding and identifying various traces of the operation of a mind in
nature’s temporal and physical structures, behaviors and paths.
Order of some significant type is usually the starting point
of design arguments. 
Design-type arguments are largely unproblematic when based upon things
nature clearly could not or would not produce (e.g.,
most human artifacts), or when the intelligent agency is itself
‘natural’ (human, alien, etc.). Identifying designed
traces of ‘lost’ human civilizations or even non-human
civilizations (via SETI) could in principle be uncontroversial.
Objections to design inferences typically arise only when the posited
designer is something more exotic or perhaps supernatural. 
But despite the variety of spirited critical attacks they have
elicited, design arguments have historically had and continue to have
widespread intuitive appeal—indeed, it is sometimes claimed that
design arguments are the most persuasive of all purely philosophical
theistic arguments. Note that while design arguments have
traditionally been employed to support theism over metaphysical
naturalism, some might also be relevant for panentheism, panpsychism,
and other views involving irreducible teleology.
The historical arguments of interest are precisely the potentially
problematic ones—inferences beginning with some empirical
features of nature and concluding with the existence of a designer. A
standard but separable second step—the natural theology
step—involves identifying the designer as God, often via
particular properties and powers required by the designing in
question. Although the argument wielded its greatest intellectual
influence during the 18th and early 19th centuries, it goes back at
least to the Greeks and in extremely clipped form comprises one of
Aquinas’s Five Ways. It was given a fuller and quite nice early
statement by Hume’s interlocutor Cleanthes (1779 [1998],
15).
The question remains, however, about the formal structure of such
arguments. What sort of logic is being employed? As it turns out, that
question does not have just a single answer. Several distinct answers
are canvassed in the following sections.
Design arguments are routinely classed as analogical
arguments—various parallels between human artifacts and certain
natural entities being taken as supporting parallel conclusions
concerning operative causation in each case. The standardly ascribed
schema is roughly thus:
Schema 1:
Therefore
(The relevant respects and properties R are referred to
variously as teleological properties or as marks or
signs of design, and objects having such properties are
sometimes referred to as teleological objects. For simplicity
and uniformity of discussion, I shall simply talk in terms of
“Rs”.)
This general argument form was criticized quite vigorously by Hume, at
several key steps. (Hume’s primary critical discussion is
contained in (Hume 1779 [1998]). Hume’s responses are widely
taken as the paradigm philosophical refutation of traditional design
arguments.) Against (1), Hume argued that the analogy is not very
good—that nature and the various things in it are not
very like human artifacts and exhibit substantial differences
from them—e.g., living vs. not, self-sustaining vs. not. Indeed,
whereas advocates of design arguments frequently cited similarities
between the cosmos on the one hand and human machines on the other,
Hume suggested (tongue perhaps only partly in cheek) that the cosmos
much more closely resembled a living organism than a machine. But if
the alleged resemblance is in relevant respects distant, then the
inference in question will be logically fragile. And while (2) may be
true in specific cases of human artifacts a, that fact is
only made relevant to natural phenomena e via (3), which
underpins the transfer of the key attribution. Against (3), Hume
argued that any number of alternative possible explanations could be
given of allegedly designed entities in nature—chance, for
instance. Thus, even were (1) true and even were there
important resemblances, the argument might confer little probabilistic
force onto the conclusion.
More generally, Hume also argued that even if something like the
stated conclusion (4) were established, that left the arguer far from
anything like a traditional conception of God. For instance, natural
evils or apparently suboptimal designs might suggest e.g., an amateur
designer or a committee of designers. And if phenomena instrumental to
the production of natural evils (e.g., disease microorganisms)
exhibited various of the Rs, then they would presumably have
to be laid at the designer’s door, further eroding the
designer’s resemblance to the wholly good deity of tradition.
And even the most impressive empirical data could properly establish
only finite (although perhaps enormous) power and wisdom, rather than
the infinite power and wisdom usually associated with divinity. But
even were one to concede some substance to the design argument’s
conclusion, that would, Hume suggested, merely set up a regress. The
designing agent would itself demand explanation, requiring ultimately
a sequence of prior analogous intelligences producing intelligences.
And even were the existence of a designer of material things
established, that did not yet automatically establish the existence of
a creator of the matter so shaped. And since analogical
arguments are a type of induction (see the entry on
 analogy and analogical reasoning),
 the conclusion even if established would be established only to some,
perhaps insignificant, degree of probability. Furthermore, we could
not ground any induction concerning the cosmos itself upon a requisite
fund of experiences of other cosmoi found to be both deliberately
designed and very like ours in relevant respects—for
the simple reason that this universe is our only sample. And finally
the fraction of this one cosmos (both spatially and temporally)
available to our inspection is extraordinarily small—not a
promising basis for a cosmically general conclusion. Hume concluded
that while the argument might constitute some limited grounds for
thinking that “the cause or causes of order in the universe
probably bear some remote analogy to human intelligence”
(Hume 1779 [1998], 88) Hume’s emphasis)—and that is not a
trivial implication—it established nothing else whatever.
Historically, not everyone agreed that Hume had fatally damaged the
argument. It is simply not true that explanatory inferences cannot
properly extend beyond merely what is required for known effects. As a
very general example, based on the few observations which humans had
made during a cosmically brief period in a spatially tiny part of the
cosmos, Newton theorized that all bits of matter at
all times and in all places attracted all
other bits of matter. There was nothing whatever logically suspect
here. Indeed, simplicity and uniformity considerations—which
have considerable well-earned scientific clout—push in the
direction of such generalizations.
But Hume certainly identified important places within the argument to
probe. First, any two (groups of) things have infinitely many
properties in common and also differ in infinitely many respects.
Whether or not artifacts and natural objects are alike in ways that
would support transfer of design attributions from the former to the
latter depends upon exactly what the relevant Rs are. Second,
whether there really are alternative means of producing Rs
independent of any mind input is often an empirical matter, which
cannot be settled either way by simple stipulation. On the other hand,
whether some of Hume’s own remarks are to the point depends upon
whether or not the strongest design arguments are analogical. And
whether Hume’s suggestions are correct concerning the uncertain
character of any designer inferred will depend upon the specific
Rs and upon what can or cannot be definitively said
concerning requirements for their production.
Key questions, then, include: what are the relevant Rs
typically cited? do those Rs genuinely signal purpose and
design? how does one show that either way? are there viable
alternative accounts of the Rs requiring no reference to
minds? how does one show that either way? The specific
Rs in question are obviously central to design argument
efforts. Although the underlying general category is, again, some
special type of orderliness, the specifics have ranged rather widely
historically. Among the more straightforwardly empirical are inter
alia uniformity, contrivance, adjustment of means to ends,
particularly exquisite complexity, particular types of functionality,
delicacy, integration of natural laws, improbability, and the fitness
(fine-tuning) of the inorganic realm for supporting life. Several
problematic proposals that are empirically further removed and have
axiological overtones have also been advanced, including the
intelligibility of nature, the directionality of evolutionary
processes, aesthetic characteristics (beauty, elegance, and the like),
apparent purpose and value (including the aptness of our world for the
existence of moral value and practice) and just the sheer niftiness of
many of the things we find in nature.
Many of the specific Rs advanced historically were vulnerable
to substantive critiques, often increasingly so as time went on.
Specifically, while it was clearly evident that various
a’s had the R character they did in virtue of
their (human) intentional production, it was much more difficult
establishing that any or all other occurrences of R likely
owed their existence to intention as well. As the standard story has
it, science increasingly acquired understandings of how nature unaided
by deliberate intent and planning could produce virtually any
R proposed, and thus while (2) might continue to hold for
virtually any human artifact a having any intended R
one might please, (3)—and the inference to (4)—became
progressively less defensible. Design, on this telling, might
gradually be explained away.
But some advocates of design arguments had been reaching for a deeper
intuition. The intuition they were attempting to capture involved
properties that in and of themselves constituted some degree of
evidence for design—properties that were not merely constantly
conjoined, for whatever reason, with instances of design. The specific
Rs were singled out not just because such properties happened
to be often or even only produced by designing agents. (Garbage heaps
fit that description.) Advocates were convinced that the
appropriate Rs in question were in their own right directly
reflective of and redolent of cognition, that this directly suggested
mind, that we could see nearly directly that they were the
general sort of thing that a mind might or even
would generate, and that consequently they did not depend for
their evidential force upon previously established constant
conjunctions or other associations with known instances of design.
When we see a text version of the Gettysburg Address, that text says
mind to us in a way totally unrelated to any
induction or analogy from past encounters with
written texts. It was that type of testimony to mind, to design, that
some historical advocates of design arguments believed that they found
in some Rs observed in nature—a testimony having no
dependency on induction or analogy. Beauty, purpose and in general
value especially when conjoined with delicate complexity were
popular underlying intuitive marks. Intricate, dynamic, stable,
functioning order of the sort we encounter in nature was frequently
placed in this category. Such order was taken to be suggestive of
minds in that it seemed nearly self-evidently the sort of thing minds,
and so far as was definitively known, only minds were prone to
produce. It was a property whose mind-resonating character we
could unhesitatingly attribute to intent.
Despite Hume’s earlier demurs that things in nature are not
really very like artifacts such as machines, most people (including
opponents of design arguments) who are most familiar with
nature’s dazzling intricacies freely admit that nature abounds
with things that look designed—that are
intention-shaped. For instance, Francis Crick (no fan of
design) issued a warning to his fellow biologists:
Along with this perception of mind-suggestiveness went a further
principle—that the mind-suggestive or intention-shaped (the
design-like) characteristics in question were too palpable to
have been generated by non-intentional means.
That allows specification of a second design inference pattern:
Schema 2:
Therefore
Notice that explicit reference to human artifacts has dropped
out of the argument, and that the argument is no longer comparative
but has become essentially deductive. Some arguments were historically
intended as arguments of that type. Consider the widely reproduced
opening passages of William Paley’s 1802 Natural
 Theology:[1]
Although Paley’s argument is routinely construed as analogical,
it in fact contains an informal statement of the above variant
argument type. Paley goes on for two chapters discussing the watch,
discussing the properties in it which evince design, destroying
potential objections to concluding design in the watch, and discussing
what can and cannot be concluded about the watch’s designer. It
is only then that entities in nature—e.g., the eye—come
onto the horizon at all. Obviously, Paley isn’t making such
heavy weather to persuade his readers to concede that the watch really
is designed and has a designer. He is, in fact, teasing out the bases
and procedures from and by which we should and should not reason about
design and designers. Thus Paley’s use of the term
‘inference’ in connection with the watch’s
 designer.[2]
Once having acquired the relevant principles, then in Chapter 3 of
Natural Theology—“Application of the
Argument”—Paley applies the same
argument (vs. presenting us with the other half of the analogical
argument) to things in nature. The cases of human artifacts and nature
represent two separate inference instances:
But the instances are instances of the same inferential
move:
The watch does play an obvious and crucial role—but as a
paradigmatic instance of design inferences rather than as the
analogical foundation for an inferential comparison.
Schema 2, not being analogically structured, would not be vulnerable
to the ills of
 analogy,[3]
 and not being inductive would claim more than mere probability for
its conclusion. That is not accidental. Indeed, it has been argued
that Paley was aware of Hume’s earlier attacks on analogical
design arguments, and deliberately structured his argument to avoid
the relevant pitfalls (Gillispie 1990, 214–229).
First, how are we to assess the premises required by this schema?
Premise (5), at least, is not particularly controversial even now.
Crick’s earlier warning to biologists would have been pointless
were there no temptation toward design attributions, and even as
implacable a contemporary opponent of design arguments as Richard
Dawkins characterized biology as:
Day-to-day contemporary biology is rife with terms like
‘design’, ‘machine’, ‘purpose’ and
allied terms. As historian of science Timothy Lenoir has remarked:
Whether or not particular biological phenomena are designed, they are
frequently enough design-like to make design language not
only fit living systems extraordinarily well, but to undergird
generation of fruitful theoretical conceptions as
 well.[4]
 Advocates of design arguments claim that the reason why theorizing
as if organisms are designed meets with such success is that
organisms are in fact designed. Those opposed would say that
all teleological concepts in biology must, in one way or another, be
reduced to natural selection.
However principle (6) (that the relevant design-like properties are
not producible by unguided natural means) will be more problematic in
evolutionary biology. What might be the rational justification for
(6)? There are two broad possibilities.
1. Empirical: induction. Induction essentially involves
establishing that some principle holds within the realm of our
knowledge/experience (the sample cases), and then, subject to
certain constraints, generalizing the principle to encompass relevant
areas beyond that realm (the test cases). The attempt to
establish the universality of a connection between having relevant
Rs and being a product of mind on the basis of an observed
consistent connection between having relevant Rs and being a
product of mind within all (most) of the cases where both R
was exhibited and we knew whether or not the phenomenon in
question was a product of mind, would constitute an inductive
generalization.
This approach would suffer from a variety of weaknesses. The
R-exhibiting things concerning which we knew whether they
were designed would be almost without exception human artifacts,
whereas the phenomena to which the generalization was being extended
would be almost without exception things in a very different
category—things in nature. And, of course, the generalization in
question could establish at best a probability, and a fairly modest
one at that.
2. Conceptual. It might be held that (6) is known in the same
conceptual, nearly a priori way in which we know
that textbooks are not producible by natural processes unaided by
mind. And our conviction here is not based on any mere induction from
prior experiences of texts. Texts carry with them essential marks of
mind, and indeed in understanding a text we see at least partway into
the mind(s) involved. Various alien artifacts (if any)—of which
we have had no prior experience whatever—could fall into this
category as well. Similarly, it has been held that we sometimes
immediately recognize that order of the requisite sort just
is a sign of mind and intent.
Alternatively, it could be argued that although there is a genuine
conceptual link between appropriate Rs and mind, design,
intent, etc., that typically our recognition of that link is
triggered by specific experiences with artifacts, or that our seeing
the connections in depth is best elicited by considerations involving
artifacts. (Both Aristotle and Galileo held a correlate of this view
concerning our acquiring knowledge of the general principles governing
nature.) On this view, once the truth of (6) became manifest to us
through experiences of artifacts, the appropriateness of its more
general application would be clear. That might explain why so many
advocates of design arguments—both historical and
current—seem to believe that they must only display a
few cases and raise their eyebrows to gain assent to design.
Either way, principle (6), or something like it, would be something
with which relevant design inferences would begin. Further
investigation of (6) requires taking a closer look at the Rs
which (6) involves.
One thing complicating general assessments of design arguments is that
the evidential force of specific Rs is affected by the
context of their occurrence. Specifically, properties which seem
clearly to constitute marks of design in known artifacts often seem to
have significantly less evidential import outside that context. For
instance, we typically construe enormous complexity in something known
to be a manufactured artifact as a deliberately intended and produced
characteristic. But mere complexity in contexts not taken to involve
artifacts (the precise arrangement of pine needles on a forest floor,
for instance) does not seem to have that same force. In the case of
natural objects with evident artifactuality absent, it is less clear
that such complexity—as well as the other traditional empirical
Rs—bespeaks intention, plan and purpose. Similarly,
absolutely straight lines in an artifact are typically results of
deliberate intention. That straight lines traveled by light rays is so
would seem to many to be less obvious.
Furthermore, even within those two contexts—artifact and
nature—the various Rs exhibit varying degrees of
evidential force. For instance, even in an artifact, mere complexity
of whatever degree speaks less clearly of intent than does an engraved
sentence. As most critics of design arguments point out, the examples
found in nature are not of the “engraved sentence”
sort.
There are two crucial upshots. First, if complexity alone is cited,
that complexity may not clearly speak of intent. Second, although the
exhibiting of genuine purpose and value might constitute persuasive
evidence of a designer, establishing that the empirical
characteristics in question really do betoken genuine purpose and
value—and not just, say, functionality—seems to many to be
difficult if not
 impossible.[5]
Evidential ambiguity would virtually disappear if it became clear that
there is no plausible means of producing some R independent
of deliberate intent. Part of the persuasiveness of (6) historically
came from absence of any known plausible non-intentional alternative
causal account of the traditional Rs. Such cases are often
linked to alleged gaps in nature—phenomena for which, it is
claimed, there can be no purely natural explanation, there being a gap
between nature’s production capabilities and the phenomenon in
question. (For example, nature’s unaided capabilities fall short
of those capabilities required for producing a radio. Thus, when we
see a radio we know that something else—human agency—was
involved in its production.) Design cases resting upon nature’s
alleged inability to produce some relevant ‘natural’
phenomenon are generally assumed to explicitly or implicitly appeal to
supernatural agency, and are typically described as
“God-of-the-gaps” arguments—a description usually
intended to be pejorative.
But evidence of design in nature does not automatically imply gaps.
Design built or “front-loaded” into nature from the very
beginning would require no further interventions within the historical
flow of nature and therefore no gaps. But since the artifact/nature
divide parallels the gap/non-gap divide, one way the implausibility of
alternative means of production could become exceptionally clear was
if R were associated with a gap in nature’s
capabilities—if the unaided course of nature genuinely could not
or would not produce R, yet we see R in
‘nature’. In such a case, the appeal to agency would be
virtually inevitable. 
The position that there are gaps in nature is not inherently
irrational—and would seem to be a legitimate empirical question.
But although gaps would profoundly strengthen design arguments, they
have their own suite of difficulties. Gaps are usually easy to spot in
cases of artifactuality, but although they may be present in nature,
establishing their existence there can usually be done (by
science, at least) only indirectly—via probability
considerations, purported limitations on nature’s abilities,
etc.
Several possible snags lurk. Gaps in nature would, again, suggest
supernatural agency, and some take science to operate under an
obligatory exclusion of such. This prohibition—commonly known as
methodological naturalism—is often claimed (mistakenly,
some argue) to be definitive of genuine
 science.[6]
 ‘Established’ limitations both on science and on nature
can and have been overturned in the past. The possibility of discovery
(or postulation) of alternative ‘natural’ means of
production would constitute a standing threat to any argument resting
in part on a perceived absence of such means. And the spotty track
record of alleged gaps provides at least a cautionary note. Such
considerations will complicate attempts to very firmly establish
design empirically on the basis of the types of properties we usually
find in nature.
The way that alleged gaps typically disappear is, of course, through
new proposed scientific theories postulating means of natural
production of phenomena previously thought to be beyond nature’s
capabilities. The most obvious example of that is, of course,
Darwin’s evolutionary theory and its descendants.
Some philosophers of science claim that in a wide variety of
scientific cases we employ an “inference to the best
explanation”
 (IBE).[7]
 The basic idea is that if one among a number of competing candidate
explanations is overall superior to others in significant
respects—enhanced likelihood, explanatory power and scope,
causal adequacy, plausibility, evidential support, fit with
already-accepted theories, predictiveness, fruitfulness, precision,
unifying power, and the like—then we are warranted in
(provisionally) accepting that candidate as the right explanation
given the evidence in question (Lipton 1991, 58). Some advocates see
design arguments as inferences to the best explanation, taking design
explanations—whatever their weaknesses—as prima
facie superior to chance, necessity, chance-driven evolution, or
whatever.
A general schema deployed in the current case would give us the
following:
Schema 3:
Therefore (probably)
In arguments of this type, superior explanatory virtues of a theory
are taken as constituting decisive epistemic support for theory
acceptability, warranted belief of the theory, and likely truth of the
theory. There are, of course, multitudes of purported explanatory,
epistemic virtues, including the incomplete list a couple paragraphs
back (and lists of such have evolved over time). Assessing hypotheses
in terms of such virtues is frequently contentious, depending, as it
does, on perceptions of ill-defined characteristics, differences in
background conceptual stances, and the like. Still, in general we
frequently manage rough and ready resolutions.
One key underlying structure in this context is typically traced to
Peirce’s notion of abduction. Suppose that some
otherwise surprising fact e would be a reasonably expectable
occurrence were hypothesis h true. That, Peirce
argued, would constitute at least some provisional reason for thinking
that h might actually be true. Peirce’s own
characterization was as follows (Peirce 1955, 151):
Schema 3:
Hence,
The measure of C being a ‘matter of course’ given
A is frequently described as the degree to which C could
be expected were A in fact true. This intuition is
sometimes—though explicitly not by Peirce
himself—formalized in terms of likelihood, defined as
follows:
The likelihood of h is the probability of finding evidence
e given that the hypothesis h is true. In cases of
competing explanatory hypotheses—say h1 and
h2—the comparative likelihoods on specified
evidence can be taken to indicate which of the competitors specific
pieces of evidence differentially support, i.e.:
Higher likelihood of h1 than h2 on
specific evidence does not automatically imply that
h1 should be accepted, is likely to be true, or is
better in some overall sense than is h2.
h1 might, in fact, be a completely lunatic theory
which nonetheless entails e, giving h1 as
high a likelihood as possible. Such maximal likelihood relative to
e would not necessarily alter h1’s
lunacy. Likelihood thus does not automatically translate into a
measure of how strongly some specific evidence e supports the
hypothesis h1 in question (Jantzen 2014a, Chap.
11).
This, then, leads directly to Bayesian probability theory. While the
Bayesian approach is undoubtedly more rigorous than appeals to IBE,
few teleological arguments are presented in these terms. For a
contrast between IBE and Bayesianism, see
 abduction.
 For an important recent critique of theistic design arguments in
Bayesian terms, see (Sober 2009), and the reply by (Kotzen (2012), and
Jantzen’s response (2014b).
Whatever one’s view of Bayesianism, IBEs have their own
shortcomings. The assessment of ‘best’ is not only a
value-tinged judgment, but is notoriously tricky (especially given the
ambiguous and hard to pinpoint import of the Rs in the
present case). There is also the very deep question of why we should
think that features which we humans find attractive in proposed
explanations should be thought to be truth-tracking. What sort of
justification might be available here? Furthermore, taking design to
be the best explanation for something requires prior identification of
the appropriate properties as design-relevant, and that recognition
must have a different
 basis.[8]
 And again, substantive comparison can only involve known
alternatives, which at any point represent a vanishingly small
fraction of the possible alternatives. Choosing the best of the known
may be the best we can do, but many would insist that without some
further suppressed and significant assumptions, being the best (as
humans see it) of the (humanly known) restricted group does not
warrant ascription of truth, or anything like it.
There are other potential issues here as well. Sober argues that
without additional very specific assumptions about the putative
designer we could specify no particular value for P(e | h)—e.g., the likelihood that a designer would
produce vertebrate eyes with the specific features we observe them to
have: and that depending on the specific assumptions made we could
come up with any value from 0 to 1 (e.g., Sober 2003, 38).
There is also the potential problem of new, previously unconsidered
hypotheses all lumped together in the catch-all basket. Without
knowing the details of what specific unconsidered hypotheses might
look like, there is simply no plausible way to anticipate the apparent
likelihood of a novel new hypothesis—let alone its other
potential explanatory virtues. This, on some views, is essentially
what happened with traditional design arguments—such arguments
were the most reasonable available until Darwinian evolution provided
a plausible (or better) alternative the details and likelihood of
which were not previously anticipatable. 
Without going into the familiar details, Darwinian processes fueled by
undesigned, unplanned, chance variations that are in turn conserved or
eliminated by way of natural selection would, it is argued, over time
produce organisms exquisitely adapted to their environmental
 niches.[9]
 And since many of the characteristics traditionally cited as
evidences of design just were various adaptations, evolution
would thus produce entities exactly fitting traditional criteria of
design. Natural selection, then, unaided by intention or intervention
could account for the existence of many (perhaps all) of the
Rs which we in fact find in biology. (A parallel debate can
be found between those who believe that life itself requires a design
explanation (Meyer 2009) and those proposing naturalistic explanations
(see the entry on
 life.)
That was—and is—widely taken as meaning that design
arguments depending upon specific biological gaps would be
weakened—perhaps fatally.
Premise (10)—not to mention the earlier (6)—would thus
look to simply be false. What had earlier appeared to be
purpose (requiring intent) was now apparently revealed as
mere unintended but successful and preserved function.
Of course, relevant premises being false merely undercuts the relevant
schemas in present form—it does not necessarily refute either
the basic design intuition or other forms of design arguments. But
some critics take a much stronger line here. Richard Dawkins, for
instance, subtitles one of his books: “Why the evidence of
evolution reveals a universe without design” (Dawkins, 1987).
Typically underlying claims of this sort is the belief that Darwinian
evolution, by providing a relevant account of the origin and
development of adaptation, diversity, and the like, has explained away
the alleged design in the biological realm—and an attendant
designer—in much the same way that kinetic theory has explained
away caloric. Indeed, this is a dominant idea underlying current
responses to design arguments. However, undercutting and explaining
away are not necessarily the same thing, and exactly what explaining
away might mean, and what a successful explaining away might require
are typically not clearly specified. So before continuing, we need
clarity concerning some relevant conceptual landscape.
That an alleged explanatory factor α is provisionally explained
away requires that there be an alternative explanation Σ meeting
these conditions:
However, (a) – (d) are incomplete in a way directly relevant to
the present discussion. Here is a very simple case. Suppose that an
elderly uncle dies in suspicious circumstances, and a number of the
relatives believe that the correct explanation is the direct agency of
a niece who is primary heir, via deliberately and directly
administering poison. However, forensic investigation establishes that
the cause of death was a mix-up among medications the uncle was
taking—an unfortunate confusion. The suspicious relatives,
however, without missing an explanatory beat shift the niece’s
agency back one level, proposing that the mix-up itself was
orchestrated by the niece—switching contents of prescription
bottles, no doubt. And that might very well turn out to be the
truth.
In that sort of case, the α in question (e.g., niecely agency)
is no longer directly appealed to in the relevant initial explanatory
level, but is not removed from all explanatory relevance to the
phenomenon in question. In general, then, for α to be explained
away in the sense of banished from all explanatory relevance the
following condition must also be met:
Roughly this means that Σ does not depend essentially on any
part β of any prior explanation where α is essential to
β. There are some additional possible technical qualifications
required, but the general intuition should be clear. 
Thus, e.g., whereas there was no need to appeal to caloric at some
prior or deeper level, with design, according to various design
advocates, there is still an explanatory lacuna (or implicit
promissory note) requiring reference to design at some explanatory
level prior to Darwinian evolution. Indeed, as some see it (and as
Paley himself suggested), there are phenomena requiring explanation in
design terms which cannot be explained away at any prior explanatory
level (short of the ultimate level).
That some phenomenon α has been explained away can be taken to
mean two very different things—either as 
or as 
(And often, of course, both.) 
For instance, few would assert that there is still an extant rational
case for belief in phlogiston—any explanatory work it did at the
proximate level seems to have ceased, and deeper explanatory uses for
it have never subsequently materialized. Perhaps its non-existence was
not positively established immediately, but removal of rational
justification for belief in some entity can morph into a case for
non-existence as the evidence for a rival hypothesis increases over
time.
Purported explanations can be informally divided into two broad
categories—those involving agents, agency, intention, and the
like; and those involving mechanism, physical causality, natural
processes, and the like. The distinction is not, of course, a clean
one (functioning artifacts typically involve both), but is useful
enough in a rough and ready way, and in what follows agent
explanations and mechanical explanations respectively will be used as
convenient handles. Nothing pernicious is built into either the broad
distinction or the specified terminology.
There are some instructive patterns that emerge in explanatory
level-shifting attempts, and in what immediately follows some of the
more basic patterns will be identified.
Intention, intervention, and other agency components of explanations
can very frequently be pushed back to prior levels—much as many
defenders of teleological arguments claim. The earlier case of the
alleged poisoning of the rich uncle by the niece is a simple example
of this.
But in some cases, the specifics of the agent explanation in question
may make appeal to some prior level less plausible or sensible. For
example, suppose that one held the view that crop circles were to be
explained in terms of direct alien activity. One could, upon getting
irrefutable video proof of human production of crop circles, still
maintain that aliens were from a distance controlling the brains of
the humans in question, and that thus the responsibility for crop
circles did still lie with alien activity. While this retreat of
levels preserves the basic explanation, it of course comes with a
significant cost in inherent implausibility.
And in some cases, pushing specific agency back a level seems nearly
unworkable. Suppose that the standard explanation of global warming
was human activity, but that subsequently a complete, completely
adequate, nailed down explanation in terms of solar cycles emerged.
That would seem to explain away the alleged human causation, and in
this sort of case it would be difficult to retreat back one level and
make the case that human agency and activity were actually driving the
solar cycles. 
Still the level-changing possibility is as a general rule available
with proposed agent explanations. And design typically is, of course,
an agent explanation.
Pushing specific explanatory factors back to a prior level often works
less smoothly in cases of purely mechanical/physical explanations than
in intentional/agency explanations. In many attempted mechanistic
relocation cases, it is difficult to see how the specific relocated
explanatory factor is even supposed to work, much less generate any
new explanatory traction. Exactly what would caloric do if pushed back
one level, for instance? 
Although level shifting of specific explanatory factors seems to work
less easily within purely physical explanations, relocation attempts
involving broad physical principles can sometimes avoid such
difficulties. For instance, for centuries determinism was a basic
background component of scientific explanations (apparently stochastic
processes being explained away epistemically). Then, early in the 20th
century physics was largely converted to a quantum mechanical picture
of nature as involving an irreducible indeterminism at a fundamental
level—apparently deterministic phenomena now being what was
explained away. However, DeBroglie, Bohm and others (even for a time
Einstein) tried to reinstate determinism by moving it back to an even
deeper fundamental level via hidden variable theories. Although the
hidden variable attempt is generally thought not to be successful, its
failure is not a failure of principle.
How one assesses the legitimacy, plausibility, or likelihood of the
specific counter-explanation will bear substantial weight here, and
that in turn will depend significantly on among other things
background beliefs, commitments, metaphysical dispositions, and the
like. If one has a prior commitment to some key α (e.g., to
theism, atheism, naturalism, determinism, materialism, or teleology),
or assigns a high prior to that α, the plausibility of taking
the proposed (new) explanation as undercutting, defeating, or refuting
α (and/or Σ) will be deeply affected, at least
initially.
Tilting the conceptual landscape via prior commitments is both an
equal opportunity epistemic necessity and a potential pitfall
here. Insisting on pushing an explanatory factor back a level is often
an indication of a strong prior commitment of some sort. Disagreement
over deeper philosophical or other principles will frequently generate
divergence over when something has or has not been explained away. One
side, committed to the principle, will accept a level change as
embodying a deeper insight into the relevant phenomenon. The other,
rejecting the principle, will see an ad hoc retreat to defend an
α which has in fact been explained away. 
Returning to the present issue, design argument advocates will of
course reject the claim that design, teleology, agency and the like
have been explained away either by science generally or by Darwinian
evolution in particular. Reasons will vary. Some will see any
science—Darwinian evolution included—as incompetent to say
anything of ultimate design relevance, pro or con. (Many on
both sides of the design issue fit here.) Some will see Darwinian
evolution as failing condition (a), (b) and/or (c), claiming that
Darwinian evolution is not explanatorily adequate to selected
α’s, is inadequately supported by the evidence, and is far
from superior to agency explanations of relevant phenomena.
(Creationists and some—not all—‘intelligent
design’ advocates fit here.) Some will argue that a Darwinian
failure occurs at (d), citing e.g., a concept of information
claimed to be both essential to evolution and freighted with agency.
(Some intelligent design advocates (e.g., Dembski, 2002 and Meyer,
1998) fit here.) However, the major contention of present interest
involves (e).
Historically, design cases were in fact widely understood to allow for
indirect intelligent agent design and causation, the very
causal structures producing the relevant phenomena being themselves
deliberately designed for the purpose of producing those
 phenomena.[11]
 For instance, it was typically believed that God could have initiated
special conditions and processes at the instant of creation which
operating entirely on their own could produce organisms and other
intended (and designed) results with no subsequent agent intervention
required. Paley himself, the authors of the Bridgewater
Treatises and others were explicitly clear that whether or not
something was designed was an issue largely separable from the means
of production in question. Historically it was insisted that design in
nature did track back eventually to intelligent agency
somewhere and that any design we find in nature would
not—and could not—have been there had there ultimately
been no mind involved. But commentators (including many scientists) at
least from the early 17th century on (e.g., Francis Bacon and Robert
Boyle) very clearly distinguished the creative initiating of nature
itself from interventions within the path of nature once initiated.
For instance, over two centuries before Darwin, Bacon wrote:
Indeed, if the Rs in question did directly indicate the
influence of a mind, then means of production—whether unbroken
causation or gappy—would be of minimal evidential importance.
Thus, the frequent contemporary claim that design arguments all
involve appeal to special divine intervention during the course of
nature’s history—that in short design arguments are
“God-of-the-gaps” arguments—represents serious
historical (and present) inaccuracy (e.g., Behe, 1996).
However, if Rs result from gapless chains of natural causal
processes, the evidential impact of those Rs again threatens
to become problematic and ambiguous, since there will a
fortiori be at the immediate level a full natural causal account
for
 them.[12]
 Design will, in such cases, play no immediate mechanistic explanatory
role, suggesting its superfluousness. But even if such conceptions
were explanatorily and scientifically superfluous at that level, that
does not entail that they are conceptually, alethically, inferential,
or otherwise superfluous in general. The role of mind might be
indirect, deeply buried, or at several levels of remove from the
immediate production mechanism but would still have to be present at
some level. In short, on the above picture Darwinian evolution will
not meet condition (e) for explaining away design, which is not itself
a shortcoming of Darwinian evolution.
But any gap-free argument will depend crucially upon the Rs
in question being ultimately dependent for their eventual
occurrence upon agent activity. That issue could be integrated back
into an altered Schema 2 by replacing (6) with:
The focus must now become whether or not the laws and conditions
required for the indirect production of life, intelligent life, etc.,
could themselves be independent of intention, design and mind at some
deep (perhaps primordial, pre-cosmic) point. In recent decades,
exactly that question has arisen increasingly insistently from within
the scientific community.
Intuitively, if the laws of physics were different, the evolution of
life would not have taken the same path. If gravity were stronger, for
example, then flying insects and giraffes would most likely not exist.
The truth is far more dramatic. Even an extraordinarily small change
in one of many key parameters in the laws of physics would have made
life impossible anywhere in the universe. Consider two examples:
The expansion rate of the universe is represented by the cosmological
constant Λ. If Λ were slighter greater, there would be
no energy sources, such as stars. If it were slightly less, the Big
Bang would have quickly led to a Big Crunch in which the universe
collapsed back onto itself. For life to be possible, Λ cannot
vary more than one part in 1053 (Collins 2003)
Life depends on, among other things, a balance of carbon and oxygen in
the universe. If the strong nuclear force were different by 0.4%,
there would not be enough of one or the other for life to exist
(Oberhummer, Csótó, and Schlattl 2000). Varying this
constant either way “would destroy almost all carbon or almost
all oxygen in every star” (Barrow 2002, 155). 
Many examples of fine-tuning have to do with star formation. Stars are
important since life requires a variety of elements: oxygen, carbon,
hydrogen, nitrogen, calcium, and phosphorus. Stars contain the only
known mechanism for producing large quantities of these elements and
are therefore necessary for life. Lee Smolin estimates that when all
of the fine-tuning examples are considered, the chance of stars
existing in the universe is 1 in 10229. “In my
opinion, a probability this tiny is not something we can let go
unexplained. Luck will certainly not do here; we need some rational
explanation of how something this unlikely turned out to be the
case” (Smolin 1999, 45). Smolin is not merely claiming that all
improbable events require an explanation, but some improbable events
are special. (In poker, every set of five cards dealt to the dealer
has the same probability, assuming that the cards are shuffled
sufficiently. If the dealer is dealt a pair on three successive hands,
no special explanation is required. If the dealer is dealt a royal
flush on three successive hands, an explanation would rightly be
demanded, and the improbability of this case isn’t even close to the
magnitude of the improbability that Smolin mentioned.)  Physicists who
have written on fine-tuning agree with Smolin that it cries out for an
explanation. One explanation is that the universe appears to be
fine-tuned for the existence of life because it literally has been
constructed for life by an intelligent
agent.
There are two other types of responses to fine-tuning: (i) it does
not, in fact, require a special explanation, and (ii) there are
alternative explanations to theistic design. Let’s briefly
consider these (also see the entry on
 fine-tuning).
Three approaches have been taken to undermine the demand for
explanation presented by fine-tuning.
In a sense, it is necessary for the fine-tuned constants to have
values in the life-permitting range: If those values were not within
that range, people would not exist. The fine-tuned constants
must take on the values that they have in order for
scientists to be surprised by their discovery in the first place. As a
matter of fact, they could not have discovered anything else.
According to the weak anthropic principle, we ought not be surprised
by having made such a discovery, since no other observation was
possible. But if we should not have been surprised to have made such a
discovery, then there is nothing unusual here that requires a special
explanation. The demand for explanation is simply misplaced.
Sober gives a related but stronger argument based on observational
selection effects (Sober 2009, 77–80). Say that Jones nets a
large number of fish from a local lake, all of which are over 10
inches long. Let hall= ‘all of the fish in the lake
are over 10 inches long’ and h1/2= ‘Half of the
fish in the lake are over 10 inches long’. The evidence e is
such that P(e | hall) >
P(e | h1/2). Now say that Jones discovers
that his net is covered with 10 inch holes, preventing him from
capturing any smaller fish. In that case, e does not favor one
hypothesis over the other. The evidence e is an artifact of the net
itself, not a random sample of the fish in the lake. 
When it comes to fine-tuning, Sober considers
hdesign=‘the constants have been set in place by an
intelligence, specifically God’, and
hchance=‘the constants are what they are as a matter
of mindless random chance’. While intuitively
one has to consider the role of the observer, who is analogous to the
net in the fishing example. Since human observers could only detect
constants in the life-permitting range, Sober argues, the correct
probabilities are
Given this equality, fine-tuning does not favor hdesign
over hchance. The selection effect prevents any
confirmation of design. 
Sober’s analysis is critiqued in (Monton 2006) and (Kotzen
2012). Also see (Jantzen 2014a, sec. 18.4). We should note that if
Sober is correct, then the naturalistic explanations for fine-tuning
considered below (4.1.2) are likewise misguided.
Let C stand for a fine-tuned parameter with physically
possible values in the range [0, ∞. If we assume that nature is
not biased toward one value of C rather than another, then
each unit subinterval in this range should be assigned equal
probability. Fine-tuning is surprising insofar as the life-permitting
range of C is tiny compared to the full interval, which
corresponds to a very small probability. 
As McGrew, McGrew, and Vestrup argue (2001), there is a problem here
in that, strictly speaking, mathematical probabilities do not apply in
these circumstances. When a probability distribution is defined over a
space of possible outcomes, it must add up to exactly 1. But for any
uniform distribution over an infinitely large space, the sum of the
probabilities will grow arbitrarily large as each unit interval is
added up. Since the range of C is infinite, McGrew et al.
conclude that there is no sense in which life-friendly universes are
improbable; the probabilities are mathematically undefined. 
One solution to this problem is to truncate the interval of possible
values. Instead of allowing C to range from [0, ∞), one
could form a finite interval [0, N], where N is very
large relative to the life-permitting range of C. A
probability distribution could then be defined over the truncated
range.
A more rigorous solution employs measure theory. Measure is sometimes
used in physics as a surrogate for probability. For example, there are
many more irrational numbers than rational ones. In measure theoretic
terms, almost all real numbers are irrational, where
“almost all” means all but a set of zero measure. In
physics, a property found for almost all of the solutions to an
equation requires no explanation; it’s what one should expect.
It’s not unusual, for instance, for a pin balancing on its tip
to fall over. Falling over is to be expected. In contrast, if a
property that has zero measure in the relevant space were actually
observed to be the case, like the pin continuing to balance on its
tip, that would demand a special explanation. Assuming one’s
model for the system is correct, nature appears to be strongly biased
against such behavior (Gibbons, Hawking, and Stewart 1987, 736). The
argument for fine-tuning can thus be recast such that almost all
values of C are outside of the life-permitting range. The
fact that our universe is life-permitting is therefore in need of
explanation.
The question of whether probabilities either do not apply or have been
improperly applied to cosmological fine-tuning continues to draw
interest. For more, see (Davies 1992), (Callender 2004), (Holder
2004), (Koperski 2005), (Manson 2009), (Jantzen 2014a, sec. 18.3), and
(Sober 2019, sec. 5.1). Manson (2018) argues that neither theism nor
naturalism provides a better explanation for fine-tuning.
Assuming that fine-tuning does require an explanation, there are
several approaches one might take (Koperski 2015, section 2.4).
That the universe is fine-tuned for life is based on current science.
But, just as many other anomalies have eventually been explained, so
might fine-tuning. Science may one day find a naturalistic answer,
eliminating the need for design. For suggestions along these lines,
see (Harnik, Kribs, and Perez 2006) and (Loeb 2014).
While this is a popular stance, it is, of course, a promissory note
rather than an explanation. The appeal to what might yet be discovered
is not itself a rival hypothesis.
It’s conceivable that life could exist in a universe with
parameter values that we do not typically believe are life-permitting.
In other words, there may be exotic forms of life that could survive
in a very different sort of universe. If so, then perhaps the
parameter intervals that are in fact life-permitting are not
fine-tuned after all. 
The main difficulty with this suggestion is that all life requires a
means for overcoming the second law of thermodynamics. Life requires
the extraction of energy from the environment. Any life-form
imaginable must therefore have systems that allow for something like
metabolism and respiration, which in turn require a minimal amount of
complexity (e.g., there can be no single-molecule life forms). Many
examples of fine-tuning do not allow for such complexity, however. If
there were no stars, for example, then there would be no stable
sources of energy and no mechanism for producing the heavier elements
in the periodic table. Such a universe would lack the chemical
building blocks needed for a living entity to extract energy from the
environment and thereby resist the pull of entropy.
While the odds of winning a national lottery are low, your odds would
obviously increase if you were to buy several million tickets. The
same idea applies to the most popular explanation for fine-tuning: a
multiverse. Perhaps physical reality consists of a massive array of
universes each with a different set of values for the relevant
constants. If there are many—perhaps infinitely
many—universes, then the odds of a life-permitting universe
being produced would seem to be much greater. While most of the
universes in the multiverse would be unfit for life, so the argument
goes, ours is one of the few where all of the constants have the
required values. 
While the philosophical literature on the multiverse continues to grow
(see (Collins 2009, 2012) and (Kraay 2014)), many of the arguments
against it share a common premise: a multiverse would not, by itself,
be a sufficient explanation of fine-tuning. More would have to be
known about the way in which universes are produced. By analogy, just
because a roulette wheel has 38 spaces does not guarantee that the
probability of Red 25 is 1/38. If the wheel is rigged in some
way—by using magnets for example—to prevent that outcome,
then the probability might be extremely small. If the table were
rigged and yet Red 25 was the actual winner, that would
require a special explanation. Likewise, if a property has zero
measure in the space of possible universes, and yet that property is
observed, its existence would still require an explanation (Earman
1987, 315). This is true regardless of whether the space of universes
is finitely or infinitely large. In order to explain fine-tuning, the
multiverse proponent would still have to show that the life-permitting
universes do not have zero measure in the space of all universes
(Koperski 2005, 307–09). 
A high-profile development in design arguments over the past 20 years
or so involves what has come to be known as Intelligent Design (ID).
Although there are variants, it generally involves efforts to
construct design arguments taking cognizance of various contemporary
scientific developments (primarily in biology, biochemistry, and
cosmology)—developments which, as most ID advocates see it, both
reveal the inadequacy of mainstream explanatory accounts (condition
(a)) and offer compelling evidence for design in nature at some level
(condition (e) again).
ID advocates propose two specialized Rs—irreducible
complexity (Behe 1996) and specified complex information
(Dembski 1998,
 2002).[13]
 Although distinctions are sometimes blurred here, while ID arguments
involving each of those Rs tend to be gap arguments,
an additional focus on mind-reflective aspects of nature is typically
more visible in ID arguments citing specified complexity than in
arguments citing irreducible complexity.
The movement has elicited vociferous criticism and opposition.
Opponents have pressed a number of objections against ID including,
inter alia contentions that ID advocates have simply gotten
the relevant science wrong, that even where the science is right the
empirical evidences cited by design advocates do not constitute
substantive grounds for design conclusions, that the existence of
demonstrably superior alternative explanations for the phenomena cited
undercuts the cogency of ID cases, and that design theories are not
legitimate science, but are just disguised creationism,
God-of-the-gaps arguments, religiously motivated, etc.
We will not pursue that dispute here except to note that even if the
case is made that ID could not count as proper science, which is
 controversial,[14]
 that would not in itself demonstrate a defect in design arguments as
such. Science need not be seen as exhausting the space of legitimate
conclusions from empirical data. In any case, the floods of vitriol in
the current ID discussion suggest that much more than the propriety of
selected inferences from particular empirical evidences is at
issue.
That question is: why do design arguments remain so durable if
empirical evidence is inferentially ambiguous, the arguments logically
controversial, and the conclusions vociferously disputed? One
possibility is that they really are better arguments than most
philosophical critics concede. Another possibility is that design
intuitions do not rest upon inferences at all. The situation
may parallel that of the existence of an external world, the existence
of other minds, and a number of other familiar matters. The 18th
century Scottish Common Sense philosopher Thomas Reid (and his
contemporary followers) argued that we are simply so constructed that
in certain normally-realized experiential circumstances we simply
find that we in fact have involuntary convictions about such
a world, about other minds, and so forth. That would explain why
historical philosophical attempts to reconstruct the
arguments by which such beliefs either arose or were justified were
such notorious failures—failures in the face of which ordinary
belief nonetheless proceeded happily and helplessly onward. If a
similar involuntary belief-producing mechanism operated with respect
to intuitions of design, that would similarly explain why
argumentative attempts have been less than universally compelling but
yet why design ideas fail to disappear despite the purported failure
of such arguments.
A number of prominent figures historically in fact held that we could
determine more or less perceptually that various things in nature were
candidates for design attributions—that they were in the
requisite respects design-like. Some, like William Whewell,
held that we could perceptually identify some things as more than mere
candidates for design (Whewell 1834, 344). Thomas Reid also held a
view in this 
region,[15] 
and Hume’s Cleanthes made suggestions in this direction.
If something like that were the operative process, then ID, in trying
to forge a scientific link to design in the sense of
inferences from empirically determined evidences would be
misconstructing the actual basis for design belief, as would be design
arguments more generally. It is perhaps telling, in this regard, that
scientific theorizing typically involves substantial creativity and
that the resultant theories are typically novel and unexpected. Design
intuitions, however, do not seem to emerge as novel construals from
creative grappling with data, but are embedded in our thinking nearly
naturally—so much so that, again, Crick thinks that biologists
have to be immunized against it. 
Perception and appreciation of the incredible intricacy and the beauty
of things in nature—whether biological or cosmic—has
certainly inclined many toward thoughts of purpose and design in
nature, and has constituted important moments of affirmation for those
who already accept design positions. The status of the corresponding
arguments of course, is not only a matter of current dispute,
but the temperature of the dispute seems to be on the rise. And
regardless of what one thinks of the arguments at this point, so long
as nature has the power to move us (as even Kant admitted that the
‘starry heavens above’ did), design convictions and
arguments are unlikely to disappear quietly.