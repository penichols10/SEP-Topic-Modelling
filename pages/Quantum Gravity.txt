Dutch artist M.C. Escher’s elegant pictorial paradoxes are
prized by many, not least by philosophers, physicists, and
mathematicians. Some of his work, for example Ascending and
Descending, relies on optical illusion to depict what is actually
an impossible situation. Other works are paradoxical in the broad
sense, but not impossible: Relativity depicts a
coherent arrangement of objects, albeit an arrangement in which the
force of gravity operates in an unfamiliar fashion. (See the
 Other Internet Resources
 section below for images.) Quantum gravity itself may be like this:
an unfamiliar yet coherent arrangement of familiar elements. Or it may
be more like Ascending and Descending, an impossible
construction which looks sensible in its local details but does not
fit together into a coherent whole when using presently existing
building materials. If the latter is true, then the construction of a
quantum theory of gravity may demand entirely unfamiliar elements.
Whatever the final outcome, the situation at present is one of flux,
with a great many competing approaches vying for the prize. However,
it is also important to note that the prize is not always the same:
string theorists seek a unified theory of all four interactions that
has the power of explaining such things as the numbers of generations
of elementary particles and other previous inexplicable properties.
Other approaches are more modest, and seek only to bring general
relativity in line with quantum theory, without necessarily invoking
the other interactions. Hence, the problem of quantum gravity
can mean very different things to different researchers and what
constitutes a possible solution to one group might not qualify as such
to another.
Given that quantum gravity does not yet exist as a working physical
theory, one might legitimately question whether philosophers have any
business being involved at this stage. Certainly the
philosopher’s task will be somewhat different from that faced
when dealing with a more-or-less settled body of theory such as
classical Newtonian mechanics, general relativity, or quantum
mechanics. In such cases, one typically proceeds by assuming the
physical soundness of the theory or theoretical framework and drawing
out the ontological and perhaps epistemological consequences of the
theory, trying to understand what it is that the theory is telling us
about the nature of space, time, matter, causation, and so on.
Theories of quantum gravity, on the other hand, are bedeviled by a
host of technical and conceptual problems, questions, and issues that
make them largely unsuited to this kind of interpretive approach. In
the case of string theory, there isn’t even really a
‘theory’ to speak of, so much as several clues pointing to
what many hope will some day be an applicable, consistent physical
theory. However, philosophers who have a taste for a broader and more
open-ended form of inquiry will find much to think about, and it is
entirely possible that future philosophers of physics will be faced
with problems of a very different flavour as a result of the peculiar
nature of quantum gravity. Indeed, Tian Cao argues that quantum
gravity offers up a unique opportunity for philosophers of
physics, leaving them “with a good chance to make some positive
contributions, rather than just analysing philosophically what
physicists have already established” (Cao, 2001, p. 138). This
sentiment has in fact been echoed by several physicists, not least by
Carlo Rovelli (a central architect of the approach known as loop
quantum gravity), who complains that he wishes philosophers would not
restrict themselves to “commenting and polishing the present
fragmentary physical theories, but would take the risk of trying to
look ahead” (Rovelli, 1997, p. 182). This raises an
important point: though we think of general relativity and quantum
theory as ‘nice’ theories from the point of view of
philosophical investigation, in a very real sense they are not the
whole story and break down at extreme scales. 
The difficulties in reconciling quantum theory and gravity into some
form of quantum gravity come from the prima facie
incompatibility of general relativity, Einstein’s relativistic
theory of gravitation, and quantum field theory, the framework for the
description of the other three forces (electromagnetism and the strong
and weak nuclear interactions). Whence the incompatibility? General
relativity is described by Einstein’s equations, which amount to
constraints on the curvature of spacetime (the Einstein tensor on the
left-hand side) due to the presence of mass and other forms of energy,
such as electromagnetic radiation (the stress-energy-momentum tensor
on the right-hand side). (See John Baez’s webpages in
 Other Internet Resources
 for an excellent introduction.) In doing so, they manage to encompass
traditional, Newtonian gravitational phenomena such as the mutual
attraction of two or more massive objects, while also predicting new
phenomena such as the bending and red-shifting of light by these
objects (which have been observed) and the existence of gravitational
radiation (until very recently, with the direct detection of
gravitational waves by LIGO, this was, of course, only indirectly
observed via the decrease in the period of binary pulsars-see the
 1993 Physics Nobel Prize presentation speech by Carl Nordling.)
In general relativity, mass and energy are treated in a purely
classical manner, where ‘classical’ means that physical
quantities such as the strengths and directions of various fields and
the positions and velocities of particles have definite values. These
quantities are represented by tensor fields, sets of (real) numbers
associated with each spacetime point. For example, the stress, energy,
and momentum
Tab(x,t) of the
electromagnetic field at some point
(x,t), are functions of the three
components Ei, Ej,
Ek, Bi,
Bj, Bk of the electric and
magnetic fields E and
B at that point. These quantities in turn
determine, via Einstein’s equations, an aspect of the
‘curvature’ of spacetime, a set of numbers
Gab(x,t) which
is in turn a function of the spacetime metric. The metric
gab(x,t) is a
set of numbers associated with each point which gives the distance to
neighboring points. A model of the world according to general
relativity consists of a spacetime manifold with a metric, the
curvature of which is constrained by the stress-energy-momentum of the
matter distribution. All physical quantities — the value of the
x-component of the electric field at some point, the scalar
curvature of spacetime at some point, and so on — have definite
values, given by real (as opposed to complex or imaginary) numbers.
Thus general relativity is a classical theory in the sense given
above.
The problem is that our fundamental theories of matter and energy, the
theories describing the interactions of various particles via the
electromagnetic force and the strong and weak nuclear forces, are all
quantum theories. In
 quantum theories,
 these physical quantities do not in general have definite
values. For example, in quantum mechanics, the position of an electron
may be specified with arbitrarily high accuracy only at the cost of a
loss of specificity in the description of its momentum, hence its
velocity. At the same time, in the quantum theory of the
electromagnetic field known as quantum electrodynamics (QED), the
electric and magnetic fields associated with the electron suffer an
associated uncertainty. In general, physical quantities are described
by a quantum state which gives a probability distribution over many
different values, and increased specificity (narrowing of the
distribution) of one property (e.g., position, electric field) gives
rise to decreased specificity of its canonically conjugate property
(e.g., momentum, magnetic field). This is an expression of
Heisenberg’s
 Uncertainty Principle.
 In the context of quantum gravity the fluctuating geometry is known
as “spacetime foam”. Likewise, if one focusses in on the
spatial geometry, it will not have a definite trajectory.
On the surface, the incompatibility between general relativity and
quantum theory might seem rather trivial. Why not just follow the
model of QED and quantize the gravitational field, similar to the way
in which the electromagnetic field was quantized? This is more or less
the path that was taken, but it encounters extraordinary difficulties.
Some physicists consider these to be ‘merely’ technical
difficulties, having to do with the non-renormalizability of the
gravitational interaction and the consequent failure of the
perturbative methods which have proven effective in ordinary quantum
field theories. However, these technical problems are closely related
to a set of daunting conceptual difficulties, of interest to
both physicists and philosophers.
The conceptual difficulties basically follow from the nature of the
gravitational interaction, in particular the equivalence of
gravitational and inertial mass, which allows one to represent gravity
as a property of spacetime itself, rather than as a field propagating
in a (passive) spacetime background. When one attempts to
quantize gravity, one is subjecting some of the properties of
spacetime to quantum fluctuations. For example, in canonical
quantizations of gravity one isolates and then quantizes geometrical
quantities (roughly the intrinsic and extrinsic curvature of three
dimensional space) functioning as the position and momentum variables.
Given the uncertainty principle and the probabilistic nature of
quantum theory, one has a picture involving fluctuations of the
geometry of space, much as the electric and magnetic fields fluctuate
in QED. But ordinary quantum theory presupposes a well-defined
classical background against which to define these
fluctuations (Weinstein, 2001a, b), and so one runs into trouble not
only in giving a mathematical characterization of the quantization
procedure (how to take into account these fluctuations in the
effective spacetime structure?) but also in giving a conceptual and
physical account of the theory that results, should one succeed. For
example, a fluctuating metric would seem to imply a fluctuating causal
structure and spatiotemporal ordering of events, in which case, how is
one to define equal-time commutation relations in the quantum theory?
(See the section on the Lagrangian formulation in the entry on
 quantum field theory.)
 
Cao (2001) believes that the conceptual nature of the problem demands
a conceptual resolution. He advocates what he calls ‘ontological
synthesis’. This approach asks for an analysis of the
ontological pictures of the two ingredient theories of quantum
gravity, so that their consistency (the consistency of the resulting
synthesis) can be properly assessed. Ontology for Cao refers to the
primary, autonomous structures from which all other properties and
relations in a theory are constructed. A fairly simple inspection of
the respective ontological constraints imposed by general relativity
and quantum field theory reveals serious tension: general relativity
discards the fixed kinematical structure of spacetime, so that
localization is rendered relational, but in quantum field theory a
fixed flat background is part of its ontological basis, from which the
standard features of the theory are derived. On the other hand, as we
have seen, quantum field theory involves quantum fluctuations in the
vicinity of a point, while general relativity involves the use of a
smooth point neighbourhood. Either way, in order to bring the two
ontological bases together, some piece of either edifice must be
demolished. Cao proposes that the tension can best be resolved by
focussing firmly on those sine qua non principles of the
respective theories. Cao views the gravitational property of universal
coupling as essential, but notes that this does not require
continuity, so that the former could be retained while discarding the
latter, without rendering the framework inconsistent, thus allowing
for quantum theory’s violent fluctuations (Cao’s prime
candidate for an essential quantum field theoretic concept). Likewise,
he argues that quantum field theory requires a fixed background in
order to localize quantum fields and set up causal structure. But he
notes that a relational account of localization could perform such a
function, with fields localized relative to each other. In so doing,
one could envisage a diffeomorphism covariant quantum field theory
(i.e. one that does not involve reference to fields localized at
points of the spacetime manifold). The resulting synthesized entity (a
violently fluctuating, universally coupled quantum gravitational
field) would then be what a quantum theory of gravity ought to
describe.
While such an approach sounds sensible enough on the surface, to
actually put it into practice in the constructive stages of
theory-building (rather than a retrospective analysis of a completed
theory) is not going to be easy—though it has to be said, the
method Cao describes bears close resemblance to the way loop quantum
gravity has developed. Lucien Hardy (2007) has developed a novel
approach to quantum gravity that shares features of Cao’s
suggestion, though the principles isolated are different from
Cao’s. The causaloid approach is intended to provide a
framework for quantum gravity theories, where idea is to
develop a general formalism that respects the key features of both
general relativity, which he takes to be the dynamical
(non-probabilistic) causal structure, and quantum theory, which he
takes to be the probabilistic (nondynamical) dynamics. The causaloid
(of some theory) is an entity that encodes all that can be calculated
in the theory. Part of the problem here is that Cao’s (and
Hardy’s) approach assumes that the ontological principles hold
at the Planck scale. However, it is perfectly possible that both of
the input theories break down at higher energies. Not only that, the
technical difficulties of setting up the kind of (physically
realistic) diffeomorphism-invariant quantum field theory he suggests
have so far proven to be an insurmountable challenge. One crucial
aspect that is missing from Cao’s framework is a notion of what
the observables might be. Of course, they must be relational,
but this still leaves the problem very much open. (The idea of making
progress by isolating appropriate principles of quantum gravity
forms the basis of a special issue: Crowther and Rickles, eds,
2014.)
We will look in more detail at how various conceptual and
methodological problems arise in two different research programs
below. But first, we introduce some key features of the leading
research programs.
All approaches to the problem of quantum gravity agree that something
must be said about the relationship between gravitation and quantized
matter. These various approaches can be catalogued in various ways,
depending on the relative weight assigned to general relativity and
quantum field theory. Some approaches view general relativity as in
need of correction and quantum field theory as generally applicable,
while others view quantum field theory as problematic and general
relativity as having a more universal status. Still others view the
theories in a more even-handed manner, perhaps with both simply
amounting to distinct limits of a deeper theory. It has often been
suggested, since the earliest days of quantum gravity research, that
bringing quantum field theory and general relativity together might
serve to cure their respective singularity problems (the former
resulting from bad high frequency behaviour of fields; the latter
resulting from certain kinds of gravitational collapse). This hope
does seem to have been borne out in many of the current approaches.
Roger Penrose has even argued that the joint consideration of
gravitation and quantum theory could resolve the infamous quantum
measurement problem (see Penrose 2001; see also the section on the
measurement problem in the entry on
 philosophical issues in quantum theory).
 The basic idea of Penrose’s proposal is fairly simple to grasp:
when there is wave-packet spreading of the centre of mass of some
body, there results a greater imprecision in the spacetime structure
associated with the spreading wave-packet, and this destroys the
coherence of the distant parts of the wave-function. There are
difficulties in distinguishing the gravitationally induced collapse
that Penrose proposes from the effective collapse induced by quantum
theory itself, thanks to decoherence—Joy Christian (2005) has
suggested that by observing oscillations in the flavor ratios of
neutrinos originating at cosmological distances one could eliminate
the confounding effects of environmental decoherence.
By far the two most popular approaches are string theory and loop
quantum gravity. The former is an example of an approach to quantum
gravity in which the gravitational field is not quantized; rather, a
distinct theory is quantized which happens to coincide with general
relativity at low energies. The latter is an approach involving
(constrained) canonical quantization, albeit of a version of general
relativity based on a different choice of variables than the usual
geometrodynamical, metric-based variables. We cover the basic details
of each of these in the following subsections.
Known variously as string theory, superstring theory, and M-theory,
this program (qua theory of quantum gravity) has its roots,
indirectly, in the observation, dating back to at least the 1930s,
that classical general relativity looks in many ways like the theory
of a massless ‘spin-two’ field propagating on the flat
Minkowski spacetime of special relativity. [See Cappelli et
al. (eds.) 2012, and Gasperini and Maharana (eds.) 2008, for
collections of essays covering the early history of string theory;
Rickles 2014 offers a conceptually-oriented history of the earlier
days of string theory; Rovelli 2001b (Other Internet Resources section
below) and 2006 offer a capsule history, and Greene 2000 provides a
popular account.] This observation led to early attempts to formulate
a quantum theory of gravity by “quantizing” this spin-two
theory. However, it turned out that the theory is not perturbatively
renormalizable, meaning that there are ineliminable infinities.
Attempts to modify the classical theory to eliminate this problem led
to a different problem, non-unitarity, and so this general approach
was moribund until the mid-1970s, when it was discovered that a theory
of one-dimensional “strings” developed around 1970 to
account for the strong interaction, actually provided a framework for
a unified theory which included gravity, because one of the modes of
oscillation of the string corresponded to a massless spin-two particle
(the ‘graviton’).
The original and still prominent idea behind string theory was to
replace the point particles of ordinary quantum field theory
(particles like photons, electrons, etc) with one-dimensional extended
objects called strings. (See Weingard, 2001 and Witten, 2001 for
overviews of the conceptual framework.) In the early development of
the theory, it was recognized that construction of a consistent
quantum theory of strings required that the strings “live”
in a larger number of spatial dimensions than the observed three.
String theories containing fermions as well as bosons must be
formulated in nine space dimensions and one time dimension. Strings
can be open or closed, and have a characteristic tension and hence
vibrational spectrum. The various modes of vibration correspond to
various particles, one of which is the graviton (the hypothetical
massless, spin-2 particle responsible for mediating gravitational
interactions). The resulting theories have the advantage of being
perturbatively renormalizable. This means that perturbative
calculations are at least mathematically tractable. Since perturbation
theory is an almost indispensable tool for physicists, this is deemed
a good thing.
String theory has undergone several mini-revolutions over the last
several years, one of which involved the discovery of various duality
relations, mathematical transformations connecting, in this case, what
appear to be physically distinct string theories — type I, type
IIA, type IIB, (heterotic) SO(32) and (heterotic)
E8×E8 — to one another and to
eleven-dimensional supergravity (a particle theory). The discovery of
these connections led to the conjecture that all of the string
theories are really aspects of a single underlying theory, which was
given the name ‘M-theory’ (though M-theory is also used
more specifically to describe the unknown theory of which
eleven-dimensional supergravity is the low energy limit). The
rationale, according to one kind of duality (S-duality), is that one
theory at strong coupling (high energy description) is physically
equivalent (in terms of physical symmetries, correlation functions and
all observable content) to another theory at weak coupling (where a
lower energy means a more tractable description), and that if all the
theories are related to one another by dualities such as this, then
they must all be aspects of some more fundamental theory. Though
attempts have been made, there has been no successful formulation of
this theory: its very existence, much less its nature, is still
largely a matter of conjecture.
There has been some recent interest in dualities by philosophers,
given their clear links to standard philosophical issues such as
underdetermination, conventionalism, and emergence/reduction. The link
comes about because in a dual pair (of theories) one has a observable
equivalence combined with what appears to be radical physical (and
mathematical) differences. These differences can be as extreme as
describing spacetimes of apparently different topological structures,
including different numbers of dimensions. This has led some
physicists to speak of spacetime emerging, depending on such
things as the coupling strength governing physical interactions. This
can be seen most clearly in the context of the AdS/CFT duality in
which a ten dimensional string theory is found to be observationally
equivalent (again covering physical symmetries, observables and their
correlation functions) to a four dimensional gauge theory — this
is sometimes called a ‘gauge/gravity’ duality since the
string theory contains gravity (all string theories contain
gravitons) while the gauge theory does not. Since there is an
equivalence between these descriptions, it makes sense to say that
neither is fundamental, and so (elements of) the spacetimes they
apparently describe are also not fundamental; thus implying that the
spacetime we observe at low-energies is an emergent phenomenon —
Vistarini 2013 is a recent discussion of spacetime emergence in string
theory. One way to view such dual pairs is in terms of the two
theories (the gauge theory and a gravitational theory) being distinct
classical limits of a more all-encompassing quantum theory. In this
case, the classical emergent structures also include the specific
gauge symmetries and degrees of freedom of the limiting theories. A
problem remains of making sense of the more fundamental theory (and
the associated physical structure it describes) from which these
spacetimes and gauge symmetries emerge. 
Philosophically speaking, there is a large question mark over whether
the dual pair should be seen as genuinely distinct in a physical sense
or as mere notational variants of the same theory — talk of a
“dictionary” relating the theories makes the latter more
palatable and suggests that the choice of physical interpretation
might be conventional. However, if we view the theories as notational
variants, then our sense of theory-individuation is seemingly
compromised, since the dual pairs involve different dynamics and
degrees of freedom. (See Joseph Polchinski 2014, for a thorough
account of the various kinds of dualities along with some of their
interpretive quirks; Rickles 2011 provides a philosophical examination
of string dualities.) 
Whereas (perturbative) string theory and other so-called
‘covariant’ approaches view the curved spacetime of
general relativity as an effective modification of a flat (or other
fixed) background geometry by a massless spin-two field, the canonical
quantum gravity program treats the full spacetime metric itself as a
kind of field, and attempts to quantize it directly without splitting
it apart into a flat part and a perturbation. However, spacetime
itself is split apart into a stack of three dimensional slices (a
foliation) on which is defined a spatial geometry. Technically, work
in this camp proceeds by writing down general relativity in so-called
‘canonical’ or ‘Hamiltonian’ form, since there
is a more-or-less clearcut way to quantize theories once they are put
in this form (Kuchar, 1993; Belot & Earman, 2001). In a canonical
description, one chooses a particular set of configuration variables
xi and canonically conjugate momentum variables
pi which describe the state of a system at some
time, and can be encoded in a phase space. Then, one obtains the
time-evolution of these variables from the Hamiltonian
H(xi,pi), which
provides the physically possible motions in the phase space a a family
of curves. Quantization proceeds by treating the configuration and
momentum variables as operators on a quantum state space (a Hilbert
space) obeying certain commutation relations analogous to the
classical Poisson-bracket relations, which effectively encode the
quantum fuzziness associated with Heisenberg’s uncertainty
principle. The Hamiltonian operator, acting on quantum states, would
then generate the dynamical evolution.
When one attempts to write general relativity down in this way, one
has to contend with the existence of constraints on the
canonical variables that are inherited from the diffeomorphism
invariance of the spacetime formulation of the theory. The single
tensorial equation that we see in standard presentations of the
Einstein field equations is translated into 10 scalar equations in the
canonical formulation, with constraints accounting for four of these
equations (the remaining six are genuine evolutionary equations).
Three of the constraints (known as the momentum or diffeomorphism
constraints) are responsible for shifting data tangential to the
initial surface and, thus, are related to the shift vector field. The
remaining constraint, known as the Hamiltonian (or scalar) constraint,
is responsible for pushing data off the initial surface, and thus is
related to the lapse function. If the constraints are not satisfied by
the canonical initial data then the development of the data with
respect to the evolution equations, will not generate a physically
possible spacetime for choices of lapse and shift. However, when the
constraints are satisfied then the various choices of lapse and
shift will always grow the same 4D spacetime (that it, the same
spacetime metric). However, to extract a notion of time from this
formulation demands that one first solve for the spacetime metric,
followed by a singling out of a specific solution. This is a kind of
classical problem of time in that since the spacetime geometry is a
dynamical variable, time is something that also must be solved for.
Further, there is arbitrariness in the time variable as a result of
the arbitrariness encoded in the constraints, stemming from the fact
that time is essentially a freely chosen label of the three
dimensional slices and so is not a physical parameter. However, one
can extract a time for each solution to the Einstein equations
by ‘deparametrizing’ the theory (i.e. isolating a variable
from within the phase space that is to play the role of time). Below
we see that things become more problematic in the shift to quantum
theory.
Although advocates of the canonical approach often accuse string
theorists of relying too heavily on classical background spacetime,
the canonical approach does something which is arguably quite similar,
in that one begins with a theory that conceives time-evolution in
terms of evolving some data specified on an a priori given
spacelike surface, and then quantizing the theory. However, this does
not imply any breaking of spacetime diffeomorphism invariance (or
general covariance) since the constraints that must be satisfied by
the data on the slice mean that the physical observables of the theory
will be independent of whatever foliation one chooses. However, the
problem is that if spacetime is quantized along these lines, the
assumption (of evolving then quantizing) does not make sense in
anything but an approximate way. That is, the evolution does not
generate a classical spacetime! Rather, solutions will be
wave-functions (solutions of some Schrödinger-type equation).
This issue in particular is decidedly neglected in both the physical
and philosophical literature (but see Isham, 1993), and there is more
that might be said. We return to the issue of time in quantum gravity
below.
Early attempts at quantizing general relativity by Bergmann, Dirac,
Peres, Wheeler, DeWitt and others in the 1950s and 1960s worked with a
seemingly natural choice for configuration variables, namely geometric
variables gij corresponding to the various
components of the ‘three-metric’ describing the intrinsic
geometry of the given spatial slice of spacetime. One can think about
arriving at this via an arbitrary slicing of a 4-dimensional
“block” universe by 3-dimensional spacelike hypersurfaces.
The conjugate momenta πij then effectively
encode the time rate-of-change of the metric, which, from the
4-dimensional perspective, is directly related to the extrinsic
curvature of the slice (meaning the curvature relative to the
spacetime in which the slice is embedded). This approach is known as
‘geometrodynamics’ since it views general relativity as
describing the dynamics of spatial geometry.
As mentioned above, in these geometric variables, as in any other
canonical formulation of general relativity, one is faced with
constraints, which encode the fact that the canonical variables cannot
be specified independently. A familiar example of a constraint is
Gauss’s law from ordinary electromagnetism, which states that,
in the absence of charges,
∇·E(x)
− 4πρ = 0 at every point x. It
means that the three components of the electric field at every point
must be chosen so as to satisfy this constraint, which in turn means
that there are only two “true” degrees of freedom
possessed by the electric field at any given point in space.
(Specifying two components of the electric field at every point
dictates the third component.) Thus, not all components of the Maxwell
equations propagate the fields in a physical sense. 
The constraints in electromagnetism may be viewed as stemming from the
U(1) gauge invariance of Maxwell’s theory, while the
constraints of general relativity stem from the diffeomorphism
invariance of the theory.
 Diffeomorphism invariance
 means, informally, that one can take a solution of Einstein’s
equations and drag it (meaning the metric and the matter fields)
around on the spacetime manifold and obtain a mathematically distinct
but physically equivalent solution. The three
‘supermomentum’ constraints in the canonical theory
reflect the freedom to drag the metric and matter fields around in
various directions on a given three-dimensional spacelike
hypersurface, while the ‘super-Hamiltonian’ constraint
reflects the freedom to drag the fields in the “time”
direction, and so to the “next” hypersurface. (Each
constraint applies at each point of the given spacelike hypersurface,
so that there are actually 4 × ∞3 constraints:
four for each point.) In the classical (unquantized) canonical
formulation of general relativity, the constraints do not pose any
particular conceptual problems (though one does face a problem in
defining suitable observables that commute with the constraints, and
this certainly has a conceptual flavour). One effectively chooses a
background space and time (via a choice of the lapse and shift
functions) “on the fly”, and one can be confident that the
spacetime that results is independent of the particular choice.
Effectively, different choices of these functions give rise to
different choices of background against which to evolve the
foreground. However, the constraints pose a serious problem (as much
conceptual as technical) when one moves to quantum theory.
All approaches to canonical quantum gravity face the so-called
“problem of time” in one form or another (Kuchař
(1992) and Isham (1993) are still excellent reviews; Rickles, 2006,
offers a more philosophical guide). The problem stems from the fact
that in preserving the diffeomorphism-invariance of general relativity
— depriving the coordinates of the background manifold of any
physical meaning — the “slices” of spacetime one is
considering inevitably include time, just as they include space. In
the canonical formulation, the diffeomorphism invariance is reflected
in the constraints, and the inclusion of what would ordinarily be a
‘time’ variable in the data is reflected in the existence
of the super-Hamiltonian constraint. The difficulties presented by
this latter constraint constitute the problem of time.
Attempts to quantize general relativity in the canonical framework
proceed by turning the canonical variables into operators on an
appropriate state space (e.g., the space of square-integrable
functions over three-metrics), and dealing somehow with the
constraints. When quantizing a theory with constraints, there are two
possible approaches. The approach usually adopted in gauge theories is
to deal with the constraints before quantization, so that only
true degrees of freedom are promoted to operators when passing to the
quantum theory. There are a variety of ways of doing this so-called
‘gauge fixing’, but they all involve removing the extra
degrees of freedom by imposing some special conditions. In general
relativity, fixing a gauge is tantamount to specifying a particular
coordinate system with respect to which the “physical”
data is described (spatial coordinates) and with respect to which it
evolves (time coordinate). This is difficult already at the classical
level, since the utility and, moreover, the very tractability of any
particular gauge generally depends on the properties of the solution
to the equations, which of course is what one is trying to find in the
first place. But in the quantum theory, one is faced with the
additional concern that the resulting theory may well not be
independent of the choice of gauge. This is closely related to the
problem of identifying true, gauge-invariant observables in the
classical theory (Torre 2005, in the Other Internet Resources
section).
The preferred approach in canonical quantum gravity is to impose the
constraints after quantizing. In this ‘constraint
quantization’ approach, due to Dirac, one treats the constraints
themselves as operators A, and demands that
“physical” states ψ be those which are solutions to
the resulting equations A ψ = 0. The problem of time is
associated with the super-Hamiltonian constraint, as mentioned above.
The super-Hamiltonian H is responsible for describing
time-evolution in the classical theory, yet its counterpart in the
constraint-quantized theory, H ψ = 0, would prima
facie seem to indicate that the true physical states of the
system do not evolve at all: there is no t. Trying to
understand how, and in what sense, the quantum theory describes the
time-evolution of something, be it states or observables, is the
essence of the problem of time (on which, more below).
In geometrodynamics, all of the constraint equations are difficult to
solve (though the super-Hamiltonian constraint, known as the
Wheeler-DeWitt equation, is especially difficult), even in the absence
of particular boundary conditions. Lacking solutions, one does not
have a grip on what the true, physical states of the theory are, and
one cannot hope to make much progress in the way of predictions. The
difficulties associated with geometric variables are addressed by the
program initiated by Ashtekar and developed by his collaborators (for
a review and further references see Rovelli 2001b (Other Internet
Resources), 2001a). Ashtekar used a different set of variables, a
complexified ‘connection’ (rather than a three-metric) and
its canonical conjugate, which made it simpler to solve the
constraints. This change of variables introduces an additional
constraint into the theory (the Gauss law constraint generating SO(3)
transformations) on account of the freedom to rotate the vectors
without disturbing the metric. The program underwent further
refinements with the introduction of the loop transform, and further
refinements still when it was understood that equivalence classes of
loops could be identified with spin networks. One is able to recover
all the standard geometrical features of general relativity from this
formulation. (See Smolin (2001, 2004) for a popular introduction;
Rovelli, 2004, offers a physically intuitive account; Thiemann, 2008,
provides the mathematical underpinnings; Rickles, 2005, offers a
philosophically-oriented review.) Note that the problems of time and
observables afflict the loop approach just as they did the earlier
geometrodynamical approach. The difference is that one has more
(mathematical) control over the theory (and its quantization), in
terms of a definable inner product, a separable state space, and more.
There is still a question mark over the construction of the full
physical Hilbert space, since the solution of the Hamiltonian
constraint remains a problem. However, some progress is being made in
various directions, e.g. Thomas Thiemann’s master constraint
programme (see Thiemann, 2006).
Though the impression often painted of the research landscape in
quantum gravity is an either/or situation between string theory and
loop quantum gravity, in reality there are very many more options on
the table. Some (e.g., Callender and Huggett 2001, Wüthrich 2004
(Other Internet Resources section); J. Mattingly 2005) have argued
that semiclassical gravity, a theory in which matter is quantized but
spacetime is classical, is at least coherent, though not quite an
empirically viable option (we discuss this below). Other approaches
include twistor theory (currently enjoying a revival in conjunction
with string theory), Bohmian approaches (Goldstein & Teufel,
2001), causal sets (see Sorkin 2003, in the Other Internet Resources
section) in which the universe is described as a set of discrete
events along with a stipulation of their causal relations, and other
discrete approaches (see Loll, 1998). Causal set theory has begun to
stimulate some philosophical interest on account of the claims, by
physicists, to the effect that the theory embodies a notion of
objective becoming or temporal passage based on the notion of the
‘birth’ of spacetime atoms (see, e.g., Dowker 2014; for a
skeptical response, see Huggett 2014; Wüthrich, 2012, pursues
instead the structuralist leanings of causal set theory). 
Also of interest are arguments to the effect that gravity itself may
play a role in quantum state reduction (Christian, 2001; Penrose,
2001; also briefly discussed below). A fairly comprehensive overview
of the current approaches to quantum gravity can be found in Oriti
(2009). In this entry we have chosen to focus upon those approaches
that are both the most actively pursued and that have received
most attention from philosophers. Let us now turn to several
methodological and philosophical issues that arise quantum gravity
research.
Research in quantum gravity has always had a rather peculiar flavor,
owing to both the technical and conceptual difficulty of the field and
the remoteness from experiment. Yoichiro Nambu (1985) wryly labels
research on quantum gravity “postmodern physics” on
account of its experimental remoteness. Thus conventional notions of
the close relationship between theory and experiment have but a
tenuous foothold, at best, in quantum gravity. However, since there
is a rudimentary ‘pecking order’ amongst the
various approaches to quantum gravity, and since the history of
quantum gravity contains various fatalities, there clearly are
some methods of theory evaluation in operation, there are
constraints functioning in something like the way experiment and
observation function. Investigating these methods and constraints
constitutes an open research problem for philosophers of
science—for initial investigations along these lines, see James
Mattingly (2005a and 2009) and Rickles (2011). Audretsch (1981) argues
that quantum gravity research conflicts with Kuhn’s account of
scientific development since it stems from the desire to unify (for
reasons not based on any empirical tension) multiple paradigms, both
of which are well-confirmed and both of which make claims to
universality. One might easily question Audretsch’s focus on
direct empirical tensions here. Given, as he admits, both general
relativity and quantum theory claim to be universal theories,
any conceptual or formal tension that can be found to hold between
them must point to either or both theories being in error in their
claims to universality—this is an empirical claim of sorts. In
the context of string theory, Peter Galison (1995) argues that
mathematical constraints take the place of standard empirical
constraints. James Cushing (1990) also considers some of the potential
methodological implications of string theory (though he deals with
string theory in its earliest days, when it underwent a transition
from the dual resonance model of hadrons into a theory of quantum
gravity). Dawid (2014) focuses in more detail on methodological issues
in string theory and defends the idea that string theory is
characterised by a uniqueness claim (the no-alternatives argument)
according to which string theory is the only way to unify
gravity and the other fundamental interactions, thus grounding
physicists’ strong belief in the theory; however, that is a
rather different problem (that of constructing a theory of everything)
than the more restricted problem of quantum gravity — quantum
gravity researchers from other approaches might simply reject the need
for such a unified theory (e.g., as opposed to a theory that is
compatible with the inclusion other interactions). 
As remarked in the introduction, there is no single, generally
agreed-upon body of theory in quantum gravity. The majority of the
physicists working in the field focus their attention on string
theory, an ambitious program which aims at providing a unified theory
of all four interactions. A non-negligible minority work on what is
now called loop quantum gravity, the goal of which is simply to
provide a quantum theory of the gravitational interaction
simpliciter. There is also significant work in other areas,
including approaches that don’t really involve the quantization
of a theory at all. [Good recent reviews of the theoretical landscape
include Carlip 2001, Smolin 2001 (Other Internet Resources section
below), 2003, Penrose 2004, and Oriti, ed, 2009.] But there is no real
consensus, for at least two reasons.
The first reason is that it is extremely difficult to make any
concrete predictions in these theories. String theory, in particular,
is plagued by a lack of experimentally testable predictions because of
the tremendous number of distinct ground or vacuum states in the
theory, with an absence of guiding principles for singling out the
physically significant ones (including our own). Though the string
community prides itself on the dearth of free parameters in the theory
(in contrast to the nineteen or so free parameters found in the
standard model of particle physics), the problem arguably resurfaces
in the huge number of vacua associated with different
compactifications of the nine space dimensions to the three we
observe. These vacua are either viewed as distinct string theories, or
else as solutions of one and the same theory (though some deeper,
unknown theory, as mentioned above). Attempts to explain why we live
in the particular vacuum that we do have recently given rise to
appeals to the infamous anthropic principle (Susskind, 2003), whereby
the existence of humans (or observers) is invoked to, in some sense,
“explain” the fact that we find ourselves in a particular
world by restricting the possible ground states to those that could
support such creatures in which we should expect our universe’s
observed features to be typical. (See Weinstein, 2006, for a
philosophical discussion of the usage of anthropic reasoning in string
theory, including an ambiguity in the meaning of
‘typicality’ in this context; Azhar, 2013, further
develops this discussion.)
Loop quantum gravity is seemingly less plagued by a lack of
predictions, and indeed it is often claimed that the discreteness of
area and volume operators are concrete predictions of the theory, with
potentially testable consequences. Proponents of this approach argue
that this makes the theory more susceptible to falsification, and thus
more scientific (in the sense of Popper; see the entry on
 Karl Popper)
 than string theory (see Smolin 2006 for this line of argument).
However, it is still quite unclear, in practice and even in principle,
how one might actually observe these quantities. There have been
recent suggestions that in order to probe the effects of the Planck
scale (discreteness, or minimal length in particular) one needs to
look to the cosmological level for tiny violations of Lorentz
invariance. Rovelli and Speziale (2003) have argued that, in fact, the
existence of a minimal length does not imply a violation of the
Lorentz symmetry (a conclusion seconded by the proponents of the
causal set programme). Their argument turns on the fact that in the
context of quantum theory, symmetries act on states (and so on mean
values) rather than eigenvalues (representing the discrete quantities
in the theory). However, in any case, there remains a question mark
over the theoretical status of the discreteness result which has been
shown to hold only for operators on the kinematical Hilbert
space, that is, for gauge-variant quantities. It is still an open
question whether this result transfers to genuine observables (i.e.
operators that satisfy all of the constraints and are defined on the
physical Hilbert space: that gauge-invariant quantities). See
Dittrich and Thiemann (2009) for a detailed investigation of the
problem and a possible resolution employing suitably gauge-fixed (by
matter) Dirac observables. Even if one overcomes this problem, and
could observe evidence of the discreteness of space, so many
approaches involve such discreteness that one would face a further
problem in using this new data to decide between the discrete
approaches. For a philosophical discussion of this and related issues
(including the question of whether the proposed discreteness breaks
Lorentz invariance), see Hagar (2009) — Hagar (2014) considers
these and related issues in a book-length treatment.
The second reason for the absence of consensus is that there are no
experiments in quantum gravity, and little in the way of observations
that might qualify as direct or indirect data or empirical evidence.
This stems in part from the lack of theoretical predictions,
since it is difficult to design an observational test of a theory if
one does not know where to look or what to look at. But it also stems
from the fact that most theories of quantum gravity appear to predict
departures from classical relativity only at energy scales on the
order of 1019 GeV. (By way of comparison, the proton-proton
collisions at Fermilab have an energy on the order of 103
GeV.) Whereas research in particle physics proceeds in large part by
examining the data collected in large particle accelerators, which are
able to smash particles together at sufficiently high energies to
probe the properties of atomic nuclei in the fallout, gravity is so
weak that there is no physically realistic way to do a comparable
experiment that would reveal properties at the energy scales at which
quantum gravitational effects are expected to be
important—it would take a particle accelerator of galactic size
to even approach the required energies. (In a little more detail, the
weakness of gravity can be compared to the strength of the
electromagnetic interaction — cf. Callender and Huggett (eds.)
2001, p. 4. An electron couples to the electromagnetic field with a
strength of 10−2, while the coupling of a mass to the
gravitational field is 10−22. Feynman (1963, p. 697)
gives an example that highlights this difference in magnitudes more
dramatically by showing how the gravitational coupling between a
proton and an electron in a hydrogen atom would shift the
wave-function of an electron by just 43 arcseconds over a time period
of 100 times the age of the Universe! Hence, quantum gravity is more
of a theorist’s problem.)
Though progress is being made in trying to at least draw observational
consequences of loop quantum gravity, a theory of quantum gravity
which arguably does make predictions (Amelino-Camelia, 2003,
in the Other Internet Resources section below; D. Mattingly, 2005), it
is remarkable that the most notable “test” of quantum
theories of gravity imposed by the community to date involves a
phenomenon which has never been observed, the so-called Hawking
radiation from black holes. Based on earlier work of Bekenstein (1973)
and others, Hawking (1974) predicted that black holes would radiate
energy, and would do so in proportion to their gravitational
“temperature,” which was in turn understood to be
proportional to their mass, angular momentum, and charge. Associated
with this temperature is an entropy (see the entry on
 the philosophy of statistical mechanics),
 and one would expect a theory of quantum gravity to allow one to
calculate the entropy associated with a black hole of given mass,
angular momentum, and charge, the entropy corresponding to the number
of quantum (micro-)states of the gravitational field having the same
mass, charge, and angular momentum. (See Unruh, 2001, and references
therein.) In their own ways, string theory and loop quantum gravity
have both passed the test of predicting an entropy for black holes
which accords with Hawking’s calculation, using very different
microscopic degrees of freedom. String theory gets the number right
for a not-particularly-physically-realistic subset of black holes
called near-extremal black holes, while loop quantum gravity gets it
right for generic black holes, but only up to an overall constant.
More recently, the causal set approach has also managed to derive the
correct value. If the Hawking effect is real, then this
consonance could be counted as evidence in favor of either or both/all
theories.
Erik Curiel (2001) has argued against the manner in which the ability
to derive the Bekenstein-Hawking result as a theorem of an approach is
used as evidence for that approach in much the same way that
empirical evidence is used to justify a theory in normal
circumstances, say predicting the value of a well-confirmed
experimental result. It is true that black hole physics is used as
testing ground for quantum gravity and the Bekenstein-Hawking result
does not have the status of an empirical fact. However, it is a strong
deduction from a framework that is fairly mature, namely
quantum field theory on a curved spacetime background. In this sense,
although it does not provide a constraint as strong as an
experimentally observed phenomenon, it might legitimately function as
a constraint on possible theories. Constraints on theory construction
come in a variety of shapes and sizes, and not all take the form of
empirical data — thought experiments are a case in point. In the
context of quantum gravity it is especially important that one have
some agreed upon constraints to guide the construction. Without them,
work would halt. It also seems reasonable to insist that a full theory
of quantum gravity be able to reproduce predictions of the
semi-classical theory of gravity, since this will be one of its
possible limits. Still, Curiel is right that researchers ought to be
rather more wary of attributing too much evidential weight to such
features that remain empirically unconfirmed.
Curiel goes on to question, more generally, the ranking of approaches
to quantum gravity given what he views as the absence of demonstrated
scientific merit in any of them: elegance and consistency might well
be merits of a scientific theory, but they do not count as
scientific. (ibid, p. S437). However, this claim hinges on the
direct alignment of scientific merit and empirical clout; but this
requires an argument, for it is far from obvious: from whence this
prescription? Surely if a theory is mathematically inconsistent that
says something about its physical status too? Moreover, the
relationship between experimental and observational data and theories
is not a simple matter. Finally, it is perhaps too quick to say that
approaches do not have empirical consequences. Already known empirical
data can confirm the predictions of a theory; therefore, it is clear
that we can judge the extent to which the various contenders satisfy
this old evidence, and how they do so. For example, string theory at
least has the potential of explaining why there are three generations
of elementary particles by invoking the Euler characteristic of the
compact spaces it employs—the Euler characteristic is equal to
twice the number of generations (see Seifert, 2004, for details).
Whatever one might think about string theory’s relationship with
anthropic reasoning, we do have here a potential explanation of a
previously inexplicable piece of old empirical data, which ought to
lend some credence to the theory. There is also the not inconsiderable
fact that string theory is able to derive general relativity (and all
the physically observed facts that are associated with this theory) as
a low energy feature. This is not a novel fact, but it is an
physical, empirical consequence of the theory nonetheless.
However, it should be noted, finally, that to date neither of the main
research programs has been shown to properly reproduce the world we
see at low energies. Indeed, it is a major challenge of loop quantum
gravity to show that it indeed has general relativity as a low-energy
limit, and a major challenge of string theory to show that it has the
standard model of particle physics plus general relativity as a
low-energy limit. There are promising indications that both theories
might be able to overcome this challenge (see Thiemann for the loop
quantum gravity case; for the string theoretic case, see Graña,
2006). A similar problem faces causal set theory in the form of the
‘inverse problem’, which roughly amounts to the difficulty
of getting continuous manifolds (with their corresponding symmetries)
from a fundamentally discrete theory (see Wallden, 2010, for a good
recent review of causal sets, including a discussion of this problem,
on which progress has also been made).
Quantum gravity raises a number of difficult philosophical questions.
To date, it is the ontological aspects of quantum gravity that have
attracted the most interest from philosophers, and it is these we will
discuss in the first five sections below. In the final section,
though, we will briefly discuss some further methodological and
epistemological issues which arise.
First, however, let us discuss the extent to which ontological
questions are tied to a particular theoretical framework. In its
current stage of development, string theory unfortunately provides
little indication of the more fundamental nature of space, time, and
matter. Despite the consideration of ever more exotic objects —
strings, p-branes, D-branes, etc. — these objects are
still understood as propagating in a background spacetime. Since
string theory is supposed to describe the emergence of classical
spacetime from some underlying quantum structure, these objects are
not to be regarded as truly fundamental. Rather, their status in
string theory is analogous to the status of particles in quantum field
theory (Witten, 2001), which is to say that they are relevant
descriptions of the fundamental physics only in situations in which
there is a background spacetime with appropriate symmetries. While
this suggests tantalising links to issues of emergence, it is
difficult to pursue them without knowing the details of the more
fundamental theory. As already mentioned, the duality relations
between the various string theories suggest that they are all
perturbative expansions of some more fundamental, non-perturbative
theory known as ‘M-theory’ (Polchinski, 2002, see the
Other Internet Resources section below). This, presumably, is the most
fundamental level, and understanding the theoretical framework at that
level is central to understanding the underlying ontology of the
theory (and so the manner in which any other structures might emerge
from it). ‘Matrix theory’ is an attempt to do just this,
to provide a mathematical formulation of M-theory, but it remains
highly speculative. Thus although string theory purports to be a
fundamental theory, the ontological implications of the theory are
still very obscure — though this could be viewed as a challenge
rather than a reason to ignore the theory.
Canonical quantum gravity, in its loop formulation or otherwise, has
to date been of greater interest to philosophers because it appears to
confront fundamental questions in a way that string theory, at least
in its perturbative guise, does not — certainly, it does so more
explicitly and in language more amenable to philosophers. Whereas
perturbative string theory treats spacetime in an essentially
classical way, canonical quantum gravity treats it as
quantum-mechanical entity, at least to the extent of treating the
geometric structure (as opposed to, say, the topological or
differential structure) as quantum-mechanical. Furthermore, many of
the issues facing canonical quantum gravity are also firmly rooted in
conceptual difficulties facing the classical theory, which
philosophers are already well acquainted with (e.g. via the
 hole argument).
As noted in
 Section 3.2.2
 above, the treatment of time presents special difficulties in
canonical quantum gravity, though they easily generalise to many other
approaches to quantum gravity. These difficulties are connected with
the special role time plays in physics, and in quantum theory in
particular. Physical laws are, in general, laws of motion, of change
from one time to another. They represent change in the form of
differential equations for the evolution of, as the case may be,
classical or quantum states; the state represents the way the system
is at some time, and the laws allow one to predict how it
will be in the future (or retrodict how it was in the past). It is not
surprising, then, that a theory of quantum spacetime would have a
problem of time, because there is no classical time against which to
evolve the “state”. The problem is not so much that the
spacetime is dynamical; there is no problem of time in classical
general relativity (in the sense that a time variable is present).
Rather, the problem is roughly that in quantizing the structure of
spacetime itself, the notion of a quantum state, representing the
structure of spacetime at some instant, and the notion of the
evolution of the state, do not get any traction, since there
are no real “instants”. (In some approaches to canonical
gravity, one fixes a time before quantizing, and quantizes the
spatial portions of the metric only. This approach is not without its
problems, however; see Isham (1993) for discussion and further
references.)
One can ask whether the problem of time arising from the canonical
program tells us something deep and important about the nature of
time. Julian Barbour (2001a,b), for one, thinks that it tells us that
time is illusory (see also Earman, 2002, in this connection). It is
argued that the fact that quantum states do not evolve under the
super-Hamiltonian means that there is no change. However, it can also
be argued (Weinstein, 1999a,b) that the super-Hamiltonian itself
should not be expected to generate time-evolution; rather, one or more
“true” Hamiltonians should play this role, though
uncovering such Hamiltonians is no easy matter. (See Butterfield &
Isham (1999) and Rovelli (2006) for further discussion.)
Bradley Monton (2006) has argued that a specific version of canonical
quantum gravity – that with a so-called constant mean
extrinsic curvature [CMC] (or fixed) foliation – has the
necessary resources to render presentism (the view that all and only
presently existing things exist) a live possibility (see the section
on Presentism, Eternalism, and The Growing Universe Theory in the
entry on
 time
 for more on presentism). The reason is that with such a fixed
foliation one has at one’s disposal some spacelike hypersurface
that contains a set of well-defined events that can be viewed through
the lens of presentism, such that this set of events at this
particular instant (or ‘thin-sandwich’) changes over time.
Though he readily admits that CMC formulations are outmoded in the
contemporary theoretical landscape, he nonetheless insists that given
the lack of experimental evidence one way or the other, it stands as a
viable route to quantum gravity, and therefore presentism remains as a
possible theory of time that is compatible with frontier theoretical
physics. Christian Wüthrich (2010) takes Monton to task on a
variety of both technical and non-technical grounds. He rightly
questions Monton’s claim that the CMC approach really is an
approach to quantum gravity, in the same sense as string theory
and loop quantum gravity. It is more of a piece of machinery that is
used within a pre-existing approach (namely, the canonical
approach). He also questions Monton’s claim, inasmuch as it does
constitute an approach of sorts, that it is viable. Simply not
being ruled out on experimental grounds does not thereby render an
approach viable. Besides, if anything has the prospect of saving
presentism, then surely it is Julian Barbour’s position
mentioned above. This at least has the added benefit of being a
research programme that is being actively pursued.
A common claim that appears in many discussions of the problem of time
(especially amongst philosophers) is that it is restricted to
canonical formulations of general relativity, and has something to do
with the Hamiltonian formalism (see Rickles 2008a, pp. 340–1 for
more details). The confusion lies in the apparently very different
ways that time is treated in general relativity as standardly
formulated, and as it appears in a canonical, Hamiltonian formulation.
In the former there is no preferred temporal frame, whereas the latter
appears to demand such a frame in order to get off the ground
(cf. Curiel, 2009, p. 59; Tim Maudlin (2004) tells a broadly similar
story).
However, this encodes several pieces of misinformation making it hard
to make sense of the claim that general relativity and canonical
theories cannot be “reconciled”. The canonical framework
is simply a tool for constructing theories, and one that makes
quantization an easier prospect. As a matter of historical fact the
canonical formulation of general relativity is a completed project,
and has been carried out in a variety of ways, using compact spaces
and non-compact spaces, and with a range of canonical variables. Of
course, general relativity, like Maxwell’s theory of
electromagnetism, possesses gauge symmetries, so it is a constrained
theory that results, and one must employ the method of constrained
Hamiltonian systems. However, there is no question that general
relativity is compatible with the canonical analysis of theories, and
the fact that time looks a little strange in this context is simply
because the formalism is attempting to capture the dynamics of general
relativity. In any case, the peculiar nature of general relativity and
quantum gravity, with respect to the treatment of time, resurfaces in
arguably the most covariant of approaches, the Feynman path-integral
approach. In this case that central task is to compute the amplitude
for going from an initial state to a final state (where these states
will be given in terms of boundary data on a pair of initial and final
hypersurfaces). The computation of this propagator proceeds à
la sum-over-histories: one counts to the number of possible spacetimes
that might interpolate between the initial and final hypersurfaces.
However, one cannot get around the fact that general relativity is a
theory with gauge freedom, and so whenever one has diffeomorphic
initial and final hypersurfaces, the propagator will be trivial.
A similar confusion can be found in discussions of the related problem
of defining observables in canonical general relativity. The claim
gets its traction from the fact that it is very difficult to construct
observables in canonical general relativity, while (apparently) it is
relatively straightforward in the standard Lagrangian description.
(See, e.g., Curiel, 2009, pp. 59–60, for an explicit statement
of this claim. Curiel cites a theorem of Torre, 1993, to the effect
that there can be no local observables in compact spacetimes, to argue
that the canonical formulation is defective somehow.) Again, this
rests on a misunderstanding over what the canonical formalism is and
how it is related to the standard spacetime formulation of general
relativity. That there are no local observables is not an artefact of
canonical general relativity. The notion that observables have to be
non-local (in this case, relational) is a generic feature that results
precisely from the full spacetime diffeomorphism invariance of general
relativity (and is, in fact, implicit in the theorem of Torre
mentioned earlier). It receives a particularly transparent description
in the context of the canonical approach because one can define
observables as quantities that commute with all of the constraints.
The same condition will hold for the four-dimensional versions, only
they will have to be spacetime diffeomorphism invariant in that case.
This will still rule out local observables since any quantities
defined at points or regions of the spacetime manifold will clearly
fail to be diffeomorphism invariant. Hence, the problems of
observables (and the result that they must be either global or
relational in general relativity) is not a special feature of the
canonical formulation, but a generic feature of theories possessing
diffeomorphism invariance. As Ashtekar and Geroch point out,
“[s]ince time is essentially a geometrical concept [in general
relativity], its definition must be in terms of the metric. But the
metric is also the dynamical variable, so the flow of time becomes
intertwined with the flow of the dynamics of the system” (1974,
p. 1215).
The problem of time is closely connected with a general puzzle about
the ontology associated with “quantum spacetime”. Quantum
theory in general resists any straightforward ontological reading, and
this goes double for quantum gravity. In quantum mechanics,
one has particles, albeit with indefinite properties. In quantum field
theory, one again has particles (at least in suitably symmetric
spacetimes), but these are secondary to the fields, which again are
things, albeit with indefinite properties. On the face of it, the only
difference in quantum gravity is that spacetime itself becomes a kind
of quantum field, and one would perhaps be inclined to say that the
properties of spacetime become indefinite. But space and time
traditionally play important roles in individuating objects and their
properties—in fact a field is in some sense a set of properties
of spacetime points — and so the quantization of such raises
real problems for ontology.
One area that philosophers might profit from is in the investigation
of the relational observables that appear to be necessitated by
diffeomorphism invariance. For example, since symmetries (such as the
gauge symmetries associated with the constraints) come with quite a
lot of metaphysical baggage attached (as philosophers of physics know
from the
 hole argument),
 such a move involves philosophically weighty assumptions. For
example, the presence of symmetries in a theory would appear to allow
for more possibilities than one without, so eradicating the symmetries
(by solving the constraints and going to the reduced, physical phase
space) means eradicating a chunk of possibility space: in particular,
one is eradicating states that are deemed to be physically equivalent,
despite having some formal differences in terms of representaton.
Hence, imposing the constraints involves some serious modal
assumptions. Belot and Earman (2001) have argued that since the
traditional positions on the ontology of spacetime (relationalism and
substantivalism) involve a commitment to a certain way of counting
possibilities, the decision to eliminate symmetries can have serious
implications for the ontology one can then adopt. Further, if some
particular method (out of retaining or eliminating symmetries) were
shown to be successful in the quest for quantizing gravity, then, they
argue, one could have good scientific reasons for favouring one of
substantivalism or relationalism. (See Belot, 2011a, for more on this
argument; Rickles, 2008c, explicitly argues against the idea that
possibility spaces have any relevance for spacetime ontology.)
In the loop quantum gravity program, the area and volume operators
have discrete spectra. Thus, like electron spins, they can
only take certain values. This suggests (but does not imply) that
space itself has a discrete nature, and perhaps time as well
(depending on how one resolves the problem of time). This in turn
suggests that space does not have the structure of a differential
manifold, but rather that it only approximates such a manifold on
large scales, or at low energies. A similar idea, that classical
spacetime is an emergent entity, can be found in several
approaches to quantum gravity (see Butterfield and Isham, 1999 and
2001, for a discussion of emergence in quantum gravity). The
possibility that a continuous structure (with continuous symmetries)
could emerge from a fundamentally discrete structure is a problem with
a clear philosophical flavour —Huggett and Wüthrich, eds.
(2013) contains a variety of papers investigating this issue, with
their own contribution focusing on the notion of recovering
‘local beables’ from such emergent theories. 
Whether or not spacetime is discrete, the quantization of spacetime
entails that our ordinary notion of the physical world, that of matter
distributed in space and time, is at best an approximation. This in
turn implies that ordinary quantum theory, in which one calculates
probabilities for events to occur in a given world, is inadequate as a
fundamental theory. As suggested in the
 Introduction,
 this may present us with a vicious circle. At the very least, one
must almost certainly generalize the framework of quantum theory. This
is an important driving force behind much of the effort in quantum
cosmology to provide a well-defined version of the
 many-worlds
 or
 relative-state
 interpretations. Much work in this area has adopted the so-called
‘decoherent histories’ or ‘consistent
histories’ formalism, whereby quantum theories are understood to
make probabilistic predictions about entire (coarse-grained)
‘histories’. Almost all of this work to date construes
histories to be histories of spatiotemporal events, and thus
presupposes a background spacetime; however, the incorporation of a
dynamical, quantized spacetime clearly drives much of the
cosmology-inspired work in this area.
More generally, one might step outside the framework of canonical,
loop quantum gravity, and ask why one should only quantize the metric.
As pointed out by Isham (1994, 2002), it may well be that the
extension of quantum theory to general relativity requires one to
quantize, in some sense, not only the metric but also the underlying
differential structure and topology. This is somewhat unnatural from
the standpoint where one begins with classical, canonical general
relativity and proceeds to “quantize” (since the
topological structure, unlike the metric structure, is not represented
by a classical variable). But one might well think that one should
start with the more fundamental, quantum theory, and then investigate
under which circumstances one gets something that looks like a
classical spacetime.
One final issue we might mention here is whether there is a conflict
between the superposition principle and general relativity. Curiel
claims that “[t]here exists no physical phenomenon well
characterized by experiment that cannot be accurately described by one
of the two theories, and no physical phenomenon that suggests that one
of the two is correct to the detriment of the other’s
accuracy” (2001, p. S432). However, Roger Penrose (2004, Chapter
30) has forcefully argued that the superposition principle can, in
some circumstances, threaten the principle of general covariance,
surely a core principle of general relativity! The idea is that if we
prepare a lump of matter in a superposition of two position states
(stationary in their ambient spacetime), χ and φ, a state
Penrose labels a “Schrödinger’s Lump” state,
then the superposition is represented by: |Ψ⟩ =
w|χ⟩ + z|φ⟩. Penrose then shows that a
stationary gravitational field does nothing to affect the fact that
any superposition of the (stationary) position states χ and φ
will also be stationary. But then introducing the gravitational field
of the lump itself raises a problem. By themselves, the components of
the superposition would not seem to raise problems, and we can simply
think of the field around the location associated with the
lump’s states individually as being nearly classical. Given the
stationarity of the states χ and φ, there will be a distinct
Killing vector (i.e. a metric preserving vector field) associated with
each them. The problem then arises: what of superpositions of these
lump states? Are they stationary? Since the Killing vector fields of
the two component stationary states live on different spacetimes, with
different structures, it seems we don’t have the invariant
spatiotemporal structure needed to answer the question. To try and say
that the spacetime is really the same (the obvious answer) would
conflict with general covariance since then one would be supposing a
robust notion of spacetime points which enables one to match up the
two spacetimes. As we have seen above, Penrose’s proposed
solution is to consider such superpositions as generating a kind of
geometric instability which causes the collapse of the
superposition.
Of course, one might question various moves in Penrose’s
reasoning here (especially as regards the nature of the gravitational
fields of stationary quantum states), so there is clearly more to be
said. But there is potentially a conflict (and a measurable one at
that: see Penrose, 2002) between the superposition principle and
principles of general relativity. Those with experience of the
standard quantum measurement problem will find much to interest them
in this problem.
It is almost Gospel that quantum gravity is what happens when you
reach the Planck scale. The standard refrain is that ‘something
peculiar’ happens to our concepts of space, time, and causality
at such such scales requiring radical revisions that must be described
by the quantum theory of gravity (see, e.g., Rovelli, 2007, p. 1287).
However, the arguments underlying this orthodoxy have not been
rigorously examined. The usual motivation involves a dimensional
analysis argument. The scales at which theories make their mark are
set by the values of the fundamental constants. In this way the
constants demarcate the domains of applicability of theories: c
tells us when specially relativistic effects will become apparent,
ℏ tells us when quantum effects will become apparent, and G
tells us when gravitational effects will become apparent. As Planck
was able to demonstrate in 1899, these constants can be combined so as
to uniquely determine a natural, absolute family of units that are
independent of all human and terrestrial baggage. The Planck length
can be written as
(Gℏ/c3)½ and has the
value 10−33 in centimeters. Planck was not aware of
the relevance of the scale set by the constants to the applicability
of general relativity, of course, but Arthur Eddington seems to have
been aware (though getting a different value as a result of using
Osborn Reynold’s determination for the finest grain believed
possible), writing in the March edition of Nature in 1918:
The idea that the Planck length amounts to a minimal length in
nature follows from the argument that if distances smaller than this
length are resolved (say in the measurement of the position of a
mass), then it would require energies concentrated in a region so
small that a mini-black hole would form, taking the observed system
with it – see Rovelli (2007, p. 1289) for this argument.
Meschini (2007) is not convinced by such arguments, and doesn’t
see that the case for the relevance of the Planck scale to quantum
gravity research has been properly made. He is suspicious of the
claims made on behalf of dimensional analysis. There is something to
Meschini’s claims, for if the dimensional argument were true
then, without realising it, Planck would have stumbled upon the
beginnings of quantum gravity before either quantum field theory or
general relativity were devised! However, Meschini speculates that the
final theory of quantum gravity “has nothing to do with one or
more of the above-mentioned constants” (p. 278). This seems too
strong a statement, since a core condition on a theory of quantum
gravity will be to reduce to general relativity and quantum field
theory as we know it, according to limits involving these constants.
Nonetheless, Meschini is surely right that the details of these
dimensional arguments, and the role of the Planck scale are calling
out for a closer analysis.
In non-generally relativistic theories the spacetime metric is frozen
to a single value assignment for all times and all solutions: it is
model independent. Of course, in general relativity the metric is what
one solves for: the metric is a dynamical variable, which implies that
the geometry of spacetime is dynamical. This intuitive notion is
bundled into the concept of background freedom, or background
independence. In general, background independence is understood to be
the freedom of a theory from background structures, where the latter
amount to some kind of absolute, non-dynamical objects in a theory.
The extent to which their respective theories incorporate background
structures has recently proven to be a divisive subject amongst string
theorists and loop quantum gravity theorists and others. It is often
claimed that the central principle that distinguishes general
relativity from other theories is its (manifest) background
independence. But background independence is a slippery notion meaning
different things to different people. We face a series of questions
when considering background independence: What, exactly, is it (beyond
the simple intuitive notion)? Why is it considered to be such an
important principle? What theories incorporate it? To what
extent do they incorporate it?
The debate between strings and loops on this matter is severely
hampered by the fact that there is no firm definition of background
independence on the table and, therefore, the two camps are almost
certainly talking past each other when discussing this issue. It seems
prima facie reasonable to think that in order to reproduce a
manifestly background independent theory like general relativity, a
quantum theory of gravity should be background independent too, and so
background independence has begun to function as a constraint on
quantum gravity theories, in much the same way that renormalizability
used to constrain the construction of quantum field theories.
Advocates of loop quantum gravity often highlight the background
independence of their theory as a virtue that it has over string
theory. However, there is no proof of this implication, and aspects of
the so-called ‘holographic principle’ seem to suggest that
a background independent theory could be dual to a background
dependent theory (see the contributions to Biquard, ed., 2005).
Furthermore, depending on how we define the intuitive notion of
background independence, and if ‘clues’ from the duality
symmetries of M-theory are anything to go by, it looks like string
theory might even be more background independent than loop
quantum gravity, for the dimensionality of spacetime becomes a
dynamical variable too (cf. Stelle, 2000, p. 7).
Indeed, various string theorists claim that their theory is background
independent. In many cases it seems that they have a different
understanding of what this entails than loop quantum gravity
researchers—this takes us to the first, definitional, question.
In particular some seem to think that the ability to place a general
metric in the Lagrangian amounts to background independence. This
falls short of the mark for how the majority of physicists understand
it, namely as a reactive dynamical coupling between spacetime and
matter. Though one can indeed place a variety of metrics in the
stringy Lagrangian, one does not then vary the metric in the action.
There is no interaction between the strings and the ambient spacetime.
Indeed, this is not really distinct from quantum field theory of point
particles in curved spacetimes: the same freedom to insert a general
metric appears there too.
There is an alternative argument for the background independence of
string theory that comes from the field theoretic formulation of the
theory: string field theory. The idea is that classical spacetime
emerges from the two dimensional conformal field theory on the strings
worldsheet. However, in this case one surely has to say something
about the target space, for the worldsheet metric takes on a metric
induced from the ambient target spacetime. Yet another argument for
the background independence of string theory might point to the fact
that the dimensionality of spacetime in string theory has to satisfy
an equation of motion (a consistency condition): this is how the
dimensionality comes out (as 26 or 10, depending on whether one
imposes supersymmetry). One contender for the definition of background
independence is a structure that is dynamical in the sense that one
has to solve equations of motion to get at its values. In this case we
would have extreme background independence stretching to the structure
of the manifold itself. However, the problem with this is that this
structure is the same in all models of the theory; yet we intuitively
expect background independent theories to be about structures that can
vary across a theory’s models.
The issues here are clearly subtle and complex, and philosophers have
only just begun to consider them. The central problem faced, as a
philosopher, when trying to make sense of claims such as these is that
there is no solid, unproblematic definition of background structure
(and therefore background independence and dependence) on the table.
Without this, one simply cannot decide who is right; one cannot decide
which theories are background independent and which are not. Hence, an
urgent issue in both physics and the philosophy of physics is to work
out exactly what is meant by ‘background independence’ in
a way that satisfies all parties, that is formally correct, and that
satisfies our intuitive notions of the concept. Until this is
achieved, background independence cannot be helpfully used to
distinguish the approaches, nor can we profitably discuss its merits.
A serious attempt to define background independence in such a way as
to make these tasks possible has been made by Domenico Giulini (2007).
But Giulini admits that a general definition still eludes us. The
stumbling block might be that background independence simply
isn’t a formal property of theories at all. Gordon Belot (2011b)
has recently argued that background independence is partly an
interpretive matter, and that one can have varying levels of
background independence (the latter notion is also defended by Lee
Smolin, 2006). Rickles (2008b) argues that the place to seek a notion
of background independence that can be put to use in the quantum
gravitational context is by focusing on the kinds of
observables that an approach employs, rather than squarely on
properties of the equations of motion.
In earlier research on quantum gravity it was often supposed that if
there was at least one quantum field in the world together with the
gravitational field, then given the universal coupling of the
gravitational field, it must follow that the quantization of the one
field somehow infects the gravitational field, implying that it must
necessarily have quantum properties too. The arguments basically
involve the consideration of a mass prepared in a superposition of
position eigenstates. If the gravitational field remained classical
(and, therefore, not constrained by the uncertainty relations) then
one could violate the uncertainty relations by simply making
measurements of the gravitational field, discovering the properties of
the quantized matter to which it was coupled. However, all attempts at
making this argument stick have so far failed, meaning that there is
no logical necessity demanding that we quantize the gravitational
field. Given that we also seemingly lack experimental reasons for
quantization of the gravitational field (since we have not observed
evidence of its quantum properties), several physicists (and
philosophers) have questioned the programme as it stands. It is, they
argue, a matter for experiment to decide, not logic. Note, however,
that this does not mean that the project of quantum gravity itself
rests on unsteady ground: if there are quantum fields and
gravitational fields in the world, then given the nature of gravity,
we need to say something about the manner in which they
interact. What is being questioned is whether this means that gravity
cannot itself remain fundamentally classical while interacting with
quantum fields. After all, as far as all our experiments show: gravity
is classical and matter is quantum. This pessimistic argument is
usually traced back to Rosenfeld, though he wavered somewhat on the
matter (see DeWitt and Rickles, 2011, p. 164 and p. 170, for
Rosenfeld’s original arguments).
If it is to remain fundamentally classical, then there is the simple
question of what such a classical gravitational field would couple to:
the quantum properties? That seems problematic for the reasons given
above. Moreover, given the form of the Einstein field equations, with
a classical c-number on the left hand side, that would mean equating a
c-number with a q-number (i.e. a quantum operator). The standard way
out of this problem is to couple the gravitational field instead to
the expectation value of the stress-energy tensor of some quantized
matter field. The expectation value is a c-number. There have been a
variety of arguments and no-go theorems against this so-called
semi-classical gravitational theory, most of which replay the kind of
argument invoking violations of the uncertainty relations sketched
above (see Eppley and Hannah 1977, and Page and Geilker 1981).
Basically, the upshot of the Eppley and Hannah paper is that, given
the coexistence of classical gravity and quantum fields, two things
can happen upon a gravitational field measurement: on the one hand the
quantum wavefunction could collapse, in which case there momentum
non-conservation. On the other hand, the measurement could leave the
quantum wavefunction in a coherent state, in which case signals can be
sent faster than light. Mattingly (2006) argues that, when properly
analyzed, the thought experiments employed by Eppley and Hannah
violate basic physical principles involving the construction of the
equipment that would be needed to make the necessary field
measurements — however, while not viewing the original
semi-classical approach as a viable option, Mattingly argues that an
extension of the approach has the potential to reveal a viable theory
of micro-gravity (see Mattingly 2010 and 2014). Adrian Kent has
recently argued that general hybrid classical/quantum theories
(including those involving gravity) need not allow superluminal
signalling or violate relativity (Kent 2018).
A batch of new approaches based on analogies with condensed matter
physics and hydrodynamics point to another way in which gravity can
escape quantization, though not in a truly fundamental sense.
According to such approaches, gravity is emergent in the sense that
the metric (or connection) variables, and other variables representing
gravitational features, are collective variables that only appear at
energies away from the Planck scale. In other words, gravity is a
purely macroscopic, low energy phenomenon and general relativity is an
effective field theory. This leaves the task of actually filling in
the details of the microscopic structure of spacetime (the
‘atoms of spacetime’) out of which the low energy
collective variables emerge (see Hu, 2009, for a conceptually oriented
review of such approaches; Crowther 2014 provides a detailed
philosophical analysis). As Rovelli notes (2007, p. 1304), the mere
fact that the gravitational field is an emergent, collective variable
does not thereby imply an absence of quantum effects, and it is
possible that collective variables too are governed by quantum
theory.
Wüthrich (2005, pp. 779–80) has argued that the very
existence of approaches to quantum gravity that do not involve the
quantization of the gravitational field means that quantization of the
gravitational field has to be a contingent matter. However,
this seems to rest on a mistake. It might still be the case that there
are reasons of logical consistency forbidding the union of a classical
and quantum field even though there are entirely distinct
non-quantization approaches. For example, string theory does not
quantize the gravitational field; however, it is clearly wrong to say
that the existence of this position would be ruled out if the various
no-go theorems outlawing hybrid classical-quantum theories were true.
The fact that one can isolate states corresponding to gravitons in the
string spectrum stands quite independent from issues over the
interaction of classical and quantum field. The question of the
necessity of quantization (as a result of coupling a classical
gravitational field to quantum fields) should be held separate from
the prospect of producing a quantum theory of gravity that does not
involve gravitational field quantization, for both input theories, for
describing the classical and quantum fields, could be fundamentally
wrong at high energies, requiring entirely new principles. However, a
stronger argument against the impossibility hybrids is provided by
James Mattingly, who points out that since there are satisfiable
axioms for semiclassical theories, inconsistency cannot be established
in general (2009, p. 381).
Research on quantum gravity is beset by a combination of formal,
experimental, and conceptual difficulties. It is inevitable that the
quest for a quantum theory of gravity will continue – whether
for reasons of necessity or not – and it seems that the
resolution of the problem will require an equivalent combination of
formal, experimental, and conceptual expertise. Given this, and given
the central position quantum gravity research occupies in theoretical
physics, it makes good sense for philosophers of physics (and general
philosophers of science) to do their best to acquaint themselves with
the central details of the problem of quantum gravity and the main
approaches that are seeking to crack the problem. Beyond this, quantum
gravity research has the potential to invigorate several standard
areas of philosophical inquiry, including our standard notions of
theory construction, selection and justification; the nature of space,
time, matter, and causality, and it also introduces a new case study
in emergence, with entirely novel features.